/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/docker/deepcam_optimized-21.09_2.sif
configs/best_configs/config_DGXA100_512GPU_BS1024_graph.sh
#!/bin/bash

# hyperparameters
export LOCAL_BATCH_SIZE=2
export START_LR=0.004
export OPTIMIZER="LAMB"
export LR_SCHEDULE_TYPE="multistep"
export LR_MILESTONES="1100 4096"
export LR_DECAY_RATE="0.1"
export LR_WARMUP_STEPS=200
export LR_WARMUP_FACTOR=1.
export WEIGHT_DECAY=0.01
export BATCHNORM_GROUP_SIZE=1

# data parameters
export SHUFFLE_MODE="global"
export DATA_FORMAT="dali-es/hdf5"
export PRECISION_MODE="amp"
export LOCAL_VALIDATION_BATCH_SIZE=8

# output parameters
#export OUTPUT_ROOT=/results/best

export TRAINING_INSTANCE_SIZE=$((128*4))

# auxiliary parameters
export LOGGING_FREQUENCY=10

# misc args
export ADDITIONAL_ARGS="--enable_jit --enable_graph"
#--disable_comm_overlap
# system parameters
#export DGXNGPU=8
#export DGXNNODES=64
#export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
#export WALLTIME=00:30:00
export DGXNGPU=4
export DGXNNODES=128
export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
export WALLTIME=01:00:00
454: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
209: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
455: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
424: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
438: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  0: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
417: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
511: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
210: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
507: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  4: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
416: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
413: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
442: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
232: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
267: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
508: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
216: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
391: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  3: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
294: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
429: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
452: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
437: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  7: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
230: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
392: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: Running Multi Instance Training
454: Running Multi Instance Training
455: Running Multi Instance Training
454: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
455: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
452: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
494: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
252: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: Running Multi Instance Training
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: Running Multi Instance Training
416: Running Multi Instance Training
209: Running Multi Instance Training
232: Running Multi Instance Training
417: Running Multi Instance Training
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: Running Multi Instance Training
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: Running Multi Instance Training
429: Running Multi Instance Training
443: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
431: Running Multi Instance Training
443: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
507: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
417: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
490: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
442: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
209: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
424: Running Multi Instance Training
426: Running Multi Instance Training
429: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
446: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
216: Running Multi Instance Training
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
426: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
267: Running Multi Instance Training
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
230: Running Multi Instance Training
208: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
386: Running Multi Instance Training
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
413: Running Multi Instance Training
340: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: Running Multi Instance Training
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: Running Multi Instance Training
  7: Running Multi Instance Training
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: Running Multi Instance Training
391: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
494: Running Multi Instance Training
511: Running Multi Instance Training
  4: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  7: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
494: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
437: Running Multi Instance Training
438: Running Multi Instance Training
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: Using bindings from SLURM: mask_cpu:
392: Running Multi Instance Training
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
438: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: Running Multi Instance Training
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: Running Multi Instance Training
392: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
292: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
252: Running Multi Instance Training
  0: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
252: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: Running Multi Instance Training
234: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
443: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: Running Multi Instance Training
208: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
449: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
121: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
490: Running Multi Instance Training
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: Running Multi Instance Training
490: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
446: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: Running Multi Instance Training
505: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
292: Running Multi Instance Training
340: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
292: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: Running Multi Instance Training
234: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
270: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: Running Multi Instance Training
329: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
385: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: Running Multi Instance Training
449: Running Multi Instance Training
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
121: Running Multi Instance Training
449: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
121: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  1: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
150: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
270: Running Multi Instance Training
270: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: Running Multi Instance Training
329: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: Running Multi Instance Training
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  1: Running Multi Instance Training
  1: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
388: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
217: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
125: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 41: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
344: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
255: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
264: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: Running Multi Instance Training
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: Running Multi Instance Training
320: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
150: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: Running Multi Instance Training
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: Running Multi Instance Training
388: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
217: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
425: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
400: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: Running Multi Instance Training
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: Running Multi Instance Training
255: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
264: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
491: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: Running Multi Instance Training
 41: Running Multi Instance Training
125: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
344: Running Multi Instance Training
344: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: Running Multi Instance Training
419: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
425: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 71: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
430: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: Running Multi Instance Training
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: Running Multi Instance Training
349: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
120: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
120: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
491: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: Running Multi Instance Training
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
419: Running Multi Instance Training
510: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
439: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
510: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 20: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: Running Multi Instance Training
430: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: Running Multi Instance Training
395: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 71: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: Running Multi Instance Training
120: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
486: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: Running Multi Instance Training
349: Running Multi Instance Training
439: Running Multi Instance Training
510: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
349: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
439: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
420: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: Running Multi Instance Training
495: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 20: Running Multi Instance Training
 20: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
464: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
328: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
246: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: Running Multi Instance Training
486: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: Running Multi Instance Training
495: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: Running Multi Instance Training
353: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: Running Multi Instance Training
328: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
219: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: Running Multi Instance Training
464: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
341: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: Running Multi Instance Training
246: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: Running Multi Instance Training
  5: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
219: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: Running Multi Instance Training
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
341: Running Multi Instance Training
341: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
151: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
441: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
448: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
362: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: Running Multi Instance Training
402: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  5: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
506: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: Running Multi Instance Training
151: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: Running Multi Instance Training
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: Running Multi Instance Training
441: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 23: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
445: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
448: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: Running Multi Instance Training
402: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: Running Multi Instance Training
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
506: Running Multi Instance Training
485: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
485: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
389: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 23: Running Multi Instance Training
445: Running Multi Instance Training
 23: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
474: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
445: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
347: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
321: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: Running Multi Instance Training
115: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
485: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
247: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: Running Multi Instance Training
 13: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
383: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
389: Running Multi Instance Training
389: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 40: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
293: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: Running Multi Instance Training
347: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: Running Multi Instance Training
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
321: Running Multi Instance Training
321: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: Running Multi Instance Training
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: Running Multi Instance Training
247: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 13: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
233: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
266: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
115: Running Multi Instance Training
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: Running Multi Instance Training
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
423: Running Multi Instance Training
 40: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: Running Multi Instance Training
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
383: Running Multi Instance Training
293: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
383: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
229: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
229: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
343: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: Running Multi Instance Training
384: Running Multi Instance Training
266: Running Multi Instance Training
233: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
195: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
266: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
124: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: Running Multi Instance Training
 69: Running Multi Instance Training
229: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: Running Multi Instance Training
343: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
253: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
451: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
351: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: Running Multi Instance Training
124: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: Running Multi Instance Training
195: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
224: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: Running Multi Instance Training
253: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: Running Multi Instance Training
393: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
376: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: Running Multi Instance Training
351: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
268: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: Running Multi Instance Training
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: Running Multi Instance Training
444: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: Running Multi Instance Training
393: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
224: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
493: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: Running Multi Instance Training
488: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
268: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: Running Multi Instance Training
376: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
382: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
101: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: Running Multi Instance Training
493: Running Multi Instance Training
488: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
493: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 42: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: Running Multi Instance Training
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
330: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: Running Multi Instance Training
330: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: Running Multi Instance Training
122: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 90: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
354: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: Running Multi Instance Training
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: Running Multi Instance Training
101: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 42: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: Running Multi Instance Training
410: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
330: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
231: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: Running Multi Instance Training
122: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: Running Multi Instance Training
149: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
354: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
113: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
303: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: Running Multi Instance Training
481: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
361: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: Running Multi Instance Training
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: Running Multi Instance Training
410: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
149: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: Running Multi Instance Training
113: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: Running Multi Instance Training
361: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
401: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
303: Running Multi Instance Training
303: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
378: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
481: Running Multi Instance Training
481: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
322: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: Running Multi Instance Training
287: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: Running Multi Instance Training
 65: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
401: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: Running Multi Instance Training
269: Running Multi Instance Training
378: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
269: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: Running Multi Instance Training
322: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
465: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: Running Multi Instance Training
421: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 65: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: Running Multi Instance Training
 70: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
465: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 22: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
128: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: Running Multi Instance Training
421: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: Running Multi Instance Training
 70: Running Multi Instance Training
487: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
487: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
350: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
302: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 15: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: Running Multi Instance Training
245: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
128: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: Running Multi Instance Training
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
350: Running Multi Instance Training
487: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
350: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: Running Multi Instance Training
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 15: Running Multi Instance Training
302: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 15: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: Running Multi Instance Training
245: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 88: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
377: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: Running Multi Instance Training
500: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
475: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
100: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: Running Multi Instance Training
 88: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: Running Multi Instance Training
377: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: Running Multi Instance Training
100: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
308: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: Running Multi Instance Training
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
500: Running Multi Instance Training
500: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
225: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
355: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
466: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: Running Multi Instance Training
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
355: Running Multi Instance Training
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: Running Multi Instance Training
409: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 27: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
355: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
308: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
480: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
192: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: Running Multi Instance Training
 64: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: Running Multi Instance Training
466: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
363: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
363: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: Running Multi Instance Training
409: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 16: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: Running Multi Instance Training
 50: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
167: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
480: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: Running Multi Instance Training
380: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: Running Multi Instance Training
380: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 27: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
192: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
363: Running Multi Instance Training
363: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
397: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
286: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: Running Multi Instance Training
356: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 16: Running Multi Instance Training
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: Running Multi Instance Training
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
167: Running Multi Instance Training
273: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 50: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
167: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: Running Multi Instance Training
110: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
473: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
503: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: Running Multi Instance Training
286: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
250: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: Running Multi Instance Training
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: Running Multi Instance Training
397: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
356: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: Running Multi Instance Training
503: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: Running Multi Instance Training
273: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
453: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
114: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
110: Running Multi Instance Training
110: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
236: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
497: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
132: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: Running Multi Instance Training
250: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: Running Multi Instance Training
453: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: Running Multi Instance Training
114: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 83: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: Running Multi Instance Training
497: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 24: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: Running Multi Instance Training
129: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
236: Running Multi Instance Training
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: Running Multi Instance Training
236: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
132: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 63: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
297: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: Running Multi Instance Training
 24: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 83: Running Multi Instance Training
 83: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: Running Multi Instance Training
194: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
126: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
307: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
332: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: Running Multi Instance Training
194: Running Multi Instance Training
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: Running Multi Instance Training
482: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 63: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: Running Multi Instance Training
297: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
418: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: Running Multi Instance Training
 45: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
103: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
307: Running Multi Instance Training
307: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
310: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: Running Multi Instance Training
482: Running Multi Instance Training
332: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
482: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: Running Multi Instance Training
418: Running Multi Instance Training
357: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 91: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
418: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
415: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
274: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: Running Multi Instance Training
262: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
103: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: Running Multi Instance Training
310: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
211: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
211: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: Running Multi Instance Training
357: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
295: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
415: Running Multi Instance Training
301: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
415: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: Running Multi Instance Training
274: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
408: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 19: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
211: Running Multi Instance Training
211: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: Running Multi Instance Training
295: Running Multi Instance Training
262: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
295: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: Running Multi Instance Training
476: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
301: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
399: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
408: Running Multi Instance Training
 51: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 28: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
408: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: Running Multi Instance Training
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: Running Multi Instance Training
204: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 19: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
428: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 82: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 61: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 61: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: Running Multi Instance Training
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: Running Multi Instance Training
399: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 51: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
306: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: Running Multi Instance Training
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
285: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: Running Multi Instance Training
285: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: Running Multi Instance Training
226: Running Multi Instance Training
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 28: Running Multi Instance Training
428: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
290: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: Running Multi Instance Training
109: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 82: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: Running Multi Instance Training
504: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 61: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
164: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
164: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: Running Multi Instance Training
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
317: Running Multi Instance Training
317: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
285: Running Multi Instance Training
285: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
326: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: Running Multi Instance Training
109: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: Running Multi Instance Training
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: Running Multi Instance Training
134: Running Multi Instance Training
504: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
164: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
134: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
276: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 66: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: Running Multi Instance Training
  6: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
249: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: Running Multi Instance Training
440: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
237: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: Running Multi Instance Training
290: Running Multi Instance Training
406: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 66: Running Multi Instance Training
290: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 76: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 66: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
509: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: Running Multi Instance Training
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: Running Multi Instance Training
  6: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: Running Multi Instance Training
276: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: Running Multi Instance Training
237: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
131: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
218: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 39: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
221: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: Running Multi Instance Training
498: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
509: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: Running Multi Instance Training
 76: Running Multi Instance Training
406: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
131: Running Multi Instance Training
131: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: Running Multi Instance Training
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: Running Multi Instance Training
370: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
218: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
242: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: Running Multi Instance Training
390: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
501: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
498: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
265: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 49: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: Running Multi Instance Training
387: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 39: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
221: Running Multi Instance Training
221: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
235: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
309: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: Running Multi Instance Training
228: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
501: Running Multi Instance Training
288: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: Running Multi Instance Training
390: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
501: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: Running Multi Instance Training
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: Running Multi Instance Training
387: Running Multi Instance Training
 49: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
387: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
479: Running Multi Instance Training
479: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: Running Multi Instance Training
165: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
309: Running Multi Instance Training
309: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
298: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
111: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
318: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  2: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: Running Multi Instance Training
288: Running Multi Instance Training
228: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
288: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
153: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 93: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: Running Multi Instance Training
 25: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
165: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: Running Multi Instance Training
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: Running Multi Instance Training
111: Running Multi Instance Training
  2: Running Multi Instance Training
279: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
279: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
111: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
318: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  2: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
254: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: Running Multi Instance Training
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: Running Multi Instance Training
153: Running Multi Instance Training
 25: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 93: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
191: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
153: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: Running Multi Instance Training
279: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
407: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
203: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: Running Multi Instance Training
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: Running Multi Instance Training
238: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
254: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 57: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
364: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: Running Multi Instance Training
407: Running Multi Instance Training
394: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
358: Running Multi Instance Training
191: Running Multi Instance Training
 30: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 46: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 46: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
272: Running Multi Instance Training
272: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: Running Multi Instance Training
203: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: Running Multi Instance Training
251: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
251: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
364: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: Running Multi Instance Training
 30: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 46: Running Multi Instance Training
 57: Running Multi Instance Training
 46: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 57: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
489: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
207: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: Running Multi Instance Training
145: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
447: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
335: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: Running Multi Instance Training
489: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
258: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
222: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 80: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: Running Multi Instance Training
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
207: Running Multi Instance Training
325: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
207: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: Running Multi Instance Training
492: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 17: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 60: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
450: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: Running Multi Instance Training
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: Running Multi Instance Training
447: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
335: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: Running Multi Instance Training
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
222: Running Multi Instance Training
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: Running Multi Instance Training
222: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: Running Multi Instance Training
260: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
342: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
369: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
369: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: Running Multi Instance Training
492: Running Multi Instance Training
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: Running Multi Instance Training
258: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
492: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
187: Running Multi Instance Training
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 94: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
450: Running Multi Instance Training
187: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
450: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
148: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 77: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
133: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
314: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: Running Multi Instance Training
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
369: Running Multi Instance Training
405: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
405: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
369: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
403: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: Running Multi Instance Training
 94: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
304: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: Running Multi Instance Training
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: Running Multi Instance Training
 77: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
148: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
123: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
133: Running Multi Instance Training
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
201: Running Multi Instance Training
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: Running Multi Instance Training
201: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
403: Running Multi Instance Training
405: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 37: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
396: Running Multi Instance Training
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: Running Multi Instance Training
173: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
314: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: Running Multi Instance Training
331: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
137: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
123: Running Multi Instance Training
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
240: Running Multi Instance Training
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: Running Multi Instance Training
240: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
435: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: Running Multi Instance Training
 37: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
422: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: Running Multi Instance Training
331: Running Multi Instance Training
162: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
173: Running Multi Instance Training
173: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: Running Multi Instance Training
137: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
323: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
283: Running Multi Instance Training
 12: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
283: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: Running Multi Instance Training
152: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
477: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
477: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
333: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
271: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: Running Multi Instance Training
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: Running Multi Instance Training
323: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 12: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
296: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
296: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
319: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: Running Multi Instance Training
477: Running Multi Instance Training
152: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: Running Multi Instance Training
333: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
263: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
158: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: Running Multi Instance Training
169: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
169: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
271: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: Running Multi Instance Training
 56: Running Multi Instance Training
296: Running Multi Instance Training
319: Running Multi Instance Training
345: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 56: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
296: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
319: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 43: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: Running Multi Instance Training
206: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
206: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: Running Multi Instance Training
190: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
141: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
291: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
146: Running Multi Instance Training
158: Running Multi Instance Training
 44: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
158: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: Running Multi Instance Training
169: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: Running Multi Instance Training
 31: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 43: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: Running Multi Instance Training
206: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 21: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: Running Multi Instance Training
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: Running Multi Instance Training
291: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
365: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: Running Multi Instance Training
 44: Running Multi Instance Training
141: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 31: Running Multi Instance Training
 52: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 31: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 68: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
278: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: Running Multi Instance Training
136: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
136: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
174: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
352: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: Running Multi Instance Training
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
278: Running Multi Instance Training
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: Running Multi Instance Training
278: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
136: Running Multi Instance Training
136: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: Running Multi Instance Training
360: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
174: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: Running Multi Instance Training
368: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: Running Multi Instance Training
352: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
381: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
184: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
336: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
467: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 79: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
324: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
348: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: Running Multi Instance Training
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: Running Multi Instance Training
360: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
368: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: Running Multi Instance Training
184: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
484: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
467: Running Multi Instance Training
 79: Running Multi Instance Training
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
324: Running Multi Instance Training
 79: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
313: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
324: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: Running Multi Instance Training
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
336: Running Multi Instance Training
336: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 73: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
241: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
484: Running Multi Instance Training
484: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: Running Multi Instance Training
379: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  8: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 38: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
313: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: Running Multi Instance Training
 92: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 35: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: Running Multi Instance Training
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
241: Running Multi Instance Training
241: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
373: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: Running Multi Instance Training
379: Running Multi Instance Training
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: Running Multi Instance Training
379: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
433: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
223: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
223: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: Running Multi Instance Training
 92: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: Running Multi Instance Training
  8: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 54: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: Running Multi Instance Training
433: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
223: Running Multi Instance Training
373: Running Multi Instance Training
112: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
223: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
373: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: Running Multi Instance Training
 54: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
202: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: Running Multi Instance Training
155: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
171: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: Running Multi Instance Training
112: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
282: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
188: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: Running Multi Instance Training
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: Running Multi Instance Training
202: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
458: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
456: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
472: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: Running Multi Instance Training
171: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
193: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: Running Multi Instance Training
411: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
282: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: Running Multi Instance Training
188: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: Running Multi Instance Training
456: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
142: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 72: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
256: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
193: Running Multi Instance Training
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
472: Running Multi Instance Training
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: Running Multi Instance Training
472: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 58: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
411: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
161: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: Running Multi Instance Training
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: Running Multi Instance Training
 89: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
142: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
130: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 72: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
256: Running Multi Instance Training
256: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
105: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: Running Multi Instance Training
 58: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
375: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: Running Multi Instance Training
213: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
337: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
337: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: Running Multi Instance Training
130: Running Multi Instance Training
 89: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
130: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
179: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: Running Multi Instance Training
139: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
139: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: Running Multi Instance Training
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: Running Multi Instance Training
105: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: Running Multi Instance Training
375: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
502: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
337: Running Multi Instance Training
102: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
337: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
172: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
144: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
213: Running Multi Instance Training
213: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 32: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: Running Multi Instance Training
185: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
185: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: Running Multi Instance Training
179: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: Running Multi Instance Training
281: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
127: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
227: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
102: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: Running Multi Instance Training
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
144: Running Multi Instance Training
144: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
284: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: Running Multi Instance Training
 32: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
300: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 53: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: Running Multi Instance Training
185: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
459: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: Running Multi Instance Training
127: Running Multi Instance Training
227: Running Multi Instance Training
281: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
127: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
227: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
156: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
315: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: Running Multi Instance Training
284: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: Running Multi Instance Training
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: Running Multi Instance Training
300: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 53: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: Running Multi Instance Training
460: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
460: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
459: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
470: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
483: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: Running Multi Instance Training
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: Running Multi Instance Training
156: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
315: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
259: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 84: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
119: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: Running Multi Instance Training
163: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
483: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: Running Multi Instance Training
432: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
259: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: Running Multi Instance Training
 84: Running Multi Instance Training
470: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 84: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: Running Multi Instance Training
163: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: Running Multi Instance Training
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: Running Multi Instance Training
 67: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
119: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 96: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
432: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: Running Multi Instance Training
170: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 67: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: Running Multi Instance Training
 96: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: Running Multi Instance Training
170: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
140: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
157: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
499: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: Running Multi Instance Training
177: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
140: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
311: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 11: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: Running Multi Instance Training
157: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: Running Multi Instance Training
499: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
212: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: Running Multi Instance Training
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
311: Running Multi Instance Training
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: Running Multi Instance Training
311: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
275: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
181: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
359: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: Running Multi Instance Training
 26: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
212: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: Running Multi Instance Training
166: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 18: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: Running Multi Instance Training
275: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: Running Multi Instance Training
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 26: Running Multi Instance Training
 26: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: Running Multi Instance Training
181: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 74: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
339: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: Running Multi Instance Training
 18: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 33: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: Running Multi Instance Training
339: Running Multi Instance Training
 74: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
339: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
374: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: Running Multi Instance Training
 33: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: Running Multi Instance Training
374: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
135: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
108: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 10: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 81: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
366: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
366: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
248: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: Running Multi Instance Training
108: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: Running Multi Instance Training
135: Running Multi Instance Training
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 81: Running Multi Instance Training
182: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
135: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
366: Running Multi Instance Training
215: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
215: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
366: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
305: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: Running Multi Instance Training
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
248: Running Multi Instance Training
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
118: Running Multi Instance Training
118: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: Running Multi Instance Training
182: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
215: Running Multi Instance Training
215: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: Running Multi Instance Training
305: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
277: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
239: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
261: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 62: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
334: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 86: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: Running Multi Instance Training
239: Running Multi Instance Training
277: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
239: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
469: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: Running Multi Instance Training
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: Running Multi Instance Training
261: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: Running Multi Instance Training
334: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: Running Multi Instance Training
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
460: Running Multi Instance Training
460: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 86: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: Running Multi Instance Training
 48: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
469: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
178: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
463: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
316: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: Running Multi Instance Training
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
178: Running Multi Instance Training
205: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
178: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 47: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: Running Multi Instance Training
316: Running Multi Instance Training
463: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
316: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
106: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: Running Multi Instance Training
205: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: Running Multi Instance Training
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: Running Multi Instance Training
 47: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
106: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
478: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 99: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
289: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: Running Multi Instance Training
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 99: Running Multi Instance Training
299: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 99: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: Running Multi Instance Training
 29: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
289: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: Running Multi Instance Training
398: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
398: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
471: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: Running Multi Instance Training
 29: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: Running Multi Instance Training
198: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
404: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: Running Multi Instance Training
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
471: Running Multi Instance Training
471: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
462: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
117: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: Running Multi Instance Training
198: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
371: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: Running Multi Instance Training
462: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: Running Multi Instance Training
 36: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
117: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: Running Multi Instance Training
371: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: Running Multi Instance Training
 36: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 97: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
220: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
457: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 95: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: Running Multi Instance Training
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
220: Running Multi Instance Training
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
457: Running Multi Instance Training
457: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: Running Multi Instance Training
 95: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
154: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
243: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: Running Multi Instance Training
154: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: Running Multi Instance Training
243: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: Running Multi Instance Training
180: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
200: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 78: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 78: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: Running Multi Instance Training
200: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 78: Running Multi Instance Training
 78: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
199: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 59: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
189: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: Running Multi Instance Training
199: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: Running Multi Instance Training
 59: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: Running Multi Instance Training
189: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
160: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
175: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
280: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 75: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: Running Multi Instance Training
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
175: Running Multi Instance Training
160: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
175: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
312: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
147: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: Running Multi Instance Training
280: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: Running Multi Instance Training
 75: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
312: Running Multi Instance Training
312: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
338: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 55: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: Running Multi Instance Training
147: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: Running Multi Instance Training
327: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
434: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: Running Multi Instance Training
338: Running Multi Instance Training
 55: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
338: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: Running Multi Instance Training
434: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
257: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
159: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
143: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: Running Multi Instance Training
257: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: Running Multi Instance Training
159: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: Running Multi Instance Training
186: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
143: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
138: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: Running Multi Instance Training
186: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: Running Multi Instance Training
138: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
196: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
196: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 34: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
196: Running Multi Instance Training
196: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: Running Multi Instance Training
 34: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
168: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: Running Multi Instance Training
168: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  9: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
372: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: Running Multi Instance Training
  9: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: Running Multi Instance Training
372: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 85: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: Running Multi Instance Training
 85: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
214: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: Running Multi Instance Training
214: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
104: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
176: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: Running Multi Instance Training
104: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: Running Multi Instance Training
176: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
116: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: Running Multi Instance Training
116: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
461: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: Running Multi Instance Training
461: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 98: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: Running Multi Instance Training
 98: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
468: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: Running Multi Instance Training
468: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
183: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: Running Multi Instance Training
183: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
197: STARTING TIMING RUN AT 2021-10-05 08:16:28 AM
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: Running Multi Instance Training
197: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483001 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483001 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 36: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 21: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
216: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 16: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 40: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 89: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 45: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
100: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
196: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 64: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 29: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 76: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 92: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 32: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
200: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
116: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 25: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
444: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
396: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
384: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
408: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 12: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 37: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
204: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
108: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
208: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
400: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  5: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
269: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
388: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
413: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
392: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
440: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 68: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 22: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
288: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
217: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
217: creating process group
300: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
277: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
264: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
360: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
120: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
192: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
220: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
304: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 17: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 17: creating process group
112: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
328: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
376: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 41: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
364: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
292: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 90: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
280: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
357: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
297: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
272: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
332: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
380: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: creating process group
213: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
213: creating process group
320: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 46: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
198: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 67: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
352: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
126: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 30: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 77: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
260: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
117: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
369: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 96: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
372: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
432: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  2: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
445: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
445: creating process group
398: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
385: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
385: creating process group
409: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
252: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 13: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 38: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 38: creating process group
205: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
109: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
209: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
401: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  6: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
270: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
389: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
256: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
404: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
393: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
441: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
441: creating process group
 69: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
248: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 23: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
308: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
219: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
301: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
301: creating process group
278: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
278: creating process group
267: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
362: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
121: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
312: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
240: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
193: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
221: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
317: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
244: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 18: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 18: creating process group
113: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
113: creating process group
329: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
377: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 42: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 42: creating process group
365: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
293: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 89: creating process group
281: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
284: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
299: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
299: creating process group
273: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
214: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
214: creating process group
 47: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
102: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
199: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 64: creating process group
127: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 31: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 79: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
263: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 35: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
105: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
202: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
118: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 97: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 26: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
433: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: creating process group
420: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
446: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
446: creating process group
399: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
386: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
386: creating process group
410: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
410: creating process group
253: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 14: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 39: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
206: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
110: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
110: creating process group
210: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: creating process group
403: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
403: creating process group
  7: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
271: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
390: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
390: creating process group
425: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: creating process group
257: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
257: creating process group
416: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
404: creating process group
428: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
394: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
442: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
442: creating process group
 71: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 71: creating process group
249: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 21: creating process group
309: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
309: creating process group
289: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
216: creating process group
302: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
302: creating process group
279: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: creating process group
264: creating process group
363: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
122: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
313: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
241: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
241: creating process group
194: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
222: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
305: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
318: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
245: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: creating process group
114: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
330: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
378: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 43: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 43: creating process group
366: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
366: creating process group
295: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 90: creating process group
282: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
358: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
358: creating process group
287: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
297: creating process group
274: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
274: creating process group
333: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
333: creating process group
381: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 81: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
215: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 46: creating process group
103: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
196: creating process group
 67: creating process group
353: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
353: creating process group
126: creating process group
 29: creating process group
 76: creating process group
263: creating process group
 94: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 94: creating process group
 32: creating process group
106: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 10: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 10: creating process group
203: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
116: creating process group
370: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
370: creating process group
 98: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 27: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
373: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 72: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
434: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
434: creating process group
 85: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  0: creating process group
421: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
447: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
447: creating process group
399: creating process group
387: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
387: creating process group
411: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
254: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
254: creating process group
 15: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 15: creating process group
 36: creating process group
207: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
229: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
111: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
111: creating process group
211: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: creating process group
439: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
400: creating process group
  5: creating process group
269: creating process group
388: creating process group
426: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
426: creating process group
413: creating process group
258: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: creating process group
232: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: creating process group
407: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
430: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
395: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
395: creating process group
224: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
443: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
443: creating process group
 68: creating process group
250: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 22: creating process group
310: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
310: creating process group
291: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
219: creating process group
336: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
303: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
303: creating process group
277: creating process group
267: creating process group
360: creating process group
123: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
348: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
314: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
242: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: creating process group
223: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
223: creating process group
306: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
340: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
319: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
319: creating process group
246: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
246: creating process group
 16: creating process group
115: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
115: creating process group
331: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
331: creating process group
379: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 40: creating process group
367: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
367: creating process group
294: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 88: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
283: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
283: creating process group
344: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
359: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
359: creating process group
284: creating process group
296: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
275: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
275: creating process group
335: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
335: creating process group
382: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: creating process group
 82: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
215: creating process group
237: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
322: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 47: creating process group
 56: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
100: creating process group
198: creating process group
 65: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 53: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
127: creating process group
 30: creating process group
 77: creating process group
260: creating process group
 95: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: creating process group
 35: creating process group
107: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 11: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 11: creating process group
200: creating process group
117: creating process group
369: creating process group
 99: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 48: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 48: creating process group
 25: creating process group
374: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 73: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
432: creating process group
 62: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 87: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: creating process group
422: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
422: creating process group
444: creating process group
396: creating process group
384: creating process group
408: creating process group
255: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
255: creating process group
 12: creating process group
 37: creating process group
204: creating process group
229: creating process group
108: creating process group
208: creating process group
439: creating process group
401: creating process group
  6: creating process group
270: creating process group
389: creating process group
427: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: creating process group
414: creating process group
259: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: creating process group
234: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
418: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
431: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
392: creating process group
225: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
440: creating process group
 69: creating process group
251: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
251: creating process group
 23: creating process group
311: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
311: creating process group
288: creating process group
218: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
337: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
325: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: creating process group
276: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
265: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
362: creating process group
120: creating process group
349: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
349: creating process group
315: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
315: creating process group
243: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
243: creating process group
192: creating process group
220: creating process group
307: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
307: creating process group
341: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
317: creating process group
247: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
247: creating process group
112: creating process group
328: creating process group
376: creating process group
 41: creating process group
364: creating process group
295: creating process group
 91: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
280: creating process group
345: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
357: creating process group
285: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
298: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
272: creating process group
332: creating process group
383: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
383: creating process group
 83: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
212: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
238: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
323: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
323: creating process group
 45: creating process group
 57: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 57: creating process group
101: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
199: creating process group
 66: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
355: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 54: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
124: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 31: creating process group
 79: creating process group
261: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 92: creating process group
 33: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
105: creating process group
  8: creating process group
203: creating process group
118: creating process group
371: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 96: creating process group
 49: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 49: creating process group
 26: creating process group
375: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: creating process group
 73: creating process group
433: creating process group
 62: creating process group
 87: creating process group
  2: creating process group
420: creating process group
398: creating process group
409: creating process group
252: creating process group
 13: creating process group
 39: creating process group
205: creating process group
228: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
109: creating process group
209: creating process group
438: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
402: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  7: creating process group
271: creating process group
391: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
425: creating process group
412: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
256: creating process group
232: creating process group
419: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
419: creating process group
406: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
428: creating process group
393: creating process group
226: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 70: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
248: creating process group
 20: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
308: creating process group
289: creating process group
218: creating process group
338: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
327: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
276: creating process group
266: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
363: creating process group
121: creating process group
350: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
350: creating process group
312: creating process group
240: creating process group
193: creating process group
221: creating process group
304: creating process group
342: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
318: creating process group
244: creating process group
114: creating process group
329: creating process group
377: creating process group
365: creating process group
292: creating process group
 88: creating process group
281: creating process group
344: creating process group
356: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
286: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
296: creating process group
273: creating process group
334: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
380: creating process group
 81: creating process group
212: creating process group
239: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
320: creating process group
 44: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 58: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
102: creating process group
197: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 65: creating process group
352: creating process group
 55: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
125: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 28: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 78: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
262: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: creating process group
 34: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
107: creating process group
  9: creating process group
202: creating process group
119: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
368: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: creating process group
 50: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 50: creating process group
 27: creating process group
372: creating process group
 72: creating process group
435: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 60: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 84: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: creating process group
397: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
411: creating process group
253: creating process group
 14: creating process group
206: creating process group
230: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
210: creating process group
438: creating process group
402: creating process group
  4: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
268: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
391: creating process group
424: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
412: creating process group
234: creating process group
416: creating process group
407: creating process group
430: creating process group
394: creating process group
227: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
227: creating process group
 70: creating process group
249: creating process group
 20: creating process group
291: creating process group
339: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
339: creating process group
324: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
265: creating process group
361: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
122: creating process group
351: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
351: creating process group
313: creating process group
242: creating process group
194: creating process group
222: creating process group
305: creating process group
343: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
316: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
245: creating process group
330: creating process group
378: creating process group
293: creating process group
 91: creating process group
282: creating process group
345: creating process group
356: creating process group
287: creating process group
298: creating process group
334: creating process group
381: creating process group
 82: creating process group
237: creating process group
321: creating process group
 44: creating process group
 59: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 59: creating process group
103: creating process group
197: creating process group
 66: creating process group
354: creating process group
 53: creating process group
124: creating process group
 28: creating process group
 78: creating process group
173: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
261: creating process group
164: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
152: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: creating process group
104: creating process group
201: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
119: creating process group
371: creating process group
 99: creating process group
 51: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 24: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
373: creating process group
 74: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
435: creating process group
 61: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 85: creating process group
423: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
397: creating process group
207: creating process group
231: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
437: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  4: creating process group
268: creating process group
424: creating process group
233: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
418: creating process group
405: creating process group
431: creating process group
224: creating process group
250: creating process group
290: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
336: creating process group
326: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
266: creating process group
158: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
361: creating process group
123: creating process group
348: creating process group
314: creating process group
180: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
306: creating process group
340: creating process group
316: creating process group
148: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: creating process group
294: creating process group
346: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
128: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
285: creating process group
 83: creating process group
238: creating process group
322: creating process group
 56: creating process group
141: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
101: creating process group
355: creating process group
160: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 54: creating process group
125: creating process group
174: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
136: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
185: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
262: creating process group
165: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
189: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
153: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 34: creating process group
106: creating process group
176: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
201: creating process group
368: creating process group
 97: creating process group
 51: creating process group
 24: creating process group
132: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
374: creating process group
 75: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 63: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 86: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
168: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
144: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
423: creating process group
480: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
492: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
228: creating process group
437: creating process group
485: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
448: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
472: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
235: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
452: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
488: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
465: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
406: creating process group
429: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
225: creating process group
476: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
290: creating process group
337: creating process group
327: creating process group
159: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
159: creating process group
341: creating process group
149: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
347: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
129: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
286: creating process group
239: creating process group
 58: creating process group
142: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 55: creating process group
175: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
186: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
190: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
154: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
177: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
133: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 74: creating process group
 60: creating process group
 86: creating process group
468: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
456: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
460: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
481: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
494: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
504: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
230: creating process group
486: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
508: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
496: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
449: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
473: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
233: creating process group
455: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
490: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
466: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
429: creating process group
501: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
226: creating process group
477: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
338: creating process group
325: creating process group
158: creating process group
181: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
342: creating process group
150: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
150: creating process group
346: creating process group
130: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
236: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
140: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
162: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 52: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
173: creating process group
138: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
187: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
167: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
167: creating process group
191: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
191: creating process group
155: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
178: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
134: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 75: creating process group
 61: creating process group
 84: creating process group
470: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
168: creating process group
146: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
457: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
460: creating process group
482: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
495: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
505: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
231: creating process group
486: creating process group
509: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
497: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
450: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
475: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
235: creating process group
452: creating process group
491: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
467: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
502: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
502: creating process group
478: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
326: creating process group
156: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
182: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
343: creating process group
151: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
151: creating process group
347: creating process group
131: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
131: creating process group
236: creating process group
141: creating process group
163: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
163: creating process group
 52: creating process group
174: creating process group
139: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
185: creating process group
164: creating process group
189: creating process group
152: creating process group
179: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
179: creating process group
135: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
135: creating process group
 63: creating process group
471: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
471: creating process group
169: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
147: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
147: creating process group
458: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
461: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
483: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
483: creating process group
492: creating process group
506: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
484: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
508: creating process group
498: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
451: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
451: creating process group
472: creating process group
455: creating process group
488: creating process group
467: creating process group
503: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
503: creating process group
479: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
324: creating process group
157: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
183: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
183: creating process group
148: creating process group
128: creating process group
142: creating process group
160: creating process group
175: creating process group
136: creating process group
186: creating process group
165: creating process group
190: creating process group
153: creating process group
176: creating process group
132: creating process group
469: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: creating process group
144: creating process group
459: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
463: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
480: creating process group
494: creating process group
507: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
485: creating process group
509: creating process group
499: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
499: creating process group
448: creating process group
473: creating process group
453: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
490: creating process group
464: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
501: creating process group
476: creating process group
156: creating process group
180: creating process group
149: creating process group
129: creating process group
143: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: creating process group
172: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: creating process group
187: creating process group
166: creating process group
188: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
154: creating process group
177: creating process group
133: creating process group
470: creating process group
170: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: creating process group
456: creating process group
462: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
481: creating process group
495: creating process group
504: creating process group
487: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
510: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
496: creating process group
449: creating process group
475: creating process group
454: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
491: creating process group
465: creating process group
500: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
477: creating process group
157: creating process group
181: creating process group
130: creating process group
140: creating process group
162: creating process group
172: creating process group
138: creating process group
184: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
188: creating process group
155: creating process group
178: creating process group
134: creating process group
468: creating process group
169: creating process group
146: creating process group
457: creating process group
482: creating process group
493: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
505: creating process group
484: creating process group
510: creating process group
497: creating process group
450: creating process group
474: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
453: creating process group
489: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
466: creating process group
500: creating process group
478: creating process group
182: creating process group
143: creating process group
139: creating process group
184: creating process group
469: creating process group
170: creating process group
458: creating process group
493: creating process group
506: creating process group
487: creating process group
511: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
498: creating process group
474: creating process group
454: creating process group
489: creating process group
464: creating process group
479: creating process group
459: creating process group
461: creating process group
507: creating process group
511: creating process group
463: creating process group
462: creating process group
  0: Process group successfully created for rank 0 . Now a global mpi barrier...
211: Process group successfully created for rank 211 . Now a global mpi barrier...
217: Process group successfully created for rank 217 . Now a global mpi barrier...
220: Process group successfully created for rank 220 . Now a global mpi barrier...
112: Process group successfully created for rank 112 . Now a global mpi barrier...
228: Process group successfully created for rank 228 . Now a global mpi barrier...
224: Process group successfully created for rank 224 . Now a global mpi barrier...
122: Process group successfully created for rank 122 . Now a global mpi barrier...
230: Process group successfully created for rank 230 . Now a global mpi barrier...
241: Process group successfully created for rank 241 . Now a global mpi barrier...
236: Process group successfully created for rank 236 . Now a global mpi barrier...
231: Process group successfully created for rank 231 . Now a global mpi barrier...
232: Process group successfully created for rank 232 . Now a global mpi barrier...
218: Process group successfully created for rank 218 . Now a global mpi barrier...
242: Process group successfully created for rank 242 . Now a global mpi barrier...
229: Process group successfully created for rank 229 . Now a global mpi barrier...
249: Process group successfully created for rank 249 . Now a global mpi barrier...
219: Process group successfully created for rank 219 . Now a global mpi barrier...
244: Process group successfully created for rank 244 . Now a global mpi barrier...
238: Process group successfully created for rank 238 . Now a global mpi barrier...
226: Process group successfully created for rank 226 . Now a global mpi barrier...
240: Process group successfully created for rank 240 . Now a global mpi barrier...
222: Process group successfully created for rank 222 . Now a global mpi barrier...
245: Process group successfully created for rank 245 . Now a global mpi barrier...
239: Process group successfully created for rank 239 . Now a global mpi barrier...
252: Process group successfully created for rank 252 . Now a global mpi barrier...
256: Process group successfully created for rank 256 . Now a global mpi barrier...
233: Process group successfully created for rank 233 . Now a global mpi barrier...
225: Process group successfully created for rank 225 . Now a global mpi barrier...
264: Process group successfully created for rank 264 . Now a global mpi barrier...
243: Process group successfully created for rank 243 . Now a global mpi barrier...
246: Process group successfully created for rank 246 . Now a global mpi barrier...
237: Process group successfully created for rank 237 . Now a global mpi barrier...
260: Process group successfully created for rank 260 . Now a global mpi barrier...
253: Process group successfully created for rank 253 . Now a global mpi barrier...
269: Process group successfully created for rank 269 . Now a global mpi barrier...
258: Process group successfully created for rank 258 . Now a global mpi barrier...
234: Process group successfully created for rank 234 . Now a global mpi barrier...
227: Process group successfully created for rank 227 . Now a global mpi barrier...
277: Process group successfully created for rank 277 . Now a global mpi barrier...
266: Process group successfully created for rank 266 . Now a global mpi barrier...
247: Process group successfully created for rank 247 . Now a global mpi barrier...
254: Process group successfully created for rank 254 . Now a global mpi barrier...
271: Process group successfully created for rank 271 . Now a global mpi barrier...
259: Process group successfully created for rank 259 . Now a global mpi barrier...
235: Process group successfully created for rank 235 . Now a global mpi barrier...
250: Process group successfully created for rank 250 . Now a global mpi barrier...
276: Process group successfully created for rank 276 . Now a global mpi barrier...
267: Process group successfully created for rank 267 . Now a global mpi barrier...
272: Process group successfully created for rank 272 . Now a global mpi barrier...
255: Process group successfully created for rank 255 . Now a global mpi barrier...
270: Process group successfully created for rank 270 . Now a global mpi barrier...
248: Process group successfully created for rank 248 . Now a global mpi barrier...
279: Process group successfully created for rank 279 . Now a global mpi barrier...
265: Process group successfully created for rank 265 . Now a global mpi barrier...
284: Process group successfully created for rank 284 . Now a global mpi barrier...
251: Process group successfully created for rank 251 . Now a global mpi barrier...
278: Process group successfully created for rank 278 . Now a global mpi barrier...
292: Process group successfully created for rank 292 . Now a global mpi barrier...
280: Process group successfully created for rank 280 . Now a global mpi barrier...
261: Process group successfully created for rank 261 . Now a global mpi barrier...
289: Process group successfully created for rank 289 . Now a global mpi barrier...
300: Process group successfully created for rank 300 . Now a global mpi barrier...
295: Process group successfully created for rank 295 . Now a global mpi barrier...
287: Process group successfully created for rank 287 . Now a global mpi barrier...
296: Process group successfully created for rank 296 . Now a global mpi barrier...
273: Process group successfully created for rank 273 . Now a global mpi barrier...
262: Process group successfully created for rank 262 . Now a global mpi barrier...
304: Process group successfully created for rank 304 . Now a global mpi barrier...
293: Process group successfully created for rank 293 . Now a global mpi barrier...
281: Process group successfully created for rank 281 . Now a global mpi barrier...
285: Process group successfully created for rank 285 . Now a global mpi barrier...
297: Process group successfully created for rank 297 . Now a global mpi barrier...
274: Process group successfully created for rank 274 . Now a global mpi barrier...
263: Process group successfully created for rank 263 . Now a global mpi barrier...
308: Process group successfully created for rank 308 . Now a global mpi barrier...
290: Process group successfully created for rank 290 . Now a global mpi barrier...
302: Process group successfully created for rank 302 . Now a global mpi barrier...
305: Process group successfully created for rank 305 . Now a global mpi barrier...
294: Process group successfully created for rank 294 . Now a global mpi barrier...
282: Process group successfully created for rank 282 . Now a global mpi barrier...
286: Process group successfully created for rank 286 . Now a global mpi barrier...
299: Process group successfully created for rank 299 . Now a global mpi barrier...
275: Process group successfully created for rank 275 . Now a global mpi barrier...
309: Process group successfully created for rank 309 . Now a global mpi barrier...
291: Process group successfully created for rank 291 . Now a global mpi barrier...
303: Process group successfully created for rank 303 . Now a global mpi barrier...
312: Process group successfully created for rank 312 . Now a global mpi barrier...
306: Process group successfully created for rank 306 . Now a global mpi barrier...
316: Process group successfully created for rank 316 . Now a global mpi barrier...
283: Process group successfully created for rank 283 . Now a global mpi barrier...
310: Process group successfully created for rank 310 . Now a global mpi barrier...
288: Process group successfully created for rank 288 . Now a global mpi barrier...
301: Process group successfully created for rank 301 . Now a global mpi barrier...
314: Process group successfully created for rank 314 . Now a global mpi barrier...
496: Process group successfully created for rank 496 . Now a global mpi barrier...
505: Process group successfully created for rank 505 . Now a global mpi barrier...
486: Process group successfully created for rank 486 . Now a global mpi barrier...
495: Process group successfully created for rank 495 . Now a global mpi barrier...
506: Process group successfully created for rank 506 . Now a global mpi barrier...
507: Process group successfully created for rank 507 . Now a global mpi barrier...
311: Process group successfully created for rank 311 . Now a global mpi barrier...
318: Process group successfully created for rank 318 . Now a global mpi barrier...
298: Process group successfully created for rank 298 . Now a global mpi barrier...
317: Process group successfully created for rank 317 . Now a global mpi barrier...
321: Process group successfully created for rank 321 . Now a global mpi barrier...
257: Process group successfully created for rank 257 . Now a global mpi barrier...
324: Process group successfully created for rank 324 . Now a global mpi barrier...
331: Process group successfully created for rank 331 . Now a global mpi barrier...
322: Process group successfully created for rank 322 . Now a global mpi barrier...
325: Process group successfully created for rank 325 . Now a global mpi barrier...
319: Process group successfully created for rank 319 . Now a global mpi barrier...
320: Process group successfully created for rank 320 . Now a global mpi barrier...
497: Process group successfully created for rank 497 . Now a global mpi barrier...
307: Process group successfully created for rank 307 . Now a global mpi barrier...
330: Process group successfully created for rank 330 . Now a global mpi barrier...
268: Process group successfully created for rank 268 . Now a global mpi barrier...
223: Process group successfully created for rank 223 . Now a global mpi barrier...
329: Process group successfully created for rank 329 . Now a global mpi barrier...
326: Process group successfully created for rank 326 . Now a global mpi barrier...
315: Process group successfully created for rank 315 . Now a global mpi barrier...
332: Process group successfully created for rank 332 . Now a global mpi barrier...
327: Process group successfully created for rank 327 . Now a global mpi barrier...
340: Process group successfully created for rank 340 . Now a global mpi barrier...
344: Process group successfully created for rank 344 . Now a global mpi barrier...
350: Process group successfully created for rank 350 . Now a global mpi barrier...
328: Process group successfully created for rank 328 . Now a global mpi barrier...
333: Process group successfully created for rank 333 . Now a global mpi barrier...
341: Process group successfully created for rank 341 . Now a global mpi barrier...
335: Process group successfully created for rank 335 . Now a global mpi barrier...
352: Process group successfully created for rank 352 . Now a global mpi barrier...
351: Process group successfully created for rank 351 . Now a global mpi barrier...
345: Process group successfully created for rank 345 . Now a global mpi barrier...
346: Process group successfully created for rank 346 . Now a global mpi barrier...
334: Process group successfully created for rank 334 . Now a global mpi barrier...
338: Process group successfully created for rank 338 . Now a global mpi barrier...
313: Process group successfully created for rank 313 . Now a global mpi barrier...
323: Process group successfully created for rank 323 . Now a global mpi barrier...
348: Process group successfully created for rank 348 . Now a global mpi barrier...
343: Process group successfully created for rank 343 . Now a global mpi barrier...
354: Process group successfully created for rank 354 . Now a global mpi barrier...
339: Process group successfully created for rank 339 . Now a global mpi barrier...
342: Process group successfully created for rank 342 . Now a global mpi barrier...
356: Process group successfully created for rank 356 . Now a global mpi barrier...
353: Process group successfully created for rank 353 . Now a global mpi barrier...
337: Process group successfully created for rank 337 . Now a global mpi barrier...
362: Process group successfully created for rank 362 . Now a global mpi barrier...
349: Process group successfully created for rank 349 . Now a global mpi barrier...
355: Process group successfully created for rank 355 . Now a global mpi barrier...
365: Process group successfully created for rank 365 . Now a global mpi barrier...
347: Process group successfully created for rank 347 . Now a global mpi barrier...
357: Process group successfully created for rank 357 . Now a global mpi barrier...
370: Process group successfully created for rank 370 . Now a global mpi barrier...
372: Process group successfully created for rank 372 . Now a global mpi barrier...
363: Process group successfully created for rank 363 . Now a global mpi barrier...
376: Process group successfully created for rank 376 . Now a global mpi barrier...
359: Process group successfully created for rank 359 . Now a global mpi barrier...
361: Process group successfully created for rank 361 . Now a global mpi barrier...
358: Process group successfully created for rank 358 . Now a global mpi barrier...
371: Process group successfully created for rank 371 . Now a global mpi barrier...
373: Process group successfully created for rank 373 . Now a global mpi barrier...
360: Process group successfully created for rank 360 . Now a global mpi barrier...
366: Process group successfully created for rank 366 . Now a global mpi barrier...
380: Process group successfully created for rank 380 . Now a global mpi barrier...
368: Process group successfully created for rank 368 . Now a global mpi barrier...
374: Process group successfully created for rank 374 . Now a global mpi barrier...
367: Process group successfully created for rank 367 . Now a global mpi barrier...
375: Process group successfully created for rank 375 . Now a global mpi barrier...
385: Process group successfully created for rank 385 . Now a global mpi barrier...
364: Process group successfully created for rank 364 . Now a global mpi barrier...
369: Process group successfully created for rank 369 . Now a global mpi barrier...
494: Process group successfully created for rank 494 . Now a global mpi barrier...
504: Process group successfully created for rank 504 . Now a global mpi barrier...
387: Process group successfully created for rank 387 . Now a global mpi barrier...
381: Process group successfully created for rank 381 . Now a global mpi barrier...
389: Process group successfully created for rank 389 . Now a global mpi barrier...
398: Process group successfully created for rank 398 . Now a global mpi barrier...
400: Process group successfully created for rank 400 . Now a global mpi barrier...
392: Process group successfully created for rank 392 . Now a global mpi barrier...
379: Process group successfully created for rank 379 . Now a global mpi barrier...
383: Process group successfully created for rank 383 . Now a global mpi barrier...
399: Process group successfully created for rank 399 . Now a global mpi barrier...
388: Process group successfully created for rank 388 . Now a global mpi barrier...
377: Process group successfully created for rank 377 . Now a global mpi barrier...
396: Process group successfully created for rank 396 . Now a global mpi barrier...
408: Process group successfully created for rank 408 . Now a global mpi barrier...
401: Process group successfully created for rank 401 . Now a global mpi barrier...
390: Process group successfully created for rank 390 . Now a global mpi barrier...
405: Process group successfully created for rank 405 . Now a global mpi barrier...
394: Process group successfully created for rank 394 . Now a global mpi barrier...
384: Process group successfully created for rank 384 . Now a global mpi barrier...
406: Process group successfully created for rank 406 . Now a global mpi barrier...
393: Process group successfully created for rank 393 . Now a global mpi barrier...
382: Process group successfully created for rank 382 . Now a global mpi barrier...
386: Process group successfully created for rank 386 . Now a global mpi barrier...
407: Process group successfully created for rank 407 . Now a global mpi barrier...
487: Process group successfully created for rank 487 . Now a global mpi barrier...
397: Process group successfully created for rank 397 . Now a global mpi barrier...
391: Process group successfully created for rank 391 . Now a global mpi barrier...
410: Process group successfully created for rank 410 . Now a global mpi barrier...
402: Process group successfully created for rank 402 . Now a global mpi barrier...
421: Process group successfully created for rank 421 . Now a global mpi barrier...
415: Process group successfully created for rank 415 . Now a global mpi barrier...
395: Process group successfully created for rank 395 . Now a global mpi barrier...
378: Process group successfully created for rank 378 . Now a global mpi barrier...
411: Process group successfully created for rank 411 . Now a global mpi barrier...
420: Process group successfully created for rank 420 . Now a global mpi barrier...
409: Process group successfully created for rank 409 . Now a global mpi barrier...
418: Process group successfully created for rank 418 . Now a global mpi barrier...
422: Process group successfully created for rank 422 . Now a global mpi barrier...
430: Process group successfully created for rank 430 . Now a global mpi barrier...
424: Process group successfully created for rank 424 . Now a global mpi barrier...
419: Process group successfully created for rank 419 . Now a global mpi barrier...
416: Process group successfully created for rank 416 . Now a global mpi barrier...
433: Process group successfully created for rank 433 . Now a global mpi barrier...
425: Process group successfully created for rank 425 . Now a global mpi barrier...
417: Process group successfully created for rank 417 . Now a global mpi barrier...
426: Process group successfully created for rank 426 . Now a global mpi barrier...
414: Process group successfully created for rank 414 . Now a global mpi barrier...
427: Process group successfully created for rank 427 . Now a global mpi barrier...
434: Process group successfully created for rank 434 . Now a global mpi barrier...
423: Process group successfully created for rank 423 . Now a global mpi barrier...
440: Process group successfully created for rank 440 . Now a global mpi barrier...
436: Process group successfully created for rank 436 . Now a global mpi barrier...
437: Process group successfully created for rank 437 . Now a global mpi barrier...
438: Process group successfully created for rank 438 . Now a global mpi barrier...
439: Process group successfully created for rank 439 . Now a global mpi barrier...
431: Process group successfully created for rank 431 . Now a global mpi barrier...
441: Process group successfully created for rank 441 . Now a global mpi barrier...
442: Process group successfully created for rank 442 . Now a global mpi barrier...
429: Process group successfully created for rank 429 . Now a global mpi barrier...
443: Process group successfully created for rank 443 . Now a global mpi barrier...
403: Process group successfully created for rank 403 . Now a global mpi barrier...
404: Process group successfully created for rank 404 . Now a global mpi barrier...
444: Process group successfully created for rank 444 . Now a global mpi barrier...
448: Process group successfully created for rank 448 . Now a global mpi barrier...
445: Process group successfully created for rank 445 . Now a global mpi barrier...
453: Process group successfully created for rank 453 . Now a global mpi barrier...
456: Process group successfully created for rank 456 . Now a global mpi barrier...
446: Process group successfully created for rank 446 . Now a global mpi barrier...
449: Process group successfully created for rank 449 . Now a global mpi barrier...
413: Process group successfully created for rank 413 . Now a global mpi barrier...
465: Process group successfully created for rank 465 . Now a global mpi barrier...
460: Process group successfully created for rank 460 . Now a global mpi barrier...
447: Process group successfully created for rank 447 . Now a global mpi barrier...
451: Process group successfully created for rank 451 . Now a global mpi barrier...
412: Process group successfully created for rank 412 . Now a global mpi barrier...
455: Process group successfully created for rank 455 . Now a global mpi barrier...
466: Process group successfully created for rank 466 . Now a global mpi barrier...
428: Process group successfully created for rank 428 . Now a global mpi barrier...
432: Process group successfully created for rank 432 . Now a global mpi barrier...
468: Process group successfully created for rank 468 . Now a global mpi barrier...
458: Process group successfully created for rank 458 . Now a global mpi barrier...
452: Process group successfully created for rank 452 . Now a global mpi barrier...
435: Process group successfully created for rank 435 . Now a global mpi barrier...
457: Process group successfully created for rank 457 . Now a global mpi barrier...
  1: Process group successfully created for rank 1 . Now a global mpi barrier...
  2: Process group successfully created for rank 2 . Now a global mpi barrier...
  3: Process group successfully created for rank 3 . Now a global mpi barrier...
  6: Process group successfully created for rank 6 . Now a global mpi barrier...
 12: Process group successfully created for rank 12 . Now a global mpi barrier...
  4: Process group successfully created for rank 4 . Now a global mpi barrier...
  5: Process group successfully created for rank 5 . Now a global mpi barrier...
 15: Process group successfully created for rank 15 . Now a global mpi barrier...
  7: Process group successfully created for rank 7 . Now a global mpi barrier...
 16: Process group successfully created for rank 16 . Now a global mpi barrier...
  9: Process group successfully created for rank 9 . Now a global mpi barrier...
 14: Process group successfully created for rank 14 . Now a global mpi barrier...
 21: Process group successfully created for rank 21 . Now a global mpi barrier...
 17: Process group successfully created for rank 17 . Now a global mpi barrier...
 11: Process group successfully created for rank 11 . Now a global mpi barrier...
 13: Process group successfully created for rank 13 . Now a global mpi barrier...
  8: Process group successfully created for rank 8 . Now a global mpi barrier...
459: Process group successfully created for rank 459 . Now a global mpi barrier...
454: Process group successfully created for rank 454 . Now a global mpi barrier...
464: Process group successfully created for rank 464 . Now a global mpi barrier...
461: Process group successfully created for rank 461 . Now a global mpi barrier...
450: Process group successfully created for rank 450 . Now a global mpi barrier...
473: Process group successfully created for rank 473 . Now a global mpi barrier...
467: Process group successfully created for rank 467 . Now a global mpi barrier...
469: Process group successfully created for rank 469 . Now a global mpi barrier...
490: Process group successfully created for rank 490 . Now a global mpi barrier...
470: Process group successfully created for rank 470 . Now a global mpi barrier...
475: Process group successfully created for rank 475 . Now a global mpi barrier...
471: Process group successfully created for rank 471 . Now a global mpi barrier...
476: Process group successfully created for rank 476 . Now a global mpi barrier...
462: Process group successfully created for rank 462 . Now a global mpi barrier...
502: Process group successfully created for rank 502 . Now a global mpi barrier...
463: Process group successfully created for rank 463 . Now a global mpi barrier...
503: Process group successfully created for rank 503 . Now a global mpi barrier...
477: Process group successfully created for rank 477 . Now a global mpi barrier...
 28: Process group successfully created for rank 28 . Now a global mpi barrier...
 24: Process group successfully created for rank 24 . Now a global mpi barrier...
 20: Process group successfully created for rank 20 . Now a global mpi barrier...
 10: Process group successfully created for rank 10 . Now a global mpi barrier...
 22: Process group successfully created for rank 22 . Now a global mpi barrier...
 18: Process group successfully created for rank 18 . Now a global mpi barrier...
 29: Process group successfully created for rank 29 . Now a global mpi barrier...
 25: Process group successfully created for rank 25 . Now a global mpi barrier...
 23: Process group successfully created for rank 23 . Now a global mpi barrier...
 19: Process group successfully created for rank 19 . Now a global mpi barrier...
 31: Process group successfully created for rank 31 . Now a global mpi barrier...
 32: Process group successfully created for rank 32 . Now a global mpi barrier...
 26: Process group successfully created for rank 26 . Now a global mpi barrier...
 36: Process group successfully created for rank 36 . Now a global mpi barrier...
 41: Process group successfully created for rank 41 . Now a global mpi barrier...
 30: Process group successfully created for rank 30 . Now a global mpi barrier...
 33: Process group successfully created for rank 33 . Now a global mpi barrier...
 50: Process group successfully created for rank 50 . Now a global mpi barrier...
 37: Process group successfully created for rank 37 . Now a global mpi barrier...
 42: Process group successfully created for rank 42 . Now a global mpi barrier...
 44: Process group successfully created for rank 44 . Now a global mpi barrier...
 57: Process group successfully created for rank 57 . Now a global mpi barrier...
 52: Process group successfully created for rank 52 . Now a global mpi barrier...
 34: Process group successfully created for rank 34 . Now a global mpi barrier...
 51: Process group successfully created for rank 51 . Now a global mpi barrier...
 38: Process group successfully created for rank 38 . Now a global mpi barrier...
 40: Process group successfully created for rank 40 . Now a global mpi barrier...
 59: Process group successfully created for rank 59 . Now a global mpi barrier...
 53: Process group successfully created for rank 53 . Now a global mpi barrier...
 35: Process group successfully created for rank 35 . Now a global mpi barrier...
 48: Process group successfully created for rank 48 . Now a global mpi barrier...
 39: Process group successfully created for rank 39 . Now a global mpi barrier...
 43: Process group successfully created for rank 43 . Now a global mpi barrier...
 45: Process group successfully created for rank 45 . Now a global mpi barrier...
 56: Process group successfully created for rank 56 . Now a global mpi barrier...
 54: Process group successfully created for rank 54 . Now a global mpi barrier...
 49: Process group successfully created for rank 49 . Now a global mpi barrier...
 60: Process group successfully created for rank 60 . Now a global mpi barrier...
 68: Process group successfully created for rank 68 . Now a global mpi barrier...
 46: Process group successfully created for rank 46 . Now a global mpi barrier...
 58: Process group successfully created for rank 58 . Now a global mpi barrier...
 64: Process group successfully created for rank 64 . Now a global mpi barrier...
 61: Process group successfully created for rank 61 . Now a global mpi barrier...
 70: Process group successfully created for rank 70 . Now a global mpi barrier...
 47: Process group successfully created for rank 47 . Now a global mpi barrier...
 65: Process group successfully created for rank 65 . Now a global mpi barrier...
 62: Process group successfully created for rank 62 . Now a global mpi barrier...
 66: Process group successfully created for rank 66 . Now a global mpi barrier...
 67: Process group successfully created for rank 67 . Now a global mpi barrier...
474: Process group successfully created for rank 474 . Now a global mpi barrier...
481: Process group successfully created for rank 481 . Now a global mpi barrier...
491: Process group successfully created for rank 491 . Now a global mpi barrier...
484: Process group successfully created for rank 484 . Now a global mpi barrier...
478: Process group successfully created for rank 478 . Now a global mpi barrier...
472: Process group successfully created for rank 472 . Now a global mpi barrier...
483: Process group successfully created for rank 483 . Now a global mpi barrier...
482: Process group successfully created for rank 482 . Now a global mpi barrier...
 69: Process group successfully created for rank 69 . Now a global mpi barrier...
 55: Process group successfully created for rank 55 . Now a global mpi barrier...
 73: Process group successfully created for rank 73 . Now a global mpi barrier...
 63: Process group successfully created for rank 63 . Now a global mpi barrier...
 76: Process group successfully created for rank 76 . Now a global mpi barrier...
 75: Process group successfully created for rank 75 . Now a global mpi barrier...
 80: Process group successfully created for rank 80 . Now a global mpi barrier...
 78: Process group successfully created for rank 78 . Now a global mpi barrier...
 72: Process group successfully created for rank 72 . Now a global mpi barrier...
 89: Process group successfully created for rank 89 . Now a global mpi barrier...
 83: Process group successfully created for rank 83 . Now a global mpi barrier...
 77: Process group successfully created for rank 77 . Now a global mpi barrier...
 27: Process group successfully created for rank 27 . Now a global mpi barrier...
 74: Process group successfully created for rank 74 . Now a global mpi barrier...
 90: Process group successfully created for rank 90 . Now a global mpi barrier...
 81: Process group successfully created for rank 81 . Now a global mpi barrier...
 79: Process group successfully created for rank 79 . Now a global mpi barrier...
 84: Process group successfully created for rank 84 . Now a global mpi barrier...
 88: Process group successfully created for rank 88 . Now a global mpi barrier...
101: Process group successfully created for rank 101 . Now a global mpi barrier...
 96: Process group successfully created for rank 96 . Now a global mpi barrier...
 85: Process group successfully created for rank 85 . Now a global mpi barrier...
 91: Process group successfully created for rank 91 . Now a global mpi barrier...
 92: Process group successfully created for rank 92 . Now a global mpi barrier...
 86: Process group successfully created for rank 86 . Now a global mpi barrier...
115: Process group successfully created for rank 115 . Now a global mpi barrier...
 82: Process group successfully created for rank 82 . Now a global mpi barrier...
102: Process group successfully created for rank 102 . Now a global mpi barrier...
 97: Process group successfully created for rank 97 . Now a global mpi barrier...
 87: Process group successfully created for rank 87 . Now a global mpi barrier...
108: Process group successfully created for rank 108 . Now a global mpi barrier...
121: Process group successfully created for rank 121 . Now a global mpi barrier...
100: Process group successfully created for rank 100 . Now a global mpi barrier...
104: Process group successfully created for rank 104 . Now a global mpi barrier...
116: Process group successfully created for rank 116 . Now a global mpi barrier...
 98: Process group successfully created for rank 98 . Now a global mpi barrier...
109: Process group successfully created for rank 109 . Now a global mpi barrier...
103: Process group successfully created for rank 103 . Now a global mpi barrier...
124: Process group successfully created for rank 124 . Now a global mpi barrier...
 94: Process group successfully created for rank 94 . Now a global mpi barrier...
107: Process group successfully created for rank 107 . Now a global mpi barrier...
117: Process group successfully created for rank 117 . Now a global mpi barrier...
 99: Process group successfully created for rank 99 . Now a global mpi barrier...
110: Process group successfully created for rank 110 . Now a global mpi barrier...
 95: Process group successfully created for rank 95 . Now a global mpi barrier...
105: Process group successfully created for rank 105 . Now a global mpi barrier...
118: Process group successfully created for rank 118 . Now a global mpi barrier...
111: Process group successfully created for rank 111 . Now a global mpi barrier...
106: Process group successfully created for rank 106 . Now a global mpi barrier...
 93: Process group successfully created for rank 93 . Now a global mpi barrier...
113: Process group successfully created for rank 113 . Now a global mpi barrier...
114: Process group successfully created for rank 114 . Now a global mpi barrier...
479: Process group successfully created for rank 479 . Now a global mpi barrier...
480: Process group successfully created for rank 480 . Now a global mpi barrier...
493: Process group successfully created for rank 493 . Now a global mpi barrier...
485: Process group successfully created for rank 485 . Now a global mpi barrier...
488: Process group successfully created for rank 488 . Now a global mpi barrier...
492: Process group successfully created for rank 492 . Now a global mpi barrier...
499: Process group successfully created for rank 499 . Now a global mpi barrier...
336: Process group successfully created for rank 336 . Now a global mpi barrier...
120: Process group successfully created for rank 120 . Now a global mpi barrier...
119: Process group successfully created for rank 119 . Now a global mpi barrier...
 71: Process group successfully created for rank 71 . Now a global mpi barrier...
123: Process group successfully created for rank 123 . Now a global mpi barrier...
125: Process group successfully created for rank 125 . Now a global mpi barrier...
127: Process group successfully created for rank 127 . Now a global mpi barrier...
126: Process group successfully created for rank 126 . Now a global mpi barrier...
132: Process group successfully created for rank 132 . Now a global mpi barrier...
137: Process group successfully created for rank 137 . Now a global mpi barrier...
144: Process group successfully created for rank 144 . Now a global mpi barrier...
148: Process group successfully created for rank 148 . Now a global mpi barrier...
141: Process group successfully created for rank 141 . Now a global mpi barrier...
128: Process group successfully created for rank 128 . Now a global mpi barrier...
138: Process group successfully created for rank 138 . Now a global mpi barrier...
145: Process group successfully created for rank 145 . Now a global mpi barrier...
149: Process group successfully created for rank 149 . Now a global mpi barrier...
136: Process group successfully created for rank 136 . Now a global mpi barrier...
152: Process group successfully created for rank 152 . Now a global mpi barrier...
146: Process group successfully created for rank 146 . Now a global mpi barrier...
129: Process group successfully created for rank 129 . Now a global mpi barrier...
139: Process group successfully created for rank 139 . Now a global mpi barrier...
153: Process group successfully created for rank 153 . Now a global mpi barrier...
133: Process group successfully created for rank 133 . Now a global mpi barrier...
147: Process group successfully created for rank 147 . Now a global mpi barrier...
151: Process group successfully created for rank 151 . Now a global mpi barrier...
130: Process group successfully created for rank 130 . Now a global mpi barrier...
140: Process group successfully created for rank 140 . Now a global mpi barrier...
154: Process group successfully created for rank 154 . Now a global mpi barrier...
134: Process group successfully created for rank 134 . Now a global mpi barrier...
131: Process group successfully created for rank 131 . Now a global mpi barrier...
142: Process group successfully created for rank 142 . Now a global mpi barrier...
135: Process group successfully created for rank 135 . Now a global mpi barrier...
143: Process group successfully created for rank 143 . Now a global mpi barrier...
501: Process group successfully created for rank 501 . Now a global mpi barrier...
508: Process group successfully created for rank 508 . Now a global mpi barrier...
155: Process group successfully created for rank 155 . Now a global mpi barrier...
150: Process group successfully created for rank 150 . Now a global mpi barrier...
161: Process group successfully created for rank 161 . Now a global mpi barrier...
158: Process group successfully created for rank 158 . Now a global mpi barrier...
163: Process group successfully created for rank 163 . Now a global mpi barrier...
164: Process group successfully created for rank 164 . Now a global mpi barrier...
159: Process group successfully created for rank 159 . Now a global mpi barrier...
160: Process group successfully created for rank 160 . Now a global mpi barrier...
170: Process group successfully created for rank 170 . Now a global mpi barrier...
156: Process group successfully created for rank 156 . Now a global mpi barrier...
162: Process group successfully created for rank 162 . Now a global mpi barrier...
165: Process group successfully created for rank 165 . Now a global mpi barrier...
171: Process group successfully created for rank 171 . Now a global mpi barrier...
157: Process group successfully created for rank 157 . Now a global mpi barrier...
172: Process group successfully created for rank 172 . Now a global mpi barrier...
186: Process group successfully created for rank 186 . Now a global mpi barrier...
166: Process group successfully created for rank 166 . Now a global mpi barrier...
176: Process group successfully created for rank 176 . Now a global mpi barrier...
169: Process group successfully created for rank 169 . Now a global mpi barrier...
180: Process group successfully created for rank 180 . Now a global mpi barrier...
173: Process group successfully created for rank 173 . Now a global mpi barrier...
167: Process group successfully created for rank 167 . Now a global mpi barrier...
178: Process group successfully created for rank 178 . Now a global mpi barrier...
168: Process group successfully created for rank 168 . Now a global mpi barrier...
174: Process group successfully created for rank 174 . Now a global mpi barrier...
179: Process group successfully created for rank 179 . Now a global mpi barrier...
181: Process group successfully created for rank 181 . Now a global mpi barrier...
175: Process group successfully created for rank 175 . Now a global mpi barrier...
498: Process group successfully created for rank 498 . Now a global mpi barrier...
500: Process group successfully created for rank 500 . Now a global mpi barrier...
509: Process group successfully created for rank 509 . Now a global mpi barrier...
511: Process group successfully created for rank 511 . Now a global mpi barrier...
185: Process group successfully created for rank 185 . Now a global mpi barrier...
184: Process group successfully created for rank 184 . Now a global mpi barrier...
189: Process group successfully created for rank 189 . Now a global mpi barrier...
182: Process group successfully created for rank 182 . Now a global mpi barrier...
196: Process group successfully created for rank 196 . Now a global mpi barrier...
177: Process group successfully created for rank 177 . Now a global mpi barrier...
183: Process group successfully created for rank 183 . Now a global mpi barrier...
198: Process group successfully created for rank 198 . Now a global mpi barrier...
187: Process group successfully created for rank 187 . Now a global mpi barrier...
190: Process group successfully created for rank 190 . Now a global mpi barrier...
205: Process group successfully created for rank 205 . Now a global mpi barrier...
208: Process group successfully created for rank 208 . Now a global mpi barrier...
192: Process group successfully created for rank 192 . Now a global mpi barrier...
197: Process group successfully created for rank 197 . Now a global mpi barrier...
191: Process group successfully created for rank 191 . Now a global mpi barrier...
200: Process group successfully created for rank 200 . Now a global mpi barrier...
210: Process group successfully created for rank 210 . Now a global mpi barrier...
193: Process group successfully created for rank 193 . Now a global mpi barrier...
221: Process group successfully created for rank 221 . Now a global mpi barrier...
199: Process group successfully created for rank 199 . Now a global mpi barrier...
188: Process group successfully created for rank 188 . Now a global mpi barrier...
207: Process group successfully created for rank 207 . Now a global mpi barrier...
489: Process group successfully created for rank 489 . Now a global mpi barrier...
194: Process group successfully created for rank 194 . Now a global mpi barrier...
203: Process group successfully created for rank 203 . Now a global mpi barrier...
204: Process group successfully created for rank 204 . Now a global mpi barrier...
195: Process group successfully created for rank 195 . Now a global mpi barrier...
206: Process group successfully created for rank 206 . Now a global mpi barrier...
209: Process group successfully created for rank 209 . Now a global mpi barrier...
201: Process group successfully created for rank 201 . Now a global mpi barrier...
510: Process group successfully created for rank 510 . Now a global mpi barrier...
216: Process group successfully created for rank 216 . Now a global mpi barrier...
212: Process group successfully created for rank 212 . Now a global mpi barrier...
202: Process group successfully created for rank 202 . Now a global mpi barrier...
213: Process group successfully created for rank 213 . Now a global mpi barrier...
214: Process group successfully created for rank 214 . Now a global mpi barrier...
215: Process group successfully created for rank 215 . Now a global mpi barrier...
158: ... barrier passed on rank  158 .
 30: ... barrier passed on rank  30 .
414: ... barrier passed on rank  414 .
286: ... barrier passed on rank  286 .
398: ... barrier passed on rank  398 .
 14: ... barrier passed on rank  14 .
270: ... barrier passed on rank  270 .
190: ... barrier passed on rank  190 .
 62: ... barrier passed on rank  62 .
446: ... barrier passed on rank  446 .
318: ... barrier passed on rank  318 .
142: ... barrier passed on rank  142 .
408: ... barrier passed on rank  408 .
402: ... barrier passed on rank  402 .
274: ... barrier passed on rank  274 .
152: ... barrier passed on rank  152 .
 24: ... barrier passed on rank  24 .
146: ... barrier passed on rank  146 .
430: ... barrier passed on rank  430 .
302: ... barrier passed on rank  302 .
264: ... barrier passed on rank  264 .
306: ... barrier passed on rank  306 .
 18: ... barrier passed on rank  18 .
280: ... barrier passed on rank  280 .
 46: ... barrier passed on rank  46 .
174: ... barrier passed on rank  174 .
178: ... barrier passed on rank  178 .
 50: ... barrier passed on rank  50 .
 72: ... barrier passed on rank  72 .
  2: ... barrier passed on rank  2 .
450: ... barrier passed on rank  450 .
258: ... barrier passed on rank  258 .
392: ... barrier passed on rank  392 .
440: ... barrier passed on rank  440 .
194: ... barrier passed on rank  194 .
328: ... barrier passed on rank  328 .
130: ... barrier passed on rank  130 .
322: ... barrier passed on rank  322 .
 56: ... barrier passed on rank  56 .
 66: ... barrier passed on rank  66 .
136: ... barrier passed on rank  136 .
184: ... barrier passed on rank  184 .
  8: ... barrier passed on rank  8 .
200: ... barrier passed on rank  200 .
434: ... barrier passed on rank  434 .
444: ... barrier passed on rank  444 .
438: ... barrier passed on rank  438 .
510: ... barrier passed on rank  510 .
400: ... barrier passed on rank  400 .
389: ... barrier passed on rank  389 .
412: ... barrier passed on rank  412 .
405: ... barrier passed on rank  405 .
394: ... barrier passed on rank  394 .
 21: ... barrier passed on rank  21 .
310: ... barrier passed on rank  310 .
300: ... barrier passed on rank  300 .
277: ... barrier passed on rank  277 .
266: ... barrier passed on rank  266 .
156: ... barrier passed on rank  156 .
182: ... barrier passed on rank  182 .
304: ... barrier passed on rank  304 .
316: ... barrier passed on rank  316 .
149: ... barrier passed on rank  149 .
 16: ... barrier passed on rank  16 .
330: ... barrier passed on rank  330 .
284: ... barrier passed on rank  284 .
 44: ... barrier passed on rank  44 .
 54: ... barrier passed on rank  54 .
 28: ... barrier passed on rank  28 .
172: ... barrier passed on rank  172 .
261: ... barrier passed on rank  261 .
188: ... barrier passed on rank  188 .
176: ... barrier passed on rank  176 .
 48: ... barrier passed on rank  48 .
133: ... barrier passed on rank  133 .
432: ... barrier passed on rank  432 .
 60: ... barrier passed on rank  60 .
144: ... barrier passed on rank  144 .
456: ... barrier passed on rank  456 .
396: ... barrier passed on rank  396 .
386: ... barrier passed on rank  386 .
410: ... barrier passed on rank  410 .
254: ... barrier passed on rank  254 .
  5: ... barrier passed on rank  5 .
268: ... barrier passed on rank  268 .
390: ... barrier passed on rank  390 .
454: ... barrier passed on rank  454 .
428: ... barrier passed on rank  428 .
442: ... barrier passed on rank  442 .
 70: ... barrier passed on rank  70 .
478: ... barrier passed on rank  478 .
326: ... barrier passed on rank  326 .
350: ... barrier passed on rank  350 .
312: ... barrier passed on rank  312 .
282: ... barrier passed on rank  282 .
272: ... barrier passed on rank  272 .
382: ... barrier passed on rank  382 .
 58: ... barrier passed on rank  58 .
198: ... barrier passed on rank  198 .
126: ... barrier passed on rank  126 .
138: ... barrier passed on rank  138 .
186: ... barrier passed on rank  186 .
 94: ... barrier passed on rank  94 .
154: ... barrier passed on rank  154 .
202: ... barrier passed on rank  202 .
 26: ... barrier passed on rank  26 .
 74: ... barrier passed on rank  74 .
458: ... barrier passed on rank  458 .
  0: ... barrier passed on rank  0 .
384: ... barrier passed on rank  384 .
 12: ... barrier passed on rank  12 .
209: ... barrier passed on rank  209 .
401: ... barrier passed on rank  401 .
448: ... barrier passed on rank  448 .
  6: ... barrier passed on rank  6 .
256: ... barrier passed on rank  256 .
472: ... barrier passed on rank  472 .
453: ... barrier passed on rank  453 .
465: ... barrier passed on rank  465 .
 69: ... barrier passed on rank  69 .
216: ... barrier passed on rank  216 .
337: ... barrier passed on rank  337 .
325: ... barrier passed on rank  325 .
314: ... barrier passed on rank  314 .
192: ... barrier passed on rank  192 .
222: ... barrier passed on rank  222 .
 17: ... barrier passed on rank  17 .
 88: ... barrier passed on rank  88 .
344: ... barrier passed on rank  344 .
 81: ... barrier passed on rank  81 .
320: ... barrier passed on rank  320 .
140: ... barrier passed on rank  140 .
197: ... barrier passed on rank  197 .
 64: ... barrier passed on rank  64 .
262: ... barrier passed on rank  262 .
 10: ... barrier passed on rank  10 .
134: ... barrier passed on rank  134 .
145: ... barrier passed on rank  145 .
504: ... barrier passed on rank  504 .
252: ... barrier passed on rank  252 .
508: ... barrier passed on rank  508 .
424: ... barrier passed on rank  424 .
406: ... barrier passed on rank  406 .
248: ... barrier passed on rank  248 .
 22: ... barrier passed on rank  22 .
278: ... barrier passed on rank  278 .
120: ... barrier passed on rank  120 .
341: ... barrier passed on rank  341 .
150: ... barrier passed on rank  150 .
376: ... barrier passed on rank  376 .
 40: ... barrier passed on rank  40 .
128: ... barrier passed on rank  128 .
296: ... barrier passed on rank  296 .
273: ... barrier passed on rank  273 .
380: ... barrier passed on rank  380 .
213: ... barrier passed on rank  213 .
124: ... barrier passed on rank  124 .
 85: ... barrier passed on rank  85 .
469: ... barrier passed on rank  469 .
168: ... barrier passed on rank  168 .
397: ... barrier passed on rank  397 .
494: ... barrier passed on rank  494 .
506: ... barrier passed on rank  506 .
110: ... barrier passed on rank  110 .
208: ... barrier passed on rank  208 .
496: ... barrier passed on rank  496 .
269: ... barrier passed on rank  269 .
426: ... barrier passed on rank  426 .
464: ... barrier passed on rank  464 .
476: ... barrier passed on rank  476 .
290: ... barrier passed on rank  290 .
122: ... barrier passed on rank  122 .
348: ... barrier passed on rank  348 .
240: ... barrier passed on rank  240 .
220: ... barrier passed on rank  220 .
112: ... barrier passed on rank  112 .
378: ... barrier passed on rank  378 .
 42: ... barrier passed on rank  42 .
366: ... barrier passed on rank  366 .
298: ... barrier passed on rank  298 .
238: ... barrier passed on rank  238 .
162: ... barrier passed on rank  162 .
 92: ... barrier passed on rank  92 .
 34: ... barrier passed on rank  34 .
368: ... barrier passed on rank  368 .
170: ... barrier passed on rank  170 .
  1: ... barrier passed on rank  1 .
421: ... barrier passed on rank  421 .
492: ... barrier passed on rank  492 .
 13: ... barrier passed on rank  13 .
 37: ... barrier passed on rank  37 .
206: ... barrier passed on rank  206 .
108: ... barrier passed on rank  108 .
210: ... barrier passed on rank  210 .
498: ... barrier passed on rank  498 .
449: ... barrier passed on rank  449 .
418: ... barrier passed on rank  418 .
466: ... barrier passed on rank  466 .
404: ... barrier passed on rank  404 .
250: ... barrier passed on rank  250 .
 20: ... barrier passed on rank  20 .
336: ... barrier passed on rank  336 .
276: ... barrier passed on rank  276 .
242: ... barrier passed on rank  242 .
193: ... barrier passed on rank  193 .
148: ... barrier passed on rank  148 .
114: ... barrier passed on rank  114 .
364: ... barrier passed on rank  364 .
293: ... barrier passed on rank  293 .
129: ... barrier passed on rank  129 .
334: ... barrier passed on rank  334 .
 80: ... barrier passed on rank  80 .
236: ... barrier passed on rank  236 .
321: ... barrier passed on rank  321 .
141: ... barrier passed on rank  141 .
 65: ... barrier passed on rank  65 .
 29: ... barrier passed on rank  29 .
 78: ... barrier passed on rank  78 .
260: ... barrier passed on rank  260 .
165: ... barrier passed on rank  165 .
370: ... barrier passed on rank  370 .
  3: ... barrier passed on rank  3 .
422: ... barrier passed on rank  422 .
445: ... barrier passed on rank  445 .
385: ... barrier passed on rank  385 .
 38: ... barrier passed on rank  38 .
403: ... barrier passed on rank  403 .
  4: ... barrier passed on rank  4 .
388: ... barrier passed on rank  388 .
413: ... barrier passed on rank  413 .
257: ... barrier passed on rank  257 .
474: ... barrier passed on rank  474 .
416: ... barrier passed on rank  416 .
452: ... barrier passed on rank  452 .
502: ... barrier passed on rank  502 .
 68: ... barrier passed on rank  68 .
308: ... barrier passed on rank  308 .
288: ... barrier passed on rank  288 .
218: ... barrier passed on rank  218 .
338: ... barrier passed on rank  338 .
324: ... barrier passed on rank  324 .
157: ... barrier passed on rank  157 .
180: ... barrier passed on rank  180 .
305: ... barrier passed on rank  305 .
317: ... barrier passed on rank  317 .
246: ... barrier passed on rank  246 .
 19: ... barrier passed on rank  19 .
294: ... barrier passed on rank  294 .
 90: ... barrier passed on rank  90 .
131: ... barrier passed on rank  131 .
285: ... barrier passed on rank  285 .
275: ... barrier passed on rank  275 .
 82: ... barrier passed on rank  82 .
196: ... barrier passed on rank  196 .
160: ... barrier passed on rank  160 .
 52: ... barrier passed on rank  52 .
166: ... barrier passed on rank  166 .
189: ... barrier passed on rank  189 .
 32: ... barrier passed on rank  32 .
177: ... barrier passed on rank  177 .
118: ... barrier passed on rank  118 .
 49: ... barrier passed on rank  49 .
132: ... barrier passed on rank  132 .
374: ... barrier passed on rank  374 .
433: ... barrier passed on rank  433 .
 61: ... barrier passed on rank  61 .
147: ... barrier passed on rank  147 .
462: ... barrier passed on rank  462 .
447: ... barrier passed on rank  447 .
387: ... barrier passed on rank  387 .
409: ... barrier passed on rank  409 .
253: ... barrier passed on rank  253 .
204: ... barrier passed on rank  204 .
436: ... barrier passed on rank  436 .
509: ... barrier passed on rank  509 .
451: ... barrier passed on rank  451 .
415: ... barrier passed on rank  415 .
259: ... barrier passed on rank  259 .
232: ... barrier passed on rank  232 .
488: ... barrier passed on rank  488 .
441: ... barrier passed on rank  441 .
309: ... barrier passed on rank  309 .
301: ... barrier passed on rank  301 .
159: ... barrier passed on rank  159 .
360: ... barrier passed on rank  360 .
313: ... barrier passed on rank  313 .
195: ... barrier passed on rank  195 .
181: ... barrier passed on rank  181 .
342: ... barrier passed on rank  342 .
319: ... barrier passed on rank  319 .
281: ... barrier passed on rank  281 .
346: ... barrier passed on rank  346 .
287: ... barrier passed on rank  287 .
332: ... barrier passed on rank  332 .
381: ... barrier passed on rank  381 .
323: ... barrier passed on rank  323 .
 57: ... barrier passed on rank  57 .
 67: ... barrier passed on rank  67 .
 53: ... barrier passed on rank  53 .
125: ... barrier passed on rank  125 .
 31: ... barrier passed on rank  31 .
 76: ... barrier passed on rank  76 .
185: ... barrier passed on rank  185 .
191: ... barrier passed on rank  191 .
153: ... barrier passed on rank  153 .
104: ... barrier passed on rank  104 .
 25: ... barrier passed on rank  25 .
 63: ... barrier passed on rank  63 .
 86: ... barrier passed on rank  86 .
460: ... barrier passed on rank  460 .
399: ... barrier passed on rank  399 .
482: ... barrier passed on rank  482 .
 15: ... barrier passed on rank  15 .
437: ... barrier passed on rank  437 .
  7: ... barrier passed on rank  7 .
271: ... barrier passed on rank  271 .
391: ... barrier passed on rank  391 .
234: ... barrier passed on rank  234 .
455: ... barrier passed on rank  455 .
490: ... barrier passed on rank  490 .
467: ... barrier passed on rank  467 .
407: ... barrier passed on rank  407 .
429: ... barrier passed on rank  429 .
393: ... barrier passed on rank  393 .
226: ... barrier passed on rank  226 .
 71: ... barrier passed on rank  71 .
477: ... barrier passed on rank  477 .
 23: ... barrier passed on rank  23 .
311: ... barrier passed on rank  311 .
339: ... barrier passed on rank  339 .
327: ... barrier passed on rank  327 .
279: ... barrier passed on rank  279 .
265: ... barrier passed on rank  265 .
362: ... barrier passed on rank  362 .
349: ... barrier passed on rank  349 .
183: ... barrier passed on rank  183 .
221: ... barrier passed on rank  221 .
340: ... barrier passed on rank  340 .
151: ... barrier passed on rank  151 .
329: ... barrier passed on rank  329 .
 83: ... barrier passed on rank  83 .
214: ... barrier passed on rank  214 .
 45: ... barrier passed on rank  45 .
143: ... barrier passed on rank  143 .
199: ... barrier passed on rank  199 .
354: ... barrier passed on rank  354 .
 55: ... barrier passed on rank  55 .
173: ... barrier passed on rank  173 .
137: ... barrier passed on rank  137 .
263: ... barrier passed on rank  263 .
106: ... barrier passed on rank  106 .
  9: ... barrier passed on rank  9 .
201: ... barrier passed on rank  201 .
 98: ... barrier passed on rank  98 .
135: ... barrier passed on rank  135 .
 73: ... barrier passed on rank  73 .
 84: ... barrier passed on rank  84 .
470: ... barrier passed on rank  470 .
457: ... barrier passed on rank  457 .
420: ... barrier passed on rank  420 .
411: ... barrier passed on rank  411 .
255: ... barrier passed on rank  255 .
 36: ... barrier passed on rank  36 .
205: ... barrier passed on rank  205 .
211: ... barrier passed on rank  211 .
439: ... barrier passed on rank  439 .
511: ... barrier passed on rank  511 .
497: ... barrier passed on rank  497 .
417: ... barrier passed on rank  417 .
431: ... barrier passed on rank  431 .
395: ... barrier passed on rank  395 .
249: ... barrier passed on rank  249 .
289: ... barrier passed on rank  289 .
217: ... barrier passed on rank  217 .
303: ... barrier passed on rank  303 .
267: ... barrier passed on rank  267 .
241: ... barrier passed on rank  241 .
307: ... barrier passed on rank  307 .
331: ... barrier passed on rank  331 .
292: ... barrier passed on rank  292 .
 89: ... barrier passed on rank  89 .
283: ... barrier passed on rank  283 .
357: ... barrier passed on rank  357 .
333: ... barrier passed on rank  333 .
383: ... barrier passed on rank  383 .
212: ... barrier passed on rank  212 .
 47: ... barrier passed on rank  47 .
 59: ... barrier passed on rank  59 .
161: ... barrier passed on rank  161 .
127: ... barrier passed on rank  127 .
 77: ... barrier passed on rank  77 .
175: ... barrier passed on rank  175 .
139: ... barrier passed on rank  139 .
187: ... barrier passed on rank  187 .
164: ... barrier passed on rank  164 .
 93: ... barrier passed on rank  93 .
 33: ... barrier passed on rank  33 .
179: ... barrier passed on rank  179 .
 11: ... barrier passed on rank  11 .
203: ... barrier passed on rank  203 .
369: ... barrier passed on rank  369 .
 51: ... barrier passed on rank  51 .
 27: ... barrier passed on rank  27 .
 75: ... barrier passed on rank  75 .
435: ... barrier passed on rank  435 .
468: ... barrier passed on rank  468 .
459: ... barrier passed on rank  459 .
480: ... barrier passed on rank  480 .
493: ... barrier passed on rank  493 .
505: ... barrier passed on rank  505 .
229: ... barrier passed on rank  229 .
109: ... barrier passed on rank  109 .
485: ... barrier passed on rank  485 .
425: ... barrier passed on rank  425 .
473: ... barrier passed on rank  473 .
419: ... barrier passed on rank  419 .
500: ... barrier passed on rank  500 .
224: ... barrier passed on rank  224 .
479: ... barrier passed on rank  479 .
291: ... barrier passed on rank  291 .
121: ... barrier passed on rank  121 .
351: ... barrier passed on rank  351 .
315: ... barrier passed on rank  315 .
244: ... barrier passed on rank  244 .
113: ... barrier passed on rank  113 .
377: ... barrier passed on rank  377 .
 41: ... barrier passed on rank  41 .
365: ... barrier passed on rank  365 .
345: ... barrier passed on rank  345 .
358: ... barrier passed on rank  358 .
297: ... barrier passed on rank  297 .
237: ... barrier passed on rank  237 .
101: ... barrier passed on rank  101 .
352: ... barrier passed on rank  352 .
163: ... barrier passed on rank  163 .
155: ... barrier passed on rank  155 .
 35: ... barrier passed on rank  35 .
116: ... barrier passed on rank  116 .
 96: ... barrier passed on rank  96 .
372: ... barrier passed on rank  372 .
 87: ... barrier passed on rank  87 .
169: ... barrier passed on rank  169 .
507: ... barrier passed on rank  507 .
207: ... barrier passed on rank  207 .
230: ... barrier passed on rank  230 .
486: ... barrier passed on rank  486 .
499: ... barrier passed on rank  499 .
501: ... barrier passed on rank  501 .
443: ... barrier passed on rank  443 .
251: ... barrier passed on rank  251 .
123: ... barrier passed on rank  123 .
243: ... barrier passed on rank  243 .
223: ... barrier passed on rank  223 .
343: ... barrier passed on rank  343 .
245: ... barrier passed on rank  245 .
115: ... barrier passed on rank  115 .
379: ... barrier passed on rank  379 .
335: ... barrier passed on rank  335 .
215: ... barrier passed on rank  215 .
102: ... barrier passed on rank  102 .
 79: ... barrier passed on rank  79 .
 95: ... barrier passed on rank  95 .
117: ... barrier passed on rank  117 .
371: ... barrier passed on rank  371 .
373: ... barrier passed on rank  373 .
471: ... barrier passed on rank  471 .
461: ... barrier passed on rank  461 .
423: ... barrier passed on rank  423 .
495: ... barrier passed on rank  495 .
 39: ... barrier passed on rank  39 .
228: ... barrier passed on rank  228 .
111: ... barrier passed on rank  111 .
484: ... barrier passed on rank  484 .
427: ... barrier passed on rank  427 .
503: ... barrier passed on rank  503 .
247: ... barrier passed on rank  247 .
 43: ... barrier passed on rank  43 .
367: ... barrier passed on rank  367 .
295: ... barrier passed on rank  295 .
356: ... barrier passed on rank  356 .
299: ... barrier passed on rank  299 .
239: ... barrier passed on rank  239 .
100: ... barrier passed on rank  100 .
167: ... barrier passed on rank  167 .
119: ... barrier passed on rank  119 .
375: ... barrier passed on rank  375 .
171: ... barrier passed on rank  171 .
463: ... barrier passed on rank  463 .
481: ... barrier passed on rank  481 .
475: ... barrier passed on rank  475 .
225: ... barrier passed on rank  225 .
219: ... barrier passed on rank  219 .
 91: ... barrier passed on rank  91 .
347: ... barrier passed on rank  347 .
353: ... barrier passed on rank  353 .
 97: ... barrier passed on rank  97 .
355: ... barrier passed on rank  355 .
 99: ... barrier passed on rank  99 .
233: ... barrier passed on rank  233 .
361: ... barrier passed on rank  361 .
105: ... barrier passed on rank  105 .
489: ... barrier passed on rank  489 .
483: ... barrier passed on rank  483 .
227: ... barrier passed on rank  227 .
231: ... barrier passed on rank  231 .
487: ... barrier passed on rank  487 .
235: ... barrier passed on rank  235 .
491: ... barrier passed on rank  491 .
363: ... barrier passed on rank  363 .
359: ... barrier passed on rank  359 .
103: ... barrier passed on rank  103 .
107: ... barrier passed on rank  107 .
  0: hkn0403:1776559:1776559 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  0: hkn0403:1776559:1776559 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  0: hkn0403:1776559:1776559 [0] NCCL INFO P2P plugin IBext
  0: hkn0403:1776559:1776559 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  0: hkn0403:1776559:1776559 [0] NCCL INFO Using network IBext
  0: NCCL version 2.11.4+cuda11.4
  1: hkn0403:1776565:1776565 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  3: hkn0403:1776560:1776560 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  2: hkn0403:1776577:1776577 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  1: hkn0403:1776565:1776565 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  1: hkn0403:1776565:1776565 [1] NCCL INFO P2P plugin IBext
  3: hkn0403:1776560:1776560 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  3: hkn0403:1776560:1776560 [3] NCCL INFO P2P plugin IBext
  2: hkn0403:1776577:1776577 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  2: hkn0403:1776577:1776577 [2] NCCL INFO P2P plugin IBext
  1: hkn0403:1776565:1776565 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  1: hkn0403:1776565:1776565 [1] NCCL INFO Using network IBext
  3: hkn0403:1776560:1776560 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  3: hkn0403:1776560:1776560 [3] NCCL INFO Using network IBext
  2: hkn0403:1776577:1776577 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  2: hkn0403:1776577:1776577 [2] NCCL INFO Using network IBext
 13: hkn0407:1823500:1823500 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 89: hkn0427:1142369:1142369 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
 14: hkn0407:1823492:1823492 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
118: hkn0506:845292:845292 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 12: hkn0407:1823520:1823520 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 15: hkn0407:1823508:1823508 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 90: hkn0427:1142341:1142341 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
 13: hkn0407:1823500:1823500 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 13: hkn0407:1823500:1823500 [1] NCCL INFO P2P plugin IBext
119: hkn0506:845284:845284 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 89: hkn0427:1142369:1142369 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 89: hkn0427:1142369:1142369 [1] NCCL INFO P2P plugin IBext
117: hkn0506:845300:845300 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
265: hkn0615:421570:421570 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
267: hkn0615:421542:421542 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
116: hkn0506:845312:845312 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 14: hkn0407:1823492:1823492 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 14: hkn0407:1823492:1823492 [2] NCCL INFO P2P plugin IBext
 12: hkn0407:1823520:1823520 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 12: hkn0407:1823520:1823520 [0] NCCL INFO P2P plugin IBext
 15: hkn0407:1823508:1823508 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 15: hkn0407:1823508:1823508 [3] NCCL INFO P2P plugin IBext
118: hkn0506:845292:845292 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
118: hkn0506:845292:845292 [2] NCCL INFO P2P plugin IBext
 90: hkn0427:1142341:1142341 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
375: hkn0713:477460:477460 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
 90: hkn0427:1142341:1142341 [2] NCCL INFO P2P plugin IBext
296: hkn0627:1795174:1795174 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
266: hkn0615:421558:421558 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
297: hkn0627:1795158:1795158 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
374: hkn0713:477468:477468 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
166: hkn0521:1205036:1205036 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
299: hkn0627:1795186:1795186 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
119: hkn0506:845284:845284 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
119: hkn0506:845284:845284 [3] NCCL INFO P2P plugin IBext
264: hkn0615:421550:421550 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
117: hkn0506:845300:845300 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
117: hkn0506:845300:845300 [1] NCCL INFO P2P plugin IBext
267: hkn0615:421542:421542 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
267: hkn0615:421542:421542 [3] NCCL INFO P2P plugin IBext
298: hkn0627:1795166:1795166 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
265: hkn0615:421570:421570 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
265: hkn0615:421570:421570 [1] NCCL INFO P2P plugin IBext
372: hkn0713:477480:477480 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
373: hkn0713:477452:477452 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
116: hkn0506:845312:845312 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
116: hkn0506:845312:845312 [0] NCCL INFO P2P plugin IBext
 12: hkn0407:1823520:1823520 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 14: hkn0407:1823492:1823492 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 15: hkn0407:1823508:1823508 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 12: hkn0407:1823520:1823520 [0] NCCL INFO Using network IBext
 14: hkn0407:1823492:1823492 [2] NCCL INFO Using network IBext
 15: hkn0407:1823508:1823508 [3] NCCL INFO Using network IBext
 90: hkn0427:1142341:1142341 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 90: hkn0427:1142341:1142341 [2] NCCL INFO Using network IBext
375: hkn0713:477460:477460 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
375: hkn0713:477460:477460 [3] NCCL INFO P2P plugin IBext
296: hkn0627:1795174:1795174 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
296: hkn0627:1795174:1795174 [0] NCCL INFO P2P plugin IBext
165: hkn0521:1205024:1205024 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
266: hkn0615:421558:421558 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
266: hkn0615:421558:421558 [2] NCCL INFO P2P plugin IBext
297: hkn0627:1795158:1795158 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
297: hkn0627:1795158:1795158 [1] NCCL INFO P2P plugin IBext
374: hkn0713:477468:477468 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
374: hkn0713:477468:477468 [2] NCCL INFO P2P plugin IBext
166: hkn0521:1205036:1205036 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
166: hkn0521:1205036:1205036 [2] NCCL INFO P2P plugin IBext
299: hkn0627:1795186:1795186 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
299: hkn0627:1795186:1795186 [3] NCCL INFO P2P plugin IBext
264: hkn0615:421550:421550 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
264: hkn0615:421550:421550 [0] NCCL INFO P2P plugin IBext
117: hkn0506:845300:845300 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
119: hkn0506:845284:845284 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
117: hkn0506:845300:845300 [1] NCCL INFO Using network IBext
119: hkn0506:845284:845284 [3] NCCL INFO Using network IBext
116: hkn0506:845312:845312 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
116: hkn0506:845312:845312 [0] NCCL INFO Using network IBext
167: hkn0521:1205008:1205008 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
 89: hkn0427:1142369:1142369 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 89: hkn0427:1142369:1142369 [1] NCCL INFO Using network IBext
 13: hkn0407:1823500:1823500 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 13: hkn0407:1823500:1823500 [1] NCCL INFO Using network IBext
372: hkn0713:477480:477480 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
372: hkn0713:477480:477480 [0] NCCL INFO P2P plugin IBext
298: hkn0627:1795166:1795166 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
298: hkn0627:1795166:1795166 [2] NCCL INFO P2P plugin IBext
373: hkn0713:477452:477452 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
373: hkn0713:477452:477452 [1] NCCL INFO P2P plugin IBext
  9: hkn0405:3214182:3214182 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 10: hkn0405:3214170:3214170 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 11: hkn0405:3214162:3214162 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
118: hkn0506:845292:845292 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
118: hkn0506:845292:845292 [2] NCCL INFO Using network IBext
164: hkn0521:1205016:1205016 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
 88: hkn0427:1142349:1142349 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
374: hkn0713:477468:477468 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
374: hkn0713:477468:477468 [2] NCCL INFO Using network IBext
264: hkn0615:421550:421550 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
264: hkn0615:421550:421550 [0] NCCL INFO Using network IBext
266: hkn0615:421558:421558 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
266: hkn0615:421558:421558 [2] NCCL INFO Using network IBext
299: hkn0627:1795186:1795186 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
299: hkn0627:1795186:1795186 [3] NCCL INFO Using network IBext
297: hkn0627:1795158:1795158 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
297: hkn0627:1795158:1795158 [1] NCCL INFO Using network IBext
165: hkn0521:1205024:1205024 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
165: hkn0521:1205024:1205024 [1] NCCL INFO P2P plugin IBext
 91: hkn0427:1142357:1142357 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
  8: hkn0405:3214154:3214154 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
298: hkn0627:1795166:1795166 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
298: hkn0627:1795166:1795166 [2] NCCL INFO Using network IBext
373: hkn0713:477452:477452 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
373: hkn0713:477452:477452 [1] NCCL INFO Using network IBext
372: hkn0713:477480:477480 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
372: hkn0713:477480:477480 [0] NCCL INFO Using network IBext
167: hkn0521:1205008:1205008 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
167: hkn0521:1205008:1205008 [3] NCCL INFO P2P plugin IBext
265: hkn0615:421570:421570 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
265: hkn0615:421570:421570 [1] NCCL INFO Using network IBext
267: hkn0615:421542:421542 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
267: hkn0615:421542:421542 [3] NCCL INFO Using network IBext
  9: hkn0405:3214182:3214182 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  9: hkn0405:3214182:3214182 [1] NCCL INFO P2P plugin IBext
 10: hkn0405:3214170:3214170 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 10: hkn0405:3214170:3214170 [2] NCCL INFO P2P plugin IBext
 11: hkn0405:3214162:3214162 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 11: hkn0405:3214162:3214162 [3] NCCL INFO P2P plugin IBext
164: hkn0521:1205016:1205016 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
164: hkn0521:1205016:1205016 [0] NCCL INFO P2P plugin IBext
375: hkn0713:477460:477460 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
375: hkn0713:477460:477460 [3] NCCL INFO Using network IBext
296: hkn0627:1795174:1795174 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
296: hkn0627:1795174:1795174 [0] NCCL INFO Using network IBext
165: hkn0521:1205024:1205024 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
167: hkn0521:1205008:1205008 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
165: hkn0521:1205024:1205024 [1] NCCL INFO Using network IBext
167: hkn0521:1205008:1205008 [3] NCCL INFO Using network IBext
 88: hkn0427:1142349:1142349 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 88: hkn0427:1142349:1142349 [0] NCCL INFO P2P plugin IBext
 91: hkn0427:1142357:1142357 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 91: hkn0427:1142357:1142357 [3] NCCL INFO P2P plugin IBext
  8: hkn0405:3214154:3214154 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  8: hkn0405:3214154:3214154 [0] NCCL INFO P2P plugin IBext
166: hkn0521:1205036:1205036 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
166: hkn0521:1205036:1205036 [2] NCCL INFO Using network IBext
164: hkn0521:1205016:1205016 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
164: hkn0521:1205016:1205016 [0] NCCL INFO Using network IBext
 88: hkn0427:1142349:1142349 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 88: hkn0427:1142349:1142349 [0] NCCL INFO Using network IBext
 23: hkn0409:2592874:2592874 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
 91: hkn0427:1142357:1142357 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 91: hkn0427:1142357:1142357 [3] NCCL INFO Using network IBext
  8: hkn0405:3214154:3214154 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  8: hkn0405:3214154:3214154 [0] NCCL INFO Using network IBext
213: hkn0535:2406206:2406206 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
 23: hkn0409:2592874:2592874 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 23: hkn0409:2592874:2592874 [3] NCCL INFO P2P plugin IBext
215: hkn0535:2406222:2406222 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
 10: hkn0405:3214170:3214170 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 10: hkn0405:3214170:3214170 [2] NCCL INFO Using network IBext
  9: hkn0405:3214182:3214182 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  9: hkn0405:3214182:3214182 [1] NCCL INFO Using network IBext
 11: hkn0405:3214162:3214162 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 11: hkn0405:3214162:3214162 [3] NCCL INFO Using network IBext
214: hkn0535:2406234:2406234 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
212: hkn0535:2406214:2406214 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
 21: hkn0409:2592894:2592894 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
310: hkn0630:1605686:1605686 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
311: hkn0630:1605706:1605706 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
308: hkn0630:1605678:1605678 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
 22: hkn0409:2592882:2592882 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
 68: hkn0422:4160376:4160376 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 20: hkn0409:2592866:2592866 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
213: hkn0535:2406206:2406206 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
213: hkn0535:2406206:2406206 [1] NCCL INFO P2P plugin IBext
309: hkn0630:1605694:1605694 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
124: hkn0508:3146346:3146346 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
215: hkn0535:2406222:2406222 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
215: hkn0535:2406222:2406222 [3] NCCL INFO P2P plugin IBext
 70: hkn0422:4160364:4160364 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 71: hkn0422:4160348:4160348 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 69: hkn0422:4160356:4160356 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
214: hkn0535:2406234:2406234 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
214: hkn0535:2406234:2406234 [2] NCCL INFO P2P plugin IBext
212: hkn0535:2406214:2406214 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
212: hkn0535:2406214:2406214 [0] NCCL INFO P2P plugin IBext
310: hkn0630:1605686:1605686 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
310: hkn0630:1605686:1605686 [2] NCCL INFO P2P plugin IBext
311: hkn0630:1605706:1605706 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
311: hkn0630:1605706:1605706 [3] NCCL INFO P2P plugin IBext
126: hkn0508:3146354:3146354 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
308: hkn0630:1605678:1605678 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
308: hkn0630:1605678:1605678 [0] NCCL INFO P2P plugin IBext
 68: hkn0422:4160376:4160376 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 68: hkn0422:4160376:4160376 [0] NCCL INFO P2P plugin IBext
 21: hkn0409:2592894:2592894 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 21: hkn0409:2592894:2592894 [1] NCCL INFO P2P plugin IBext
315: hkn0631:1029032:1029032 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
 22: hkn0409:2592882:2592882 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 22: hkn0409:2592882:2592882 [2] NCCL INFO P2P plugin IBext
125: hkn0508:3146338:3146338 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
127: hkn0508:3146366:3146366 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
 35: hkn0412:2269608:2269608 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 20: hkn0409:2592866:2592866 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 20: hkn0409:2592866:2592866 [0] NCCL INFO P2P plugin IBext
 67: hkn0421:2189234:2189234 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
122: hkn0507:3194301:3194301 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
309: hkn0630:1605694:1605694 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
309: hkn0630:1605694:1605694 [1] NCCL INFO P2P plugin IBext
124: hkn0508:3146346:3146346 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
124: hkn0508:3146346:3146346 [0] NCCL INFO P2P plugin IBext
215: hkn0535:2406222:2406222 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
215: hkn0535:2406222:2406222 [3] NCCL INFO Using network IBext
212: hkn0535:2406214:2406214 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
214: hkn0535:2406234:2406234 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
212: hkn0535:2406214:2406214 [0] NCCL INFO Using network IBext
214: hkn0535:2406234:2406234 [2] NCCL INFO Using network IBext
 65: hkn0421:2189204:2189204 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
 66: hkn0421:2189220:2189220 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
451: hkn0734:1163769:1163769 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
176: hkn0525:994034:994034 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
 23: hkn0409:2592874:2592874 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 23: hkn0409:2592874:2592874 [3] NCCL INFO Using network IBext
 71: hkn0422:4160348:4160348 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 71: hkn0422:4160348:4160348 [3] NCCL INFO P2P plugin IBext
 70: hkn0422:4160364:4160364 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 70: hkn0422:4160364:4160364 [2] NCCL INFO P2P plugin IBext
 32: hkn0412:2269616:2269616 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 69: hkn0422:4160356:4160356 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 69: hkn0422:4160356:4160356 [1] NCCL INFO P2P plugin IBext
 20: hkn0409:2592866:2592866 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 22: hkn0409:2592882:2592882 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 20: hkn0409:2592866:2592866 [0] NCCL INFO Using network IBext
 22: hkn0409:2592882:2592882 [2] NCCL INFO Using network IBext
 21: hkn0409:2592894:2592894 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 21: hkn0409:2592894:2592894 [1] NCCL INFO Using network IBext
 64: hkn0421:2189212:2189212 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
314: hkn0631:1029016:1029016 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
315: hkn0631:1029032:1029032 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
315: hkn0631:1029032:1029032 [3] NCCL INFO P2P plugin IBext
179: hkn0525:994006:994006 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
312: hkn0631:1029044:1029044 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
 35: hkn0412:2269608:2269608 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 35: hkn0412:2269608:2269608 [3] NCCL INFO P2P plugin IBext
 34: hkn0412:2269636:2269636 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
450: hkn0734:1163781:1163781 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
 67: hkn0421:2189234:2189234 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 67: hkn0421:2189234:2189234 [3] NCCL INFO P2P plugin IBext
125: hkn0508:3146338:3146338 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
125: hkn0508:3146338:3146338 [1] NCCL INFO P2P plugin IBext
127: hkn0508:3146366:3146366 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
127: hkn0508:3146366:3146366 [3] NCCL INFO P2P plugin IBext
121: hkn0507:3194285:3194285 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
126: hkn0508:3146354:3146354 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
126: hkn0508:3146354:3146354 [2] NCCL INFO P2P plugin IBext
334: hkn0636:1661541:1661541 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
177: hkn0525:994014:994014 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
313: hkn0631:1029024:1029024 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
213: hkn0535:2406206:2406206 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
213: hkn0535:2406206:2406206 [1] NCCL INFO Using network IBext
120: hkn0507:3194293:3194293 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
309: hkn0630:1605694:1605694 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
309: hkn0630:1605694:1605694 [1] NCCL INFO Using network IBext
122: hkn0507:3194301:3194301 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
122: hkn0507:3194301:3194301 [2] NCCL INFO P2P plugin IBext
448: hkn0734:1163761:1163761 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
 33: hkn0412:2269624:2269624 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
335: hkn0636:1661521:1661521 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
123: hkn0507:3194313:3194313 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
178: hkn0525:994022:994022 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
449: hkn0734:1163753:1163753 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
451: hkn0734:1163769:1163769 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
451: hkn0734:1163769:1163769 [3] NCCL INFO P2P plugin IBext
176: hkn0525:994034:994034 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
176: hkn0525:994034:994034 [0] NCCL INFO P2P plugin IBext
 65: hkn0421:2189204:2189204 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 65: hkn0421:2189204:2189204 [1] NCCL INFO P2P plugin IBext
 66: hkn0421:2189220:2189220 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 66: hkn0421:2189220:2189220 [2] NCCL INFO P2P plugin IBext
 32: hkn0412:2269616:2269616 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 32: hkn0412:2269616:2269616 [0] NCCL INFO P2P plugin IBext
 71: hkn0422:4160348:4160348 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 69: hkn0422:4160356:4160356 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 70: hkn0422:4160364:4160364 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 71: hkn0422:4160348:4160348 [3] NCCL INFO Using network IBext
 69: hkn0422:4160356:4160356 [1] NCCL INFO Using network IBext
 70: hkn0422:4160364:4160364 [2] NCCL INFO Using network IBext
 64: hkn0421:2189212:2189212 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 64: hkn0421:2189212:2189212 [0] NCCL INFO P2P plugin IBext
308: hkn0630:1605678:1605678 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
308: hkn0630:1605678:1605678 [0] NCCL INFO Using network IBext
314: hkn0631:1029016:1029016 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
314: hkn0631:1029016:1029016 [2] NCCL INFO P2P plugin IBext
310: hkn0630:1605686:1605686 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
333: hkn0636:1661529:1661529 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
310: hkn0630:1605686:1605686 [2] NCCL INFO Using network IBext
311: hkn0630:1605706:1605706 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
311: hkn0630:1605706:1605706 [3] NCCL INFO Using network IBext
179: hkn0525:994006:994006 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
179: hkn0525:994006:994006 [3] NCCL INFO P2P plugin IBext
312: hkn0631:1029044:1029044 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
312: hkn0631:1029044:1029044 [0] NCCL INFO P2P plugin IBext
 34: hkn0412:2269636:2269636 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 34: hkn0412:2269636:2269636 [2] NCCL INFO P2P plugin IBext
450: hkn0734:1163781:1163781 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
450: hkn0734:1163781:1163781 [2] NCCL INFO P2P plugin IBext
121: hkn0507:3194285:3194285 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
121: hkn0507:3194285:3194285 [1] NCCL INFO P2P plugin IBext
125: hkn0508:3146338:3146338 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
126: hkn0508:3146354:3146354 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
125: hkn0508:3146338:3146338 [1] NCCL INFO Using network IBext
 68: hkn0422:4160376:4160376 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
126: hkn0508:3146354:3146354 [2] NCCL INFO Using network IBext
 68: hkn0422:4160376:4160376 [0] NCCL INFO Using network IBext
127: hkn0508:3146366:3146366 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
127: hkn0508:3146366:3146366 [3] NCCL INFO Using network IBext
334: hkn0636:1661541:1661541 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
334: hkn0636:1661541:1661541 [2] NCCL INFO P2P plugin IBext
332: hkn0636:1661513:1661513 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
355: hkn0707:4027153:4027153 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
177: hkn0525:994014:994014 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
177: hkn0525:994014:994014 [1] NCCL INFO P2P plugin IBext
313: hkn0631:1029024:1029024 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
313: hkn0631:1029024:1029024 [1] NCCL INFO P2P plugin IBext
120: hkn0507:3194293:3194293 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
120: hkn0507:3194293:3194293 [0] NCCL INFO P2P plugin IBext
448: hkn0734:1163761:1163761 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
448: hkn0734:1163761:1163761 [0] NCCL INFO P2P plugin IBext
 33: hkn0412:2269624:2269624 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 33: hkn0412:2269624:2269624 [1] NCCL INFO P2P plugin IBext
124: hkn0508:3146346:3146346 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
124: hkn0508:3146346:3146346 [0] NCCL INFO Using network IBext
335: hkn0636:1661521:1661521 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
335: hkn0636:1661521:1661521 [3] NCCL INFO P2P plugin IBext
123: hkn0507:3194313:3194313 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
123: hkn0507:3194313:3194313 [3] NCCL INFO P2P plugin IBext
178: hkn0525:994022:994022 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
178: hkn0525:994022:994022 [2] NCCL INFO P2P plugin IBext
449: hkn0734:1163753:1163753 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
449: hkn0734:1163753:1163753 [1] NCCL INFO P2P plugin IBext
 40: hkn0414:1988896:1988896 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
 32: hkn0412:2269616:2269616 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 32: hkn0412:2269616:2269616 [0] NCCL INFO Using network IBext
 34: hkn0412:2269636:2269636 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 34: hkn0412:2269636:2269636 [2] NCCL INFO Using network IBext
 64: hkn0421:2189212:2189212 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 64: hkn0421:2189212:2189212 [0] NCCL INFO Using network IBext
 65: hkn0421:2189204:2189204 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 66: hkn0421:2189220:2189220 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 65: hkn0421:2189204:2189204 [1] NCCL INFO Using network IBext
 66: hkn0421:2189220:2189220 [2] NCCL INFO Using network IBext
312: hkn0631:1029044:1029044 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
312: hkn0631:1029044:1029044 [0] NCCL INFO Using network IBext
314: hkn0631:1029016:1029016 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
314: hkn0631:1029016:1029016 [2] NCCL INFO Using network IBext
354: hkn0707:4027145:4027145 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
313: hkn0631:1029024:1029024 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
313: hkn0631:1029024:1029024 [1] NCCL INFO Using network IBext
177: hkn0525:994014:994014 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
179: hkn0525:994006:994006 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
147: hkn0513:3020216:3020216 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
177: hkn0525:994014:994014 [1] NCCL INFO Using network IBext
179: hkn0525:994006:994006 [3] NCCL INFO Using network IBext
450: hkn0734:1163781:1163781 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
450: hkn0734:1163781:1163781 [2] NCCL INFO Using network IBext
448: hkn0734:1163761:1163761 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
448: hkn0734:1163761:1163761 [0] NCCL INFO Using network IBext
 33: hkn0412:2269624:2269624 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 33: hkn0412:2269624:2269624 [1] NCCL INFO Using network IBext
121: hkn0507:3194285:3194285 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
121: hkn0507:3194285:3194285 [1] NCCL INFO Using network IBext
 35: hkn0412:2269608:2269608 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 35: hkn0412:2269608:2269608 [3] NCCL INFO Using network IBext
333: hkn0636:1661529:1661529 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
333: hkn0636:1661529:1661529 [1] NCCL INFO P2P plugin IBext
 67: hkn0421:2189234:2189234 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 67: hkn0421:2189234:2189234 [3] NCCL INFO Using network IBext
315: hkn0631:1029032:1029032 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
315: hkn0631:1029032:1029032 [3] NCCL INFO Using network IBext
123: hkn0507:3194313:3194313 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
178: hkn0525:994022:994022 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
123: hkn0507:3194313:3194313 [3] NCCL INFO Using network IBext
178: hkn0525:994022:994022 [2] NCCL INFO Using network IBext
355: hkn0707:4027153:4027153 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
355: hkn0707:4027153:4027153 [3] NCCL INFO P2P plugin IBext
120: hkn0507:3194293:3194293 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
120: hkn0507:3194293:3194293 [0] NCCL INFO Using network IBext
332: hkn0636:1661513:1661513 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
332: hkn0636:1661513:1661513 [0] NCCL INFO P2P plugin IBext
449: hkn0734:1163753:1163753 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
449: hkn0734:1163753:1163753 [1] NCCL INFO Using network IBext
122: hkn0507:3194301:3194301 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
122: hkn0507:3194301:3194301 [2] NCCL INFO Using network IBext
335: hkn0636:1661521:1661521 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
335: hkn0636:1661521:1661521 [3] NCCL INFO Using network IBext
 43: hkn0414:1988916:1988916 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
352: hkn0707:4027165:4027165 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
 41: hkn0414:1988888:1988888 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
377: hkn0714:439253:439253 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
 58: hkn0419:1551505:1551505 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
221: hkn0602:3370890:3370890 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
144: hkn0513:3020204:3020204 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
451: hkn0734:1163769:1163769 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
451: hkn0734:1163769:1163769 [3] NCCL INFO Using network IBext
353: hkn0707:4027137:4027137 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
 40: hkn0414:1988896:1988896 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 40: hkn0414:1988896:1988896 [0] NCCL INFO P2P plugin IBext
176: hkn0525:994034:994034 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
176: hkn0525:994034:994034 [0] NCCL INFO Using network IBext
333: hkn0636:1661529:1661529 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
333: hkn0636:1661529:1661529 [1] NCCL INFO Using network IBext
145: hkn0513:3020188:3020188 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
354: hkn0707:4027145:4027145 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
354: hkn0707:4027145:4027145 [2] NCCL INFO P2P plugin IBext
332: hkn0636:1661513:1661513 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
146: hkn0513:3020196:3020196 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
332: hkn0636:1661513:1661513 [0] NCCL INFO Using network IBext
147: hkn0513:3020216:3020216 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
147: hkn0513:3020216:3020216 [3] NCCL INFO P2P plugin IBext
 42: hkn0414:1988904:1988904 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
 74: hkn0423:1712179:1712179 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 72: hkn0423:1712171:1712171 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
379: hkn0714:439265:439265 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
 73: hkn0423:1712163:1712163 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
376: hkn0714:439237:439237 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
334: hkn0636:1661541:1661541 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
334: hkn0636:1661541:1661541 [2] NCCL INFO Using network IBext
 56: hkn0419:1551497:1551497 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
 59: hkn0419:1551517:1551517 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
271: hkn0616:412189:412189 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
365: hkn0711:591174:591174 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
352: hkn0707:4027165:4027165 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
352: hkn0707:4027165:4027165 [0] NCCL INFO P2P plugin IBext
 43: hkn0414:1988916:1988916 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 43: hkn0414:1988916:1988916 [3] NCCL INFO P2P plugin IBext
364: hkn0711:591166:591166 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
366: hkn0711:591185:591185 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
367: hkn0711:591158:591158 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
 58: hkn0419:1551505:1551505 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 58: hkn0419:1551505:1551505 [2] NCCL INFO P2P plugin IBext
378: hkn0714:439245:439245 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
 57: hkn0419:1551489:1551489 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
377: hkn0714:439253:439253 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
377: hkn0714:439253:439253 [1] NCCL INFO P2P plugin IBext
221: hkn0602:3370890:3370890 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
221: hkn0602:3370890:3370890 [1] NCCL INFO P2P plugin IBext
 41: hkn0414:1988888:1988888 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 41: hkn0414:1988888:1988888 [1] NCCL INFO P2P plugin IBext
268: hkn0616:412169:412169 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
353: hkn0707:4027137:4027137 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
353: hkn0707:4027137:4027137 [1] NCCL INFO P2P plugin IBext
 95: hkn0428:674595:674595 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
115: hkn0505:2310997:2310997 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
144: hkn0513:3020204:3020204 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
144: hkn0513:3020204:3020204 [0] NCCL INFO P2P plugin IBext
145: hkn0513:3020188:3020188 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
145: hkn0513:3020188:3020188 [1] NCCL INFO P2P plugin IBext
354: hkn0707:4027145:4027145 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
354: hkn0707:4027145:4027145 [2] NCCL INFO Using network IBext
146: hkn0513:3020196:3020196 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
146: hkn0513:3020196:3020196 [2] NCCL INFO P2P plugin IBext
 42: hkn0414:1988904:1988904 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 42: hkn0414:1988904:1988904 [2] NCCL INFO P2P plugin IBext
 74: hkn0423:1712179:1712179 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 74: hkn0423:1712179:1712179 [2] NCCL INFO P2P plugin IBext
 72: hkn0423:1712171:1712171 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 72: hkn0423:1712171:1712171 [0] NCCL INFO P2P plugin IBext
379: hkn0714:439265:439265 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
379: hkn0714:439265:439265 [3] NCCL INFO P2P plugin IBext
 73: hkn0423:1712163:1712163 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 73: hkn0423:1712163:1712163 [1] NCCL INFO P2P plugin IBext
 94: hkn0428:674575:674575 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
352: hkn0707:4027165:4027165 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
352: hkn0707:4027165:4027165 [0] NCCL INFO Using network IBext
113: hkn0505:2311005:2311005 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
376: hkn0714:439237:439237 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
376: hkn0714:439237:439237 [0] NCCL INFO P2P plugin IBext
355: hkn0707:4027153:4027153 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
355: hkn0707:4027153:4027153 [3] NCCL INFO Using network IBext
158: hkn0516:2923196:2923196 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 75: hkn0423:1712190:1712190 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 56: hkn0419:1551497:1551497 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 56: hkn0419:1551497:1551497 [0] NCCL INFO P2P plugin IBext
271: hkn0616:412189:412189 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
271: hkn0616:412189:412189 [3] NCCL INFO P2P plugin IBext
353: hkn0707:4027137:4027137 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
353: hkn0707:4027137:4027137 [1] NCCL INFO Using network IBext
 59: hkn0419:1551517:1551517 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 59: hkn0419:1551517:1551517 [3] NCCL INFO P2P plugin IBext
 92: hkn0428:674583:674583 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
 41: hkn0414:1988888:1988888 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 43: hkn0414:1988916:1988916 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 41: hkn0414:1988888:1988888 [1] NCCL INFO Using network IBext
 43: hkn0414:1988916:1988916 [3] NCCL INFO Using network IBext
159: hkn0516:2923224:2923224 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
365: hkn0711:591174:591174 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
365: hkn0711:591174:591174 [1] NCCL INFO P2P plugin IBext
378: hkn0714:439245:439245 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
378: hkn0714:439245:439245 [2] NCCL INFO P2P plugin IBext
112: hkn0505:2311025:2311025 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
114: hkn0505:2311013:2311013 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
366: hkn0711:591185:591185 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
366: hkn0711:591185:591185 [2] NCCL INFO P2P plugin IBext
 57: hkn0419:1551489:1551489 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 57: hkn0419:1551489:1551489 [1] NCCL INFO P2P plugin IBext
 42: hkn0414:1988904:1988904 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 42: hkn0414:1988904:1988904 [2] NCCL INFO Using network IBext
268: hkn0616:412169:412169 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
268: hkn0616:412169:412169 [0] NCCL INFO P2P plugin IBext
367: hkn0711:591158:591158 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
367: hkn0711:591158:591158 [3] NCCL INFO P2P plugin IBext
364: hkn0711:591166:591166 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
364: hkn0711:591166:591166 [0] NCCL INFO P2P plugin IBext
115: hkn0505:2310997:2310997 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
115: hkn0505:2310997:2310997 [3] NCCL INFO P2P plugin IBext
 95: hkn0428:674595:674595 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 95: hkn0428:674595:674595 [3] NCCL INFO P2P plugin IBext
220: hkn0602:3370918:3370918 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
 40: hkn0414:1988896:1988896 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 40: hkn0414:1988896:1988896 [0] NCCL INFO Using network IBext
270: hkn0616:412161:412161 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
146: hkn0513:3020196:3020196 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
146: hkn0513:3020196:3020196 [2] NCCL INFO Using network IBext
144: hkn0513:3020204:3020204 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
144: hkn0513:3020204:3020204 [0] NCCL INFO Using network IBext
145: hkn0513:3020188:3020188 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
145: hkn0513:3020188:3020188 [1] NCCL INFO Using network IBext
147: hkn0513:3020216:3020216 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
147: hkn0513:3020216:3020216 [3] NCCL INFO Using network IBext
157: hkn0516:2923212:2923212 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 93: hkn0428:674567:674567 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
222: hkn0602:3370898:3370898 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
376: hkn0714:439237:439237 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
376: hkn0714:439237:439237 [0] NCCL INFO Using network IBext
379: hkn0714:439265:439265 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
379: hkn0714:439265:439265 [3] NCCL INFO Using network IBext
269: hkn0616:412177:412177 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
 94: hkn0428:674575:674575 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 94: hkn0428:674575:674575 [2] NCCL INFO P2P plugin IBext
113: hkn0505:2311005:2311005 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
113: hkn0505:2311005:2311005 [1] NCCL INFO P2P plugin IBext
 75: hkn0423:1712190:1712190 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 75: hkn0423:1712190:1712190 [3] NCCL INFO P2P plugin IBext
223: hkn0602:3370906:3370906 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
378: hkn0714:439245:439245 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
378: hkn0714:439245:439245 [2] NCCL INFO Using network IBext
 50: hkn0417:2274860:2274860 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
158: hkn0516:2923196:2923196 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
158: hkn0516:2923196:2923196 [2] NCCL INFO P2P plugin IBext
 56: hkn0419:1551497:1551497 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 56: hkn0419:1551497:1551497 [0] NCCL INFO Using network IBext
 59: hkn0419:1551517:1551517 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 59: hkn0419:1551517:1551517 [3] NCCL INFO Using network IBext
 51: hkn0417:2274868:2274868 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
 57: hkn0419:1551489:1551489 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 57: hkn0419:1551489:1551489 [1] NCCL INFO Using network IBext
 92: hkn0428:674583:674583 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 92: hkn0428:674583:674583 [0] NCCL INFO P2P plugin IBext
114: hkn0505:2311013:2311013 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
114: hkn0505:2311013:2311013 [2] NCCL INFO P2P plugin IBext
377: hkn0714:439253:439253 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
377: hkn0714:439253:439253 [1] NCCL INFO Using network IBext
159: hkn0516:2923224:2923224 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
159: hkn0516:2923224:2923224 [3] NCCL INFO P2P plugin IBext
156: hkn0516:2923204:2923204 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
268: hkn0616:412169:412169 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
268: hkn0616:412169:412169 [0] NCCL INFO Using network IBext
 58: hkn0419:1551505:1551505 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
112: hkn0505:2311025:2311025 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
112: hkn0505:2311025:2311025 [0] NCCL INFO P2P plugin IBext
 58: hkn0419:1551505:1551505 [2] NCCL INFO Using network IBext
 49: hkn0417:2274876:2274876 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
367: hkn0711:591158:591158 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
367: hkn0711:591158:591158 [3] NCCL INFO Using network IBext
364: hkn0711:591166:591166 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
364: hkn0711:591166:591166 [0] NCCL INFO Using network IBext
220: hkn0602:3370918:3370918 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
220: hkn0602:3370918:3370918 [0] NCCL INFO P2P plugin IBext
270: hkn0616:412161:412161 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
270: hkn0616:412161:412161 [2] NCCL INFO P2P plugin IBext
221: hkn0602:3370890:3370890 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
221: hkn0602:3370890:3370890 [1] NCCL INFO Using network IBext
157: hkn0516:2923212:2923212 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
157: hkn0516:2923212:2923212 [1] NCCL INFO P2P plugin IBext
222: hkn0602:3370898:3370898 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
222: hkn0602:3370898:3370898 [2] NCCL INFO P2P plugin IBext
 93: hkn0428:674567:674567 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 93: hkn0428:674567:674567 [1] NCCL INFO P2P plugin IBext
269: hkn0616:412177:412177 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
269: hkn0616:412177:412177 [1] NCCL INFO P2P plugin IBext
113: hkn0505:2311005:2311005 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
113: hkn0505:2311005:2311005 [1] NCCL INFO Using network IBext
223: hkn0602:3370906:3370906 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
223: hkn0602:3370906:3370906 [3] NCCL INFO P2P plugin IBext
 50: hkn0417:2274860:2274860 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 50: hkn0417:2274860:2274860 [2] NCCL INFO P2P plugin IBext
 94: hkn0428:674575:674575 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 94: hkn0428:674575:674575 [2] NCCL INFO Using network IBext
114: hkn0505:2311013:2311013 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
 92: hkn0428:674583:674583 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 92: hkn0428:674583:674583 [0] NCCL INFO Using network IBext
114: hkn0505:2311013:2311013 [2] NCCL INFO Using network IBext
 72: hkn0423:1712171:1712171 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 72: hkn0423:1712171:1712171 [0] NCCL INFO Using network IBext
 73: hkn0423:1712163:1712163 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 73: hkn0423:1712163:1712163 [1] NCCL INFO Using network IBext
 75: hkn0423:1712190:1712190 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 75: hkn0423:1712190:1712190 [3] NCCL INFO Using network IBext
 74: hkn0423:1712179:1712179 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 74: hkn0423:1712179:1712179 [2] NCCL INFO Using network IBext
112: hkn0505:2311025:2311025 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
112: hkn0505:2311025:2311025 [0] NCCL INFO Using network IBext
 51: hkn0417:2274868:2274868 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 51: hkn0417:2274868:2274868 [3] NCCL INFO P2P plugin IBext
271: hkn0616:412189:412189 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
271: hkn0616:412189:412189 [3] NCCL INFO Using network IBext
 48: hkn0417:2274888:2274888 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
220: hkn0602:3370918:3370918 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
220: hkn0602:3370918:3370918 [0] NCCL INFO Using network IBext
270: hkn0616:412161:412161 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
270: hkn0616:412161:412161 [2] NCCL INFO Using network IBext
159: hkn0516:2923224:2923224 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
159: hkn0516:2923224:2923224 [3] NCCL INFO Using network IBext
365: hkn0711:591174:591174 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
365: hkn0711:591174:591174 [1] NCCL INFO Using network IBext
156: hkn0516:2923204:2923204 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
156: hkn0516:2923204:2923204 [0] NCCL INFO P2P plugin IBext
366: hkn0711:591185:591185 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
366: hkn0711:591185:591185 [2] NCCL INFO Using network IBext
 49: hkn0417:2274876:2274876 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 49: hkn0417:2274876:2274876 [1] NCCL INFO P2P plugin IBext
157: hkn0516:2923212:2923212 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
222: hkn0602:3370898:3370898 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
157: hkn0516:2923212:2923212 [1] NCCL INFO Using network IBext
222: hkn0602:3370898:3370898 [2] NCCL INFO Using network IBext
 93: hkn0428:674567:674567 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 93: hkn0428:674567:674567 [1] NCCL INFO Using network IBext
115: hkn0505:2310997:2310997 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
115: hkn0505:2310997:2310997 [3] NCCL INFO Using network IBext
 95: hkn0428:674595:674595 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
269: hkn0616:412177:412177 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
269: hkn0616:412177:412177 [1] NCCL INFO Using network IBext
 95: hkn0428:674595:674595 [3] NCCL INFO Using network IBext
223: hkn0602:3370906:3370906 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
223: hkn0602:3370906:3370906 [3] NCCL INFO Using network IBext
158: hkn0516:2923196:2923196 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
158: hkn0516:2923196:2923196 [2] NCCL INFO Using network IBext
156: hkn0516:2923204:2923204 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
156: hkn0516:2923204:2923204 [0] NCCL INFO Using network IBext
 48: hkn0417:2274888:2274888 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 48: hkn0417:2274888:2274888 [0] NCCL INFO P2P plugin IBext
498: hkn0812:701043:701043 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
 49: hkn0417:2274876:2274876 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 49: hkn0417:2274876:2274876 [1] NCCL INFO Using network IBext
263: hkn0613:909932:909932 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
246: hkn0608:492947:492947 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
262: hkn0613:909916:909916 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
260: hkn0613:909924:909924 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
497: hkn0812:701035:701035 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
245: hkn0608:492963:492963 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
247: hkn0608:492955:492955 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
261: hkn0613:909944:909944 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
 48: hkn0417:2274888:2274888 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 48: hkn0417:2274888:2274888 [0] NCCL INFO Using network IBext
499: hkn0812:701057:701057 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
244: hkn0608:492975:492975 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
 50: hkn0417:2274860:2274860 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 50: hkn0417:2274860:2274860 [2] NCCL INFO Using network IBext
 51: hkn0417:2274868:2274868 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 51: hkn0417:2274868:2274868 [3] NCCL INFO Using network IBext
496: hkn0812:701027:701027 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
427: hkn0727:1353022:1353022 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
425: hkn0727:1353010:1353010 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
426: hkn0727:1353002:1353002 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
498: hkn0812:701043:701043 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
498: hkn0812:701043:701043 [2] NCCL INFO P2P plugin IBext
246: hkn0608:492947:492947 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
246: hkn0608:492947:492947 [2] NCCL INFO P2P plugin IBext
263: hkn0613:909932:909932 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
263: hkn0613:909932:909932 [3] NCCL INFO P2P plugin IBext
424: hkn0727:1353001:1353001 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
262: hkn0613:909916:909916 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
262: hkn0613:909916:909916 [2] NCCL INFO P2P plugin IBext
438: hkn0731:1393942:1393942 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
260: hkn0613:909924:909924 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
260: hkn0613:909924:909924 [0] NCCL INFO P2P plugin IBext
247: hkn0608:492955:492955 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
247: hkn0608:492955:492955 [3] NCCL INFO P2P plugin IBext
245: hkn0608:492963:492963 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
245: hkn0608:492963:492963 [1] NCCL INFO P2P plugin IBext
261: hkn0613:909944:909944 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
261: hkn0613:909944:909944 [1] NCCL INFO P2P plugin IBext
497: hkn0812:701035:701035 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
497: hkn0812:701035:701035 [1] NCCL INFO P2P plugin IBext
499: hkn0812:701057:701057 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
499: hkn0812:701057:701057 [3] NCCL INFO P2P plugin IBext
204: hkn0532:932494:932494 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
244: hkn0608:492975:492975 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
244: hkn0608:492975:492975 [0] NCCL INFO P2P plugin IBext
496: hkn0812:701027:701027 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
496: hkn0812:701027:701027 [0] NCCL INFO P2P plugin IBext
427: hkn0727:1353022:1353022 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
427: hkn0727:1353022:1353022 [3] NCCL INFO P2P plugin IBext
425: hkn0727:1353010:1353010 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
425: hkn0727:1353010:1353010 [1] NCCL INFO P2P plugin IBext
436: hkn0731:1393962:1393962 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
426: hkn0727:1353002:1353002 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
426: hkn0727:1353002:1353002 [2] NCCL INFO P2P plugin IBext
439: hkn0731:1393950:1393950 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
424: hkn0727:1353001:1353001 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
424: hkn0727:1353001:1353001 [0] NCCL INFO P2P plugin IBext
438: hkn0731:1393942:1393942 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
438: hkn0731:1393942:1393942 [2] NCCL INFO P2P plugin IBext
260: hkn0613:909924:909924 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
260: hkn0613:909924:909924 [0] NCCL INFO Using network IBext
261: hkn0613:909944:909944 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
261: hkn0613:909944:909944 [1] NCCL INFO Using network IBext
194: hkn0529:1548054:1548054 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
247: hkn0608:492955:492955 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
247: hkn0608:492955:492955 [3] NCCL INFO Using network IBext
244: hkn0608:492975:492975 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
245: hkn0608:492963:492963 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
244: hkn0608:492975:492975 [0] NCCL INFO Using network IBext
245: hkn0608:492963:492963 [1] NCCL INFO Using network IBext
195: hkn0529:1548038:1548038 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
499: hkn0812:701057:701057 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
497: hkn0812:701035:701035 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
499: hkn0812:701057:701057 [3] NCCL INFO Using network IBext
497: hkn0812:701035:701035 [1] NCCL INFO Using network IBext
496: hkn0812:701027:701027 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
496: hkn0812:701027:701027 [0] NCCL INFO Using network IBext
204: hkn0532:932494:932494 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
204: hkn0532:932494:932494 [0] NCCL INFO P2P plugin IBext
192: hkn0529:1548046:1548046 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
161: hkn0520:2720094:2720094 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
426: hkn0727:1353002:1353002 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
424: hkn0727:1353001:1353001 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
426: hkn0727:1353002:1353002 [2] NCCL INFO Using network IBext
424: hkn0727:1353001:1353001 [0] NCCL INFO Using network IBext
498: hkn0812:701043:701043 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
498: hkn0812:701043:701043 [2] NCCL INFO Using network IBext
436: hkn0731:1393962:1393962 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
436: hkn0731:1393962:1393962 [0] NCCL INFO P2P plugin IBext
163: hkn0520:2720102:2720102 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
207: hkn0532:932502:932502 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
246: hkn0608:492947:492947 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
263: hkn0613:909932:909932 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
246: hkn0608:492947:492947 [2] NCCL INFO Using network IBext
263: hkn0613:909932:909932 [3] NCCL INFO Using network IBext
262: hkn0613:909916:909916 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
262: hkn0613:909916:909916 [2] NCCL INFO Using network IBext
437: hkn0731:1393941:1393941 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
439: hkn0731:1393950:1393950 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
439: hkn0731:1393950:1393950 [3] NCCL INFO P2P plugin IBext
205: hkn0532:932522:932522 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
194: hkn0529:1548054:1548054 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
194: hkn0529:1548054:1548054 [2] NCCL INFO P2P plugin IBext
162: hkn0520:2720086:2720086 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
193: hkn0529:1548066:1548066 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
406: hkn0721:2306498:2306498 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
 97: hkn0501:1335155:1335155 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 99: hkn0501:1335147:1335147 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
195: hkn0529:1548038:1548038 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
195: hkn0529:1548038:1548038 [3] NCCL INFO P2P plugin IBext
206: hkn0532:932510:932510 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
160: hkn0520:2720114:2720114 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
 96: hkn0501:1335139:1335139 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 98: hkn0501:1335167:1335167 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
161: hkn0520:2720094:2720094 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
161: hkn0520:2720094:2720094 [1] NCCL INFO P2P plugin IBext
407: hkn0721:2306506:2306506 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
436: hkn0731:1393962:1393962 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
439: hkn0731:1393950:1393950 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
439: hkn0731:1393950:1393950 [3] NCCL INFO Using network IBext
436: hkn0731:1393962:1393962 [0] NCCL INFO Using network IBext
425: hkn0727:1353010:1353010 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
427: hkn0727:1353022:1353022 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
425: hkn0727:1353010:1353010 [1] NCCL INFO Using network IBext
427: hkn0727:1353022:1353022 [3] NCCL INFO Using network IBext
163: hkn0520:2720102:2720102 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
163: hkn0520:2720102:2720102 [3] NCCL INFO P2P plugin IBext
207: hkn0532:932502:932502 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
207: hkn0532:932502:932502 [3] NCCL INFO P2P plugin IBext
192: hkn0529:1548046:1548046 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
192: hkn0529:1548046:1548046 [0] NCCL INFO P2P plugin IBext
437: hkn0731:1393941:1393941 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
437: hkn0731:1393941:1393941 [1] NCCL INFO P2P plugin IBext
438: hkn0731:1393942:1393942 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
438: hkn0731:1393942:1393942 [2] NCCL INFO Using network IBext
205: hkn0532:932522:932522 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
205: hkn0532:932522:932522 [1] NCCL INFO P2P plugin IBext
162: hkn0520:2720086:2720086 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
162: hkn0520:2720086:2720086 [2] NCCL INFO P2P plugin IBext
193: hkn0529:1548066:1548066 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
193: hkn0529:1548066:1548066 [1] NCCL INFO P2P plugin IBext
406: hkn0721:2306498:2306498 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
406: hkn0721:2306498:2306498 [2] NCCL INFO P2P plugin IBext
195: hkn0529:1548038:1548038 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
195: hkn0529:1548038:1548038 [3] NCCL INFO Using network IBext
405: hkn0721:2306514:2306514 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
206: hkn0532:932510:932510 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
206: hkn0532:932510:932510 [2] NCCL INFO P2P plugin IBext
404: hkn0721:2306526:2306526 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
192: hkn0529:1548046:1548046 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
192: hkn0529:1548046:1548046 [0] NCCL INFO Using network IBext
 99: hkn0501:1335147:1335147 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 99: hkn0501:1335147:1335147 [3] NCCL INFO P2P plugin IBext
 97: hkn0501:1335155:1335155 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 97: hkn0501:1335155:1335155 [1] NCCL INFO P2P plugin IBext
414: hkn0724:1723187:1723187 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
437: hkn0731:1393941:1393941 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
437: hkn0731:1393941:1393941 [1] NCCL INFO Using network IBext
160: hkn0520:2720114:2720114 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
160: hkn0520:2720114:2720114 [0] NCCL INFO P2P plugin IBext
 96: hkn0501:1335139:1335139 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 96: hkn0501:1335139:1335139 [0] NCCL INFO P2P plugin IBext
207: hkn0532:932502:932502 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
207: hkn0532:932502:932502 [3] NCCL INFO Using network IBext
204: hkn0532:932494:932494 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
204: hkn0532:932494:932494 [0] NCCL INFO Using network IBext
407: hkn0721:2306506:2306506 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
407: hkn0721:2306506:2306506 [3] NCCL INFO P2P plugin IBext
163: hkn0520:2720102:2720102 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
163: hkn0520:2720102:2720102 [3] NCCL INFO Using network IBext
 98: hkn0501:1335167:1335167 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 98: hkn0501:1335167:1335167 [2] NCCL INFO P2P plugin IBext
 79: hkn0424:2955186:2955186 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
205: hkn0532:932522:932522 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
205: hkn0532:932522:932522 [1] NCCL INFO Using network IBext
162: hkn0520:2720086:2720086 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
162: hkn0520:2720086:2720086 [2] NCCL INFO Using network IBext
193: hkn0529:1548066:1548066 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
193: hkn0529:1548066:1548066 [1] NCCL INFO Using network IBext
206: hkn0532:932510:932510 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
206: hkn0532:932510:932510 [2] NCCL INFO Using network IBext
 77: hkn0424:2955178:2955178 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
194: hkn0529:1548054:1548054 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
194: hkn0529:1548054:1548054 [2] NCCL INFO Using network IBext
413: hkn0724:1723172:1723172 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
160: hkn0520:2720114:2720114 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
160: hkn0520:2720114:2720114 [0] NCCL INFO Using network IBext
405: hkn0721:2306514:2306514 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
405: hkn0721:2306514:2306514 [1] NCCL INFO P2P plugin IBext
412: hkn0724:1723179:1723179 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
485: hkn0808:977901:977901 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
415: hkn0724:1723198:1723198 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
414: hkn0724:1723187:1723187 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
414: hkn0724:1723187:1723187 [2] NCCL INFO P2P plugin IBext
484: hkn0808:977921:977921 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
404: hkn0721:2306526:2306526 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
404: hkn0721:2306526:2306526 [0] NCCL INFO P2P plugin IBext
 76: hkn0424:2955170:2955170 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
 96: hkn0501:1335139:1335139 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 96: hkn0501:1335139:1335139 [0] NCCL INFO Using network IBext
 98: hkn0501:1335167:1335167 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 98: hkn0501:1335167:1335167 [2] NCCL INFO Using network IBext
486: hkn0808:977893:977893 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
407: hkn0721:2306506:2306506 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
407: hkn0721:2306506:2306506 [3] NCCL INFO Using network IBext
 79: hkn0424:2955186:2955186 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 79: hkn0424:2955186:2955186 [3] NCCL INFO P2P plugin IBext
161: hkn0520:2720094:2720094 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
161: hkn0520:2720094:2720094 [1] NCCL INFO Using network IBext
 78: hkn0424:2955198:2955198 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
405: hkn0721:2306514:2306514 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
405: hkn0721:2306514:2306514 [1] NCCL INFO Using network IBext
 77: hkn0424:2955178:2955178 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 77: hkn0424:2955178:2955178 [1] NCCL INFO P2P plugin IBext
404: hkn0721:2306526:2306526 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
404: hkn0721:2306526:2306526 [0] NCCL INFO Using network IBext
413: hkn0724:1723172:1723172 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
413: hkn0724:1723172:1723172 [1] NCCL INFO P2P plugin IBext
150: hkn0514:2957943:2957943 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
406: hkn0721:2306498:2306498 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
406: hkn0721:2306498:2306498 [2] NCCL INFO Using network IBext
487: hkn0808:977909:977909 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
485: hkn0808:977901:977901 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
485: hkn0808:977901:977901 [1] NCCL INFO P2P plugin IBext
412: hkn0724:1723179:1723179 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
412: hkn0724:1723179:1723179 [0] NCCL INFO P2P plugin IBext
415: hkn0724:1723198:1723198 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
415: hkn0724:1723198:1723198 [3] NCCL INFO P2P plugin IBext
148: hkn0514:2957971:2957971 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
484: hkn0808:977921:977921 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
484: hkn0808:977921:977921 [0] NCCL INFO P2P plugin IBext
 99: hkn0501:1335147:1335147 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 99: hkn0501:1335147:1335147 [3] NCCL INFO Using network IBext
 76: hkn0424:2955170:2955170 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 76: hkn0424:2955170:2955170 [0] NCCL INFO P2P plugin IBext
 97: hkn0501:1335155:1335155 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 97: hkn0501:1335155:1335155 [1] NCCL INFO Using network IBext
486: hkn0808:977893:977893 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
486: hkn0808:977893:977893 [2] NCCL INFO P2P plugin IBext
 87: hkn0426:821258:821258 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
 78: hkn0424:2955198:2955198 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 78: hkn0424:2955198:2955198 [2] NCCL INFO P2P plugin IBext
151: hkn0514:2957951:2957951 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
149: hkn0514:2957959:2957959 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
 77: hkn0424:2955178:2955178 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 77: hkn0424:2955178:2955178 [1] NCCL INFO Using network IBext
 84: hkn0426:821266:821266 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
150: hkn0514:2957943:2957943 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
150: hkn0514:2957943:2957943 [2] NCCL INFO P2P plugin IBext
412: hkn0724:1723179:1723179 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
413: hkn0724:1723172:1723172 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
413: hkn0724:1723172:1723172 [1] NCCL INFO Using network IBext
415: hkn0724:1723198:1723198 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
415: hkn0724:1723198:1723198 [3] NCCL INFO Using network IBext
412: hkn0724:1723179:1723179 [0] NCCL INFO Using network IBext
487: hkn0808:977909:977909 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
487: hkn0808:977909:977909 [3] NCCL INFO P2P plugin IBext
 86: hkn0426:821274:821274 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
 76: hkn0424:2955170:2955170 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 76: hkn0424:2955170:2955170 [0] NCCL INFO Using network IBext
 85: hkn0426:821286:821286 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
100: hkn0502:236295:236295 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
 82: hkn0425:2091279:2091279 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
148: hkn0514:2957971:2957971 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
148: hkn0514:2957971:2957971 [0] NCCL INFO P2P plugin IBext
414: hkn0724:1723187:1723187 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
414: hkn0724:1723187:1723187 [2] NCCL INFO Using network IBext
 80: hkn0425:2091287:2091287 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
486: hkn0808:977893:977893 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
486: hkn0808:977893:977893 [2] NCCL INFO Using network IBext
 78: hkn0424:2955198:2955198 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 78: hkn0424:2955198:2955198 [2] NCCL INFO Using network IBext
 79: hkn0424:2955186:2955186 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 79: hkn0424:2955186:2955186 [3] NCCL INFO Using network IBext
 83: hkn0425:2091271:2091271 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
174: hkn0524:1141010:1141010 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
216: hkn0601:124960:124960 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
 87: hkn0426:821258:821258 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 87: hkn0426:821258:821258 [3] NCCL INFO P2P plugin IBext
173: hkn0524:1141002:1141002 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
487: hkn0808:977909:977909 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
487: hkn0808:977909:977909 [3] NCCL INFO Using network IBext
151: hkn0514:2957951:2957951 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
151: hkn0514:2957951:2957951 [3] NCCL INFO P2P plugin IBext
446: hkn0733:1396572:1396572 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
103: hkn0502:236303:236303 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
444: hkn0733:1396588:1396588 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
102: hkn0502:236315:236315 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
149: hkn0514:2957959:2957959 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
149: hkn0514:2957959:2957959 [1] NCCL INFO P2P plugin IBext
 81: hkn0425:2091299:2091299 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
175: hkn0524:1141030:1141030 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
 84: hkn0426:821266:821266 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 84: hkn0426:821266:821266 [0] NCCL INFO P2P plugin IBext
 86: hkn0426:821274:821274 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 86: hkn0426:821274:821274 [2] NCCL INFO P2P plugin IBext
172: hkn0524:1141018:1141018 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
148: hkn0514:2957971:2957971 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
148: hkn0514:2957971:2957971 [0] NCCL INFO Using network IBext
484: hkn0808:977921:977921 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
484: hkn0808:977921:977921 [0] NCCL INFO Using network IBext
485: hkn0808:977901:977901 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
485: hkn0808:977901:977901 [1] NCCL INFO Using network IBext
 85: hkn0426:821286:821286 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 85: hkn0426:821286:821286 [1] NCCL INFO P2P plugin IBext
100: hkn0502:236295:236295 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
100: hkn0502:236295:236295 [0] NCCL INFO P2P plugin IBext
 82: hkn0425:2091279:2091279 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 82: hkn0425:2091279:2091279 [2] NCCL INFO P2P plugin IBext
219: hkn0601:124976:124976 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
 80: hkn0425:2091287:2091287 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 80: hkn0425:2091287:2091287 [0] NCCL INFO P2P plugin IBext
445: hkn0733:1396580:1396580 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
422: hkn0726:1555349:1555349 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
101: hkn0502:236287:236287 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
151: hkn0514:2957951:2957951 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
151: hkn0514:2957951:2957951 [3] NCCL INFO Using network IBext
 83: hkn0425:2091271:2091271 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 83: hkn0425:2091271:2091271 [3] NCCL INFO P2P plugin IBext
174: hkn0524:1141010:1141010 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
174: hkn0524:1141010:1141010 [2] NCCL INFO P2P plugin IBext
420: hkn0726:1555321:1555321 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
216: hkn0601:124960:124960 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
216: hkn0601:124960:124960 [0] NCCL INFO P2P plugin IBext
149: hkn0514:2957959:2957959 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
173: hkn0524:1141002:1141002 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
173: hkn0524:1141002:1141002 [1] NCCL INFO P2P plugin IBext
149: hkn0514:2957959:2957959 [1] NCCL INFO Using network IBext
218: hkn0601:124988:124988 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
423: hkn0726:1555329:1555329 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
446: hkn0733:1396572:1396572 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
446: hkn0733:1396572:1396572 [2] NCCL INFO P2P plugin IBext
103: hkn0502:236303:236303 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
103: hkn0502:236303:236303 [3] NCCL INFO P2P plugin IBext
444: hkn0733:1396588:1396588 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
444: hkn0733:1396588:1396588 [0] NCCL INFO P2P plugin IBext
217: hkn0601:124968:124968 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
447: hkn0733:1396600:1396600 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
102: hkn0502:236315:236315 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
102: hkn0502:236315:236315 [2] NCCL INFO P2P plugin IBext
 81: hkn0425:2091299:2091299 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 81: hkn0425:2091299:2091299 [1] NCCL INFO P2P plugin IBext
150: hkn0514:2957943:2957943 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
150: hkn0514:2957943:2957943 [2] NCCL INFO Using network IBext
 85: hkn0426:821286:821286 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 84: hkn0426:821266:821266 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 85: hkn0426:821286:821286 [1] NCCL INFO Using network IBext
 86: hkn0426:821274:821274 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 84: hkn0426:821266:821266 [0] NCCL INFO Using network IBext
 86: hkn0426:821274:821274 [2] NCCL INFO Using network IBext
421: hkn0726:1555337:1555337 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
175: hkn0524:1141030:1141030 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
175: hkn0524:1141030:1141030 [3] NCCL INFO P2P plugin IBext
172: hkn0524:1141018:1141018 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
172: hkn0524:1141018:1141018 [0] NCCL INFO P2P plugin IBext
219: hkn0601:124976:124976 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
219: hkn0601:124976:124976 [3] NCCL INFO P2P plugin IBext
445: hkn0733:1396580:1396580 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
445: hkn0733:1396580:1396580 [1] NCCL INFO P2P plugin IBext
422: hkn0726:1555349:1555349 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
422: hkn0726:1555349:1555349 [2] NCCL INFO P2P plugin IBext
 83: hkn0425:2091271:2091271 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 83: hkn0425:2091271:2091271 [3] NCCL INFO Using network IBext
101: hkn0502:236287:236287 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
101: hkn0502:236287:236287 [1] NCCL INFO P2P plugin IBext
420: hkn0726:1555321:1555321 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
420: hkn0726:1555321:1555321 [0] NCCL INFO P2P plugin IBext
 81: hkn0425:2091299:2091299 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 81: hkn0425:2091299:2091299 [1] NCCL INFO Using network IBext
218: hkn0601:124988:124988 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
218: hkn0601:124988:124988 [2] NCCL INFO P2P plugin IBext
102: hkn0502:236315:236315 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
102: hkn0502:236315:236315 [2] NCCL INFO Using network IBext
103: hkn0502:236303:236303 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
103: hkn0502:236303:236303 [3] NCCL INFO Using network IBext
423: hkn0726:1555329:1555329 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
423: hkn0726:1555329:1555329 [3] NCCL INFO P2P plugin IBext
 87: hkn0426:821258:821258 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 87: hkn0426:821258:821258 [3] NCCL INFO Using network IBext
217: hkn0601:124968:124968 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
217: hkn0601:124968:124968 [1] NCCL INFO P2P plugin IBext
447: hkn0733:1396600:1396600 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
447: hkn0733:1396600:1396600 [3] NCCL INFO P2P plugin IBext
172: hkn0524:1141018:1141018 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
175: hkn0524:1141030:1141030 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
175: hkn0524:1141030:1141030 [3] NCCL INFO Using network IBext
172: hkn0524:1141018:1141018 [0] NCCL INFO Using network IBext
421: hkn0726:1555337:1555337 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
421: hkn0726:1555337:1555337 [1] NCCL INFO P2P plugin IBext
101: hkn0502:236287:236287 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
101: hkn0502:236287:236287 [1] NCCL INFO Using network IBext
100: hkn0502:236295:236295 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
100: hkn0502:236295:236295 [0] NCCL INFO Using network IBext
219: hkn0601:124976:124976 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
219: hkn0601:124976:124976 [3] NCCL INFO Using network IBext
445: hkn0733:1396580:1396580 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
445: hkn0733:1396580:1396580 [1] NCCL INFO Using network IBext
218: hkn0601:124988:124988 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
218: hkn0601:124988:124988 [2] NCCL INFO Using network IBext
 80: hkn0425:2091287:2091287 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 80: hkn0425:2091287:2091287 [0] NCCL INFO Using network IBext
 82: hkn0425:2091279:2091279 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 82: hkn0425:2091279:2091279 [2] NCCL INFO Using network IBext
420: hkn0726:1555321:1555321 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
423: hkn0726:1555329:1555329 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
420: hkn0726:1555321:1555321 [0] NCCL INFO Using network IBext
423: hkn0726:1555329:1555329 [3] NCCL INFO Using network IBext
217: hkn0601:124968:124968 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
217: hkn0601:124968:124968 [1] NCCL INFO Using network IBext
 31: hkn0411:2323097:2323097 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
447: hkn0733:1396600:1396600 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
447: hkn0733:1396600:1396600 [3] NCCL INFO Using network IBext
216: hkn0601:124960:124960 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
216: hkn0601:124960:124960 [0] NCCL INFO Using network IBext
174: hkn0524:1141010:1141010 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
174: hkn0524:1141010:1141010 [2] NCCL INFO Using network IBext
421: hkn0726:1555337:1555337 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
421: hkn0726:1555337:1555337 [1] NCCL INFO Using network IBext
173: hkn0524:1141002:1141002 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
173: hkn0524:1141002:1141002 [1] NCCL INFO Using network IBext
446: hkn0733:1396572:1396572 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
446: hkn0733:1396572:1396572 [2] NCCL INFO Using network IBext
287: hkn0623:1879987:1879987 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
 28: hkn0411:2323081:2323081 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
444: hkn0733:1396588:1396588 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
444: hkn0733:1396588:1396588 [0] NCCL INFO Using network IBext
 30: hkn0411:2323089:2323089 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
284: hkn0623:1880015:1880015 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
 29: hkn0411:2323109:2323109 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
285: hkn0623:1880003:1880003 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
327: hkn0634:1528094:1528094 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
422: hkn0726:1555349:1555349 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
422: hkn0726:1555349:1555349 [2] NCCL INFO Using network IBext
 31: hkn0411:2323097:2323097 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 31: hkn0411:2323097:2323097 [3] NCCL INFO P2P plugin IBext
324: hkn0634:1528076:1528076 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
287: hkn0623:1879987:1879987 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
287: hkn0623:1879987:1879987 [3] NCCL INFO P2P plugin IBext
470: hkn0804:1212841:1212841 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
 28: hkn0411:2323081:2323081 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 28: hkn0411:2323081:2323081 [0] NCCL INFO P2P plugin IBext
286: hkn0623:1879995:1879995 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
 30: hkn0411:2323089:2323089 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 30: hkn0411:2323089:2323089 [2] NCCL INFO P2P plugin IBext
284: hkn0623:1880015:1880015 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
284: hkn0623:1880015:1880015 [0] NCCL INFO P2P plugin IBext
 29: hkn0411:2323109:2323109 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 29: hkn0411:2323109:2323109 [1] NCCL INFO P2P plugin IBext
285: hkn0623:1880003:1880003 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
285: hkn0623:1880003:1880003 [1] NCCL INFO P2P plugin IBext
327: hkn0634:1528094:1528094 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
327: hkn0634:1528094:1528094 [3] NCCL INFO P2P plugin IBext
326: hkn0634:1528060:1528060 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
325: hkn0634:1528068:1528068 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
510: hkn0816:382843:382843 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
442: hkn0732:1218881:1218881 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
324: hkn0634:1528076:1528076 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
324: hkn0634:1528076:1528076 [0] NCCL INFO P2P plugin IBext
470: hkn0804:1212841:1212841 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
470: hkn0804:1212841:1212841 [2] NCCL INFO P2P plugin IBext
431: hkn0728:1331257:1331257 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
 30: hkn0411:2323089:2323089 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 30: hkn0411:2323089:2323089 [2] NCCL INFO Using network IBext
469: hkn0804:1212849:1212849 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
 28: hkn0411:2323081:2323081 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 29: hkn0411:2323109:2323109 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 28: hkn0411:2323081:2323081 [0] NCCL INFO Using network IBext
 29: hkn0411:2323109:2323109 [1] NCCL INFO Using network IBext
468: hkn0804:1212869:1212869 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
440: hkn0732:1218902:1218902 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
286: hkn0623:1879995:1879995 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
286: hkn0623:1879995:1879995 [2] NCCL INFO P2P plugin IBext
441: hkn0732:1218890:1218890 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
284: hkn0623:1880015:1880015 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
285: hkn0623:1880003:1880003 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
284: hkn0623:1880015:1880015 [0] NCCL INFO Using network IBext
285: hkn0623:1880003:1880003 [1] NCCL INFO Using network IBext
307: hkn0629:1599276:1599276 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
443: hkn0732:1218882:1218882 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
304: hkn0629:1599292:1599292 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
428: hkn0728:1331278:1331278 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
306: hkn0629:1599284:1599284 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
325: hkn0634:1528068:1528068 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
325: hkn0634:1528068:1528068 [1] NCCL INFO P2P plugin IBext
326: hkn0634:1528060:1528060 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
326: hkn0634:1528060:1528060 [2] NCCL INFO P2P plugin IBext
442: hkn0732:1218881:1218881 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
510: hkn0816:382843:382843 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
510: hkn0816:382843:382843 [2] NCCL INFO P2P plugin IBext
442: hkn0732:1218881:1218881 [2] NCCL INFO P2P plugin IBext
509: hkn0816:382855:382855 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
324: hkn0634:1528076:1528076 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
324: hkn0634:1528076:1528076 [0] NCCL INFO Using network IBext
430: hkn0728:1331266:1331266 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
 31: hkn0411:2323097:2323097 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 31: hkn0411:2323097:2323097 [3] NCCL INFO Using network IBext
286: hkn0623:1879995:1879995 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
286: hkn0623:1879995:1879995 [2] NCCL INFO Using network IBext
305: hkn0629:1599304:1599304 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
471: hkn0804:1212857:1212857 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
287: hkn0623:1879987:1879987 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
287: hkn0623:1879987:1879987 [3] NCCL INFO Using network IBext
429: hkn0728:1331258:1331258 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
289: hkn0624:1780160:1780160 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
431: hkn0728:1331257:1331257 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
431: hkn0728:1331257:1331257 [3] NCCL INFO P2P plugin IBext
440: hkn0732:1218902:1218902 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
440: hkn0732:1218902:1218902 [0] NCCL INFO P2P plugin IBext
469: hkn0804:1212849:1212849 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
469: hkn0804:1212849:1212849 [1] NCCL INFO P2P plugin IBext
468: hkn0804:1212869:1212869 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
468: hkn0804:1212869:1212869 [0] NCCL INFO P2P plugin IBext
441: hkn0732:1218890:1218890 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
441: hkn0732:1218890:1218890 [1] NCCL INFO P2P plugin IBext
307: hkn0629:1599276:1599276 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
307: hkn0629:1599276:1599276 [3] NCCL INFO P2P plugin IBext
325: hkn0634:1528068:1528068 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
325: hkn0634:1528068:1528068 [1] NCCL INFO Using network IBext
326: hkn0634:1528060:1528060 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
326: hkn0634:1528060:1528060 [2] NCCL INFO Using network IBext
443: hkn0732:1218882:1218882 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
443: hkn0732:1218882:1218882 [3] NCCL INFO P2P plugin IBext
490: hkn0809:944543:944543 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
491: hkn0809:944551:944551 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
304: hkn0629:1599292:1599292 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
304: hkn0629:1599292:1599292 [0] NCCL INFO P2P plugin IBext
428: hkn0728:1331278:1331278 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
428: hkn0728:1331278:1331278 [0] NCCL INFO P2P plugin IBext
327: hkn0634:1528094:1528094 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
327: hkn0634:1528094:1528094 [3] NCCL INFO Using network IBext
 37: hkn0413:2373940:2373940 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
511: hkn0816:382835:382835 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
306: hkn0629:1599284:1599284 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
306: hkn0629:1599284:1599284 [2] NCCL INFO P2P plugin IBext
509: hkn0816:382855:382855 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
509: hkn0816:382855:382855 [1] NCCL INFO P2P plugin IBext
 36: hkn0413:2373960:2373960 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
 39: hkn0413:2373932:2373932 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
 38: hkn0413:2373948:2373948 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
430: hkn0728:1331266:1331266 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
430: hkn0728:1331266:1331266 [2] NCCL INFO P2P plugin IBext
305: hkn0629:1599304:1599304 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
305: hkn0629:1599304:1599304 [1] NCCL INFO P2P plugin IBext
488: hkn0809:944559:944559 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
471: hkn0804:1212857:1212857 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
471: hkn0804:1212857:1212857 [3] NCCL INFO P2P plugin IBext
289: hkn0624:1780160:1780160 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
289: hkn0624:1780160:1780160 [1] NCCL INFO P2P plugin IBext
429: hkn0728:1331258:1331258 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
429: hkn0728:1331258:1331258 [1] NCCL INFO P2P plugin IBext
470: hkn0804:1212841:1212841 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
470: hkn0804:1212841:1212841 [2] NCCL INFO Using network IBext
508: hkn0816:382834:382834 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
468: hkn0804:1212869:1212869 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
469: hkn0804:1212849:1212849 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
468: hkn0804:1212869:1212869 [0] NCCL INFO Using network IBext
469: hkn0804:1212849:1212849 [1] NCCL INFO Using network IBext
440: hkn0732:1218902:1218902 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
440: hkn0732:1218902:1218902 [0] NCCL INFO Using network IBext
441: hkn0732:1218890:1218890 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
441: hkn0732:1218890:1218890 [1] NCCL INFO Using network IBext
443: hkn0732:1218882:1218882 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
443: hkn0732:1218882:1218882 [3] NCCL INFO Using network IBext
128: hkn0509:3131628:3131628 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
490: hkn0809:944543:944543 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
490: hkn0809:944543:944543 [2] NCCL INFO P2P plugin IBext
491: hkn0809:944551:944551 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
491: hkn0809:944551:944551 [3] NCCL INFO P2P plugin IBext
428: hkn0728:1331278:1331278 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
428: hkn0728:1331278:1331278 [0] NCCL INFO Using network IBext
430: hkn0728:1331266:1331266 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
430: hkn0728:1331266:1331266 [2] NCCL INFO Using network IBext
129: hkn0509:3131636:3131636 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
306: hkn0629:1599284:1599284 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
306: hkn0629:1599284:1599284 [2] NCCL INFO Using network IBext
 37: hkn0413:2373940:2373940 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 37: hkn0413:2373940:2373940 [1] NCCL INFO P2P plugin IBext
305: hkn0629:1599304:1599304 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
305: hkn0629:1599304:1599304 [1] NCCL INFO Using network IBext
511: hkn0816:382835:382835 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
511: hkn0816:382835:382835 [3] NCCL INFO P2P plugin IBext
489: hkn0809:944571:944571 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
442: hkn0732:1218881:1218881 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
471: hkn0804:1212857:1212857 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
471: hkn0804:1212857:1212857 [3] NCCL INFO Using network IBext
 39: hkn0413:2373932:2373932 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 39: hkn0413:2373932:2373932 [3] NCCL INFO P2P plugin IBext
442: hkn0732:1218881:1218881 [2] NCCL INFO Using network IBext
 36: hkn0413:2373960:2373960 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 36: hkn0413:2373960:2373960 [0] NCCL INFO P2P plugin IBext
288: hkn0624:1780140:1780140 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
 38: hkn0413:2373948:2373948 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 38: hkn0413:2373948:2373948 [2] NCCL INFO P2P plugin IBext
429: hkn0728:1331258:1331258 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
509: hkn0816:382855:382855 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
509: hkn0816:382855:382855 [1] NCCL INFO Using network IBext
429: hkn0728:1331258:1331258 [1] NCCL INFO Using network IBext
510: hkn0816:382843:382843 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
510: hkn0816:382843:382843 [2] NCCL INFO Using network IBext
290: hkn0624:1780132:1780132 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
488: hkn0809:944559:944559 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
488: hkn0809:944559:944559 [0] NCCL INFO P2P plugin IBext
291: hkn0624:1780148:1780148 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
431: hkn0728:1331257:1331257 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
431: hkn0728:1331257:1331257 [3] NCCL INFO Using network IBext
511: hkn0816:382835:382835 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
511: hkn0816:382835:382835 [3] NCCL INFO Using network IBext
508: hkn0816:382834:382834 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
508: hkn0816:382834:382834 [0] NCCL INFO P2P plugin IBext
131: hkn0509:3131644:3131644 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
130: hkn0509:3131655:3131655 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
128: hkn0509:3131628:3131628 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
128: hkn0509:3131628:3131628 [0] NCCL INFO P2P plugin IBext
304: hkn0629:1599292:1599292 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
304: hkn0629:1599292:1599292 [0] NCCL INFO Using network IBext
307: hkn0629:1599276:1599276 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
307: hkn0629:1599276:1599276 [3] NCCL INFO Using network IBext
129: hkn0509:3131636:3131636 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
129: hkn0509:3131636:3131636 [1] NCCL INFO P2P plugin IBext
489: hkn0809:944571:944571 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
489: hkn0809:944571:944571 [1] NCCL INFO P2P plugin IBext
 36: hkn0413:2373960:2373960 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 38: hkn0413:2373948:2373948 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 39: hkn0413:2373932:2373932 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 36: hkn0413:2373960:2373960 [0] NCCL INFO Using network IBext
 38: hkn0413:2373948:2373948 [2] NCCL INFO Using network IBext
 39: hkn0413:2373932:2373932 [3] NCCL INFO Using network IBext
288: hkn0624:1780140:1780140 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
288: hkn0624:1780140:1780140 [0] NCCL INFO P2P plugin IBext
488: hkn0809:944559:944559 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
488: hkn0809:944559:944559 [0] NCCL INFO Using network IBext
290: hkn0624:1780132:1780132 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
290: hkn0624:1780132:1780132 [2] NCCL INFO P2P plugin IBext
508: hkn0816:382834:382834 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
291: hkn0624:1780148:1780148 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
291: hkn0624:1780148:1780148 [3] NCCL INFO P2P plugin IBext
508: hkn0816:382834:382834 [0] NCCL INFO Using network IBext
130: hkn0509:3131655:3131655 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
130: hkn0509:3131655:3131655 [2] NCCL INFO P2P plugin IBext
131: hkn0509:3131644:3131644 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
131: hkn0509:3131644:3131644 [3] NCCL INFO P2P plugin IBext
 61: hkn0420:3217408:3217408 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
489: hkn0809:944571:944571 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
489: hkn0809:944571:944571 [1] NCCL INFO Using network IBext
129: hkn0509:3131636:3131636 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
491: hkn0809:944551:944551 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
491: hkn0809:944551:944551 [3] NCCL INFO Using network IBext
129: hkn0509:3131636:3131636 [1] NCCL INFO Using network IBext
490: hkn0809:944543:944543 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
490: hkn0809:944543:944543 [2] NCCL INFO Using network IBext
 60: hkn0420:3217416:3217416 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
288: hkn0624:1780140:1780140 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
288: hkn0624:1780140:1780140 [0] NCCL INFO Using network IBext
289: hkn0624:1780160:1780160 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
289: hkn0624:1780160:1780160 [1] NCCL INFO Using network IBext
 37: hkn0413:2373940:2373940 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 37: hkn0413:2373940:2373940 [1] NCCL INFO Using network IBext
290: hkn0624:1780132:1780132 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
290: hkn0624:1780132:1780132 [2] NCCL INFO Using network IBext
291: hkn0624:1780148:1780148 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
291: hkn0624:1780148:1780148 [3] NCCL INFO Using network IBext
105: hkn0503:2906935:2906935 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
107: hkn0503:2906943:2906943 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
106: hkn0503:2906951:2906951 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
130: hkn0509:3131655:3131655 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
131: hkn0509:3131644:3131644 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
130: hkn0509:3131655:3131655 [2] NCCL INFO Using network IBext
131: hkn0509:3131644:3131644 [3] NCCL INFO Using network IBext
128: hkn0509:3131628:3131628 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
128: hkn0509:3131628:3131628 [0] NCCL INFO Using network IBext
 61: hkn0420:3217408:3217408 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 61: hkn0420:3217408:3217408 [1] NCCL INFO P2P plugin IBext
104: hkn0503:2906963:2906963 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
 63: hkn0420:3217400:3217400 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
 60: hkn0420:3217416:3217416 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 60: hkn0420:3217416:3217416 [0] NCCL INFO P2P plugin IBext
211: hkn0534:1155652:1155652 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
105: hkn0503:2906935:2906935 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
105: hkn0503:2906935:2906935 [1] NCCL INFO P2P plugin IBext
107: hkn0503:2906943:2906943 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
107: hkn0503:2906943:2906943 [3] NCCL INFO P2P plugin IBext
257: hkn0612:924227:924227 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
210: hkn0534:1155637:1155637 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
106: hkn0503:2906951:2906951 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
106: hkn0503:2906951:2906951 [2] NCCL INFO P2P plugin IBext
 60: hkn0420:3217416:3217416 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 60: hkn0420:3217416:3217416 [0] NCCL INFO Using network IBext
104: hkn0503:2906963:2906963 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
104: hkn0503:2906963:2906963 [0] NCCL INFO P2P plugin IBext
209: hkn0534:1155638:1155638 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
393: hkn0718:3924262:3924262 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
208: hkn0534:1155640:1155640 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
211: hkn0534:1155652:1155652 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
211: hkn0534:1155652:1155652 [3] NCCL INFO P2P plugin IBext
 63: hkn0420:3217400:3217400 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 63: hkn0420:3217400:3217400 [3] NCCL INFO P2P plugin IBext
257: hkn0612:924227:924227 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
257: hkn0612:924227:924227 [1] NCCL INFO P2P plugin IBext
395: hkn0718:3924254:3924254 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
259: hkn0612:924215:924215 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
106: hkn0503:2906951:2906951 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
106: hkn0503:2906951:2906951 [2] NCCL INFO Using network IBext
210: hkn0534:1155637:1155637 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
210: hkn0534:1155637:1155637 [2] NCCL INFO P2P plugin IBext
104: hkn0503:2906963:2906963 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
104: hkn0503:2906963:2906963 [0] NCCL INFO Using network IBext
258: hkn0612:924199:924199 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
394: hkn0718:3924274:3924274 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
369: hkn0712:302289:302289 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
381: hkn0715:409138:409138 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
383: hkn0715:409110:409110 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
 61: hkn0420:3217408:3217408 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 61: hkn0420:3217408:3217408 [1] NCCL INFO Using network IBext
393: hkn0718:3924262:3924262 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
393: hkn0718:3924262:3924262 [1] NCCL INFO P2P plugin IBext
256: hkn0612:924207:924207 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
 63: hkn0420:3217400:3217400 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 63: hkn0420:3217400:3217400 [3] NCCL INFO Using network IBext
209: hkn0534:1155638:1155638 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
209: hkn0534:1155638:1155638 [1] NCCL INFO P2P plugin IBext
392: hkn0718:3924246:3924246 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
208: hkn0534:1155640:1155640 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
208: hkn0534:1155640:1155640 [0] NCCL INFO P2P plugin IBext
382: hkn0715:409118:409118 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
107: hkn0503:2906943:2906943 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
105: hkn0503:2906935:2906935 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
107: hkn0503:2906943:2906943 [3] NCCL INFO Using network IBext
105: hkn0503:2906935:2906935 [1] NCCL INFO Using network IBext
259: hkn0612:924215:924215 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
259: hkn0612:924215:924215 [3] NCCL INFO P2P plugin IBext
395: hkn0718:3924254:3924254 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
395: hkn0718:3924254:3924254 [3] NCCL INFO P2P plugin IBext
210: hkn0534:1155637:1155637 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
210: hkn0534:1155637:1155637 [2] NCCL INFO Using network IBext
368: hkn0712:302297:302297 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
369: hkn0712:302289:302289 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
369: hkn0712:302289:302289 [1] NCCL INFO P2P plugin IBext
258: hkn0612:924199:924199 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
258: hkn0612:924199:924199 [2] NCCL INFO P2P plugin IBext
394: hkn0718:3924274:3924274 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
394: hkn0718:3924274:3924274 [2] NCCL INFO P2P plugin IBext
383: hkn0715:409110:409110 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
383: hkn0715:409110:409110 [3] NCCL INFO P2P plugin IBext
381: hkn0715:409138:409138 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
381: hkn0715:409138:409138 [1] NCCL INFO P2P plugin IBext
208: hkn0534:1155640:1155640 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
380: hkn0715:409126:409126 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
208: hkn0534:1155640:1155640 [0] NCCL INFO Using network IBext
209: hkn0534:1155638:1155638 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
209: hkn0534:1155638:1155638 [1] NCCL INFO Using network IBext
256: hkn0612:924207:924207 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
256: hkn0612:924207:924207 [0] NCCL INFO P2P plugin IBext
392: hkn0718:3924246:3924246 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
392: hkn0718:3924246:3924246 [0] NCCL INFO P2P plugin IBext
371: hkn0712:302309:302309 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
211: hkn0534:1155652:1155652 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
382: hkn0715:409118:409118 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
382: hkn0715:409118:409118 [2] NCCL INFO P2P plugin IBext
211: hkn0534:1155652:1155652 [3] NCCL INFO Using network IBext
258: hkn0612:924199:924199 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
258: hkn0612:924199:924199 [2] NCCL INFO Using network IBext
259: hkn0612:924215:924215 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
259: hkn0612:924215:924215 [3] NCCL INFO Using network IBext
394: hkn0718:3924274:3924274 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
395: hkn0718:3924254:3924254 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
395: hkn0718:3924254:3924254 [3] NCCL INFO Using network IBext
394: hkn0718:3924274:3924274 [2] NCCL INFO Using network IBext
368: hkn0712:302297:302297 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
368: hkn0712:302297:302297 [0] NCCL INFO P2P plugin IBext
257: hkn0612:924227:924227 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
257: hkn0612:924227:924227 [1] NCCL INFO Using network IBext
242: hkn0607:911587:911587 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
256: hkn0612:924207:924207 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
256: hkn0612:924207:924207 [0] NCCL INFO Using network IBext
 62: hkn0420:3217428:3217428 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
392: hkn0718:3924246:3924246 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
392: hkn0718:3924246:3924246 [0] NCCL INFO Using network IBext
345: hkn0705:790443:790443 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
370: hkn0712:302281:302281 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
346: hkn0705:790431:790431 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
380: hkn0715:409126:409126 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
380: hkn0715:409126:409126 [0] NCCL INFO P2P plugin IBext
344: hkn0705:790415:790415 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
243: hkn0607:911615:911615 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
393: hkn0718:3924262:3924262 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
393: hkn0718:3924262:3924262 [1] NCCL INFO Using network IBext
240: hkn0607:911595:911595 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
224: hkn0603:1420450:1420450 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
382: hkn0715:409118:409118 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
382: hkn0715:409118:409118 [2] NCCL INFO Using network IBext
371: hkn0712:302309:302309 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
371: hkn0712:302309:302309 [3] NCCL INFO P2P plugin IBext
241: hkn0607:911603:911603 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
347: hkn0705:790423:790423 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
368: hkn0712:302297:302297 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
368: hkn0712:302297:302297 [0] NCCL INFO Using network IBext
380: hkn0715:409126:409126 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
242: hkn0607:911587:911587 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
242: hkn0607:911587:911587 [2] NCCL INFO P2P plugin IBext
380: hkn0715:409126:409126 [0] NCCL INFO Using network IBext
369: hkn0712:302289:302289 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
369: hkn0712:302289:302289 [1] NCCL INFO Using network IBext
134: hkn0510:2769278:2769278 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
227: hkn0603:1420478:1420478 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
225: hkn0603:1420458:1420458 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
345: hkn0705:790443:790443 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
345: hkn0705:790443:790443 [1] NCCL INFO P2P plugin IBext
370: hkn0712:302281:302281 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
370: hkn0712:302281:302281 [2] NCCL INFO P2P plugin IBext
383: hkn0715:409110:409110 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
383: hkn0715:409110:409110 [3] NCCL INFO Using network IBext
381: hkn0715:409138:409138 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
344: hkn0705:790415:790415 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
344: hkn0705:790415:790415 [0] NCCL INFO P2P plugin IBext
381: hkn0715:409138:409138 [1] NCCL INFO Using network IBext
243: hkn0607:911615:911615 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
243: hkn0607:911615:911615 [3] NCCL INFO P2P plugin IBext
346: hkn0705:790431:790431 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
346: hkn0705:790431:790431 [2] NCCL INFO P2P plugin IBext
371: hkn0712:302309:302309 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
371: hkn0712:302309:302309 [3] NCCL INFO Using network IBext
135: hkn0510:2769298:2769298 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
 62: hkn0420:3217428:3217428 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 62: hkn0420:3217428:3217428 [2] NCCL INFO P2P plugin IBext
224: hkn0603:1420450:1420450 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
224: hkn0603:1420450:1420450 [0] NCCL INFO P2P plugin IBext
226: hkn0603:1420466:1420466 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
240: hkn0607:911595:911595 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
240: hkn0607:911595:911595 [0] NCCL INFO P2P plugin IBext
241: hkn0607:911603:911603 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
241: hkn0607:911603:911603 [1] NCCL INFO P2P plugin IBext
347: hkn0705:790423:790423 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
347: hkn0705:790423:790423 [3] NCCL INFO P2P plugin IBext
465: hkn0803:883787:883787 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
133: hkn0510:2769286:2769286 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
411: hkn0723:215353:215353 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
370: hkn0712:302281:302281 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
370: hkn0712:302281:302281 [2] NCCL INFO Using network IBext
409: hkn0723:215333:215333 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
254: hkn0611:717063:717063 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
134: hkn0510:2769278:2769278 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
134: hkn0510:2769278:2769278 [2] NCCL INFO P2P plugin IBext
467: hkn0803:883807:883807 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
227: hkn0603:1420478:1420478 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
227: hkn0603:1420478:1420478 [3] NCCL INFO P2P plugin IBext
225: hkn0603:1420458:1420458 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
225: hkn0603:1420458:1420458 [1] NCCL INFO P2P plugin IBext
240: hkn0607:911595:911595 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
240: hkn0607:911595:911595 [0] NCCL INFO Using network IBext
243: hkn0607:911615:911615 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
243: hkn0607:911615:911615 [3] NCCL INFO Using network IBext
241: hkn0607:911603:911603 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
241: hkn0607:911603:911603 [1] NCCL INFO Using network IBext
135: hkn0510:2769298:2769298 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
135: hkn0510:2769298:2769298 [3] NCCL INFO P2P plugin IBext
132: hkn0510:2769270:2769270 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
226: hkn0603:1420466:1420466 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
226: hkn0603:1420466:1420466 [2] NCCL INFO P2P plugin IBext
 62: hkn0420:3217428:3217428 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 62: hkn0420:3217428:3217428 [2] NCCL INFO Using network IBext
347: hkn0705:790423:790423 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
255: hkn0611:717043:717043 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
347: hkn0705:790423:790423 [3] NCCL INFO Using network IBext
253: hkn0611:717051:717051 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
465: hkn0803:883787:883787 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
465: hkn0803:883787:883787 [1] NCCL INFO P2P plugin IBext
408: hkn0723:215341:215341 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
133: hkn0510:2769286:2769286 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
133: hkn0510:2769286:2769286 [1] NCCL INFO P2P plugin IBext
410: hkn0723:215325:215325 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
464: hkn0803:883779:883779 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
411: hkn0723:215353:215353 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
411: hkn0723:215353:215353 [3] NCCL INFO P2P plugin IBext
242: hkn0607:911587:911587 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
242: hkn0607:911587:911587 [2] NCCL INFO Using network IBext
466: hkn0803:883795:883795 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
409: hkn0723:215333:215333 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
409: hkn0723:215333:215333 [1] NCCL INFO P2P plugin IBext
254: hkn0611:717063:717063 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
254: hkn0611:717063:717063 [2] NCCL INFO P2P plugin IBext
225: hkn0603:1420458:1420458 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
252: hkn0611:717035:717035 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
226: hkn0603:1420466:1420466 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
225: hkn0603:1420458:1420458 [1] NCCL INFO Using network IBext
226: hkn0603:1420466:1420466 [2] NCCL INFO Using network IBext
227: hkn0603:1420478:1420478 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
227: hkn0603:1420478:1420478 [3] NCCL INFO Using network IBext
467: hkn0803:883807:883807 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
467: hkn0803:883807:883807 [3] NCCL INFO P2P plugin IBext
345: hkn0705:790443:790443 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
345: hkn0705:790443:790443 [1] NCCL INFO Using network IBext
344: hkn0705:790415:790415 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
344: hkn0705:790415:790415 [0] NCCL INFO Using network IBext
346: hkn0705:790431:790431 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
346: hkn0705:790431:790431 [2] NCCL INFO Using network IBext
135: hkn0510:2769298:2769298 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
135: hkn0510:2769298:2769298 [3] NCCL INFO Using network IBext
132: hkn0510:2769270:2769270 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
132: hkn0510:2769270:2769270 [0] NCCL INFO P2P plugin IBext
133: hkn0510:2769286:2769286 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
133: hkn0510:2769286:2769286 [1] NCCL INFO Using network IBext
224: hkn0603:1420450:1420450 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
224: hkn0603:1420450:1420450 [0] NCCL INFO Using network IBext
279: hkn0621:1998830:1998830 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
255: hkn0611:717043:717043 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
255: hkn0611:717043:717043 [3] NCCL INFO P2P plugin IBext
253: hkn0611:717051:717051 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
253: hkn0611:717051:717051 [1] NCCL INFO P2P plugin IBext
408: hkn0723:215341:215341 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
408: hkn0723:215341:215341 [0] NCCL INFO P2P plugin IBext
277: hkn0621:1998849:1998849 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
198: hkn0530:1265343:1265343 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
276: hkn0621:1998822:1998822 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
410: hkn0723:215325:215325 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
410: hkn0723:215325:215325 [2] NCCL INFO P2P plugin IBext
278: hkn0621:1998838:1998838 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
464: hkn0803:883779:883779 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
464: hkn0803:883779:883779 [0] NCCL INFO P2P plugin IBext
409: hkn0723:215333:215333 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
409: hkn0723:215333:215333 [1] NCCL INFO Using network IBext
466: hkn0803:883795:883795 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
466: hkn0803:883795:883795 [2] NCCL INFO P2P plugin IBext
134: hkn0510:2769278:2769278 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
134: hkn0510:2769278:2769278 [2] NCCL INFO Using network IBext
132: hkn0510:2769270:2769270 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
132: hkn0510:2769270:2769270 [0] NCCL INFO Using network IBext
252: hkn0611:717035:717035 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
252: hkn0611:717035:717035 [0] NCCL INFO P2P plugin IBext
467: hkn0803:883807:883807 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
467: hkn0803:883807:883807 [3] NCCL INFO Using network IBext
408: hkn0723:215341:215341 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
408: hkn0723:215341:215341 [0] NCCL INFO Using network IBext
197: hkn0530:1265371:1265371 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
410: hkn0723:215325:215325 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
410: hkn0723:215325:215325 [2] NCCL INFO Using network IBext
169: hkn0523:1555324:1555324 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
255: hkn0611:717043:717043 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
253: hkn0611:717051:717051 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
255: hkn0611:717043:717043 [3] NCCL INFO Using network IBext
253: hkn0611:717051:717051 [1] NCCL INFO Using network IBext
464: hkn0803:883779:883779 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
464: hkn0803:883779:883779 [0] NCCL INFO Using network IBext
466: hkn0803:883795:883795 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
466: hkn0803:883795:883795 [2] NCCL INFO Using network IBext
465: hkn0803:883787:883787 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
465: hkn0803:883787:883787 [1] NCCL INFO Using network IBext
196: hkn0530:1265359:1265359 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
279: hkn0621:1998830:1998830 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
279: hkn0621:1998830:1998830 [3] NCCL INFO P2P plugin IBext
198: hkn0530:1265343:1265343 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
198: hkn0530:1265343:1265343 [2] NCCL INFO P2P plugin IBext
277: hkn0621:1998849:1998849 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
277: hkn0621:1998849:1998849 [1] NCCL INFO P2P plugin IBext
252: hkn0611:717035:717035 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
252: hkn0611:717035:717035 [0] NCCL INFO Using network IBext
411: hkn0723:215353:215353 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
411: hkn0723:215353:215353 [3] NCCL INFO Using network IBext
276: hkn0621:1998822:1998822 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
276: hkn0621:1998822:1998822 [0] NCCL INFO P2P plugin IBext
170: hkn0523:1555340:1555340 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
278: hkn0621:1998838:1998838 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
278: hkn0621:1998838:1998838 [2] NCCL INFO P2P plugin IBext
168: hkn0523:1555352:1555352 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
254: hkn0611:717063:717063 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
254: hkn0611:717063:717063 [2] NCCL INFO Using network IBext
199: hkn0530:1265351:1265351 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
142: hkn0512:3051335:3051335 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
458: hkn0801:2247264:2247264 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
197: hkn0530:1265371:1265371 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
197: hkn0530:1265371:1265371 [1] NCCL INFO P2P plugin IBext
169: hkn0523:1555324:1555324 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
169: hkn0523:1555324:1555324 [1] NCCL INFO P2P plugin IBext
473: hkn0805:1119333:1119333 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
143: hkn0512:3051355:3051355 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
196: hkn0530:1265359:1265359 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
196: hkn0530:1265359:1265359 [0] NCCL INFO P2P plugin IBext
171: hkn0523:1555332:1555332 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
474: hkn0805:1119317:1119317 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
190: hkn0528:1308903:1308903 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
170: hkn0523:1555340:1555340 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
170: hkn0523:1555340:1555340 [2] NCCL INFO P2P plugin IBext
168: hkn0523:1555352:1555352 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
168: hkn0523:1555352:1555352 [0] NCCL INFO P2P plugin IBext
199: hkn0530:1265351:1265351 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
199: hkn0530:1265351:1265351 [3] NCCL INFO P2P plugin IBext
142: hkn0512:3051335:3051335 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
142: hkn0512:3051335:3051335 [2] NCCL INFO P2P plugin IBext
141: hkn0512:3051327:3051327 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
140: hkn0512:3051343:3051343 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
458: hkn0801:2247264:2247264 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
458: hkn0801:2247264:2247264 [2] NCCL INFO P2P plugin IBext
196: hkn0530:1265359:1265359 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
197: hkn0530:1265371:1265371 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
196: hkn0530:1265359:1265359 [0] NCCL INFO Using network IBext
197: hkn0530:1265371:1265371 [1] NCCL INFO Using network IBext
473: hkn0805:1119333:1119333 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
473: hkn0805:1119333:1119333 [1] NCCL INFO P2P plugin IBext
189: hkn0528:1308923:1308923 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
143: hkn0512:3051355:3051355 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
143: hkn0512:3051355:3051355 [3] NCCL INFO P2P plugin IBext
198: hkn0530:1265343:1265343 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
198: hkn0530:1265343:1265343 [2] NCCL INFO Using network IBext
 45: hkn0415:2503635:2503635 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
171: hkn0523:1555332:1555332 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
171: hkn0523:1555332:1555332 [3] NCCL INFO P2P plugin IBext
188: hkn0528:1308911:1308911 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
474: hkn0805:1119317:1119317 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
474: hkn0805:1119317:1119317 [2] NCCL INFO P2P plugin IBext
168: hkn0523:1555352:1555352 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
168: hkn0523:1555352:1555352 [0] NCCL INFO Using network IBext
190: hkn0528:1308903:1308903 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
190: hkn0528:1308903:1308903 [2] NCCL INFO P2P plugin IBext
170: hkn0523:1555340:1555340 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
170: hkn0523:1555340:1555340 [2] NCCL INFO Using network IBext
199: hkn0530:1265351:1265351 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
199: hkn0530:1265351:1265351 [3] NCCL INFO Using network IBext
187: hkn0527:1356160:1356160 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
191: hkn0528:1308895:1308895 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
 47: hkn0415:2503663:2503663 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
279: hkn0621:1998830:1998830 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
277: hkn0621:1998849:1998849 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
278: hkn0621:1998838:1998838 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
279: hkn0621:1998830:1998830 [3] NCCL INFO Using network IBext
276: hkn0621:1998822:1998822 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
277: hkn0621:1998849:1998849 [1] NCCL INFO Using network IBext
278: hkn0621:1998838:1998838 [2] NCCL INFO Using network IBext
276: hkn0621:1998822:1998822 [0] NCCL INFO Using network IBext
472: hkn0805:1119345:1119345 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
475: hkn0805:1119325:1119325 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
110: hkn0504:48311:48311 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
111: hkn0504:48327:48327 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
 46: hkn0415:2503643:2503643 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
456: hkn0801:2247272:2247272 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
141: hkn0512:3051327:3051327 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
141: hkn0512:3051327:3051327 [1] NCCL INFO P2P plugin IBext
459: hkn0801:2247280:2247280 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
 44: hkn0415:2503651:2503651 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
140: hkn0512:3051343:3051343 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
140: hkn0512:3051343:3051343 [0] NCCL INFO P2P plugin IBext
108: hkn0504:48339:48339 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
171: hkn0523:1555332:1555332 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
171: hkn0523:1555332:1555332 [3] NCCL INFO Using network IBext
169: hkn0523:1555324:1555324 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
169: hkn0523:1555324:1555324 [1] NCCL INFO Using network IBext
109: hkn0504:48319:48319 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
143: hkn0512:3051355:3051355 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
143: hkn0512:3051355:3051355 [3] NCCL INFO Using network IBext
189: hkn0528:1308923:1308923 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
189: hkn0528:1308923:1308923 [1] NCCL INFO P2P plugin IBext
457: hkn0801:2247291:2247291 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
474: hkn0805:1119317:1119317 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
474: hkn0805:1119317:1119317 [2] NCCL INFO Using network IBext
 45: hkn0415:2503635:2503635 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 45: hkn0415:2503635:2503635 [1] NCCL INFO P2P plugin IBext
188: hkn0528:1308911:1308911 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
188: hkn0528:1308911:1308911 [0] NCCL INFO P2P plugin IBext
187: hkn0527:1356160:1356160 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
187: hkn0527:1356160:1356160 [3] NCCL INFO P2P plugin IBext
141: hkn0512:3051327:3051327 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
141: hkn0512:3051327:3051327 [1] NCCL INFO Using network IBext
191: hkn0528:1308895:1308895 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
191: hkn0528:1308895:1308895 [3] NCCL INFO P2P plugin IBext
 47: hkn0415:2503663:2503663 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 47: hkn0415:2503663:2503663 [3] NCCL INFO P2P plugin IBext
140: hkn0512:3051343:3051343 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
140: hkn0512:3051343:3051343 [0] NCCL INFO Using network IBext
110: hkn0504:48311:48311 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
110: hkn0504:48311:48311 [2] NCCL INFO P2P plugin IBext
111: hkn0504:48327:48327 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
111: hkn0504:48327:48327 [3] NCCL INFO P2P plugin IBext
 46: hkn0415:2503643:2503643 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 46: hkn0415:2503643:2503643 [2] NCCL INFO P2P plugin IBext
475: hkn0805:1119325:1119325 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
475: hkn0805:1119325:1119325 [3] NCCL INFO P2P plugin IBext
472: hkn0805:1119345:1119345 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
472: hkn0805:1119345:1119345 [0] NCCL INFO P2P plugin IBext
142: hkn0512:3051335:3051335 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
142: hkn0512:3051335:3051335 [2] NCCL INFO Using network IBext
459: hkn0801:2247280:2247280 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
459: hkn0801:2247280:2247280 [3] NCCL INFO P2P plugin IBext
108: hkn0504:48339:48339 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
108: hkn0504:48339:48339 [0] NCCL INFO P2P plugin IBext
456: hkn0801:2247272:2247272 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
456: hkn0801:2247272:2247272 [0] NCCL INFO P2P plugin IBext
 44: hkn0415:2503651:2503651 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 44: hkn0415:2503651:2503651 [0] NCCL INFO P2P plugin IBext
476: hkn0806:1061522:1061522 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
109: hkn0504:48319:48319 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
109: hkn0504:48319:48319 [1] NCCL INFO P2P plugin IBext
188: hkn0528:1308911:1308911 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
188: hkn0528:1308911:1308911 [0] NCCL INFO Using network IBext
473: hkn0805:1119333:1119333 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
473: hkn0805:1119333:1119333 [1] NCCL INFO Using network IBext
189: hkn0528:1308923:1308923 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
189: hkn0528:1308923:1308923 [1] NCCL INFO Using network IBext
479: hkn0806:1061530:1061530 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
191: hkn0528:1308895:1308895 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
191: hkn0528:1308895:1308895 [3] NCCL INFO Using network IBext
457: hkn0801:2247291:2247291 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
457: hkn0801:2247291:2247291 [1] NCCL INFO P2P plugin IBext
458: hkn0801:2247264:2247264 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
458: hkn0801:2247264:2247264 [2] NCCL INFO Using network IBext
184: hkn0527:1356168:1356168 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
477: hkn0806:1061538:1061538 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
190: hkn0528:1308903:1308903 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
190: hkn0528:1308903:1308903 [2] NCCL INFO Using network IBext
 46: hkn0415:2503643:2503643 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 47: hkn0415:2503663:2503663 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 46: hkn0415:2503643:2503643 [2] NCCL INFO Using network IBext
 47: hkn0415:2503663:2503663 [3] NCCL INFO Using network IBext
472: hkn0805:1119345:1119345 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
475: hkn0805:1119325:1119325 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
472: hkn0805:1119345:1119345 [0] NCCL INFO Using network IBext
475: hkn0805:1119325:1119325 [3] NCCL INFO Using network IBext
459: hkn0801:2247280:2247280 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
459: hkn0801:2247280:2247280 [3] NCCL INFO Using network IBext
456: hkn0801:2247272:2247272 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
456: hkn0801:2247272:2247272 [0] NCCL INFO Using network IBext
 44: hkn0415:2503651:2503651 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 44: hkn0415:2503651:2503651 [0] NCCL INFO Using network IBext
329: hkn0635:1232786:1232786 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
186: hkn0527:1356188:1356188 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
109: hkn0504:48319:48319 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
108: hkn0504:48339:48339 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
109: hkn0504:48319:48319 [1] NCCL INFO Using network IBext
108: hkn0504:48339:48339 [0] NCCL INFO Using network IBext
457: hkn0801:2247291:2247291 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
457: hkn0801:2247291:2247291 [1] NCCL INFO Using network IBext
478: hkn0806:1061550:1061550 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
476: hkn0806:1061522:1061522 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
476: hkn0806:1061522:1061522 [0] NCCL INFO P2P plugin IBext
185: hkn0527:1356176:1356176 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
356: hkn0708:420442:420442 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
479: hkn0806:1061530:1061530 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
479: hkn0806:1061530:1061530 [3] NCCL INFO P2P plugin IBext
 45: hkn0415:2503635:2503635 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 45: hkn0415:2503635:2503635 [1] NCCL INFO Using network IBext
477: hkn0806:1061538:1061538 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
477: hkn0806:1061538:1061538 [1] NCCL INFO P2P plugin IBext
184: hkn0527:1356168:1356168 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
184: hkn0527:1356168:1356168 [0] NCCL INFO P2P plugin IBext
329: hkn0635:1232786:1232786 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
329: hkn0635:1232786:1232786 [1] NCCL INFO P2P plugin IBext
330: hkn0635:1232802:1232802 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
110: hkn0504:48311:48311 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
187: hkn0527:1356160:1356160 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
110: hkn0504:48311:48311 [2] NCCL INFO Using network IBext
187: hkn0527:1356160:1356160 [3] NCCL INFO Using network IBext
111: hkn0504:48327:48327 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
111: hkn0504:48327:48327 [3] NCCL INFO Using network IBext
186: hkn0527:1356188:1356188 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
186: hkn0527:1356188:1356188 [2] NCCL INFO P2P plugin IBext
357: hkn0708:420450:420450 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
359: hkn0708:420470:420470 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
478: hkn0806:1061550:1061550 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
478: hkn0806:1061550:1061550 [2] NCCL INFO P2P plugin IBext
185: hkn0527:1356176:1356176 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
185: hkn0527:1356176:1356176 [1] NCCL INFO P2P plugin IBext
356: hkn0708:420442:420442 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
356: hkn0708:420442:420442 [0] NCCL INFO P2P plugin IBext
477: hkn0806:1061538:1061538 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
479: hkn0806:1061530:1061530 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
477: hkn0806:1061538:1061538 [1] NCCL INFO Using network IBext
479: hkn0806:1061530:1061530 [3] NCCL INFO Using network IBext
184: hkn0527:1356168:1356168 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
184: hkn0527:1356168:1356168 [0] NCCL INFO Using network IBext
275: hkn0617:2301957:2301957 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
272: hkn0617:2301945:2301945 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
328: hkn0635:1232794:1232794 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
358: hkn0708:420458:420458 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
186: hkn0527:1356188:1356188 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
186: hkn0527:1356188:1356188 [2] NCCL INFO Using network IBext
331: hkn0635:1232814:1232814 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
478: hkn0806:1061550:1061550 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
478: hkn0806:1061550:1061550 [2] NCCL INFO Using network IBext
330: hkn0635:1232802:1232802 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
330: hkn0635:1232802:1232802 [2] NCCL INFO P2P plugin IBext
185: hkn0527:1356176:1356176 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
185: hkn0527:1356176:1356176 [1] NCCL INFO Using network IBext
273: hkn0617:2301927:2301927 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
248: hkn0609:718056:718056 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
396: hkn0719:1312979:1312979 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
359: hkn0708:420470:420470 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
359: hkn0708:420470:420470 [3] NCCL INFO P2P plugin IBext
274: hkn0617:2301935:2301935 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
476: hkn0806:1061522:1061522 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
476: hkn0806:1061522:1061522 [0] NCCL INFO Using network IBext
357: hkn0708:420450:420450 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
357: hkn0708:420450:420450 [1] NCCL INFO P2P plugin IBext
275: hkn0617:2301957:2301957 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
275: hkn0617:2301957:2301957 [3] NCCL INFO P2P plugin IBext
249: hkn0609:718036:718036 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
272: hkn0617:2301945:2301945 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
272: hkn0617:2301945:2301945 [0] NCCL INFO P2P plugin IBext
328: hkn0635:1232794:1232794 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
328: hkn0635:1232794:1232794 [0] NCCL INFO P2P plugin IBext
398: hkn0719:1312991:1312991 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
358: hkn0708:420458:420458 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
358: hkn0708:420458:420458 [2] NCCL INFO P2P plugin IBext
331: hkn0635:1232814:1232814 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
331: hkn0635:1232814:1232814 [3] NCCL INFO P2P plugin IBext
251: hkn0609:718044:718044 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
330: hkn0635:1232802:1232802 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
330: hkn0635:1232802:1232802 [2] NCCL INFO Using network IBext
329: hkn0635:1232786:1232786 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
329: hkn0635:1232786:1232786 [1] NCCL INFO Using network IBext
397: hkn0719:1312963:1312963 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
273: hkn0617:2301927:2301927 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
273: hkn0617:2301927:2301927 [1] NCCL INFO P2P plugin IBext
248: hkn0609:718056:718056 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
248: hkn0609:718056:718056 [0] NCCL INFO P2P plugin IBext
357: hkn0708:420450:420450 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
359: hkn0708:420470:420470 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
357: hkn0708:420450:420450 [1] NCCL INFO Using network IBext
359: hkn0708:420470:420470 [3] NCCL INFO Using network IBext
396: hkn0719:1312979:1312979 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
396: hkn0719:1312979:1312979 [0] NCCL INFO P2P plugin IBext
274: hkn0617:2301935:2301935 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
274: hkn0617:2301935:2301935 [2] NCCL INFO P2P plugin IBext
250: hkn0609:718028:718028 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
328: hkn0635:1232794:1232794 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
328: hkn0635:1232794:1232794 [0] NCCL INFO Using network IBext
356: hkn0708:420442:420442 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
356: hkn0708:420442:420442 [0] NCCL INFO Using network IBext
331: hkn0635:1232814:1232814 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
358: hkn0708:420458:420458 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
331: hkn0635:1232814:1232814 [3] NCCL INFO Using network IBext
358: hkn0708:420458:420458 [2] NCCL INFO Using network IBext
249: hkn0609:718036:718036 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
249: hkn0609:718036:718036 [1] NCCL INFO P2P plugin IBext
398: hkn0719:1312991:1312991 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
398: hkn0719:1312991:1312991 [2] NCCL INFO P2P plugin IBext
399: hkn0719:1312971:1312971 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
251: hkn0609:718044:718044 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
251: hkn0609:718044:718044 [3] NCCL INFO P2P plugin IBext
229: hkn0604:696459:696459 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
397: hkn0719:1312963:1312963 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
397: hkn0719:1312963:1312963 [1] NCCL INFO P2P plugin IBext
274: hkn0617:2301935:2301935 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
274: hkn0617:2301935:2301935 [2] NCCL INFO Using network IBext
273: hkn0617:2301927:2301927 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
273: hkn0617:2301927:2301927 [1] NCCL INFO Using network IBext
250: hkn0609:718028:718028 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
250: hkn0609:718028:718028 [2] NCCL INFO P2P plugin IBext
231: hkn0604:696467:696467 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
249: hkn0609:718036:718036 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
249: hkn0609:718036:718036 [1] NCCL INFO Using network IBext
275: hkn0617:2301957:2301957 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
275: hkn0617:2301957:2301957 [3] NCCL INFO Using network IBext
272: hkn0617:2301945:2301945 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
272: hkn0617:2301945:2301945 [0] NCCL INFO Using network IBext
398: hkn0719:1312991:1312991 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
251: hkn0609:718044:718044 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
398: hkn0719:1312991:1312991 [2] NCCL INFO Using network IBext
251: hkn0609:718044:718044 [3] NCCL INFO Using network IBext
399: hkn0719:1312971:1312971 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
399: hkn0719:1312971:1312971 [3] NCCL INFO P2P plugin IBext
397: hkn0719:1312963:1312963 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
397: hkn0719:1312963:1312963 [1] NCCL INFO Using network IBext
229: hkn0604:696459:696459 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
229: hkn0604:696459:696459 [1] NCCL INFO P2P plugin IBext
  7: hkn0404:1346645:1346645 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
248: hkn0609:718056:718056 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
248: hkn0609:718056:718056 [0] NCCL INFO Using network IBext
250: hkn0609:718028:718028 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
250: hkn0609:718028:718028 [2] NCCL INFO Using network IBext
462: hkn0802:1207559:1207559 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
396: hkn0719:1312979:1312979 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
396: hkn0719:1312979:1312979 [0] NCCL INFO Using network IBext
399: hkn0719:1312971:1312971 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
399: hkn0719:1312971:1312971 [3] NCCL INFO Using network IBext
463: hkn0802:1207551:1207551 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
231: hkn0604:696467:696467 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
231: hkn0604:696467:696467 [3] NCCL INFO P2P plugin IBext
295: hkn0626:1305656:1305656 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
294: hkn0626:1305634:1305634 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
480: hkn0807:1026285:1026285 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
292: hkn0626:1305637:1305637 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
293: hkn0626:1305645:1305645 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
  4: hkn0404:1346644:1346644 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
481: hkn0807:1026277:1026277 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
461: hkn0802:1207571:1207571 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
  7: hkn0404:1346645:1346645 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  7: hkn0404:1346645:1346645 [3] NCCL INFO P2P plugin IBext
434: hkn0730:1408975:1408975 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
483: hkn0807:1026305:1026305 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
228: hkn0604:696478:696478 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
  5: hkn0404:1346653:1346653 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
482: hkn0807:1026293:1026293 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
462: hkn0802:1207559:1207559 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
462: hkn0802:1207559:1207559 [2] NCCL INFO P2P plugin IBext
230: hkn0604:696451:696451 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
  6: hkn0404:1346665:1346665 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
231: hkn0604:696467:696467 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
231: hkn0604:696467:696467 [3] NCCL INFO Using network IBext
433: hkn0730:1408955:1408955 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
463: hkn0802:1207551:1207551 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
463: hkn0802:1207551:1207551 [3] NCCL INFO P2P plugin IBext
295: hkn0626:1305656:1305656 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
295: hkn0626:1305656:1305656 [3] NCCL INFO P2P plugin IBext
294: hkn0626:1305634:1305634 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
294: hkn0626:1305634:1305634 [2] NCCL INFO P2P plugin IBext
480: hkn0807:1026285:1026285 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
480: hkn0807:1026285:1026285 [0] NCCL INFO P2P plugin IBext
460: hkn0802:1207543:1207543 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
321: hkn0633:1533546:1533546 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
292: hkn0626:1305637:1305637 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
292: hkn0626:1305637:1305637 [0] NCCL INFO P2P plugin IBext
293: hkn0626:1305645:1305645 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
293: hkn0626:1305645:1305645 [1] NCCL INFO P2P plugin IBext
481: hkn0807:1026277:1026277 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
481: hkn0807:1026277:1026277 [1] NCCL INFO P2P plugin IBext
363: hkn0710:362780:362780 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
461: hkn0802:1207571:1207571 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
461: hkn0802:1207571:1207571 [1] NCCL INFO P2P plugin IBext
434: hkn0730:1408975:1408975 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
434: hkn0730:1408975:1408975 [2] NCCL INFO P2P plugin IBext
  4: hkn0404:1346644:1346644 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  4: hkn0404:1346644:1346644 [0] NCCL INFO P2P plugin IBext
483: hkn0807:1026305:1026305 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
483: hkn0807:1026305:1026305 [3] NCCL INFO P2P plugin IBext
229: hkn0604:696459:696459 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
229: hkn0604:696459:696459 [1] NCCL INFO Using network IBext
432: hkn0730:1408963:1408963 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
 55: hkn0418:1876416:1876416 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
228: hkn0604:696478:696478 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
228: hkn0604:696478:696478 [0] NCCL INFO P2P plugin IBext
  5: hkn0404:1346653:1346653 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  5: hkn0404:1346653:1346653 [1] NCCL INFO P2P plugin IBext
482: hkn0807:1026293:1026293 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
482: hkn0807:1026293:1026293 [2] NCCL INFO P2P plugin IBext
230: hkn0604:696451:696451 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
230: hkn0604:696451:696451 [2] NCCL INFO P2P plugin IBext
360: hkn0710:362792:362792 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
  6: hkn0404:1346665:1346665 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  6: hkn0404:1346665:1346665 [2] NCCL INFO P2P plugin IBext
463: hkn0802:1207551:1207551 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
435: hkn0730:1408947:1408947 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
463: hkn0802:1207551:1207551 [3] NCCL INFO Using network IBext
433: hkn0730:1408955:1408955 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
433: hkn0730:1408955:1408955 [1] NCCL INFO P2P plugin IBext
361: hkn0710:362772:362772 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
320: hkn0633:1533538:1533538 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
460: hkn0802:1207543:1207543 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
460: hkn0802:1207543:1207543 [0] NCCL INFO P2P plugin IBext
461: hkn0802:1207571:1207571 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
461: hkn0802:1207571:1207571 [1] NCCL INFO Using network IBext
292: hkn0626:1305637:1305637 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
293: hkn0626:1305645:1305645 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
292: hkn0626:1305637:1305637 [0] NCCL INFO Using network IBext
321: hkn0633:1533546:1533546 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
321: hkn0633:1533546:1533546 [1] NCCL INFO P2P plugin IBext
293: hkn0626:1305645:1305645 [1] NCCL INFO Using network IBext
323: hkn0633:1533566:1533566 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
362: hkn0710:362764:362764 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
481: hkn0807:1026277:1026277 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
481: hkn0807:1026277:1026277 [1] NCCL INFO Using network IBext
483: hkn0807:1026305:1026305 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
228: hkn0604:696478:696478 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
483: hkn0807:1026305:1026305 [3] NCCL INFO Using network IBext
228: hkn0604:696478:696478 [0] NCCL INFO Using network IBext
230: hkn0604:696451:696451 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
230: hkn0604:696451:696451 [2] NCCL INFO Using network IBext
482: hkn0807:1026293:1026293 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
482: hkn0807:1026293:1026293 [2] NCCL INFO Using network IBext
 54: hkn0418:1876396:1876396 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
363: hkn0710:362780:362780 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
363: hkn0710:362780:362780 [3] NCCL INFO P2P plugin IBext
  5: hkn0404:1346653:1346653 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  5: hkn0404:1346653:1346653 [1] NCCL INFO Using network IBext
  4: hkn0404:1346644:1346644 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  4: hkn0404:1346644:1346644 [0] NCCL INFO Using network IBext
  7: hkn0404:1346645:1346645 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  7: hkn0404:1346645:1346645 [3] NCCL INFO Using network IBext
  6: hkn0404:1346665:1346665 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  6: hkn0404:1346665:1346665 [2] NCCL INFO Using network IBext
432: hkn0730:1408963:1408963 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
432: hkn0730:1408963:1408963 [0] NCCL INFO P2P plugin IBext
 55: hkn0418:1876416:1876416 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 55: hkn0418:1876416:1876416 [3] NCCL INFO P2P plugin IBext
462: hkn0802:1207559:1207559 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
322: hkn0633:1533554:1533554 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
462: hkn0802:1207559:1207559 [2] NCCL INFO Using network IBext
460: hkn0802:1207543:1207543 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
360: hkn0710:362792:362792 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
360: hkn0710:362792:362792 [0] NCCL INFO P2P plugin IBext
460: hkn0802:1207543:1207543 [0] NCCL INFO Using network IBext
433: hkn0730:1408955:1408955 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
433: hkn0730:1408955:1408955 [1] NCCL INFO Using network IBext
320: hkn0633:1533538:1533538 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
320: hkn0633:1533538:1533538 [0] NCCL INFO P2P plugin IBext
349: hkn0706:759478:759478 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
361: hkn0710:362772:362772 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
361: hkn0710:362772:362772 [1] NCCL INFO P2P plugin IBext
435: hkn0730:1408947:1408947 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
435: hkn0730:1408947:1408947 [3] NCCL INFO P2P plugin IBext
294: hkn0626:1305634:1305634 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
294: hkn0626:1305634:1305634 [2] NCCL INFO Using network IBext
480: hkn0807:1026285:1026285 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
480: hkn0807:1026285:1026285 [0] NCCL INFO Using network IBext
295: hkn0626:1305656:1305656 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
295: hkn0626:1305656:1305656 [3] NCCL INFO Using network IBext
323: hkn0633:1533566:1533566 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
323: hkn0633:1533566:1533566 [3] NCCL INFO P2P plugin IBext
432: hkn0730:1408963:1408963 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
432: hkn0730:1408963:1408963 [0] NCCL INFO Using network IBext
362: hkn0710:362764:362764 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
362: hkn0710:362764:362764 [2] NCCL INFO P2P plugin IBext
 54: hkn0418:1876396:1876396 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 54: hkn0418:1876396:1876396 [2] NCCL INFO P2P plugin IBext
 27: hkn0410:1166917:1166917 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
350: hkn0706:759494:759494 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
434: hkn0730:1408975:1408975 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
434: hkn0730:1408975:1408975 [2] NCCL INFO Using network IBext
351: hkn0706:759486:759486 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
435: hkn0730:1408947:1408947 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
435: hkn0730:1408947:1408947 [3] NCCL INFO Using network IBext
361: hkn0710:362772:362772 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
361: hkn0710:362772:362772 [1] NCCL INFO Using network IBext
360: hkn0710:362792:362792 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
360: hkn0710:362792:362792 [0] NCCL INFO Using network IBext
322: hkn0633:1533554:1533554 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
322: hkn0633:1533554:1533554 [2] NCCL INFO P2P plugin IBext
232: hkn0605:719349:719349 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
320: hkn0633:1533538:1533538 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
323: hkn0633:1533566:1533566 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
320: hkn0633:1533538:1533538 [0] NCCL INFO Using network IBext
323: hkn0633:1533566:1533566 [3] NCCL INFO Using network IBext
349: hkn0706:759478:759478 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
349: hkn0706:759478:759478 [1] NCCL INFO P2P plugin IBext
362: hkn0710:362764:362764 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
362: hkn0710:362764:362764 [2] NCCL INFO Using network IBext
340: hkn0704:799215:799215 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
348: hkn0706:759506:759506 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
321: hkn0633:1533546:1533546 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
321: hkn0633:1533546:1533546 [1] NCCL INFO Using network IBext
 54: hkn0418:1876396:1876396 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 54: hkn0418:1876396:1876396 [2] NCCL INFO Using network IBext
363: hkn0710:362780:362780 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
363: hkn0710:362780:362780 [3] NCCL INFO Using network IBext
 27: hkn0410:1166917:1166917 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 27: hkn0410:1166917:1166917 [3] NCCL INFO P2P plugin IBext
322: hkn0633:1533554:1533554 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
322: hkn0633:1533554:1533554 [2] NCCL INFO Using network IBext
350: hkn0706:759494:759494 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
350: hkn0706:759494:759494 [2] NCCL INFO P2P plugin IBext
351: hkn0706:759486:759486 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
351: hkn0706:759486:759486 [3] NCCL INFO P2P plugin IBext
 55: hkn0418:1876416:1876416 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 55: hkn0418:1876416:1876416 [3] NCCL INFO Using network IBext
235: hkn0605:719372:719372 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
 24: hkn0410:1166925:1166925 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 25: hkn0410:1166933:1166933 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
232: hkn0605:719349:719349 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
232: hkn0605:719349:719349 [0] NCCL INFO P2P plugin IBext
341: hkn0704:799223:799223 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
340: hkn0704:799215:799215 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
340: hkn0704:799215:799215 [0] NCCL INFO P2P plugin IBext
348: hkn0706:759506:759506 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
348: hkn0706:759506:759506 [0] NCCL INFO P2P plugin IBext
342: hkn0704:799243:799243 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
 26: hkn0410:1166945:1166945 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
452: hkn0736:1515544:1515544 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
233: hkn0605:719360:719360 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
234: hkn0605:719352:719352 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
343: hkn0704:799231:799231 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
350: hkn0706:759494:759494 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
351: hkn0706:759486:759486 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
350: hkn0706:759494:759494 [2] NCCL INFO Using network IBext
351: hkn0706:759486:759486 [3] NCCL INFO Using network IBext
235: hkn0605:719372:719372 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
235: hkn0605:719372:719372 [3] NCCL INFO P2P plugin IBext
 24: hkn0410:1166925:1166925 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 24: hkn0410:1166925:1166925 [0] NCCL INFO P2P plugin IBext
348: hkn0706:759506:759506 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
 25: hkn0410:1166933:1166933 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 25: hkn0410:1166933:1166933 [1] NCCL INFO P2P plugin IBext
348: hkn0706:759506:759506 [0] NCCL INFO Using network IBext
349: hkn0706:759478:759478 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
349: hkn0706:759478:759478 [1] NCCL INFO Using network IBext
341: hkn0704:799223:799223 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
341: hkn0704:799223:799223 [1] NCCL INFO P2P plugin IBext
342: hkn0704:799243:799243 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
342: hkn0704:799243:799243 [2] NCCL INFO P2P plugin IBext
452: hkn0736:1515544:1515544 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
452: hkn0736:1515544:1515544 [0] NCCL INFO P2P plugin IBext
 26: hkn0410:1166945:1166945 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 26: hkn0410:1166945:1166945 [2] NCCL INFO P2P plugin IBext
455: hkn0736:1515543:1515543 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
233: hkn0605:719360:719360 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
233: hkn0605:719360:719360 [1] NCCL INFO P2P plugin IBext
234: hkn0605:719352:719352 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
234: hkn0605:719352:719352 [2] NCCL INFO P2P plugin IBext
343: hkn0704:799231:799231 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
343: hkn0704:799231:799231 [3] NCCL INFO P2P plugin IBext
235: hkn0605:719372:719372 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
235: hkn0605:719372:719372 [3] NCCL INFO Using network IBext
453: hkn0736:1515557:1515557 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
 27: hkn0410:1166917:1166917 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 27: hkn0410:1166917:1166917 [3] NCCL INFO Using network IBext
 25: hkn0410:1166933:1166933 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 25: hkn0410:1166933:1166933 [1] NCCL INFO Using network IBext
 24: hkn0410:1166925:1166925 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 24: hkn0410:1166925:1166925 [0] NCCL INFO Using network IBext
 26: hkn0410:1166945:1166945 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 26: hkn0410:1166945:1166945 [2] NCCL INFO Using network IBext
232: hkn0605:719349:719349 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
232: hkn0605:719349:719349 [0] NCCL INFO Using network IBext
233: hkn0605:719360:719360 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
 52: hkn0418:1876388:1876388 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
233: hkn0605:719360:719360 [1] NCCL INFO Using network IBext
234: hkn0605:719352:719352 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
234: hkn0605:719352:719352 [2] NCCL INFO Using network IBext
342: hkn0704:799243:799243 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
341: hkn0704:799223:799223 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
342: hkn0704:799243:799243 [2] NCCL INFO Using network IBext
341: hkn0704:799223:799223 [1] NCCL INFO Using network IBext
454: hkn0736:1515545:1515545 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
343: hkn0704:799231:799231 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
343: hkn0704:799231:799231 [3] NCCL INFO Using network IBext
340: hkn0704:799215:799215 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
340: hkn0704:799215:799215 [0] NCCL INFO Using network IBext
455: hkn0736:1515543:1515543 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
455: hkn0736:1515543:1515543 [3] NCCL INFO P2P plugin IBext
391: hkn0717:1459:1459 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
 53: hkn0418:1876404:1876404 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
453: hkn0736:1515557:1515557 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
453: hkn0736:1515557:1515557 [1] NCCL INFO P2P plugin IBext
389: hkn0717:1475:1475 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
153: hkn0515:2903997:2903997 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
152: hkn0515:2904005:2904005 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
400: hkn0720:14302:14302 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
454: hkn0736:1515545:1515545 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
454: hkn0736:1515545:1515545 [2] NCCL INFO P2P plugin IBext
455: hkn0736:1515543:1515543 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
455: hkn0736:1515543:1515543 [3] NCCL INFO Using network IBext
500: hkn0814:683023:683023 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
 52: hkn0418:1876388:1876388 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 52: hkn0418:1876388:1876388 [0] NCCL INFO P2P plugin IBext
391: hkn0717:1459:1459 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
391: hkn0717:1459:1459 [3] NCCL INFO P2P plugin IBext
138: hkn0511:3073676:3073676 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
239: hkn0606:2379367:2379367 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
453: hkn0736:1515557:1515557 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
453: hkn0736:1515557:1515557 [1] NCCL INFO Using network IBext
452: hkn0736:1515544:1515544 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
452: hkn0736:1515544:1515544 [0] NCCL INFO Using network IBext
137: hkn0511:3073646:3073646 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
136: hkn0511:3073654:3073654 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
 53: hkn0418:1876404:1876404 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 53: hkn0418:1876404:1876404 [1] NCCL INFO P2P plugin IBext
154: hkn0515:2904025:2904025 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
238: hkn0606:2379355:2379355 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
454: hkn0736:1515545:1515545 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
454: hkn0736:1515545:1515545 [2] NCCL INFO Using network IBext
389: hkn0717:1475:1475 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
389: hkn0717:1475:1475 [1] NCCL INFO P2P plugin IBext
237: hkn0606:2379347:2379347 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
388: hkn0717:1467:1467 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
153: hkn0515:2903997:2903997 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
153: hkn0515:2903997:2903997 [1] NCCL INFO P2P plugin IBext
501: hkn0814:683039:683039 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
139: hkn0511:3073664:3073664 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
152: hkn0515:2904005:2904005 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
152: hkn0515:2904005:2904005 [0] NCCL INFO P2P plugin IBext
236: hkn0606:2379339:2379339 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
400: hkn0720:14302:14302 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
400: hkn0720:14302:14302 [0] NCCL INFO P2P plugin IBext
500: hkn0814:683023:683023 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
500: hkn0814:683023:683023 [0] NCCL INFO P2P plugin IBext
182: hkn0526:1435637:1435637 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
402: hkn0720:14310:14310 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
155: hkn0515:2904013:2904013 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
138: hkn0511:3073676:3073676 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
138: hkn0511:3073676:3073676 [2] NCCL INFO P2P plugin IBext
502: hkn0814:683050:683050 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
 52: hkn0418:1876388:1876388 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 52: hkn0418:1876388:1876388 [0] NCCL INFO Using network IBext
239: hkn0606:2379367:2379367 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
239: hkn0606:2379367:2379367 [3] NCCL INFO P2P plugin IBext
 53: hkn0418:1876404:1876404 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 53: hkn0418:1876404:1876404 [1] NCCL INFO Using network IBext
401: hkn0720:14318:14318 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
202: hkn0531:1237910:1237910 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
390: hkn0717:1487:1487 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
201: hkn0531:1237902:1237902 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
300: hkn0628:679159:679159 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
137: hkn0511:3073646:3073646 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
137: hkn0511:3073646:3073646 [1] NCCL INFO P2P plugin IBext
154: hkn0515:2904025:2904025 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
154: hkn0515:2904025:2904025 [2] NCCL INFO P2P plugin IBext
183: hkn0526:1435657:1435657 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
136: hkn0511:3073654:3073654 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
136: hkn0511:3073654:3073654 [0] NCCL INFO P2P plugin IBext
389: hkn0717:1475:1475 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
389: hkn0717:1475:1475 [1] NCCL INFO Using network IBext
237: hkn0606:2379347:2379347 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
237: hkn0606:2379347:2379347 [1] NCCL INFO P2P plugin IBext
180: hkn0526:1435645:1435645 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
238: hkn0606:2379355:2379355 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
238: hkn0606:2379355:2379355 [2] NCCL INFO P2P plugin IBext
282: hkn0622:2027744:2027744 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
388: hkn0717:1467:1467 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
388: hkn0717:1467:1467 [0] NCCL INFO P2P plugin IBext
303: hkn0628:679131:679131 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
200: hkn0531:1237922:1237922 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
203: hkn0531:1237894:1237894 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
503: hkn0814:683031:683031 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
403: hkn0720:14330:14330 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
152: hkn0515:2904005:2904005 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
152: hkn0515:2904005:2904005 [0] NCCL INFO Using network IBext
181: hkn0526:1435629:1435629 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
139: hkn0511:3073664:3073664 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
139: hkn0511:3073664:3073664 [3] NCCL INFO P2P plugin IBext
501: hkn0814:683039:683039 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
501: hkn0814:683039:683039 [1] NCCL INFO P2P plugin IBext
236: hkn0606:2379339:2379339 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
236: hkn0606:2379339:2379339 [0] NCCL INFO P2P plugin IBext
182: hkn0526:1435637:1435637 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
182: hkn0526:1435637:1435637 [2] NCCL INFO P2P plugin IBext
391: hkn0717:1459:1459 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
391: hkn0717:1459:1459 [3] NCCL INFO Using network IBext
283: hkn0622:2027736:2027736 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
402: hkn0720:14310:14310 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
402: hkn0720:14310:14310 [2] NCCL INFO P2P plugin IBext
155: hkn0515:2904013:2904013 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
155: hkn0515:2904013:2904013 [3] NCCL INFO P2P plugin IBext
154: hkn0515:2904025:2904025 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
154: hkn0515:2904025:2904025 [2] NCCL INFO Using network IBext
388: hkn0717:1467:1467 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
388: hkn0717:1467:1467 [0] NCCL INFO Using network IBext
502: hkn0814:683050:683050 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
502: hkn0814:683050:683050 [2] NCCL INFO P2P plugin IBext
281: hkn0622:2027752:2027752 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
401: hkn0720:14318:14318 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
401: hkn0720:14318:14318 [1] NCCL INFO P2P plugin IBext
390: hkn0717:1487:1487 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
390: hkn0717:1487:1487 [2] NCCL INFO P2P plugin IBext
202: hkn0531:1237910:1237910 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
202: hkn0531:1237910:1237910 [2] NCCL INFO P2P plugin IBext
280: hkn0622:2027764:2027764 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
136: hkn0511:3073654:3073654 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
136: hkn0511:3073654:3073654 [0] NCCL INFO Using network IBext
201: hkn0531:1237902:1237902 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
201: hkn0531:1237902:1237902 [1] NCCL INFO P2P plugin IBext
137: hkn0511:3073646:3073646 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
137: hkn0511:3073646:3073646 [1] NCCL INFO Using network IBext
300: hkn0628:679159:679159 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
300: hkn0628:679159:679159 [0] NCCL INFO P2P plugin IBext
183: hkn0526:1435657:1435657 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
183: hkn0526:1435657:1435657 [3] NCCL INFO P2P plugin IBext
139: hkn0511:3073664:3073664 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
139: hkn0511:3073664:3073664 [3] NCCL INFO Using network IBext
302: hkn0628:679139:679139 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
237: hkn0606:2379347:2379347 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
238: hkn0606:2379355:2379355 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
237: hkn0606:2379347:2379347 [1] NCCL INFO Using network IBext
238: hkn0606:2379355:2379355 [2] NCCL INFO Using network IBext
282: hkn0622:2027744:2027744 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
282: hkn0622:2027744:2027744 [2] NCCL INFO P2P plugin IBext
180: hkn0526:1435645:1435645 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
180: hkn0526:1435645:1435645 [0] NCCL INFO P2P plugin IBext
301: hkn0628:679147:679147 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
236: hkn0606:2379339:2379339 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
303: hkn0628:679131:679131 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
303: hkn0628:679131:679131 [3] NCCL INFO P2P plugin IBext
236: hkn0606:2379339:2379339 [0] NCCL INFO Using network IBext
153: hkn0515:2903997:2903997 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
153: hkn0515:2903997:2903997 [1] NCCL INFO Using network IBext
200: hkn0531:1237922:1237922 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
200: hkn0531:1237922:1237922 [0] NCCL INFO P2P plugin IBext
503: hkn0814:683031:683031 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
503: hkn0814:683031:683031 [3] NCCL INFO P2P plugin IBext
403: hkn0720:14330:14330 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
403: hkn0720:14330:14330 [3] NCCL INFO P2P plugin IBext
203: hkn0531:1237894:1237894 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
203: hkn0531:1237894:1237894 [3] NCCL INFO P2P plugin IBext
155: hkn0515:2904013:2904013 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
155: hkn0515:2904013:2904013 [3] NCCL INFO Using network IBext
181: hkn0526:1435629:1435629 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
181: hkn0526:1435629:1435629 [1] NCCL INFO P2P plugin IBext
501: hkn0814:683039:683039 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
501: hkn0814:683039:683039 [1] NCCL INFO Using network IBext
500: hkn0814:683023:683023 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
500: hkn0814:683023:683023 [0] NCCL INFO Using network IBext
502: hkn0814:683050:683050 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
502: hkn0814:683050:683050 [2] NCCL INFO Using network IBext
390: hkn0717:1487:1487 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
390: hkn0717:1487:1487 [2] NCCL INFO Using network IBext
283: hkn0622:2027736:2027736 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
283: hkn0622:2027736:2027736 [3] NCCL INFO P2P plugin IBext
400: hkn0720:14302:14302 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
138: hkn0511:3073676:3073676 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
401: hkn0720:14318:14318 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
138: hkn0511:3073676:3073676 [2] NCCL INFO Using network IBext
401: hkn0720:14318:14318 [1] NCCL INFO Using network IBext
402: hkn0720:14310:14310 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
400: hkn0720:14302:14302 [0] NCCL INFO Using network IBext
402: hkn0720:14310:14310 [2] NCCL INFO Using network IBext
281: hkn0622:2027752:2027752 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
281: hkn0622:2027752:2027752 [1] NCCL INFO P2P plugin IBext
503: hkn0814:683031:683031 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
503: hkn0814:683031:683031 [3] NCCL INFO Using network IBext
280: hkn0622:2027764:2027764 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
280: hkn0622:2027764:2027764 [0] NCCL INFO P2P plugin IBext
403: hkn0720:14330:14330 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
403: hkn0720:14330:14330 [3] NCCL INFO Using network IBext
239: hkn0606:2379367:2379367 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
239: hkn0606:2379367:2379367 [3] NCCL INFO Using network IBext
183: hkn0526:1435657:1435657 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
180: hkn0526:1435645:1435645 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
183: hkn0526:1435657:1435657 [3] NCCL INFO Using network IBext
180: hkn0526:1435645:1435645 [0] NCCL INFO Using network IBext
181: hkn0526:1435629:1435629 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
181: hkn0526:1435629:1435629 [1] NCCL INFO Using network IBext
302: hkn0628:679139:679139 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
302: hkn0628:679139:679139 [2] NCCL INFO P2P plugin IBext
301: hkn0628:679147:679147 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
301: hkn0628:679147:679147 [1] NCCL INFO P2P plugin IBext
200: hkn0531:1237922:1237922 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
203: hkn0531:1237894:1237894 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
203: hkn0531:1237894:1237894 [3] NCCL INFO Using network IBext
200: hkn0531:1237922:1237922 [0] NCCL INFO Using network IBext
504: hkn0815:402353:402353 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
507: hkn0815:402329:402329 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
283: hkn0622:2027736:2027736 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
281: hkn0622:2027752:2027752 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
283: hkn0622:2027736:2027736 [3] NCCL INFO Using network IBext
182: hkn0526:1435637:1435637 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
281: hkn0622:2027752:2027752 [1] NCCL INFO Using network IBext
182: hkn0526:1435637:1435637 [2] NCCL INFO Using network IBext
280: hkn0622:2027764:2027764 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
280: hkn0622:2027764:2027764 [0] NCCL INFO Using network IBext
202: hkn0531:1237910:1237910 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
201: hkn0531:1237902:1237902 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
202: hkn0531:1237910:1237910 [2] NCCL INFO Using network IBext
201: hkn0531:1237902:1237902 [1] NCCL INFO Using network IBext
301: hkn0628:679147:679147 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
301: hkn0628:679147:679147 [1] NCCL INFO Using network IBext
302: hkn0628:679139:679139 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
302: hkn0628:679139:679139 [2] NCCL INFO Using network IBext
300: hkn0628:679159:679159 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
300: hkn0628:679159:679159 [0] NCCL INFO Using network IBext
282: hkn0622:2027744:2027744 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
282: hkn0622:2027744:2027744 [2] NCCL INFO Using network IBext
303: hkn0628:679131:679131 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
303: hkn0628:679131:679131 [3] NCCL INFO Using network IBext
492: hkn0810:946764:946764 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
507: hkn0815:402329:402329 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
507: hkn0815:402329:402329 [3] NCCL INFO P2P plugin IBext
504: hkn0815:402353:402353 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
504: hkn0815:402353:402353 [0] NCCL INFO P2P plugin IBext
492: hkn0810:946764:946764 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
492: hkn0810:946764:946764 [0] NCCL INFO P2P plugin IBext
505: hkn0815:402333:402333 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
417: hkn0725:3119163:3119163 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
418: hkn0725:3119184:3119184 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
493: hkn0810:946752:946752 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
494: hkn0810:946736:946736 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
338: hkn0703:748322:748322 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
506: hkn0815:402341:402341 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
386: hkn0716:115704:115704 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
 17: hkn0408:2898045:2898045 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
505: hkn0815:402333:402333 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
505: hkn0815:402333:402333 [1] NCCL INFO P2P plugin IBext
 16: hkn0408:2898029:2898029 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
495: hkn0810:946744:946744 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
384: hkn0716:115715:115715 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
417: hkn0725:3119163:3119163 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
417: hkn0725:3119163:3119163 [1] NCCL INFO P2P plugin IBext
418: hkn0725:3119184:3119184 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
418: hkn0725:3119184:3119184 [2] NCCL INFO P2P plugin IBext
 19: hkn0408:2898037:2898037 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
493: hkn0810:946752:946752 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
493: hkn0810:946752:946752 [1] NCCL INFO P2P plugin IBext
494: hkn0810:946736:946736 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
494: hkn0810:946736:946736 [2] NCCL INFO P2P plugin IBext
338: hkn0703:748322:748322 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
338: hkn0703:748322:748322 [2] NCCL INFO P2P plugin IBext
416: hkn0725:3119164:3119164 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
 18: hkn0408:2898057:2898057 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
507: hkn0815:402329:402329 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
507: hkn0815:402329:402329 [3] NCCL INFO Using network IBext
504: hkn0815:402353:402353 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
504: hkn0815:402353:402353 [0] NCCL INFO Using network IBext
506: hkn0815:402341:402341 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
506: hkn0815:402341:402341 [2] NCCL INFO P2P plugin IBext
386: hkn0716:115704:115704 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
386: hkn0716:115704:115704 [2] NCCL INFO P2P plugin IBext
336: hkn0703:748295:748295 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
505: hkn0815:402333:402333 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
505: hkn0815:402333:402333 [1] NCCL INFO Using network IBext
419: hkn0725:3119172:3119172 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
339: hkn0703:748311:748311 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
 17: hkn0408:2898045:2898045 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 17: hkn0408:2898045:2898045 [1] NCCL INFO P2P plugin IBext
316: hkn0632:1765871:1765871 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
495: hkn0810:946744:946744 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
495: hkn0810:946744:946744 [3] NCCL INFO P2P plugin IBext
319: hkn0632:1765859:1765859 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
494: hkn0810:946736:946736 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
494: hkn0810:946736:946736 [2] NCCL INFO Using network IBext
492: hkn0810:946764:946764 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
493: hkn0810:946752:946752 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
493: hkn0810:946752:946752 [1] NCCL INFO Using network IBext
492: hkn0810:946764:946764 [0] NCCL INFO Using network IBext
 16: hkn0408:2898029:2898029 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 16: hkn0408:2898029:2898029 [0] NCCL INFO P2P plugin IBext
337: hkn0703:748303:748303 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
506: hkn0815:402341:402341 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
506: hkn0815:402341:402341 [2] NCCL INFO Using network IBext
 19: hkn0408:2898037:2898037 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 19: hkn0408:2898037:2898037 [3] NCCL INFO P2P plugin IBext
385: hkn0716:115707:115707 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
384: hkn0716:115715:115715 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
384: hkn0716:115715:115715 [0] NCCL INFO P2P plugin IBext
 18: hkn0408:2898057:2898057 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
416: hkn0725:3119164:3119164 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
416: hkn0725:3119164:3119164 [0] NCCL INFO P2P plugin IBext
 18: hkn0408:2898057:2898057 [2] NCCL INFO P2P plugin IBext
387: hkn0716:115727:115727 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
318: hkn0632:1765851:1765851 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
495: hkn0810:946744:946744 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
495: hkn0810:946744:946744 [3] NCCL INFO Using network IBext
419: hkn0725:3119172:3119172 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
419: hkn0725:3119172:3119172 [3] NCCL INFO P2P plugin IBext
317: hkn0632:1765843:1765843 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
339: hkn0703:748311:748311 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
339: hkn0703:748311:748311 [3] NCCL INFO P2P plugin IBext
316: hkn0632:1765871:1765871 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
316: hkn0632:1765871:1765871 [0] NCCL INFO P2P plugin IBext
336: hkn0703:748295:748295 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
336: hkn0703:748295:748295 [0] NCCL INFO P2P plugin IBext
319: hkn0632:1765859:1765859 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
319: hkn0632:1765859:1765859 [3] NCCL INFO P2P plugin IBext
 18: hkn0408:2898057:2898057 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 19: hkn0408:2898037:2898037 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 18: hkn0408:2898057:2898057 [2] NCCL INFO Using network IBext
 19: hkn0408:2898037:2898037 [3] NCCL INFO Using network IBext
337: hkn0703:748303:748303 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
337: hkn0703:748303:748303 [1] NCCL INFO P2P plugin IBext
385: hkn0716:115707:115707 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
385: hkn0716:115707:115707 [1] NCCL INFO P2P plugin IBext
384: hkn0716:115715:115715 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
384: hkn0716:115715:115715 [0] NCCL INFO Using network IBext
417: hkn0725:3119163:3119163 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
417: hkn0725:3119163:3119163 [1] NCCL INFO Using network IBext
418: hkn0725:3119184:3119184 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
418: hkn0725:3119184:3119184 [2] NCCL INFO Using network IBext
416: hkn0725:3119164:3119164 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
419: hkn0725:3119172:3119172 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
419: hkn0725:3119172:3119172 [3] NCCL INFO Using network IBext
416: hkn0725:3119164:3119164 [0] NCCL INFO Using network IBext
387: hkn0716:115727:115727 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
387: hkn0716:115727:115727 [3] NCCL INFO P2P plugin IBext
386: hkn0716:115704:115704 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
386: hkn0716:115704:115704 [2] NCCL INFO Using network IBext
318: hkn0632:1765851:1765851 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
318: hkn0632:1765851:1765851 [2] NCCL INFO P2P plugin IBext
336: hkn0703:748295:748295 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
336: hkn0703:748295:748295 [0] NCCL INFO Using network IBext
338: hkn0703:748322:748322 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
339: hkn0703:748311:748311 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
338: hkn0703:748322:748322 [2] NCCL INFO Using network IBext
339: hkn0703:748311:748311 [3] NCCL INFO Using network IBext
317: hkn0632:1765843:1765843 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
317: hkn0632:1765843:1765843 [1] NCCL INFO P2P plugin IBext
337: hkn0703:748303:748303 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
337: hkn0703:748303:748303 [1] NCCL INFO Using network IBext
385: hkn0716:115707:115707 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
385: hkn0716:115707:115707 [1] NCCL INFO Using network IBext
 17: hkn0408:2898045:2898045 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 17: hkn0408:2898045:2898045 [1] NCCL INFO Using network IBext
 16: hkn0408:2898029:2898029 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 16: hkn0408:2898029:2898029 [0] NCCL INFO Using network IBext
387: hkn0716:115727:115727 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
387: hkn0716:115727:115727 [3] NCCL INFO Using network IBext
317: hkn0632:1765843:1765843 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
318: hkn0632:1765851:1765851 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
317: hkn0632:1765843:1765843 [1] NCCL INFO Using network IBext
318: hkn0632:1765851:1765851 [2] NCCL INFO Using network IBext
319: hkn0632:1765859:1765859 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
319: hkn0632:1765859:1765859 [3] NCCL INFO Using network IBext
316: hkn0632:1765871:1765871 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
316: hkn0632:1765871:1765871 [0] NCCL INFO Using network IBext
251: hkn0609:718044:718148 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
195: hkn0529:1548038:1548157 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  7: hkn0404:1346645:1346762 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 13: hkn0407:1823500:1823618 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
279: hkn0621:1998830:1998944 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
192: hkn0529:1548046:1548160 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
248: hkn0609:718056:718153 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
409: hkn0723:215333:215489 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
435: hkn0730:1408947:1409077 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
430: hkn0728:1331266:1331371 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
229: hkn0604:696459:696573 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
176: hkn0525:994034:994135 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
190: hkn0528:1308903:1309021 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
193: hkn0529:1548066:1548163 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
110: hkn0504:48311:48436 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
288: hkn0624:1780140:1780284 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
194: hkn0529:1548054:1548165 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
235: hkn0605:719372:719467 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 12: hkn0407:1823520:1823613 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
249: hkn0609:718036:718147 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  4: hkn0404:1346644:1346761 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 14: hkn0407:1823492:1823615 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
250: hkn0609:718028:718154 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
128: hkn0509:3131628:3131753 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
276: hkn0621:1998822:1998945 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
372: hkn0713:477480:477575 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  6: hkn0404:1346665:1346763 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
127: hkn0508:3146366:3146462 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
233: hkn0605:719360:719472 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
335: hkn0636:1661521:1661639 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 15: hkn0407:1823508:1823614 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  5: hkn0404:1346653:1346760 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
365: hkn0711:591174:591286 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
106: hkn0503:2906951:2907055 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 38: hkn0413:2373948:2374057 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
236: hkn0606:2379339:2379462 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
207: hkn0532:932502:932816 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
286: hkn0623:1879995:1880114 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
433: hkn0730:1408955:1409068 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
454: hkn0736:1515545:1515656 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
429: hkn0728:1331258:1331374 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
292: hkn0626:1305637:1305778 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
102: hkn0502:236315:236406 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
283: hkn0622:2027736:2027858 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
198: hkn0530:1265343:1265469 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
124: hkn0508:3146346:3146464 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
277: hkn0621:1998849:1998946 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
408: hkn0723:215341:215495 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
438: hkn0731:1393942:1394083 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
247: hkn0608:492955:493068 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
231: hkn0604:696467:696570 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
232: hkn0605:719349:719471 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
133: hkn0510:2769286:2769390 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 39: hkn0413:2373932:2374059 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
111: hkn0504:48327:48437 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
126: hkn0508:3146354:3146461 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
278: hkn0621:1998838:1998943 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
411: hkn0723:215353:215498 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
291: hkn0624:1780148:1780287 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
405: hkn0721:2306514:2306619 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
234: hkn0605:719352:719473 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
179: hkn0525:994006:994130 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
410: hkn0723:215325:215496 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
125: hkn0508:3146338:3146460 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 83: hkn0425:2091271:2091395 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
455: hkn0736:1515543:1515649 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
130: hkn0509:3131655:3131751 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 37: hkn0413:2373940:2374062 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
442: hkn0732:1218881:1219002 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
202: hkn0531:1237910:1238025 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
428: hkn0728:1331278:1331370 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
329: hkn0635:1232786:1232910 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
293: hkn0626:1305645:1305779 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
167: hkn0521:1205008:1205131 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
289: hkn0624:1780160:1780285 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
138: hkn0511:3073676:3073772 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
170: hkn0523:1555340:1555444 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
224: hkn0603:1420450:1420575 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
315: hkn0631:1029032:1029141 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 79: hkn0424:2955186:2955299 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 36: hkn0413:2373960:2374058 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
191: hkn0528:1308895:1309019 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
432: hkn0730:1408963:1409072 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
373: hkn0713:477452:477574 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
228: hkn0604:696478:696578 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 58: hkn0419:1551505:1551604 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
178: hkn0525:994022:994132 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
341: hkn0704:799223:799342 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
173: hkn0524:1141002:1141130 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
237: hkn0606:2379347:2379461 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
129: hkn0509:3131636:3131744 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
431: hkn0728:1331257:1331376 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
105: hkn0503:2906935:2907063 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 92: hkn0428:674583:674690 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
285: hkn0623:1880003:1880109 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
434: hkn0730:1408975:1409075 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
254: hkn0611:717063:717166 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
290: hkn0624:1780132:1780286 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
246: hkn0608:492947:493073 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
366: hkn0711:591185:591287 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
333: hkn0636:1661529:1661644 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
230: hkn0604:696451:696579 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
177: hkn0525:994014:994129 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
109: hkn0504:48319:48430 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
305: hkn0629:1599304:1599395 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
206: hkn0532:932510:932820 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
393: hkn0718:3924262:3924378 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
264: hkn0615:421550:421660 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
295: hkn0626:1305656:1305785 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 61: hkn0420:3217408:3217553 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
463: hkn0802:1207551:1207689 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
452: hkn0736:1515544:1515654 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
101: hkn0502:236287:236411 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
377: hkn0714:439253:439365 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
239: hkn0606:2379367:2379465 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
108: hkn0504:48339:48431 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
131: hkn0509:3131644:3131750 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 35: hkn0412:2269608:2269737 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
475: hkn0805:1119325:1119448 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
263: hkn0613:909932:910042 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
311: hkn0630:1605706:1605807 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
398: hkn0719:1312991:1313080 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
337: hkn0703:748303:748410 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
115: hkn0505:2310997:2311121 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 90: hkn0427:1142341:1142458 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
284: hkn0623:1880015:1880110 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
134: hkn0510:2769278:2769396 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
294: hkn0626:1305634:1305784 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 95: hkn0428:674595:674697 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
334: hkn0636:1661541:1661648 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
494: hkn0810:946736:946861 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
340: hkn0704:799215:799344 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
280: hkn0622:2027764:2027860 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
493: hkn0810:946752:946862 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
338: hkn0703:748322:748407 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
437: hkn0731:1393941:1394086 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
238: hkn0606:2379355:2379460 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
453: hkn0736:1515557:1515653 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
375: hkn0713:477460:477578 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
168: hkn0523:1555352:1555443 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
367: hkn0711:591158:591280 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
374: hkn0713:477468:477571 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
245: hkn0608:492963:493070 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
426: hkn0727:1353002:1353113 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
466: hkn0803:883795:883893 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
332: hkn0636:1661513:1661645 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 52: hkn0418:1876388:1876514 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 72: hkn0423:1712171:1712286 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
204: hkn0532:932494:932817 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
312: hkn0631:1029044:1029136 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
100: hkn0502:236295:236412 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
225: hkn0603:1420458:1420572 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
364: hkn0711:591166:591281 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
299: hkn0627:1795186:1795268 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
107: hkn0503:2906943:2907062 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
267: hkn0615:421542:421667 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
404: hkn0721:2306526:2306622 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 44: hkn0415:2503651:2503760 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
439: hkn0731:1393950:1394081 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
132: hkn0510:2769270:2769395 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
169: hkn0523:1555324:1555450 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
320: hkn0633:1533538:1533659 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
339: hkn0703:748311:748409 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
104: hkn0503:2906963:2907057 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
371: hkn0712:302309:302405 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
205: hkn0532:932522:932818 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 82: hkn0425:2091279:2091402 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
344: hkn0705:790415:790543 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
135: hkn0510:2769298:2769389 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 68: hkn0422:4160376:4160473 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
287: hkn0623:1879987:1880116 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 93: hkn0428:674567:674696 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
343: hkn0704:799231:799343 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
244: hkn0608:492975:493069 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
189: hkn0528:1308923:1309018 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
441: hkn0732:1218890:1218999 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
282: hkn0622:2027744:2027863 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
171: hkn0523:1555332:1555449 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
188: hkn0528:1308911:1309016 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
342: hkn0704:799243:799339 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
200: hkn0531:1237922:1238019 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
325: hkn0634:1528068:1528186 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
114: hkn0505:2311013:2311117 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
103: hkn0502:236303:236407 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
436: hkn0731:1393962:1394080 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 57: hkn0419:1551489:1551602 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
336: hkn0703:748295:748408 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
241: hkn0607:911603:911711 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
274: hkn0617:2301935:2302046 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 94: hkn0428:674575:674691 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 10: hkn0405:3214170:3214279 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
281: hkn0622:2027752:2027859 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
492: hkn0810:946764:946863 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
203: hkn0531:1237894:1238018 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
136: hkn0511:3073654:3073767 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 77: hkn0424:2955178:2955291 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
165: hkn0521:1205024:1205132 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
328: hkn0635:1232794:1232913 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
220: hkn0602:3370918:3371090 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 80: hkn0425:2091287:2091403 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
392: hkn0718:3924246:3924376 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
227: hkn0603:1420478:1420573 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
201: hkn0531:1237902:1238024 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
406: hkn0721:2306498:2306623 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
495: hkn0810:946744:946866 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
308: hkn0630:1605678:1605803 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
174: hkn0524:1141010:1141129 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 34: hkn0412:2269636:2269732 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
197: hkn0530:1265371:1265467 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
306: hkn0629:1599284:1599393 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
157: hkn0516:2923212:2923315 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 88: hkn0427:1142349:1142466 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 33: hkn0412:2269624:2269736 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
445: hkn0733:1396580:1396694 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
112: hkn0505:2311025:2311118 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
369: hkn0712:302289:302403 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 60: hkn0420:3217416:3217549 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
460: hkn0802:1207543:1207697 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
265: hkn0615:421570:421665 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
421: hkn0726:1555337:1555444 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
172: hkn0524:1141018:1141124 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
113: hkn0505:2311005:2311114 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
322: hkn0633:1533554:1533664 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
399: hkn0719:1312971:1313088 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
440: hkn0732:1218902:1218998 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
378: hkn0714:439245:439363 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 81: hkn0425:2091299:2091397 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
226: hkn0603:1420466:1420571 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
313: hkn0631:1029024:1029139 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
166: hkn0521:1205036:1205135 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
407: hkn0721:2306506:2306615 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 32: hkn0412:2269616:2269733 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
255: hkn0611:717043:717161 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
266: hkn0615:421558:421661 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 84: hkn0426:821266:821410 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 56: hkn0419:1551497:1551601 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
310: hkn0630:1605686:1605806 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  1: hkn0403:1776565:1776936 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
443: hkn0732:1218882:1219000 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
271: hkn0616:412189:412285 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
314: hkn0631:1029016:1029137 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
261: hkn0613:909944:910037 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
309: hkn0630:1605694:1605798 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
175: hkn0524:1141030:1141123 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
351: hkn0706:759486:759602 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
139: hkn0511:3073664:3073769 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
472: hkn0805:1119345:1119447 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
394: hkn0718:3924274:3924372 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
321: hkn0633:1533546:1533662 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
240: hkn0607:911595:911709 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 76: hkn0424:2955170:2955294 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
395: hkn0718:3924254:3924371 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 59: hkn0419:1551517:1551600 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 54: hkn0418:1876396:1876507 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
164: hkn0521:1205016:1205137 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
304: hkn0629:1599292:1599400 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 19: hkn0408:2898037:2898154 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
396: hkn0719:1312979:1313087 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
296: hkn0627:1795174:1795274 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
462: hkn0802:1207559:1207696 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
252: hkn0611:717035:717164 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
137: hkn0511:3073646:3073768 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 62: hkn0420:3217428:3217558 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
425: hkn0727:1353010:1353119 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
323: hkn0633:1533566:1533658 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
221: hkn0602:3370890:3371086 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 22: hkn0409:2592882:2592991 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
259: hkn0612:924215:924321 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
379: hkn0714:439265:439360 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 47: hkn0415:2503663:2503759 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
180: hkn0526:1435645:1435749 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 75: hkn0423:1712190:1712287 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 89: hkn0427:1142369:1142461 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
464: hkn0803:883779:883891 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
331: hkn0635:1232814:1232915 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
307: hkn0629:1599276:1599401 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
349: hkn0706:759478:759608 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
242: hkn0607:911587:911714 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
330: hkn0635:1232802:1232909 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 26: hkn0410:1166945:1167042 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
346: hkn0705:790431:790545 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
272: hkn0617:2301945:2302053 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 63: hkn0420:3217400:3217555 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
253: hkn0611:717051:717160 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
370: hkn0712:302281:302408 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
324: hkn0634:1528076:1528180 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 78: hkn0424:2955198:2955298 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
260: hkn0613:909924:910036 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
376: hkn0714:439237:439359 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
347: hkn0705:790423:790536 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 55: hkn0418:1876416:1876509 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
473: hkn0805:1119333:1119444 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 71: hkn0422:4160348:4160470 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
327: hkn0634:1528094:1528189 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
397: hkn0719:1312963:1313082 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
243: hkn0607:911615:911710 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
461: hkn0802:1207571:1207691 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
381: hkn0715:409138:409236 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 45: hkn0415:2503635:2503763 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 99: hkn0501:1335147:1335272 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
258: hkn0612:924199:924320 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 29: hkn0411:2323109:2323200 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
326: hkn0634:1528060:1528187 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
361: hkn0710:362772:362881 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 91: hkn0427:1142357:1142467 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
316: hkn0632:1765871:1765970 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 18: hkn0408:2898057:2898153 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
345: hkn0705:790443:790544 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
348: hkn0706:759506:759606 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 53: hkn0418:1876404:1876515 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
474: hkn0805:1119317:1119439 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
275: hkn0617:2301957:2302052 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 17: hkn0408:2898045:2898159 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 48: hkn0417:2274888:2274985 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  2: hkn0403:1776577:1776939 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
196: hkn0530:1265359:1265466 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
262: hkn0613:909916:910043 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
368: hkn0712:302297:302400 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
350: hkn0706:759494:759603 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
302: hkn0628:679139:679252 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
215: hkn0535:2406222:2406330 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
444: hkn0733:1396588:1396702 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 46: hkn0415:2503643:2503758 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
154: hkn0515:2904025:2904145 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
297: hkn0627:1795158:1795270 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
424: hkn0727:1353001:1353114 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
414: hkn0724:1723187:1723325 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 74: hkn0423:1712179:1712289 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
402: hkn0720:14310:14477 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
465: hkn0803:883787:883894 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
476: hkn0806:1061522:1061652 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
273: hkn0617:2301927:2302047 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 86: hkn0426:821274:821408 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
423: hkn0726:1555329:1555441 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
223: hkn0602:3370906:3371095 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
269: hkn0616:412177:412290 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
298: hkn0627:1795166:1795271 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
427: hkn0727:1353022:1353120 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 16: hkn0408:2898029:2898160 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  0: hkn0403:1776559:1776930 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
256: hkn0612:924207:924324 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
383: hkn0715:409110:409235 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
156: hkn0516:2923204:2923321 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
182: hkn0526:1435637:1435754 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
268: hkn0616:412169:412281 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
257: hkn0612:924227:924322 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 70: hkn0422:4160364:4160469 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 27: hkn0410:1166917:1167039 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
213: hkn0535:2406206:2406337 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
355: hkn0707:4027153:4027260 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  8: hkn0405:3214154:3214272 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
270: hkn0616:412161:412288 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
199: hkn0530:1265351:1265471 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  3: hkn0403:1776560:1776937 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 23: hkn0409:2592874:2592989 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
477: hkn0806:1061538:1061645 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 73: hkn0423:1712163:1712288 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 87: hkn0426:821258:821413 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
300: hkn0628:679159:679255 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
183: hkn0526:1435657:1435750 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
467: hkn0803:883807:883885 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
222: hkn0602:3370898:3371093 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
446: hkn0733:1396572:1396700 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
382: hkn0715:409118:409228 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
148: hkn0514:2957971:2958065 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
508: hkn0816:382834:382958 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
362: hkn0710:362764:362885 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
214: hkn0535:2406234:2406334 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
140: hkn0512:3051343:3051451 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
158: hkn0516:2923196:2923320 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
181: hkn0526:1435629:1435751 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
317: hkn0632:1765843:1765966 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 69: hkn0422:4160356:4160471 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 50: hkn0417:2274860:2274988 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
447: hkn0733:1396600:1396698 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
417: hkn0725:3119163:3119280 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
380: hkn0715:409126:409232 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
186: hkn0527:1356188:1356283 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  9: hkn0405:3214182:3214280 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 24: hkn0410:1166925:1167041 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
301: hkn0628:679147:679253 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 25: hkn0410:1166933:1167040 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
319: hkn0632:1765859:1765969 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
360: hkn0710:362792:362882 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
212: hkn0535:2406214:2406333 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
420: hkn0726:1555321:1555442 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
116: hkn0506:845312:845412 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
422: hkn0726:1555349:1555447 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 21: hkn0409:2592894:2592992 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
303: hkn0628:679131:679256 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
363: hkn0710:362780:362887 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 85: hkn0426:821286:821409 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
413: hkn0724:1723172:1723322 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
401: hkn0720:14318:14478 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
318: hkn0632:1765851:1765965 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 11: hkn0405:3214162:3214281 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
152: hkn0515:2904005:2904143 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
208: hkn0534:1155640:1155748 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
415: hkn0724:1723198:1723323 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
143: hkn0512:3051355:3051445 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 96: hkn0501:1335139:1335266 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
159: hkn0516:2923224:2923313 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
510: hkn0816:382843:382953 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 20: hkn0409:2592866:2592990 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
478: hkn0806:1061550:1061649 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 28: hkn0411:2323081:2323201 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
150: hkn0514:2957943:2958073 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
400: hkn0720:14302:14479 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
419: hkn0725:3119172:3119282 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 98: hkn0501:1335167:1335267 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
412: hkn0724:1723179:1723321 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
142: hkn0512:3051335:3051453 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 97: hkn0501:1335155:1335273 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
353: hkn0707:4027137:4027262 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
155: hkn0515:2904013:2904151 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
499: hkn0812:701057:701148 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
153: hkn0515:2903997:2904149 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
479: hkn0806:1061530:1061646 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 51: hkn0417:2274868:2274989 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
483: hkn0807:1026305:1026402 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
403: hkn0720:14330:14481 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
141: hkn0512:3051327:3051449 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
509: hkn0816:382855:382951 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
151: hkn0514:2957951:2958068 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 31: hkn0411:2323097:2323204 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
391: hkn0717:1459:1584 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
418: hkn0725:3119184:3119279 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
210: hkn0534:1155637:1155744 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
184: hkn0527:1356168:1356280 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
149: hkn0514:2957959:2958071 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
511: hkn0816:382835:382955 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
352: hkn0707:4027165:4027259 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
416: hkn0725:3119164:3119281 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
121: hkn0507:3194285:3194409 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
354: hkn0707:4027145:4027255 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
457: hkn0801:2247291:2247389 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 30: hkn0411:2323089:2323199 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 49: hkn0417:2274876:2274980 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
187: hkn0527:1356160:1356277 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
211: hkn0534:1155652:1155751 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 41: hkn0414:1988888:1989009 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
356: hkn0708:420442:420567 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
185: hkn0527:1356176:1356285 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
386: hkn0716:115704:115853 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
480: hkn0807:1026285:1026406 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
209: hkn0534:1155638:1155749 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
470: hkn0804:1212841:1212966 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
507: hkn0815:402329:402444 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
481: hkn0807:1026277:1026401 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
118: hkn0506:845292:845415 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
487: hkn0808:977909:978016 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
357: hkn0708:420450:420563 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 67: hkn0421:2189234:2189409 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
496: hkn0812:701027:701151 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
217: hkn0601:124968:125085 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
482: hkn0807:1026293:1026403 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
147: hkn0513:3020216:3020303 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 43: hkn0414:1988916:1989008 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
448: hkn0734:1163761:1163871 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
388: hkn0717:1467:1586 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 40: hkn0414:1988896:1989013 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
497: hkn0812:701035:701150 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
387: hkn0716:115727:115858 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
216: hkn0601:124960:125086 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 42: hkn0414:1988904:1989011 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
504: hkn0815:402353:402445 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
458: hkn0801:2247264:2247382 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
119: hkn0506:845284:845410 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
218: hkn0601:124988:125082 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
358: hkn0708:420458:420568 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
384: hkn0716:115715:115850 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
389: hkn0717:1475:1580 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
122: hkn0507:3194301:3194415 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
471: hkn0804:1212857:1212971 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
385: hkn0716:115707:115856 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
117: hkn0506:845300:845411 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
484: hkn0808:977921:978021 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
498: hkn0812:701043:701153 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
469: hkn0804:1212849:1212967 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
219: hkn0601:124976:125081 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
390: hkn0717:1487:1589 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
456: hkn0801:2247272:2247387 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 65: hkn0421:2189204:2189405 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
468: hkn0804:1212869:1212968 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
459: hkn0801:2247280:2247386 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
359: hkn0708:420470:420564 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
506: hkn0815:402341:402450 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
123: hkn0507:3194313:3194412 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
146: hkn0513:3020196:3020300 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
145: hkn0513:3020188:3020302 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 66: hkn0421:2189220:2189406 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
505: hkn0815:402333:402447 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
120: hkn0507:3194293:3194413 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
450: hkn0734:1163781:1163870 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
161: hkn0520:2720094:2720215 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
485: hkn0808:977901:978022 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
486: hkn0808:977893:978014 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
449: hkn0734:1163753:1163873 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
503: hkn0814:683031:683177 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 64: hkn0421:2189212:2189407 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
162: hkn0520:2720086:2720209 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
144: hkn0513:3020204:3020301 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
451: hkn0734:1163769:1163876 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
500: hkn0814:683023:683174 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
160: hkn0520:2720114:2720212 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
501: hkn0814:683039:683170 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
502: hkn0814:683050:683175 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
163: hkn0520:2720102:2720208 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
490: hkn0809:944543:944669 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
488: hkn0809:944559:944660 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
489: hkn0809:944571:944666 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
491: hkn0809:944551:944668 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
122: hkn0507:3194301:3194415 [2] NCCL INFO Trees [0] 123/-1/-1->122->121 [1] 123/-1/-1->122->121
124: hkn0508:3146346:3146464 [0] NCCL INFO Trees [0] 125/-1/-1->124->120 [1] 125/60/-1->124->252
123: hkn0507:3194313:3194412 [3] NCCL INFO Trees [0] -1/-1/-1->123->122 [1] -1/-1/-1->123->122
123: hkn0507:3194313:3194412 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
121: hkn0507:3194285:3194409 [1] NCCL INFO Trees [0] 122/116/-1->121->120 [1] 122/-1/-1->121->120
125: hkn0508:3146338:3146460 [1] NCCL INFO Trees [0] 126/-1/-1->125->124 [1] 126/188/-1->125->124
125: hkn0508:3146338:3146460 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
122: hkn0507:3194301:3194415 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
126: hkn0508:3146354:3146461 [2] NCCL INFO Trees [0] 127/-1/-1->126->125 [1] 127/-1/-1->126->125
126: hkn0508:3146354:3146461 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
121: hkn0507:3194285:3194409 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
128: hkn0509:3131628:3131753 [0] NCCL INFO Trees [0] 129/192/-1->128->257 [1] 129/-1/-1->128->132
124: hkn0508:3146346:3146464 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
127: hkn0508:3146366:3146462 [3] NCCL INFO Trees [0] -1/-1/-1->127->126 [1] -1/-1/-1->127->126
127: hkn0508:3146366:3146462 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
119: hkn0506:845284:845410 [3] NCCL INFO Trees [0] -1/-1/-1->119->118 [1] -1/-1/-1->119->118
119: hkn0506:845284:845410 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
120: hkn0507:3194293:3194413 [0] NCCL INFO Trees [0] 121/124/-1->120->112 [1] 121/-1/-1->120->117
128: hkn0509:3131628:3131753 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
118: hkn0506:845292:845415 [2] NCCL INFO Trees [0] 119/-1/-1->118->117 [1] 119/-1/-1->118->117
120: hkn0507:3194293:3194413 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
118: hkn0506:845292:845415 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
129: hkn0509:3131636:3131744 [1] NCCL INFO Trees [0] 130/64/-1->129->128 [1] 130/-1/-1->129->128
131: hkn0509:3131644:3131750 [3] NCCL INFO Trees [0] -1/-1/-1->131->130 [1] -1/-1/-1->131->130
116: hkn0506:845312:845412 [0] NCCL INFO Trees [0] 117/-1/-1->116->121 [1] 117/112/-1->116->109
116: hkn0506:845312:845412 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
129: hkn0509:3131636:3131744 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
131: hkn0509:3131644:3131750 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
117: hkn0506:845300:845411 [1] NCCL INFO Trees [0] 118/-1/-1->117->116 [1] 118/120/-1->117->116
130: hkn0509:3131655:3131751 [2] NCCL INFO Trees [0] 131/-1/-1->130->129 [1] 131/-1/-1->130->129
117: hkn0506:845300:845411 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
130: hkn0509:3131655:3131751 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
132: hkn0510:2769270:2769395 [0] NCCL INFO Trees [0] 133/-1/-1->132->137 [1] 133/128/-1->132->140
115: hkn0505:2310997:2311121 [3] NCCL INFO Trees [0] -1/-1/-1->115->114 [1] -1/-1/-1->115->114
132: hkn0510:2769270:2769395 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
115: hkn0505:2310997:2311121 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
136: hkn0511:3073654:3073767 [0] NCCL INFO Trees [0] 137/140/-1->136->145 [1] 137/-1/-1->136->133
136: hkn0511:3073654:3073767 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
133: hkn0510:2769286:2769390 [1] NCCL INFO Trees [0] 134/-1/-1->133->132 [1] 134/136/-1->133->132
133: hkn0510:2769286:2769390 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
114: hkn0505:2311013:2311117 [2] NCCL INFO Trees [0] 115/-1/-1->114->113 [1] 115/-1/-1->114->113
134: hkn0510:2769278:2769396 [2] NCCL INFO Trees [0] 135/-1/-1->134->133 [1] 135/-1/-1->134->133
111: hkn0504:48327:48437 [3] NCCL INFO Trees [0] -1/-1/-1->111->110 [1] -1/-1/-1->111->110
114: hkn0505:2311013:2311117 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
138: hkn0511:3073676:3073772 [2] NCCL INFO Trees [0] 139/-1/-1->138->137 [1] 139/-1/-1->138->137
134: hkn0510:2769278:2769396 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
111: hkn0504:48327:48437 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
138: hkn0511:3073676:3073772 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
135: hkn0510:2769298:2769389 [3] NCCL INFO Trees [0] -1/-1/-1->135->134 [1] -1/-1/-1->135->134
112: hkn0505:2311025:2311118 [0] NCCL INFO Trees [0] 113/120/-1->112->96 [1] 113/-1/-1->112->116
137: hkn0511:3073646:3073768 [1] NCCL INFO Trees [0] 138/132/-1->137->136 [1] 138/-1/-1->137->136
135: hkn0510:2769298:2769389 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
110: hkn0504:48311:48436 [2] NCCL INFO Trees [0] 111/-1/-1->110->109 [1] 111/-1/-1->110->109
139: hkn0511:3073664:3073769 [3] NCCL INFO Trees [0] -1/-1/-1->139->138 [1] -1/-1/-1->139->138
137: hkn0511:3073646:3073768 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
110: hkn0504:48311:48436 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
139: hkn0511:3073664:3073769 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
113: hkn0505:2311005:2311114 [1] NCCL INFO Trees [0] 114/104/-1->113->112 [1] 114/-1/-1->113->112
113: hkn0505:2311005:2311114 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
112: hkn0505:2311025:2311118 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
140: hkn0512:3051343:3051451 [0] NCCL INFO Trees [0] 141/-1/-1->140->136 [1] 141/132/-1->140->156
109: hkn0504:48319:48430 [1] NCCL INFO Trees [0] 110/-1/-1->109->108 [1] 110/116/-1->109->108
140: hkn0512:3051343:3051451 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
109: hkn0504:48319:48430 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
108: hkn0504:48339:48431 [0] NCCL INFO Trees [0] 109/-1/-1->108->104 [1] 109/100/-1->108->93
143: hkn0512:3051355:3051445 [3] NCCL INFO Trees [0] -1/-1/-1->143->142 [1] -1/-1/-1->143->142
108: hkn0504:48339:48431 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
143: hkn0512:3051355:3051445 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
141: hkn0512:3051327:3051449 [1] NCCL INFO Trees [0] 142/-1/-1->141->140 [1] 142/148/-1->141->140
102: hkn0502:236315:236406 [2] NCCL INFO Trees [0] 103/-1/-1->102->101 [1] 103/-1/-1->102->101
102: hkn0502:236315:236406 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
105: hkn0503:2906935:2907063 [1] NCCL INFO Trees [0] 106/100/-1->105->104 [1] 106/-1/-1->105->104
147: hkn0513:3020216:3020303 [3] NCCL INFO Trees [0] -1/-1/-1->147->146 [1] -1/-1/-1->147->146
141: hkn0512:3051327:3051449 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
153: hkn0515:2903997:2904149 [1] NCCL INFO Trees [0] 154/148/-1->153->152 [1] 154/-1/-1->153->152
106: hkn0503:2906951:2907055 [2] NCCL INFO Trees [0] 107/-1/-1->106->105 [1] 107/-1/-1->106->105
147: hkn0513:3020216:3020303 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
148: hkn0514:2957971:2958065 [0] NCCL INFO Trees [0] 149/-1/-1->148->153 [1] 149/144/-1->148->141
142: hkn0512:3051335:3051453 [2] NCCL INFO Trees [0] 143/-1/-1->142->141 [1] 143/-1/-1->142->141
101: hkn0502:236287:236411 [1] NCCL INFO Trees [0] 102/-1/-1->101->100 [1] 102/104/-1->101->100
101: hkn0502:236287:236411 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
146: hkn0513:3020196:3020300 [2] NCCL INFO Trees [0] 147/-1/-1->146->145 [1] 147/-1/-1->146->145
146: hkn0513:3020196:3020300 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
142: hkn0512:3051335:3051453 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
103: hkn0502:236303:236407 [3] NCCL INFO Trees [0] -1/-1/-1->103->102 [1] -1/-1/-1->103->102
103: hkn0502:236303:236407 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
153: hkn0515:2903997:2904149 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
105: hkn0503:2906935:2907063 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
145: hkn0513:3020188:3020302 [1] NCCL INFO Trees [0] 146/136/-1->145->144 [1] 146/-1/-1->145->144
150: hkn0514:2957943:2958073 [2] NCCL INFO Trees [0] 151/-1/-1->150->149 [1] 151/-1/-1->150->149
150: hkn0514:2957943:2958073 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
154: hkn0515:2904025:2904145 [2] NCCL INFO Trees [0] 155/-1/-1->154->153 [1] 155/-1/-1->154->153
154: hkn0515:2904025:2904145 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
106: hkn0503:2906951:2907055 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
145: hkn0513:3020188:3020302 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
148: hkn0514:2957971:2958065 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
100: hkn0502:236295:236412 [0] NCCL INFO Trees [0] 101/-1/-1->100->105 [1] 101/96/-1->100->108
100: hkn0502:236295:236412 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
155: hkn0515:2904013:2904151 [3] NCCL INFO Trees [0] -1/-1/-1->155->154 [1] -1/-1/-1->155->154
155: hkn0515:2904013:2904151 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
104: hkn0503:2906963:2907057 [0] NCCL INFO Trees [0] 105/108/-1->104->113 [1] 105/-1/-1->104->101
104: hkn0503:2906963:2907057 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
144: hkn0513:3020204:3020301 [0] NCCL INFO Trees [0] 145/152/-1->144->161 [1] 145/-1/-1->144->148
152: hkn0515:2904005:2904143 [0] NCCL INFO Trees [0] 153/156/-1->152->144 [1] 153/-1/-1->152->149
107: hkn0503:2906943:2907062 [3] NCCL INFO Trees [0] -1/-1/-1->107->106 [1] -1/-1/-1->107->106
107: hkn0503:2906943:2907062 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
149: hkn0514:2957959:2958071 [1] NCCL INFO Trees [0] 150/-1/-1->149->148 [1] 150/152/-1->149->148
152: hkn0515:2904005:2904143 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
144: hkn0513:3020204:3020301 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
151: hkn0514:2957951:2958068 [3] NCCL INFO Trees [0] -1/-1/-1->151->150 [1] -1/-1/-1->151->150
156: hkn0516:2923204:2923321 [0] NCCL INFO Trees [0] 157/-1/-1->156->152 [1] 157/140/-1->156->188
149: hkn0514:2957959:2958071 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
151: hkn0514:2957951:2958068 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
156: hkn0516:2923204:2923321 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
159: hkn0516:2923224:2923313 [3] NCCL INFO Trees [0] -1/-1/-1->159->158 [1] -1/-1/-1->159->158
159: hkn0516:2923224:2923313 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
157: hkn0516:2923212:2923315 [1] NCCL INFO Trees [0] 158/-1/-1->157->156 [1] 158/172/-1->157->156
157: hkn0516:2923212:2923315 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 99: hkn0501:1335147:1335272 [3] NCCL INFO Trees [0] -1/-1/-1->99->98 [1] -1/-1/-1->99->98
158: hkn0516:2923196:2923320 [2] NCCL INFO Trees [0] 159/-1/-1->158->157 [1] 159/-1/-1->158->157
158: hkn0516:2923196:2923320 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
160: hkn0520:2720114:2720212 [0] NCCL INFO Trees [0] 161/176/-1->160->193 [1] 161/-1/-1->160->164
161: hkn0520:2720094:2720215 [1] NCCL INFO Trees [0] 162/144/-1->161->160 [1] 162/-1/-1->161->160
161: hkn0520:2720094:2720215 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 99: hkn0501:1335147:1335272 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
160: hkn0520:2720114:2720212 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 98: hkn0501:1335167:1335267 [2] NCCL INFO Trees [0] 99/-1/-1->98->97 [1] 99/-1/-1->98->97
 98: hkn0501:1335167:1335267 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
162: hkn0520:2720086:2720209 [2] NCCL INFO Trees [0] 163/-1/-1->162->161 [1] 163/-1/-1->162->161
162: hkn0520:2720086:2720209 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
163: hkn0520:2720102:2720208 [3] NCCL INFO Trees [0] -1/-1/-1->163->162 [1] -1/-1/-1->163->162
163: hkn0520:2720102:2720208 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 96: hkn0501:1335139:1335266 [0] NCCL INFO Trees [0] 97/112/-1->96->64 [1] 97/-1/-1->96->100
 96: hkn0501:1335139:1335266 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
164: hkn0521:1205016:1205137 [0] NCCL INFO Trees [0] 165/-1/-1->164->169 [1] 165/160/-1->164->172
 97: hkn0501:1335155:1335273 [1] NCCL INFO Trees [0] 98/80/-1->97->96 [1] 98/-1/-1->97->96
164: hkn0521:1205016:1205137 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 97: hkn0501:1335155:1335273 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
167: hkn0521:1205008:1205131 [3] NCCL INFO Trees [0] -1/-1/-1->167->166 [1] -1/-1/-1->167->166
167: hkn0521:1205008:1205131 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
168: hkn0523:1555352:1555443 [0] NCCL INFO Trees [0] 169/172/-1->168->177 [1] 169/-1/-1->168->165
165: hkn0521:1205024:1205132 [1] NCCL INFO Trees [0] 166/-1/-1->165->164 [1] 166/168/-1->165->164
 95: hkn0428:674595:674697 [3] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] -1/-1/-1->95->94
168: hkn0523:1555352:1555443 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
166: hkn0521:1205036:1205135 [2] NCCL INFO Trees [0] 167/-1/-1->166->165 [1] 167/-1/-1->166->165
 95: hkn0428:674595:674697 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
165: hkn0521:1205024:1205132 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 94: hkn0428:674575:674691 [2] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 95/-1/-1->94->93
 94: hkn0428:674575:674691 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
166: hkn0521:1205036:1205135 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
169: hkn0523:1555324:1555450 [1] NCCL INFO Trees [0] 170/164/-1->169->168 [1] 170/-1/-1->169->168
172: hkn0524:1141018:1141124 [0] NCCL INFO Trees [0] 173/-1/-1->172->168 [1] 173/164/-1->172->157
172: hkn0524:1141018:1141124 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 92: hkn0428:674583:674690 [0] NCCL INFO Trees [0] 93/-1/-1->92->88 [1] 93/76/-1->92->61
169: hkn0523:1555324:1555450 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 92: hkn0428:674583:674690 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
170: hkn0523:1555340:1555444 [2] NCCL INFO Trees [0] 171/-1/-1->170->169 [1] 171/-1/-1->170->169
173: hkn0524:1141002:1141130 [1] NCCL INFO Trees [0] 174/-1/-1->173->172 [1] 174/180/-1->173->172
173: hkn0524:1141002:1141130 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
171: hkn0523:1555332:1555449 [3] NCCL INFO Trees [0] -1/-1/-1->171->170 [1] -1/-1/-1->171->170
170: hkn0523:1555340:1555444 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
174: hkn0524:1141010:1141129 [2] NCCL INFO Trees [0] 175/-1/-1->174->173 [1] 175/-1/-1->174->173
174: hkn0524:1141010:1141129 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 93: hkn0428:674567:674696 [1] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 94/108/-1->93->92
171: hkn0523:1555332:1555449 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
175: hkn0524:1141030:1141123 [3] NCCL INFO Trees [0] -1/-1/-1->175->174 [1] -1/-1/-1->175->174
 93: hkn0428:674567:674696 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 90: hkn0427:1142341:1142458 [2] NCCL INFO Trees [0] 91/-1/-1->90->89 [1] 91/-1/-1->90->89
175: hkn0524:1141030:1141123 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
176: hkn0525:994034:994135 [0] NCCL INFO Trees [0] 177/184/-1->176->160 [1] 177/-1/-1->176->180
 90: hkn0427:1142341:1142458 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
176: hkn0525:994034:994135 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 91: hkn0427:1142357:1142467 [3] NCCL INFO Trees [0] -1/-1/-1->91->90 [1] -1/-1/-1->91->90
 91: hkn0427:1142357:1142467 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 89: hkn0427:1142369:1142461 [1] NCCL INFO Trees [0] 90/84/-1->89->88 [1] 90/-1/-1->89->88
180: hkn0526:1435645:1435749 [0] NCCL INFO Trees [0] 181/-1/-1->180->185 [1] 181/176/-1->180->173
 89: hkn0427:1142369:1142461 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 88: hkn0427:1142349:1142466 [0] NCCL INFO Trees [0] 89/92/-1->88->80 [1] 89/-1/-1->88->85
177: hkn0525:994014:994129 [1] NCCL INFO Trees [0] 178/168/-1->177->176 [1] 178/-1/-1->177->176
177: hkn0525:994014:994129 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
183: hkn0526:1435657:1435750 [3] NCCL INFO Trees [0] -1/-1/-1->183->182 [1] -1/-1/-1->183->182
 88: hkn0427:1142349:1142466 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
180: hkn0526:1435645:1435749 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
186: hkn0527:1356188:1356283 [2] NCCL INFO Trees [0] 187/-1/-1->186->185 [1] 187/-1/-1->186->185
178: hkn0525:994022:994132 [2] NCCL INFO Trees [0] 179/-1/-1->178->177 [1] 179/-1/-1->178->177
178: hkn0525:994022:994132 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 87: hkn0426:821258:821413 [3] NCCL INFO Trees [0] -1/-1/-1->87->86 [1] -1/-1/-1->87->86
 87: hkn0426:821258:821413 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
183: hkn0526:1435657:1435750 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
179: hkn0525:994006:994130 [3] NCCL INFO Trees [0] -1/-1/-1->179->178 [1] -1/-1/-1->179->178
179: hkn0525:994006:994130 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
181: hkn0526:1435629:1435751 [1] NCCL INFO Trees [0] 182/-1/-1->181->180 [1] 182/184/-1->181->180
181: hkn0526:1435629:1435751 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
186: hkn0527:1356188:1356283 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
188: hkn0528:1308911:1309016 [0] NCCL INFO Trees [0] 189/-1/-1->188->184 [1] 189/156/-1->188->125
188: hkn0528:1308911:1309016 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
192: hkn0529:1548046:1548160 [0] NCCL INFO Trees [0] 193/224/-1->192->128 [1] 193/-1/-1->192->196
192: hkn0529:1548046:1548160 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
182: hkn0526:1435637:1435754 [2] NCCL INFO Trees [0] 183/-1/-1->182->181 [1] 183/-1/-1->182->181
182: hkn0526:1435637:1435754 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
198: hkn0530:1265343:1265469 [2] NCCL INFO Trees [0] 199/-1/-1->198->197 [1] 199/-1/-1->198->197
198: hkn0530:1265343:1265469 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
187: hkn0527:1356160:1356277 [3] NCCL INFO Trees [0] -1/-1/-1->187->186 [1] -1/-1/-1->187->186
199: hkn0530:1265351:1265471 [3] NCCL INFO Trees [0] -1/-1/-1->199->198 [1] -1/-1/-1->199->198
199: hkn0530:1265351:1265471 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
187: hkn0527:1356160:1356277 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
190: hkn0528:1308903:1309021 [2] NCCL INFO Trees [0] 191/-1/-1->190->189 [1] 191/-1/-1->190->189
190: hkn0528:1308903:1309021 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 86: hkn0426:821274:821408 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] 87/-1/-1->86->85
193: hkn0529:1548066:1548163 [1] NCCL INFO Trees [0] 194/160/-1->193->192 [1] 194/-1/-1->193->192
193: hkn0529:1548066:1548163 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
184: hkn0527:1356168:1356280 [0] NCCL INFO Trees [0] 185/188/-1->184->176 [1] 185/-1/-1->184->181
191: hkn0528:1308895:1309019 [3] NCCL INFO Trees [0] -1/-1/-1->191->190 [1] -1/-1/-1->191->190
191: hkn0528:1308895:1309019 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 86: hkn0426:821274:821408 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
194: hkn0529:1548054:1548165 [2] NCCL INFO Trees [0] 195/-1/-1->194->193 [1] 195/-1/-1->194->193
194: hkn0529:1548054:1548165 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
185: hkn0527:1356176:1356285 [1] NCCL INFO Trees [0] 186/180/-1->185->184 [1] 186/-1/-1->185->184
195: hkn0529:1548038:1548157 [3] NCCL INFO Trees [0] -1/-1/-1->195->194 [1] -1/-1/-1->195->194
195: hkn0529:1548038:1548157 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
196: hkn0530:1265359:1265466 [0] NCCL INFO Trees [0] 197/-1/-1->196->201 [1] 197/192/-1->196->204
196: hkn0530:1265359:1265466 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
184: hkn0527:1356168:1356280 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
197: hkn0530:1265371:1265467 [1] NCCL INFO Trees [0] 198/-1/-1->197->196 [1] 198/200/-1->197->196
197: hkn0530:1265371:1265467 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
185: hkn0527:1356176:1356285 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
189: hkn0528:1308923:1309018 [1] NCCL INFO Trees [0] 190/-1/-1->189->188 [1] 190/220/-1->189->188
189: hkn0528:1308923:1309018 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 85: hkn0426:821286:821409 [1] NCCL INFO Trees [0] 86/-1/-1->85->84 [1] 86/88/-1->85->84
 79: hkn0424:2955186:2955299 [3] NCCL INFO Trees [0] -1/-1/-1->79->78 [1] -1/-1/-1->79->78
 79: hkn0424:2955186:2955299 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 85: hkn0426:821286:821409 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 83: hkn0425:2091271:2091395 [3] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] -1/-1/-1->83->82
 83: hkn0425:2091271:2091395 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 78: hkn0424:2955198:2955298 [2] NCCL INFO Trees [0] 79/-1/-1->78->77 [1] 79/-1/-1->78->77
 78: hkn0424:2955198:2955298 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
202: hkn0531:1237910:1238025 [2] NCCL INFO Trees [0] 203/-1/-1->202->201 [1] 203/-1/-1->202->201
 84: hkn0426:821266:821410 [0] NCCL INFO Trees [0] 85/-1/-1->84->89 [1] 85/80/-1->84->77
202: hkn0531:1237910:1238025 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 84: hkn0426:821266:821410 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
201: hkn0531:1237902:1238024 [1] NCCL INFO Trees [0] 202/196/-1->201->200 [1] 202/-1/-1->201->200
207: hkn0532:932502:932816 [3] NCCL INFO Trees [0] -1/-1/-1->207->206 [1] -1/-1/-1->207->206
201: hkn0531:1237902:1238024 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 82: hkn0425:2091279:2091402 [2] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 83/-1/-1->82->81
 77: hkn0424:2955178:2955291 [1] NCCL INFO Trees [0] 78/-1/-1->77->76 [1] 78/84/-1->77->76
207: hkn0532:932502:932816 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 82: hkn0425:2091279:2091402 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 77: hkn0424:2955178:2955291 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
203: hkn0531:1237894:1238018 [3] NCCL INFO Trees [0] -1/-1/-1->203->202 [1] -1/-1/-1->203->202
 73: hkn0423:1712163:1712288 [1] NCCL INFO Trees [0] 74/68/-1->73->72 [1] 74/-1/-1->73->72
 81: hkn0425:2091299:2091397 [1] NCCL INFO Trees [0] 82/72/-1->81->80 [1] 82/-1/-1->81->80
 76: hkn0424:2955170:2955294 [0] NCCL INFO Trees [0] 77/-1/-1->76->72 [1] 77/68/-1->76->92
200: hkn0531:1237922:1238019 [0] NCCL INFO Trees [0] 201/204/-1->200->209 [1] 201/-1/-1->200->197
 80: hkn0425:2091287:2091403 [0] NCCL INFO Trees [0] 81/88/-1->80->97 [1] 81/-1/-1->80->84
 80: hkn0425:2091287:2091403 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
203: hkn0531:1237894:1238018 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 75: hkn0423:1712190:1712287 [3] NCCL INFO Trees [0] -1/-1/-1->75->74 [1] -1/-1/-1->75->74
208: hkn0534:1155640:1155748 [0] NCCL INFO Trees [0] 209/216/-1->208->225 [1] 209/-1/-1->208->212
225: hkn0603:1420458:1420572 [1] NCCL INFO Trees [0] 226/208/-1->225->224 [1] 226/-1/-1->225->224
 81: hkn0425:2091299:2091397 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
200: hkn0531:1237922:1238019 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 73: hkn0423:1712163:1712288 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
204: hkn0532:932494:932817 [0] NCCL INFO Trees [0] 205/-1/-1->204->200 [1] 205/196/-1->204->220
208: hkn0534:1155640:1155748 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 76: hkn0424:2955170:2955294 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 74: hkn0423:1712179:1712289 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] 75/-1/-1->74->73
 74: hkn0423:1712179:1712289 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
211: hkn0534:1155652:1155751 [3] NCCL INFO Trees [0] -1/-1/-1->211->210 [1] -1/-1/-1->211->210
 75: hkn0423:1712190:1712287 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
205: hkn0532:932522:932818 [1] NCCL INFO Trees [0] 206/-1/-1->205->204 [1] 206/212/-1->205->204
205: hkn0532:932522:932818 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
211: hkn0534:1155652:1155751 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
225: hkn0603:1420458:1420572 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 71: hkn0422:4160348:4160470 [3] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] -1/-1/-1->71->70
 72: hkn0423:1712171:1712286 [0] NCCL INFO Trees [0] 73/76/-1->72->81 [1] 73/-1/-1->72->69
 72: hkn0423:1712171:1712286 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
206: hkn0532:932510:932820 [2] NCCL INFO Trees [0] 207/-1/-1->206->205 [1] 207/-1/-1->206->205
206: hkn0532:932510:932820 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
209: hkn0534:1155638:1155749 [1] NCCL INFO Trees [0] 210/200/-1->209->208 [1] 210/-1/-1->209->208
209: hkn0534:1155638:1155749 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 71: hkn0422:4160348:4160470 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
204: hkn0532:932494:932817 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
210: hkn0534:1155637:1155744 [2] NCCL INFO Trees [0] 211/-1/-1->210->209 [1] 211/-1/-1->210->209
210: hkn0534:1155637:1155744 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
438: hkn0731:1393942:1394083 [2] NCCL INFO Trees [0] 439/-1/-1->438->437 [1] 439/-1/-1->438->437
226: hkn0603:1420466:1420571 [2] NCCL INFO Trees [0] 227/-1/-1->226->225 [1] 227/-1/-1->226->225
222: hkn0602:3370898:3371093 [2] NCCL INFO Trees [0] 223/-1/-1->222->221 [1] 223/-1/-1->222->221
213: hkn0535:2406206:2406337 [1] NCCL INFO Trees [0] 214/-1/-1->213->212 [1] 214/216/-1->213->212
438: hkn0731:1393942:1394083 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
226: hkn0603:1420466:1420571 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 70: hkn0422:4160364:4160469 [2] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 71/-1/-1->70->69
213: hkn0535:2406206:2406337 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
227: hkn0603:1420478:1420573 [3] NCCL INFO Trees [0] -1/-1/-1->227->226 [1] -1/-1/-1->227->226
227: hkn0603:1420478:1420573 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 70: hkn0422:4160364:4160469 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
212: hkn0535:2406214:2406333 [0] NCCL INFO Trees [0] 213/-1/-1->212->217 [1] 213/208/-1->212->205
212: hkn0535:2406214:2406333 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
458: hkn0801:2247264:2247382 [2] NCCL INFO Trees [0] 459/-1/-1->458->457 [1] 459/-1/-1->458->457
458: hkn0801:2247264:2247382 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
224: hkn0603:1420450:1420575 [0] NCCL INFO Trees [0] 225/240/-1->224->192 [1] 225/-1/-1->224->228
219: hkn0601:124976:125081 [3] NCCL INFO Trees [0] -1/-1/-1->219->218 [1] -1/-1/-1->219->218
215: hkn0535:2406222:2406330 [3] NCCL INFO Trees [0] -1/-1/-1->215->214 [1] -1/-1/-1->215->214
215: hkn0535:2406222:2406330 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
229: hkn0604:696459:696573 [1] NCCL INFO Trees [0] 230/-1/-1->229->228 [1] 230/232/-1->229->228
214: hkn0535:2406234:2406334 [2] NCCL INFO Trees [0] 215/-1/-1->214->213 [1] 215/-1/-1->214->213
459: hkn0801:2247280:2247386 [3] NCCL INFO Trees [0] -1/-1/-1->459->458 [1] -1/-1/-1->459->458
229: hkn0604:696459:696573 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
454: hkn0736:1515545:1515656 [2] NCCL INFO Trees [0] 455/-1/-1->454->453 [1] 455/-1/-1->454->453
 69: hkn0422:4160356:4160471 [1] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 70/72/-1->69->68
248: hkn0609:718056:718153 [0] NCCL INFO Trees [0] 249/252/-1->248->240 [1] 249/-1/-1->248->245
248: hkn0609:718056:718153 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
247: hkn0608:492955:493068 [3] NCCL INFO Trees [0] -1/-1/-1->247->246 [1] -1/-1/-1->247->246
263: hkn0613:909932:910042 [3] NCCL INFO Trees [0] -1/-1/-1->263->262 [1] -1/-1/-1->263->262
445: hkn0733:1396580:1396694 [1] NCCL INFO Trees [0] 446/-1/-1->445->444 [1] 446/476/-1->445->444
439: hkn0731:1393950:1394081 [3] NCCL INFO Trees [0] -1/-1/-1->439->438 [1] -1/-1/-1->439->438
258: hkn0612:924199:924320 [2] NCCL INFO Trees [0] 259/-1/-1->258->257 [1] 259/-1/-1->258->257
454: hkn0736:1515545:1515656 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
224: hkn0603:1420450:1420575 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
442: hkn0732:1218881:1219002 [2] NCCL INFO Trees [0] 443/-1/-1->442->441 [1] 443/-1/-1->442->441
 69: hkn0422:4160356:4160471 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
249: hkn0609:718036:718147 [1] NCCL INFO Trees [0] 250/244/-1->249->248 [1] 250/-1/-1->249->248
249: hkn0609:718036:718147 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
222: hkn0602:3370898:3371093 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
214: hkn0535:2406234:2406334 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
459: hkn0801:2247280:2247386 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
461: hkn0802:1207571:1207691 [1] NCCL INFO Trees [0] 462/-1/-1->461->460 [1] 462/468/-1->461->460
228: hkn0604:696478:696578 [0] NCCL INFO Trees [0] 229/-1/-1->228->233 [1] 229/224/-1->228->236
439: hkn0731:1393950:1394081 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
258: hkn0612:924199:924320 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 68: hkn0422:4160376:4160473 [0] NCCL INFO Trees [0] 69/-1/-1->68->73 [1] 69/64/-1->68->76
250: hkn0609:718028:718154 [2] NCCL INFO Trees [0] 251/-1/-1->250->249 [1] 251/-1/-1->250->249
250: hkn0609:718028:718154 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
219: hkn0601:124976:125081 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
221: hkn0602:3370890:3371086 [1] NCCL INFO Trees [0] 222/-1/-1->221->220 [1] 222/236/-1->221->220
247: hkn0608:492955:493068 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
263: hkn0613:909932:910042 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
456: hkn0801:2247272:2247387 [0] NCCL INFO Trees [0] 457/460/-1->456->465 [1] 457/-1/-1->456->453
445: hkn0733:1396580:1396694 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
230: hkn0604:696451:696579 [2] NCCL INFO Trees [0] 231/-1/-1->230->229 [1] 231/-1/-1->230->229
230: hkn0604:696451:696579 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
437: hkn0731:1393941:1394086 [1] NCCL INFO Trees [0] 438/-1/-1->437->436 [1] 438/440/-1->437->436
448: hkn0734:1163761:1163871 [0] NCCL INFO Trees [0] 449/480/-1->448->384 [1] 449/-1/-1->448->452
448: hkn0734:1163761:1163871 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
256: hkn0612:924207:924324 [0] NCCL INFO Trees [0] 257/384/-1->256->0 [1] 257/-1/-1->256->260
233: hkn0605:719360:719472 [1] NCCL INFO Trees [0] 234/228/-1->233->232 [1] 234/-1/-1->233->232
453: hkn0736:1515557:1515653 [1] NCCL INFO Trees [0] 454/-1/-1->453->452 [1] 454/456/-1->453->452
442: hkn0732:1218881:1219002 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 68: hkn0422:4160376:4160473 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
251: hkn0609:718044:718148 [3] NCCL INFO Trees [0] -1/-1/-1->251->250 [1] -1/-1/-1->251->250
216: hkn0601:124960:125086 [0] NCCL INFO Trees [0] 217/220/-1->216->208 [1] 217/-1/-1->216->213
221: hkn0602:3370890:3371086 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
260: hkn0613:909924:910036 [0] NCCL INFO Trees [0] 261/-1/-1->260->265 [1] 261/256/-1->260->268
456: hkn0801:2247272:2247387 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
462: hkn0802:1207559:1207696 [2] NCCL INFO Trees [0] 463/-1/-1->462->461 [1] 463/-1/-1->462->461
444: hkn0733:1396588:1396702 [0] NCCL INFO Trees [0] 445/-1/-1->444->440 [1] 445/412/-1->444->381
444: hkn0733:1396588:1396702 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
252: hkn0611:717035:717164 [0] NCCL INFO Trees [0] 253/-1/-1->252->248 [1] 253/124/-1->252->508
231: hkn0604:696467:696570 [3] NCCL INFO Trees [0] -1/-1/-1->231->230 [1] -1/-1/-1->231->230
437: hkn0731:1393941:1394086 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
451: hkn0734:1163769:1163876 [3] NCCL INFO Trees [0] -1/-1/-1->451->450 [1] -1/-1/-1->451->450
451: hkn0734:1163769:1163876 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
257: hkn0612:924227:924322 [1] NCCL INFO Trees [0] 258/128/-1->257->256 [1] 258/-1/-1->257->256
257: hkn0612:924227:924322 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
453: hkn0736:1515557:1515653 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
443: hkn0732:1218882:1219000 [3] NCCL INFO Trees [0] -1/-1/-1->443->442 [1] -1/-1/-1->443->442
251: hkn0609:718044:718148 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
217: hkn0601:124968:125085 [1] NCCL INFO Trees [0] 218/212/-1->217->216 [1] 218/-1/-1->217->216
264: hkn0615:421550:421660 [0] NCCL INFO Trees [0] 265/268/-1->264->273 [1] 265/-1/-1->264->261
223: hkn0602:3370906:3371095 [3] NCCL INFO Trees [0] -1/-1/-1->223->222 [1] -1/-1/-1->223->222
245: hkn0608:492963:493070 [1] NCCL INFO Trees [0] 246/-1/-1->245->244 [1] 246/248/-1->245->244
237: hkn0606:2379347:2379461 [1] NCCL INFO Trees [0] 238/-1/-1->237->236 [1] 238/244/-1->237->236
260: hkn0613:909924:910036 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
457: hkn0801:2247291:2247389 [1] NCCL INFO Trees [0] 458/452/-1->457->456 [1] 458/-1/-1->457->456
457: hkn0801:2247291:2247389 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
461: hkn0802:1207571:1207691 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
446: hkn0733:1396572:1396700 [2] NCCL INFO Trees [0] 447/-1/-1->446->445 [1] 447/-1/-1->446->445
255: hkn0611:717043:717161 [3] NCCL INFO Trees [0] -1/-1/-1->255->254 [1] -1/-1/-1->255->254
228: hkn0604:696478:696578 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
436: hkn0731:1393962:1394080 [0] NCCL INFO Trees [0] 437/-1/-1->436->441 [1] 437/432/-1->436->429
436: hkn0731:1393962:1394080 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
449: hkn0734:1163753:1163873 [1] NCCL INFO Trees [0] 450/416/-1->449->448 [1] 450/-1/-1->449->448
449: hkn0734:1163753:1163873 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
259: hkn0612:924215:924321 [3] NCCL INFO Trees [0] -1/-1/-1->259->258 [1] -1/-1/-1->259->258
259: hkn0612:924215:924321 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
452: hkn0736:1515544:1515654 [0] NCCL INFO Trees [0] 453/-1/-1->452->457 [1] 453/448/-1->452->460
440: hkn0732:1218902:1218998 [0] NCCL INFO Trees [0] 441/444/-1->440->432 [1] 441/-1/-1->440->437
440: hkn0732:1218902:1218998 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
218: hkn0601:124988:125082 [2] NCCL INFO Trees [0] 219/-1/-1->218->217 [1] 219/-1/-1->218->217
264: hkn0615:421550:421660 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
223: hkn0602:3370906:3371095 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
245: hkn0608:492963:493070 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
239: hkn0606:2379367:2379465 [3] NCCL INFO Trees [0] -1/-1/-1->239->238 [1] -1/-1/-1->239->238
 67: hkn0421:2189234:2189409 [3] NCCL INFO Trees [0] -1/-1/-1->67->66 [1] -1/-1/-1->67->66
261: hkn0613:909944:910037 [1] NCCL INFO Trees [0] 262/-1/-1->261->260 [1] 262/264/-1->261->260
261: hkn0613:909944:910037 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
470: hkn0804:1212841:1212966 [2] NCCL INFO Trees [0] 471/-1/-1->470->469 [1] 471/-1/-1->470->469
462: hkn0802:1207559:1207696 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
447: hkn0733:1396600:1396698 [3] NCCL INFO Trees [0] -1/-1/-1->447->446 [1] -1/-1/-1->447->446
252: hkn0611:717035:717164 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
231: hkn0604:696467:696570 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
269: hkn0616:412177:412290 [1] NCCL INFO Trees [0] 270/-1/-1->269->268 [1] 270/276/-1->269->268
256: hkn0612:924207:924324 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
472: hkn0805:1119345:1119447 [0] NCCL INFO Trees [0] 473/476/-1->472->464 [1] 473/-1/-1->472->469
232: hkn0605:719349:719471 [0] NCCL INFO Trees [0] 233/236/-1->232->241 [1] 233/-1/-1->232->229
455: hkn0736:1515543:1515649 [3] NCCL INFO Trees [0] -1/-1/-1->455->454 [1] -1/-1/-1->455->454
466: hkn0803:883795:883893 [2] NCCL INFO Trees [0] 467/-1/-1->466->465 [1] 467/-1/-1->466->465
441: hkn0732:1218890:1218999 [1] NCCL INFO Trees [0] 442/436/-1->441->440 [1] 442/-1/-1->441->440
441: hkn0732:1218890:1218999 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
216: hkn0601:124960:125086 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
267: hkn0615:421542:421667 [3] NCCL INFO Trees [0] -1/-1/-1->267->266 [1] -1/-1/-1->267->266
220: hkn0602:3370918:3371090 [0] NCCL INFO Trees [0] 221/-1/-1->220->216 [1] 221/204/-1->220->189
220: hkn0602:3370918:3371090 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
246: hkn0608:492947:493073 [2] NCCL INFO Trees [0] 247/-1/-1->246->245 [1] 247/-1/-1->246->245
237: hkn0606:2379347:2379461 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 67: hkn0421:2189234:2189409 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
262: hkn0613:909916:910043 [2] NCCL INFO Trees [0] 263/-1/-1->262->261 [1] 263/-1/-1->262->261
262: hkn0613:909916:910043 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
434: hkn0730:1408975:1409075 [2] NCCL INFO Trees [0] 435/-1/-1->434->433 [1] 435/-1/-1->434->433
470: hkn0804:1212841:1212966 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
460: hkn0802:1207543:1207697 [0] NCCL INFO Trees [0] 461/-1/-1->460->456 [1] 461/452/-1->460->476
460: hkn0802:1207543:1207697 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
446: hkn0733:1396572:1396700 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
253: hkn0611:717051:717160 [1] NCCL INFO Trees [0] 254/-1/-1->253->252 [1] 254/380/-1->253->252
253: hkn0611:717051:717160 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
450: hkn0734:1163781:1163870 [2] NCCL INFO Trees [0] 451/-1/-1->450->449 [1] 451/-1/-1->450->449
270: hkn0616:412161:412288 [2] NCCL INFO Trees [0] 271/-1/-1->270->269 [1] 271/-1/-1->270->269
270: hkn0616:412161:412288 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
472: hkn0805:1119345:1119447 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
233: hkn0605:719360:719472 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
452: hkn0736:1515544:1515654 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
467: hkn0803:883807:883885 [3] NCCL INFO Trees [0] -1/-1/-1->467->466 [1] -1/-1/-1->467->466
431: hkn0728:1331257:1331376 [3] NCCL INFO Trees [0] -1/-1/-1->431->430 [1] -1/-1/-1->431->430
443: hkn0732:1218882:1219000 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
217: hkn0601:124968:125085 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
267: hkn0615:421542:421667 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
243: hkn0607:911615:911710 [3] NCCL INFO Trees [0] -1/-1/-1->243->242 [1] -1/-1/-1->243->242
246: hkn0608:492947:493073 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
275: hkn0617:2301957:2302052 [3] NCCL INFO Trees [0] -1/-1/-1->275->274 [1] -1/-1/-1->275->274
239: hkn0606:2379367:2379465 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
435: hkn0730:1408947:1409077 [3] NCCL INFO Trees [0] -1/-1/-1->435->434 [1] -1/-1/-1->435->434
435: hkn0730:1408947:1409077 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
463: hkn0802:1207551:1207689 [3] NCCL INFO Trees [0] -1/-1/-1->463->462 [1] -1/-1/-1->463->462
463: hkn0802:1207551:1207689 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
423: hkn0726:1555329:1555441 [3] NCCL INFO Trees [0] -1/-1/-1->423->422 [1] -1/-1/-1->423->422
447: hkn0733:1396600:1396698 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
254: hkn0611:717063:717166 [2] NCCL INFO Trees [0] 255/-1/-1->254->253 [1] 255/-1/-1->254->253
254: hkn0611:717063:717166 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
450: hkn0734:1163781:1163870 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
268: hkn0616:412169:412281 [0] NCCL INFO Trees [0] 269/-1/-1->268->264 [1] 269/260/-1->268->284
474: hkn0805:1119317:1119439 [2] NCCL INFO Trees [0] 475/-1/-1->474->473 [1] 475/-1/-1->474->473
474: hkn0805:1119317:1119439 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
234: hkn0605:719352:719473 [2] NCCL INFO Trees [0] 235/-1/-1->234->233 [1] 235/-1/-1->234->233
455: hkn0736:1515543:1515649 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
464: hkn0803:883779:883891 [0] NCCL INFO Trees [0] 465/472/-1->464->481 [1] 465/-1/-1->464->468
464: hkn0803:883779:883891 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
476: hkn0806:1061522:1061652 [0] NCCL INFO Trees [0] 477/-1/-1->476->472 [1] 477/460/-1->476->445
218: hkn0601:124988:125082 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
265: hkn0615:421570:421665 [1] NCCL INFO Trees [0] 266/260/-1->265->264 [1] 266/-1/-1->265->264
265: hkn0615:421570:421665 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
243: hkn0607:911615:911710 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
244: hkn0608:492975:493069 [0] NCCL INFO Trees [0] 245/-1/-1->244->249 [1] 245/240/-1->244->237
274: hkn0617:2301935:2302046 [2] NCCL INFO Trees [0] 275/-1/-1->274->273 [1] 275/-1/-1->274->273
236: hkn0606:2379339:2379462 [0] NCCL INFO Trees [0] 237/-1/-1->236->232 [1] 237/228/-1->236->221
236: hkn0606:2379339:2379462 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 27: hkn0410:1166917:1167039 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26
434: hkn0730:1408975:1409075 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
469: hkn0804:1212849:1212967 [1] NCCL INFO Trees [0] 470/-1/-1->469->468 [1] 470/472/-1->469->468
423: hkn0726:1555329:1555441 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
255: hkn0611:717043:717161 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
269: hkn0616:412177:412290 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
475: hkn0805:1119325:1119448 [3] NCCL INFO Trees [0] -1/-1/-1->475->474 [1] -1/-1/-1->475->474
235: hkn0605:719372:719467 [3] NCCL INFO Trees [0] -1/-1/-1->235->234 [1] -1/-1/-1->235->234
419: hkn0725:3119172:3119282 [3] NCCL INFO Trees [0] -1/-1/-1->419->418 [1] -1/-1/-1->419->418
465: hkn0803:883787:883894 [1] NCCL INFO Trees [0] 466/456/-1->465->464 [1] 466/-1/-1->465->464
465: hkn0803:883787:883894 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
278: hkn0621:1998838:1998943 [2] NCCL INFO Trees [0] 279/-1/-1->278->277 [1] 279/-1/-1->278->277
266: hkn0615:421558:421661 [2] NCCL INFO Trees [0] 267/-1/-1->266->265 [1] 267/-1/-1->266->265
266: hkn0615:421558:421661 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
240: hkn0607:911595:911709 [0] NCCL INFO Trees [0] 241/248/-1->240->224 [1] 241/-1/-1->240->244
244: hkn0608:492975:493069 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
282: hkn0622:2027744:2027863 [2] NCCL INFO Trees [0] 283/-1/-1->282->281 [1] 283/-1/-1->282->281
275: hkn0617:2301957:2302052 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
238: hkn0606:2379355:2379460 [2] NCCL INFO Trees [0] 239/-1/-1->238->237 [1] 239/-1/-1->238->237
238: hkn0606:2379355:2379460 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 27: hkn0410:1166917:1167039 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
432: hkn0730:1408963:1409072 [0] NCCL INFO Trees [0] 433/440/-1->432->416 [1] 433/-1/-1->432->436
471: hkn0804:1212857:1212971 [3] NCCL INFO Trees [0] -1/-1/-1->471->470 [1] -1/-1/-1->471->470
471: hkn0804:1212857:1212971 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
268: hkn0616:412169:412281 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
473: hkn0805:1119333:1119444 [1] NCCL INFO Trees [0] 474/468/-1->473->472 [1] 474/-1/-1->473->472
232: hkn0605:719349:719471 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
419: hkn0725:3119172:3119282 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
466: hkn0803:883795:883893 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
431: hkn0728:1331257:1331376 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
278: hkn0621:1998838:1998943 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
241: hkn0607:911603:911711 [1] NCCL INFO Trees [0] 242/232/-1->241->240 [1] 242/-1/-1->241->240
241: hkn0607:911603:911711 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
283: hkn0622:2027736:2027858 [3] NCCL INFO Trees [0] -1/-1/-1->283->282 [1] -1/-1/-1->283->282
273: hkn0617:2301927:2302047 [1] NCCL INFO Trees [0] 274/264/-1->273->272 [1] 274/-1/-1->273->272
273: hkn0617:2301927:2302047 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 66: hkn0421:2189220:2189406 [2] NCCL INFO Trees [0] 67/-1/-1->66->65 [1] 67/-1/-1->66->65
 29: hkn0411:2323109:2323200 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/44/-1->29->28
433: hkn0730:1408955:1409068 [1] NCCL INFO Trees [0] 434/424/-1->433->432 [1] 434/-1/-1->433->432
433: hkn0730:1408955:1409068 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
468: hkn0804:1212869:1212968 [0] NCCL INFO Trees [0] 469/-1/-1->468->473 [1] 469/464/-1->468->461
468: hkn0804:1212869:1212968 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
271: hkn0616:412189:412285 [3] NCCL INFO Trees [0] -1/-1/-1->271->270 [1] -1/-1/-1->271->270
475: hkn0805:1119325:1119448 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
234: hkn0605:719352:719473 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
417: hkn0725:3119163:3119280 [1] NCCL INFO Trees [0] 418/400/-1->417->416 [1] 418/-1/-1->417->416
467: hkn0803:883807:883885 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
476: hkn0806:1061522:1061652 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
279: hkn0621:1998830:1998944 [3] NCCL INFO Trees [0] -1/-1/-1->279->278 [1] -1/-1/-1->279->278
242: hkn0607:911587:911714 [2] NCCL INFO Trees [0] 243/-1/-1->242->241 [1] 243/-1/-1->242->241
242: hkn0607:911587:911714 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
282: hkn0622:2027744:2027863 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
274: hkn0617:2301935:2302046 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 66: hkn0421:2189220:2189406 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 29: hkn0411:2323109:2323200 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
432: hkn0730:1408963:1409072 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
469: hkn0804:1212849:1212967 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
481: hkn0807:1026277:1026401 [1] NCCL INFO Trees [0] 482/464/-1->481->480 [1] 482/-1/-1->481->480
481: hkn0807:1026277:1026401 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 37: hkn0413:2373940:2374062 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/40/-1->37->36
271: hkn0616:412189:412285 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
425: hkn0727:1353010:1353119 [1] NCCL INFO Trees [0] 426/420/-1->425->424 [1] 426/-1/-1->425->424
473: hkn0805:1119333:1119444 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
235: hkn0605:719372:719467 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
418: hkn0725:3119184:3119279 [2] NCCL INFO Trees [0] 419/-1/-1->418->417 [1] 419/-1/-1->418->417
418: hkn0725:3119184:3119279 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
429: hkn0728:1331258:1331374 [1] NCCL INFO Trees [0] 430/-1/-1->429->428 [1] 430/436/-1->429->428
477: hkn0806:1061538:1061645 [1] NCCL INFO Trees [0] 478/-1/-1->477->476 [1] 478/492/-1->477->476
279: hkn0621:1998830:1998944 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
240: hkn0607:911595:911709 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
283: hkn0622:2027736:2027858 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
272: hkn0617:2301945:2302053 [0] NCCL INFO Trees [0] 273/280/-1->272->289 [1] 273/-1/-1->272->276
272: hkn0617:2301945:2302053 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 31: hkn0411:2323097:2323204 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30
420: hkn0726:1555321:1555442 [0] NCCL INFO Trees [0] 421/-1/-1->420->425 [1] 421/416/-1->420->428
482: hkn0807:1026293:1026403 [2] NCCL INFO Trees [0] 483/-1/-1->482->481 [1] 483/-1/-1->482->481
482: hkn0807:1026293:1026403 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 38: hkn0413:2373948:2374057 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37
426: hkn0727:1353002:1353113 [2] NCCL INFO Trees [0] 427/-1/-1->426->425 [1] 427/-1/-1->426->425
414: hkn0724:1723187:1723325 [2] NCCL INFO Trees [0] 415/-1/-1->414->413 [1] 415/-1/-1->414->413
417: hkn0725:3119163:3119280 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
477: hkn0806:1061538:1061645 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
276: hkn0621:1998822:1998945 [0] NCCL INFO Trees [0] 277/-1/-1->276->281 [1] 277/272/-1->276->269
276: hkn0621:1998822:1998945 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
281: hkn0622:2027752:2027859 [1] NCCL INFO Trees [0] 282/276/-1->281->280 [1] 282/-1/-1->281->280
281: hkn0622:2027752:2027859 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 58: hkn0419:1551505:1551604 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57
 65: hkn0421:2189204:2189405 [1] NCCL INFO Trees [0] 66/32/-1->65->64 [1] 66/-1/-1->65->64
 65: hkn0421:2189204:2189405 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 31: hkn0411:2323097:2323204 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
420: hkn0726:1555321:1555442 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
480: hkn0807:1026285:1026406 [0] NCCL INFO Trees [0] 481/496/-1->480->448 [1] 481/-1/-1->480->484
480: hkn0807:1026285:1026406 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 37: hkn0413:2373940:2374062 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
486: hkn0808:977893:978014 [2] NCCL INFO Trees [0] 487/-1/-1->486->485 [1] 487/-1/-1->486->485
425: hkn0727:1353010:1353119 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
416: hkn0725:3119164:3119281 [0] NCCL INFO Trees [0] 417/432/-1->416->449 [1] 417/-1/-1->416->420
416: hkn0725:3119164:3119281 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
478: hkn0806:1061550:1061649 [2] NCCL INFO Trees [0] 479/-1/-1->478->477 [1] 479/-1/-1->478->477
277: hkn0621:1998849:1998946 [1] NCCL INFO Trees [0] 278/-1/-1->277->276 [1] 278/280/-1->277->276
277: hkn0621:1998849:1998946 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 40: hkn0414:1988896:1989013 [0] NCCL INFO Trees [0] 41/44/-1->40->49 [1] 41/-1/-1->40->37
280: hkn0622:2027764:2027860 [0] NCCL INFO Trees [0] 281/284/-1->280->272 [1] 281/-1/-1->280->277
 58: hkn0419:1551505:1551604 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 28: hkn0411:2323081:2323201 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/12/-1->28->60
 62: hkn0420:3217428:3217558 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61
 62: hkn0420:3217428:3217558 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
421: hkn0726:1555337:1555444 [1] NCCL INFO Trees [0] 422/-1/-1->421->420 [1] 422/424/-1->421->420
483: hkn0807:1026305:1026402 [3] NCCL INFO Trees [0] -1/-1/-1->483->482 [1] -1/-1/-1->483->482
 38: hkn0413:2373948:2374057 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
486: hkn0808:977893:978014 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
426: hkn0727:1353002:1353113 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
414: hkn0724:1723187:1723325 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
430: hkn0728:1331266:1331371 [2] NCCL INFO Trees [0] 431/-1/-1->430->429 [1] 431/-1/-1->430->429
430: hkn0728:1331266:1331371 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
479: hkn0806:1061530:1061646 [3] NCCL INFO Trees [0] -1/-1/-1->479->478 [1] -1/-1/-1->479->478
 40: hkn0414:1988896:1989013 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
280: hkn0622:2027764:2027860 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 57: hkn0419:1551489:1551602 [1] NCCL INFO Trees [0] 58/52/-1->57->56 [1] 58/-1/-1->57->56
 57: hkn0419:1551489:1551602 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 55: hkn0418:1876416:1876509 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54
 30: hkn0411:2323089:2323199 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29
 35: hkn0412:2269608:2269737 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34
 35: hkn0412:2269608:2269737 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 25: hkn0410:1166933:1167040 [1] NCCL INFO Trees [0] 26/20/-1->25->24 [1] 26/-1/-1->25->24
 25: hkn0410:1166933:1167040 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 63: hkn0420:3217400:3217555 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62
422: hkn0726:1555349:1555447 [2] NCCL INFO Trees [0] 423/-1/-1->422->421 [1] 423/-1/-1->422->421
411: hkn0723:215353:215498 [3] NCCL INFO Trees [0] -1/-1/-1->411->410 [1] -1/-1/-1->411->410
483: hkn0807:1026305:1026402 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 39: hkn0413:2373932:2374059 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38
484: hkn0808:977921:978021 [0] NCCL INFO Trees [0] 485/-1/-1->484->489 [1] 485/480/-1->484->492
484: hkn0808:977921:978021 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
424: hkn0727:1353001:1353114 [0] NCCL INFO Trees [0] 425/428/-1->424->433 [1] 425/-1/-1->424->421
415: hkn0724:1723198:1723323 [3] NCCL INFO Trees [0] -1/-1/-1->415->414 [1] -1/-1/-1->415->414
429: hkn0728:1331258:1331374 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
478: hkn0806:1061550:1061649 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 41: hkn0414:1988888:1989009 [1] NCCL INFO Trees [0] 42/36/-1->41->40 [1] 42/-1/-1->41->40
 41: hkn0414:1988888:1989009 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
287: hkn0623:1879987:1880116 [3] NCCL INFO Trees [0] -1/-1/-1->287->286 [1] -1/-1/-1->287->286
 59: hkn0419:1551517:1551600 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58
 54: hkn0418:1876396:1876507 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53
 28: hkn0411:2323081:2323201 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 34: hkn0412:2269636:2269732 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33
 26: hkn0410:1166945:1167042 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25
 63: hkn0420:3217400:3217555 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
422: hkn0726:1555349:1555447 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
411: hkn0723:215353:215498 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 39: hkn0413:2373932:2374059 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
427: hkn0727:1353022:1353120 [3] NCCL INFO Trees [0] -1/-1/-1->427->426 [1] -1/-1/-1->427->426
427: hkn0727:1353022:1353120 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
413: hkn0724:1723172:1723322 [1] NCCL INFO Trees [0] 414/-1/-1->413->412 [1] 414/428/-1->413->412
488: hkn0809:944559:944660 [0] NCCL INFO Trees [0] 489/492/-1->488->497 [1] 489/-1/-1->488->485
428: hkn0728:1331278:1331370 [0] NCCL INFO Trees [0] 429/-1/-1->428->424 [1] 429/420/-1->428->413
479: hkn0806:1061530:1061646 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
288: hkn0624:1780140:1780284 [0] NCCL INFO Trees [0] 289/304/-1->288->321 [1] 289/-1/-1->288->292
 43: hkn0414:1988916:1989008 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42
 43: hkn0414:1988916:1989008 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 59: hkn0419:1551517:1551600 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 55: hkn0418:1876416:1876509 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 30: hkn0411:2323089:2323199 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 34: hkn0412:2269636:2269732 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 50: hkn0417:2274860:2274988 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49
 26: hkn0410:1166945:1167042 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 61: hkn0420:3217408:3217553 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/92/-1->61->60
421: hkn0726:1555337:1555444 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
409: hkn0723:215333:215489 [1] NCCL INFO Trees [0] 410/404/-1->409->408 [1] 410/-1/-1->409->408
 36: hkn0413:2373960:2374058 [0] NCCL INFO Trees [0] 37/-1/-1->36->41 [1] 37/32/-1->36->44
 36: hkn0413:2373960:2374058 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
485: hkn0808:977901:978022 [1] NCCL INFO Trees [0] 486/-1/-1->485->484 [1] 486/488/-1->485->484
485: hkn0808:977901:978022 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
424: hkn0727:1353001:1353114 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
415: hkn0724:1723198:1723323 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
490: hkn0809:944543:944669 [2] NCCL INFO Trees [0] 491/-1/-1->490->489 [1] 491/-1/-1->490->489
428: hkn0728:1331278:1331370 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
288: hkn0624:1780140:1780284 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
287: hkn0623:1879987:1880116 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 44: hkn0415:2503651:2503760 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/36/-1->44->29
 56: hkn0419:1551497:1551601 [0] NCCL INFO Trees [0] 57/60/-1->56->48 [1] 57/-1/-1->56->53
 56: hkn0419:1551497:1551601 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 54: hkn0418:1876396:1876507 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 32: hkn0412:2269616:2269733 [0] NCCL INFO Trees [0] 33/48/-1->32->65 [1] 33/-1/-1->32->36
 50: hkn0417:2274860:2274988 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 24: hkn0410:1166925:1167041 [0] NCCL INFO Trees [0] 25/28/-1->24->16 [1] 25/-1/-1->24->21
 61: hkn0420:3217408:3217553 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
410: hkn0723:215325:215496 [2] NCCL INFO Trees [0] 411/-1/-1->410->409 [1] 411/-1/-1->410->409
487: hkn0808:977909:978016 [3] NCCL INFO Trees [0] -1/-1/-1->487->486 [1] -1/-1/-1->487->486
413: hkn0724:1723172:1723322 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
488: hkn0809:944559:944660 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 21: hkn0409:2592894:2592992 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/24/-1->21->20
 21: hkn0409:2592894:2592992 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
289: hkn0624:1780160:1780285 [1] NCCL INFO Trees [0] 290/272/-1->289->288 [1] 290/-1/-1->289->288
284: hkn0623:1880015:1880110 [0] NCCL INFO Trees [0] 285/-1/-1->284->280 [1] 285/268/-1->284->316
284: hkn0623:1880015:1880110 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 44: hkn0415:2503651:2503760 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 64: hkn0421:2189212:2189407 [0] NCCL INFO Trees [0] 65/96/-1->64->129 [1] 65/-1/-1->64->68
 64: hkn0421:2189212:2189407 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 53: hkn0418:1876404:1876515 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/56/-1->53->52
 33: hkn0412:2269624:2269736 [1] NCCL INFO Trees [0] 34/16/-1->33->32 [1] 34/-1/-1->33->32
 48: hkn0417:2274888:2274985 [0] NCCL INFO Trees [0] 49/56/-1->48->32 [1] 49/-1/-1->48->52
 24: hkn0410:1166925:1167041 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 60: hkn0420:3217416:3217549 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/28/-1->60->124
409: hkn0723:215333:215489 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
487: hkn0808:977909:978016 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
412: hkn0724:1723179:1723321 [0] NCCL INFO Trees [0] 413/-1/-1->412->408 [1] 413/396/-1->412->444
412: hkn0724:1723179:1723321 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
490: hkn0809:944543:944669 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
393: hkn0718:3924262:3924378 [1] NCCL INFO Trees [0] 394/388/-1->393->392 [1] 394/-1/-1->393->392
 22: hkn0409:2592882:2592991 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21
291: hkn0624:1780148:1780287 [3] NCCL INFO Trees [0] -1/-1/-1->291->290 [1] -1/-1/-1->291->290
 42: hkn0414:1988904:1989011 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41
292: hkn0626:1305637:1305778 [0] NCCL INFO Trees [0] 293/-1/-1->292->297 [1] 293/288/-1->292->300
292: hkn0626:1305637:1305778 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
285: hkn0623:1880003:1880109 [1] NCCL INFO Trees [0] 286/-1/-1->285->284 [1] 286/300/-1->285->284
285: hkn0623:1880003:1880109 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 45: hkn0415:2503635:2503763 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/52/-1->45->44
 45: hkn0415:2503635:2503763 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 53: hkn0418:1876404:1876515 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 32: hkn0412:2269616:2269733 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 48: hkn0417:2274888:2274985 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 60: hkn0420:3217416:3217549 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
410: hkn0723:215325:215496 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
391: hkn0717:1459:1584 [3] NCCL INFO Trees [0] -1/-1/-1->391->390 [1] -1/-1/-1->391->390
489: hkn0809:944571:944666 [1] NCCL INFO Trees [0] 490/484/-1->489->488 [1] 490/-1/-1->489->488
489: hkn0809:944571:944666 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
393: hkn0718:3924262:3924378 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 23: hkn0409:2592874:2592989 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22
 23: hkn0409:2592874:2592989 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
289: hkn0624:1780160:1780285 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
326: hkn0634:1528060:1528187 [2] NCCL INFO Trees [0] 327/-1/-1->326->325 [1] 327/-1/-1->326->325
 42: hkn0414:1988904:1989011 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
293: hkn0626:1305645:1305779 [1] NCCL INFO Trees [0] 294/-1/-1->293->292 [1] 294/296/-1->293->292
286: hkn0623:1879995:1880114 [2] NCCL INFO Trees [0] 287/-1/-1->286->285 [1] 287/-1/-1->286->285
286: hkn0623:1879995:1880114 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 46: hkn0415:2503643:2503758 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45
 46: hkn0415:2503643:2503758 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 52: hkn0418:1876388:1876514 [0] NCCL INFO Trees [0] 53/-1/-1->52->57 [1] 53/48/-1->52->45
 33: hkn0412:2269624:2269736 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 51: hkn0417:2274868:2274989 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50
396: hkn0719:1312979:1313087 [0] NCCL INFO Trees [0] 397/-1/-1->396->392 [1] 397/388/-1->396->412
396: hkn0719:1312979:1313087 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
408: hkn0723:215341:215495 [0] NCCL INFO Trees [0] 409/412/-1->408->400 [1] 409/-1/-1->408->405
402: hkn0720:14310:14477 [2] NCCL INFO Trees [0] 403/-1/-1->402->401 [1] 403/-1/-1->402->401
391: hkn0717:1459:1584 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
491: hkn0809:944551:944668 [3] NCCL INFO Trees [0] -1/-1/-1->491->490 [1] -1/-1/-1->491->490
491: hkn0809:944551:944668 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
406: hkn0721:2306498:2306623 [2] NCCL INFO Trees [0] 407/-1/-1->406->405 [1] 407/-1/-1->406->405
406: hkn0721:2306498:2306623 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
394: hkn0718:3924274:3924372 [2] NCCL INFO Trees [0] 395/-1/-1->394->393 [1] 395/-1/-1->394->393
394: hkn0718:3924274:3924372 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 22: hkn0409:2592882:2592991 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
290: hkn0624:1780132:1780286 [2] NCCL INFO Trees [0] 291/-1/-1->290->289 [1] 291/-1/-1->290->289
326: hkn0634:1528060:1528187 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
329: hkn0635:1232786:1232910 [1] NCCL INFO Trees [0] 330/324/-1->329->328 [1] 330/-1/-1->329->328
293: hkn0626:1305645:1305779 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 47: hkn0415:2503663:2503759 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46
 47: hkn0415:2503663:2503759 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 52: hkn0418:1876388:1876514 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 51: hkn0417:2274868:2274989 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
398: hkn0719:1312991:1313080 [2] NCCL INFO Trees [0] 399/-1/-1->398->397 [1] 399/-1/-1->398->397
398: hkn0719:1312991:1313080 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
408: hkn0723:215341:215495 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
492: hkn0810:946764:946863 [0] NCCL INFO Trees [0] 493/-1/-1->492->488 [1] 493/484/-1->492->477
402: hkn0720:14310:14477 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
407: hkn0721:2306506:2306615 [3] NCCL INFO Trees [0] -1/-1/-1->407->406 [1] -1/-1/-1->407->406
407: hkn0721:2306506:2306615 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
395: hkn0718:3924254:3924371 [3] NCCL INFO Trees [0] -1/-1/-1->395->394 [1] -1/-1/-1->395->394
291: hkn0624:1780148:1780287 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
327: hkn0634:1528094:1528189 [3] NCCL INFO Trees [0] -1/-1/-1->327->326 [1] -1/-1/-1->327->326
329: hkn0635:1232786:1232910 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
294: hkn0626:1305634:1305784 [2] NCCL INFO Trees [0] 295/-1/-1->294->293 [1] 295/-1/-1->294->293
335: hkn0636:1661521:1661639 [3] NCCL INFO Trees [0] -1/-1/-1->335->334 [1] -1/-1/-1->335->334
 49: hkn0417:2274876:2274980 [1] NCCL INFO Trees [0] 50/40/-1->49->48 [1] 50/-1/-1->49->48
 49: hkn0417:2274876:2274980 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
399: hkn0719:1312971:1313088 [3] NCCL INFO Trees [0] -1/-1/-1->399->398 [1] -1/-1/-1->399->398
399: hkn0719:1312971:1313088 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
492: hkn0810:946764:946863 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
403: hkn0720:14330:14481 [3] NCCL INFO Trees [0] -1/-1/-1->403->402 [1] -1/-1/-1->403->402
405: hkn0721:2306514:2306619 [1] NCCL INFO Trees [0] 406/-1/-1->405->404 [1] 406/408/-1->405->404
405: hkn0721:2306514:2306619 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
395: hkn0718:3924254:3924371 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
290: hkn0624:1780132:1780286 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
338: hkn0703:748322:748407 [2] NCCL INFO Trees [0] 339/-1/-1->338->337 [1] 339/-1/-1->338->337
327: hkn0634:1528094:1528189 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
331: hkn0635:1232814:1232915 [3] NCCL INFO Trees [0] -1/-1/-1->331->330 [1] -1/-1/-1->331->330
295: hkn0626:1305656:1305785 [3] NCCL INFO Trees [0] -1/-1/-1->295->294 [1] -1/-1/-1->295->294
335: hkn0636:1661521:1661639 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 00/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
397: hkn0719:1312963:1313082 [1] NCCL INFO Trees [0] 398/-1/-1->397->396 [1] 398/404/-1->397->396
403: hkn0720:14330:14481 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
389: hkn0717:1475:1580 [1] NCCL INFO Trees [0] 390/-1/-1->389->388 [1] 390/392/-1->389->388
404: hkn0721:2306526:2306622 [0] NCCL INFO Trees [0] 405/-1/-1->404->409 [1] 405/400/-1->404->397
392: hkn0718:3924246:3924376 [0] NCCL INFO Trees [0] 393/396/-1->392->401 [1] 393/-1/-1->392->389
338: hkn0703:748322:748407 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
328: hkn0635:1232794:1232913 [0] NCCL INFO Trees [0] 329/332/-1->328->337 [1] 329/-1/-1->328->325
328: hkn0635:1232794:1232913 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
294: hkn0626:1305634:1305784 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
332: hkn0636:1661513:1661645 [0] NCCL INFO Trees [0] 333/-1/-1->332->328 [1] 333/324/-1->332->348
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 01/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
397: hkn0719:1312963:1313082 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
400: hkn0720:14302:14479 [0] NCCL INFO Trees [0] 401/408/-1->400->417 [1] 401/-1/-1->400->404
390: hkn0717:1487:1589 [2] NCCL INFO Trees [0] 391/-1/-1->390->389 [1] 391/-1/-1->390->389
404: hkn0721:2306526:2306622 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
392: hkn0718:3924246:3924376 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
339: hkn0703:748311:748409 [3] NCCL INFO Trees [0] -1/-1/-1->339->338 [1] -1/-1/-1->339->338
330: hkn0635:1232802:1232909 [2] NCCL INFO Trees [0] 331/-1/-1->330->329 [1] 331/-1/-1->330->329
295: hkn0626:1305656:1305785 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
333: hkn0636:1661529:1661644 [1] NCCL INFO Trees [0] 334/-1/-1->333->332 [1] 334/340/-1->333->332
333: hkn0636:1661529:1661644 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
401: hkn0720:14318:14478 [1] NCCL INFO Trees [0] 402/392/-1->401->400 [1] 402/-1/-1->401->400
401: hkn0720:14318:14478 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
499: hkn0812:701057:701148 [3] NCCL INFO Trees [0] -1/-1/-1->499->498 [1] -1/-1/-1->499->498
389: hkn0717:1475:1580 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
339: hkn0703:748311:748409 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
343: hkn0704:799231:799343 [3] NCCL INFO Trees [0] -1/-1/-1->343->342 [1] -1/-1/-1->343->342
 19: hkn0408:2898037:2898154 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18
331: hkn0635:1232814:1232915 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
334: hkn0636:1661541:1661648 [2] NCCL INFO Trees [0] 335/-1/-1->334->333 [1] 335/-1/-1->334->333
334: hkn0636:1661541:1661648 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
380: hkn0715:409126:409232 [0] NCCL INFO Trees [0] 381/-1/-1->380->376 [1] 381/316/-1->380->253
380: hkn0715:409126:409232 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  0: hkn0403:1776559:1776930 [0] NCCL INFO Trees [0] 1/256/-1->0->-1 [1] 1/-1/-1->0->4
493: hkn0810:946752:946862 [1] NCCL INFO Trees [0] 494/-1/-1->493->492 [1] 494/500/-1->493->492
509: hkn0816:382855:382951 [1] NCCL INFO Trees [0] 510/-1/-1->509->508 [1] 510/-1/-1->509->508
400: hkn0720:14302:14479 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
499: hkn0812:701057:701148 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
390: hkn0717:1487:1589 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
502: hkn0814:683050:683175 [2] NCCL INFO Trees [0] 503/-1/-1->502->501 [1] 503/-1/-1->502->501
337: hkn0703:748303:748410 [1] NCCL INFO Trees [0] 338/328/-1->337->336 [1] 338/-1/-1->337->336
 19: hkn0408:2898037:2898154 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
330: hkn0635:1232802:1232909 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
379: hkn0714:439265:439360 [3] NCCL INFO Trees [0] -1/-1/-1->379->378 [1] -1/-1/-1->379->378
332: hkn0636:1661513:1661645 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  0: hkn0403:1776559:1776930 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
384: hkn0716:115715:115850 [0] NCCL INFO Trees [0] 385/448/-1->384->256 [1] 385/-1/-1->384->388
494: hkn0810:946736:946861 [2] NCCL INFO Trees [0] 495/-1/-1->494->493 [1] 495/-1/-1->494->493
505: hkn0815:402333:402447 [1] NCCL INFO Trees [0] 506/500/-1->505->504 [1] 506/-1/-1->505->504
509: hkn0816:382855:382951 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
496: hkn0812:701027:701151 [0] NCCL INFO Trees [0] 497/504/-1->496->480 [1] 497/-1/-1->496->500
496: hkn0812:701027:701151 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
502: hkn0814:683050:683175 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 20: hkn0409:2592866:2592990 [0] NCCL INFO Trees [0] 21/-1/-1->20->25 [1] 21/16/-1->20->13
336: hkn0703:748295:748408 [0] NCCL INFO Trees [0] 337/344/-1->336->353 [1] 337/-1/-1->336->340
343: hkn0704:799231:799343 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
379: hkn0714:439265:439360 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
344: hkn0705:790415:790543 [0] NCCL INFO Trees [0] 345/348/-1->344->336 [1] 345/-1/-1->344->341
296: hkn0627:1795174:1795274 [0] NCCL INFO Trees [0] 297/300/-1->296->305 [1] 297/-1/-1->296->293
 10: hkn0405:3214170:3214279 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
493: hkn0810:946752:946862 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
507: hkn0815:402329:402444 [3] NCCL INFO Trees [0] -1/-1/-1->507->506 [1] -1/-1/-1->507->506
507: hkn0815:402329:402444 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
497: hkn0812:701035:701150 [1] NCCL INFO Trees [0] 498/488/-1->497->496 [1] 498/-1/-1->497->496
  4: hkn0404:1346644:1346761 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/0/-1->4->12
500: hkn0814:683023:683174 [0] NCCL INFO Trees [0] 501/-1/-1->500->505 [1] 501/496/-1->500->493
 20: hkn0409:2592866:2592990 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
337: hkn0703:748303:748410 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
340: hkn0704:799215:799344 [0] NCCL INFO Trees [0] 341/-1/-1->340->345 [1] 341/336/-1->340->333
340: hkn0704:799215:799344 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 18: hkn0408:2898057:2898153 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17
344: hkn0705:790415:790543 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
296: hkn0627:1795174:1795274 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
381: hkn0715:409138:409236 [1] NCCL INFO Trees [0] 382/-1/-1->381->380 [1] 382/444/-1->381->380
375: hkn0713:477460:477578 [3] NCCL INFO Trees [0] -1/-1/-1->375->374 [1] -1/-1/-1->375->374
  1: hkn0403:1776565:1776936 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
385: hkn0716:115707:115856 [1] NCCL INFO Trees [0] 386/320/-1->385->384 [1] 386/-1/-1->385->384
385: hkn0716:115707:115856 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
494: hkn0810:946736:946861 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
505: hkn0815:402333:402447 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
498: hkn0812:701043:701153 [2] NCCL INFO Trees [0] 499/-1/-1->498->497 [1] 499/-1/-1->498->497
  5: hkn0404:1346653:1346760 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/8/-1->5->4
336: hkn0703:748295:748408 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
301: hkn0628:679147:679253 [1] NCCL INFO Trees [0] 302/-1/-1->301->300 [1] 302/308/-1->301->300
341: hkn0704:799223:799342 [1] NCCL INFO Trees [0] 342/-1/-1->341->340 [1] 342/344/-1->341->340
341: hkn0704:799223:799342 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 18: hkn0408:2898057:2898153 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
377: hkn0714:439253:439365 [1] NCCL INFO Trees [0] 378/372/-1->377->376 [1] 378/-1/-1->377->376
346: hkn0705:790431:790545 [2] NCCL INFO Trees [0] 347/-1/-1->346->345 [1] 347/-1/-1->346->345
381: hkn0715:409138:409236 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 10: hkn0405:3214170:3214279 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
375: hkn0713:477460:477578 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  2: hkn0403:1776577:1776939 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
384: hkn0716:115715:115850 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
495: hkn0810:946744:946866 [3] NCCL INFO Trees [0] -1/-1/-1->495->494 [1] -1/-1/-1->495->494
495: hkn0810:946744:946866 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
506: hkn0815:402341:402450 [2] NCCL INFO Trees [0] 507/-1/-1->506->505 [1] 507/-1/-1->506->505
510: hkn0816:382843:382953 [2] NCCL INFO Trees [0] 511/-1/-1->510->509 [1] 511/-1/-1->510->509
497: hkn0812:701035:701150 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  6: hkn0404:1346665:1346763 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
  6: hkn0404:1346665:1346763 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
501: hkn0814:683039:683170 [1] NCCL INFO Trees [0] 502/-1/-1->501->500 [1] 502/504/-1->501->500
301: hkn0628:679147:679253 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
349: hkn0706:759478:759608 [1] NCCL INFO Trees [0] 350/-1/-1->349->348 [1] 350/364/-1->349->348
305: hkn0629:1599304:1599395 [1] NCCL INFO Trees [0] 306/296/-1->305->304 [1] 306/-1/-1->305->304
342: hkn0704:799243:799339 [2] NCCL INFO Trees [0] 343/-1/-1->342->341 [1] 343/-1/-1->342->341
342: hkn0704:799243:799339 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 17: hkn0408:2898045:2898159 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] 18/-1/-1->17->16
 17: hkn0408:2898045:2898159 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
377: hkn0714:439253:439365 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
346: hkn0705:790431:790545 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
299: hkn0627:1795186:1795268 [3] NCCL INFO Trees [0] -1/-1/-1->299->298 [1] -1/-1/-1->299->298
382: hkn0715:409118:409228 [2] NCCL INFO Trees [0] 383/-1/-1->382->381 [1] 383/-1/-1->382->381
 11: hkn0405:3214162:3214281 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10
371: hkn0712:302309:302405 [3] NCCL INFO Trees [0] -1/-1/-1->371->370 [1] -1/-1/-1->371->370
372: hkn0713:477480:477575 [0] NCCL INFO Trees [0] 373/-1/-1->372->377 [1] 373/368/-1->372->365
  3: hkn0403:1776560:1776937 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
386: hkn0716:115704:115853 [2] NCCL INFO Trees [0] 387/-1/-1->386->385 [1] 387/-1/-1->386->385
506: hkn0815:402341:402450 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 14: hkn0407:1823492:1823615 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
511: hkn0816:382835:382955 [3] NCCL INFO Trees [0] -1/-1/-1->511->510 [1] -1/-1/-1->511->510
498: hkn0812:701043:701153 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  4: hkn0404:1346644:1346761 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
388: hkn0717:1467:1586 [0] NCCL INFO Trees [0] 389/-1/-1->388->393 [1] 389/384/-1->388->396
503: hkn0814:683031:683177 [3] NCCL INFO Trees [0] -1/-1/-1->503->502 [1] -1/-1/-1->503->502
503: hkn0814:683031:683177 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
311: hkn0630:1605706:1605807 [3] NCCL INFO Trees [0] -1/-1/-1->311->310 [1] -1/-1/-1->311->310
325: hkn0634:1528068:1528186 [1] NCCL INFO Trees [0] 326/-1/-1->325->324 [1] 326/328/-1->325->324
302: hkn0628:679139:679252 [2] NCCL INFO Trees [0] 303/-1/-1->302->301 [1] 303/-1/-1->302->301
349: hkn0706:759478:759608 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
305: hkn0629:1599304:1599395 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 16: hkn0408:2898029:2898160 [0] NCCL INFO Trees [0] 17/24/-1->16->33 [1] 17/-1/-1->16->20
376: hkn0714:439237:439359 [0] NCCL INFO Trees [0] 377/380/-1->376->368 [1] 377/-1/-1->376->373
347: hkn0705:790423:790536 [3] NCCL INFO Trees [0] -1/-1/-1->347->346 [1] -1/-1/-1->347->346
299: hkn0627:1795186:1795268 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
383: hkn0715:409110:409235 [3] NCCL INFO Trees [0] -1/-1/-1->383->382 [1] -1/-1/-1->383->382
 11: hkn0405:3214162:3214281 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
371: hkn0712:302309:302405 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
372: hkn0713:477480:477575 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  1: hkn0403:1776565:1776936 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
387: hkn0716:115727:115858 [3] NCCL INFO Trees [0] -1/-1/-1->387->386 [1] -1/-1/-1->387->386
504: hkn0815:402353:402445 [0] NCCL INFO Trees [0] 505/508/-1->504->496 [1] 505/-1/-1->504->501
 15: hkn0407:1823508:1823614 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
508: hkn0816:382834:382958 [0] NCCL INFO Trees [0] 509/-1/-1->508->504 [1] 509/252/-1->508->-1
508: hkn0816:382834:382958 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  5: hkn0404:1346653:1346760 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
388: hkn0717:1467:1586 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
500: hkn0814:683023:683174 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
302: hkn0628:679139:679252 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
363: hkn0710:362780:362887 [3] NCCL INFO Trees [0] -1/-1/-1->363->362 [1] -1/-1/-1->363->362
363: hkn0710:362780:362887 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
350: hkn0706:759494:759603 [2] NCCL INFO Trees [0] 351/-1/-1->350->349 [1] 351/-1/-1->350->349
313: hkn0631:1029024:1029139 [1] NCCL INFO Trees [0] 314/308/-1->313->312 [1] 314/-1/-1->313->312
304: hkn0629:1599292:1599400 [0] NCCL INFO Trees [0] 305/312/-1->304->288 [1] 305/-1/-1->304->308
319: hkn0632:1765859:1765969 [3] NCCL INFO Trees [0] -1/-1/-1->319->318 [1] -1/-1/-1->319->318
 16: hkn0408:2898029:2898160 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
378: hkn0714:439245:439363 [2] NCCL INFO Trees [0] 379/-1/-1->378->377 [1] 379/-1/-1->378->377
378: hkn0714:439245:439363 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
347: hkn0705:790423:790536 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
297: hkn0627:1795158:1795270 [1] NCCL INFO Trees [0] 298/292/-1->297->296 [1] 298/-1/-1->297->296
382: hkn0715:409118:409228 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
355: hkn0707:4027153:4027260 [3] NCCL INFO Trees [0] -1/-1/-1->355->354 [1] -1/-1/-1->355->354
  8: hkn0405:3214154:3214272 [0] NCCL INFO Trees [0] 9/12/-1->8->17 [1] 9/-1/-1->8->5
369: hkn0712:302289:302403 [1] NCCL INFO Trees [0] 370/360/-1->369->368 [1] 370/-1/-1->369->368
373: hkn0713:477452:477574 [1] NCCL INFO Trees [0] 374/-1/-1->373->372 [1] 374/376/-1->373->372
  2: hkn0403:1776577:1776939 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
386: hkn0716:115704:115853 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
504: hkn0815:402353:402445 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
510: hkn0816:382843:382953 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  7: hkn0404:1346645:1346762 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
501: hkn0814:683039:683170 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
311: hkn0630:1605706:1605807 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
325: hkn0634:1528068:1528186 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
300: hkn0628:679159:679255 [0] NCCL INFO Trees [0] 301/-1/-1->300->296 [1] 301/292/-1->300->285
122: hkn0507:3194301:3194415 [2] NCCL INFO Channel 00 : 122[ca000] -> 121[4b000] via P2P/IPC/read
350: hkn0706:759494:759603 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
312: hkn0631:1029044:1029136 [0] NCCL INFO Trees [0] 313/316/-1->312->304 [1] 313/-1/-1->312->309
304: hkn0629:1599292:1599400 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
319: hkn0632:1765859:1765969 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
376: hkn0714:439237:439359 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
365: hkn0711:591174:591286 [1] NCCL INFO Trees [0] 366/-1/-1->365->364 [1] 366/372/-1->365->364
345: hkn0705:790443:790544 [1] NCCL INFO Trees [0] 346/340/-1->345->344 [1] 346/-1/-1->345->344
345: hkn0705:790443:790544 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
297: hkn0627:1795158:1795270 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
383: hkn0715:409110:409235 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
320: hkn0633:1533538:1533659 [0] NCCL INFO Trees [0] 321/352/-1->320->385 [1] 321/-1/-1->320->324
355: hkn0707:4027153:4027260 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  8: hkn0405:3214154:3214272 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
369: hkn0712:302289:302403 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
374: hkn0713:477468:477571 [2] NCCL INFO Trees [0] 375/-1/-1->374->373 [1] 375/-1/-1->374->373
  3: hkn0403:1776560:1776937 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
387: hkn0716:115727:115858 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 13: hkn0407:1823500:1823618 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/20/-1->13->12
511: hkn0816:382835:382955 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  7: hkn0404:1346645:1346762 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
310: hkn0630:1605686:1605806 [2] NCCL INFO Trees [0] 311/-1/-1->310->309 [1] 311/-1/-1->310->309
324: hkn0634:1528076:1528180 [0] NCCL INFO Trees [0] 325/-1/-1->324->329 [1] 325/320/-1->324->332
303: hkn0628:679131:679256 [3] NCCL INFO Trees [0] -1/-1/-1->303->302 [1] -1/-1/-1->303->302
303: hkn0628:679131:679256 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
361: hkn0710:362772:362881 [1] NCCL INFO Trees [0] 362/356/-1->361->360 [1] 362/-1/-1->361->360
351: hkn0706:759486:759602 [3] NCCL INFO Trees [0] -1/-1/-1->351->350 [1] -1/-1/-1->351->350
313: hkn0631:1029024:1029139 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
306: hkn0629:1599284:1599393 [2] NCCL INFO Trees [0] 307/-1/-1->306->305 [1] 307/-1/-1->306->305
316: hkn0632:1765871:1765970 [0] NCCL INFO Trees [0] 317/-1/-1->316->312 [1] 317/284/-1->316->380
316: hkn0632:1765871:1765970 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
365: hkn0711:591174:591286 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
356: hkn0708:420442:420567 [0] NCCL INFO Trees [0] 357/-1/-1->356->361 [1] 357/352/-1->356->364
298: hkn0627:1795166:1795271 [2] NCCL INFO Trees [0] 299/-1/-1->298->297 [1] 299/-1/-1->298->297
298: hkn0627:1795166:1795271 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
320: hkn0633:1533538:1533659 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
354: hkn0707:4027145:4027255 [2] NCCL INFO Trees [0] 355/-1/-1->354->353 [1] 355/-1/-1->354->353
  9: hkn0405:3214182:3214280 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/-1/-1->9->8
370: hkn0712:302281:302408 [2] NCCL INFO Trees [0] 371/-1/-1->370->369 [1] 371/-1/-1->370->369
373: hkn0713:477452:477574 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 14: hkn0407:1823492:1823615 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
310: hkn0630:1605686:1605806 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
324: hkn0634:1528076:1528180 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
300: hkn0628:679159:679255 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
361: hkn0710:362772:362881 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
351: hkn0706:759486:759602 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
312: hkn0631:1029044:1029136 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
307: hkn0629:1599276:1599401 [3] NCCL INFO Trees [0] -1/-1/-1->307->306 [1] -1/-1/-1->307->306
318: hkn0632:1765851:1765965 [2] NCCL INFO Trees [0] 319/-1/-1->318->317 [1] 319/-1/-1->318->317
318: hkn0632:1765851:1765965 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
357: hkn0708:420450:420563 [1] NCCL INFO Trees [0] 358/-1/-1->357->356 [1] 358/360/-1->357->356
354: hkn0707:4027145:4027255 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  9: hkn0405:3214182:3214280 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
370: hkn0712:302281:302408 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
374: hkn0713:477468:477571 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 15: hkn0407:1823508:1823614 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
308: hkn0630:1605678:1605803 [0] NCCL INFO Trees [0] 309/-1/-1->308->313 [1] 309/304/-1->308->301
362: hkn0710:362764:362885 [2] NCCL INFO Trees [0] 363/-1/-1->362->361 [1] 363/-1/-1->362->361
348: hkn0706:759506:759606 [0] NCCL INFO Trees [0] 349/-1/-1->348->344 [1] 349/332/-1->348->317
314: hkn0631:1029016:1029137 [2] NCCL INFO Trees [0] 315/-1/-1->314->313 [1] 315/-1/-1->314->313
314: hkn0631:1029016:1029137 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
306: hkn0629:1599284:1599393 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
317: hkn0632:1765843:1765966 [1] NCCL INFO Trees [0] 318/-1/-1->317->316 [1] 318/348/-1->317->316
317: hkn0632:1765843:1765966 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
364: hkn0711:591166:591281 [0] NCCL INFO Trees [0] 365/-1/-1->364->360 [1] 365/356/-1->364->349
358: hkn0708:420458:420568 [2] NCCL INFO Trees [0] 359/-1/-1->358->357 [1] 359/-1/-1->358->357
321: hkn0633:1533546:1533662 [1] NCCL INFO Trees [0] 322/288/-1->321->320 [1] 322/-1/-1->321->320
321: hkn0633:1533546:1533662 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
352: hkn0707:4027165:4027259 [0] NCCL INFO Trees [0] 353/368/-1->352->320 [1] 353/-1/-1->352->356
352: hkn0707:4027165:4027259 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
118: hkn0506:845292:845415 [2] NCCL INFO Channel 00 : 118[ca000] -> 117[4b000] via P2P/IPC/read
368: hkn0712:302297:302400 [0] NCCL INFO Trees [0] 369/376/-1->368->352 [1] 369/-1/-1->368->372
 12: hkn0407:1823520:1823613 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/4/-1->12->28
308: hkn0630:1605678:1605803 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
360: hkn0710:362792:362882 [0] NCCL INFO Trees [0] 361/364/-1->360->369 [1] 361/-1/-1->360->357
348: hkn0706:759506:759606 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
315: hkn0631:1029032:1029141 [3] NCCL INFO Trees [0] -1/-1/-1->315->314 [1] -1/-1/-1->315->314
307: hkn0629:1599276:1599401 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
366: hkn0711:591185:591287 [2] NCCL INFO Trees [0] 367/-1/-1->366->365 [1] 367/-1/-1->366->365
356: hkn0708:420442:420567 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
322: hkn0633:1533554:1533664 [2] NCCL INFO Trees [0] 323/-1/-1->322->321 [1] 323/-1/-1->322->321
353: hkn0707:4027137:4027262 [1] NCCL INFO Trees [0] 354/336/-1->353->352 [1] 354/-1/-1->353->352
368: hkn0712:302297:302400 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 13: hkn0407:1823500:1823618 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
309: hkn0630:1605694:1605798 [1] NCCL INFO Trees [0] 310/-1/-1->309->308 [1] 310/312/-1->309->308
309: hkn0630:1605694:1605798 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
362: hkn0710:362764:362885 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
315: hkn0631:1029032:1029141 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
367: hkn0711:591158:591280 [3] NCCL INFO Trees [0] -1/-1/-1->367->366 [1] -1/-1/-1->367->366
357: hkn0708:420450:420563 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
323: hkn0633:1533566:1533658 [3] NCCL INFO Trees [0] -1/-1/-1->323->322 [1] -1/-1/-1->323->322
353: hkn0707:4027137:4027262 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 12: hkn0407:1823520:1823613 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
360: hkn0710:362792:362882 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
364: hkn0711:591166:591281 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
358: hkn0708:420458:420568 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
322: hkn0633:1533554:1533664 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
366: hkn0711:591185:591287 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
359: hkn0708:420470:420564 [3] NCCL INFO Trees [0] -1/-1/-1->359->358 [1] -1/-1/-1->359->358
359: hkn0708:420470:420564 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
323: hkn0633:1533566:1533658 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
126: hkn0508:3146354:3146461 [2] NCCL INFO Channel 00 : 126[ca000] -> 125[4b000] via P2P/IPC/read
367: hkn0711:591158:591280 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
130: hkn0509:3131655:3131751 [2] NCCL INFO Channel 00 : 130[ca000] -> 129[4b000] via P2P/IPC/read
134: hkn0510:2769278:2769396 [2] NCCL INFO Channel 00 : 134[ca000] -> 133[4b000] via P2P/IPC/read
118: hkn0506:845292:845415 [2] NCCL INFO Channel 01 : 118[ca000] -> 117[4b000] via P2P/IPC/read
114: hkn0505:2311013:2311117 [2] NCCL INFO Channel 00 : 114[ca000] -> 113[4b000] via P2P/IPC/read
122: hkn0507:3194301:3194415 [2] NCCL INFO Channel 01 : 122[ca000] -> 121[4b000] via P2P/IPC/read
138: hkn0511:3073676:3073772 [2] NCCL INFO Channel 00 : 138[ca000] -> 137[4b000] via P2P/IPC/read
126: hkn0508:3146354:3146461 [2] NCCL INFO Channel 01 : 126[ca000] -> 125[4b000] via P2P/IPC/read
134: hkn0510:2769278:2769396 [2] NCCL INFO Channel 01 : 134[ca000] -> 133[4b000] via P2P/IPC/read
130: hkn0509:3131655:3131751 [2] NCCL INFO Channel 01 : 130[ca000] -> 129[4b000] via P2P/IPC/read
114: hkn0505:2311013:2311117 [2] NCCL INFO Channel 01 : 114[ca000] -> 113[4b000] via P2P/IPC/read
106: hkn0503:2906951:2907055 [2] NCCL INFO Channel 00 : 106[ca000] -> 105[4b000] via P2P/IPC/read
150: hkn0514:2957943:2958073 [2] NCCL INFO Channel 00 : 150[ca000] -> 149[4b000] via P2P/IPC/read
142: hkn0512:3051335:3051453 [2] NCCL INFO Channel 00 : 142[ca000] -> 141[4b000] via P2P/IPC/read
146: hkn0513:3020196:3020300 [2] NCCL INFO Channel 00 : 146[ca000] -> 145[4b000] via P2P/IPC/read
154: hkn0515:2904025:2904145 [2] NCCL INFO Channel 00 : 154[ca000] -> 153[4b000] via P2P/IPC/read
102: hkn0502:236315:236406 [2] NCCL INFO Channel 00 : 102[ca000] -> 101[4b000] via P2P/IPC/read
138: hkn0511:3073676:3073772 [2] NCCL INFO Channel 01 : 138[ca000] -> 137[4b000] via P2P/IPC/read
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
 98: hkn0501:1335167:1335267 [2] NCCL INFO Channel 00 : 98[ca000] -> 97[4b000] via P2P/IPC/read
162: hkn0520:2720086:2720209 [2] NCCL INFO Channel 00 : 162[ca000] -> 161[4b000] via P2P/IPC/read
158: hkn0516:2923196:2923320 [2] NCCL INFO Channel 00 : 158[ca000] -> 157[4b000] via P2P/IPC/read
146: hkn0513:3020196:3020300 [2] NCCL INFO Channel 01 : 146[ca000] -> 145[4b000] via P2P/IPC/read
166: hkn0521:1205036:1205135 [2] NCCL INFO Channel 00 : 166[ca000] -> 165[4b000] via P2P/IPC/read
102: hkn0502:236315:236406 [2] NCCL INFO Channel 01 : 102[ca000] -> 101[4b000] via P2P/IPC/read
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
 94: hkn0428:674575:674691 [2] NCCL INFO Channel 00 : 94[ca000] -> 93[4b000] via P2P/IPC/read
 86: hkn0426:821274:821408 [2] NCCL INFO Channel 00 : 86[ca000] -> 85[4b000] via P2P/IPC/read
170: hkn0523:1555340:1555444 [2] NCCL INFO Channel 00 : 170[ca000] -> 169[4b000] via P2P/IPC/read
142: hkn0512:3051335:3051453 [2] NCCL INFO Channel 01 : 142[ca000] -> 141[4b000] via P2P/IPC/read
 98: hkn0501:1335167:1335267 [2] NCCL INFO Channel 01 : 98[ca000] -> 97[4b000] via P2P/IPC/read
182: hkn0526:1435637:1435754 [2] NCCL INFO Channel 00 : 182[ca000] -> 181[4b000] via P2P/IPC/read
150: hkn0514:2957943:2958073 [2] NCCL INFO Channel 01 : 150[ca000] -> 149[4b000] via P2P/IPC/read
158: hkn0516:2923196:2923320 [2] NCCL INFO Channel 01 : 158[ca000] -> 157[4b000] via P2P/IPC/read
174: hkn0524:1141010:1141129 [2] NCCL INFO Channel 00 : 174[ca000] -> 173[4b000] via P2P/IPC/read
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
 90: hkn0427:1142341:1142458 [2] NCCL INFO Channel 00 : 90[ca000] -> 89[4b000] via P2P/IPC/read
154: hkn0515:2904025:2904145 [2] NCCL INFO Channel 01 : 154[ca000] -> 153[4b000] via P2P/IPC/read
162: hkn0520:2720086:2720209 [2] NCCL INFO Channel 01 : 162[ca000] -> 161[4b000] via P2P/IPC/read
106: hkn0503:2906951:2907055 [2] NCCL INFO Channel 01 : 106[ca000] -> 105[4b000] via P2P/IPC/read
116: hkn0506:845312:845412 [0] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
 86: hkn0426:821274:821408 [2] NCCL INFO Channel 01 : 86[ca000] -> 85[4b000] via P2P/IPC/read
166: hkn0521:1205036:1205135 [2] NCCL INFO Channel 01 : 166[ca000] -> 165[4b000] via P2P/IPC/read
194: hkn0529:1548054:1548165 [2] NCCL INFO Channel 00 : 194[ca000] -> 193[4b000] via P2P/IPC/read
178: hkn0525:994022:994132 [2] NCCL INFO Channel 00 : 178[ca000] -> 177[4b000] via P2P/IPC/read
110: hkn0504:48311:48436 [2] NCCL INFO Channel 00 : 110[ca000] -> 109[4b000] via P2P/IPC/read
186: hkn0527:1356188:1356283 [2] NCCL INFO Channel 00 : 186[ca000] -> 185[4b000] via P2P/IPC/read
170: hkn0523:1555340:1555444 [2] NCCL INFO Channel 01 : 170[ca000] -> 169[4b000] via P2P/IPC/read
 78: hkn0424:2955198:2955298 [2] NCCL INFO Channel 00 : 78[ca000] -> 77[4b000] via P2P/IPC/read
117: hkn0506:845300:845411 [1] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
198: hkn0530:1265343:1265469 [2] NCCL INFO Channel 00 : 198[ca000] -> 197[4b000] via P2P/IPC/read
 94: hkn0428:674575:674691 [2] NCCL INFO Channel 01 : 94[ca000] -> 93[4b000] via P2P/IPC/read
 90: hkn0427:1142341:1142458 [2] NCCL INFO Channel 01 : 90[ca000] -> 89[4b000] via P2P/IPC/read
 70: hkn0422:4160364:4160469 [2] NCCL INFO Channel 00 : 70[ca000] -> 69[4b000] via P2P/IPC/read
182: hkn0526:1435637:1435754 [2] NCCL INFO Channel 01 : 182[ca000] -> 181[4b000] via P2P/IPC/read
 82: hkn0425:2091279:2091402 [2] NCCL INFO Channel 00 : 82[ca000] -> 81[4b000] via P2P/IPC/read
 74: hkn0423:1712179:1712289 [2] NCCL INFO Channel 00 : 74[ca000] -> 73[4b000] via P2P/IPC/read
210: hkn0534:1155637:1155744 [2] NCCL INFO Channel 00 : 210[ca000] -> 209[4b000] via P2P/IPC/read
202: hkn0531:1237910:1238025 [2] NCCL INFO Channel 00 : 202[ca000] -> 201[4b000] via P2P/IPC/read
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
174: hkn0524:1141010:1141129 [2] NCCL INFO Channel 01 : 174[ca000] -> 173[4b000] via P2P/IPC/read
133: hkn0510:2769286:2769390 [1] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
206: hkn0532:932510:932820 [2] NCCL INFO Channel 00 : 206[ca000] -> 205[4b000] via P2P/IPC/read
190: hkn0528:1308903:1309021 [2] NCCL INFO Channel 00 : 190[ca000] -> 189[4b000] via P2P/IPC/read
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
438: hkn0731:1393942:1394083 [2] NCCL INFO Channel 00 : 438[ca000] -> 437[4b000] via P2P/IPC/read
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
230: hkn0604:696451:696579 [2] NCCL INFO Channel 00 : 230[ca000] -> 229[4b000] via P2P/IPC/read
186: hkn0527:1356188:1356283 [2] NCCL INFO Channel 01 : 186[ca000] -> 185[4b000] via P2P/IPC/read
178: hkn0525:994022:994132 [2] NCCL INFO Channel 01 : 178[ca000] -> 177[4b000] via P2P/IPC/read
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
222: hkn0602:3370898:3371093 [2] NCCL INFO Channel 00 : 222[ca000] -> 221[4b000] via P2P/IPC/read
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
 78: hkn0424:2955198:2955298 [2] NCCL INFO Channel 01 : 78[ca000] -> 77[4b000] via P2P/IPC/read
446: hkn0733:1396572:1396700 [2] NCCL INFO Channel 00 : 446[ca000] -> 445[4b000] via P2P/IPC/read
262: hkn0613:909916:910043 [2] NCCL INFO Channel 00 : 262[ca000] -> 261[4b000] via P2P/IPC/read
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
458: hkn0801:2247264:2247382 [2] NCCL INFO Channel 00 : 458[ca000] -> 457[4b000] via P2P/IPC/read
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
198: hkn0530:1265343:1265469 [2] NCCL INFO Channel 01 : 198[ca000] -> 197[4b000] via P2P/IPC/read
194: hkn0529:1548054:1548165 [2] NCCL INFO Channel 01 : 194[ca000] -> 193[4b000] via P2P/IPC/read
254: hkn0611:717063:717166 [2] NCCL INFO Channel 00 : 254[ca000] -> 253[4b000] via P2P/IPC/read
110: hkn0504:48311:48436 [2] NCCL INFO Channel 01 : 110[ca000] -> 109[4b000] via P2P/IPC/read
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
270: hkn0616:412161:412288 [2] NCCL INFO Channel 00 : 270[ca000] -> 269[4b000] via P2P/IPC/read
 70: hkn0422:4160364:4160469 [2] NCCL INFO Channel 01 : 70[ca000] -> 69[4b000] via P2P/IPC/read
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
454: hkn0736:1515545:1515656 [2] NCCL INFO Channel 00 : 454[ca000] -> 453[4b000] via P2P/IPC/read
218: hkn0601:124988:125082 [2] NCCL INFO Channel 00 : 218[ca000] -> 217[4b000] via P2P/IPC/read
 82: hkn0425:2091279:2091402 [2] NCCL INFO Channel 01 : 82[ca000] -> 81[4b000] via P2P/IPC/read
246: hkn0608:492947:493073 [2] NCCL INFO Channel 00 : 246[ca000] -> 245[4b000] via P2P/IPC/read
214: hkn0535:2406234:2406334 [2] NCCL INFO Channel 00 : 214[ca000] -> 213[4b000] via P2P/IPC/read
202: hkn0531:1237910:1238025 [2] NCCL INFO Channel 01 : 202[ca000] -> 201[4b000] via P2P/IPC/read
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
462: hkn0802:1207559:1207696 [2] NCCL INFO Channel 00 : 462[ca000] -> 461[4b000] via P2P/IPC/read
176: hkn0525:994034:994135 [0] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
258: hkn0612:924199:924320 [2] NCCL INFO Channel 00 : 258[ca000] -> 257[4b000] via P2P/IPC/read
442: hkn0732:1218881:1219002 [2] NCCL INFO Channel 00 : 442[ca000] -> 441[4b000] via P2P/IPC/read
 66: hkn0421:2189220:2189406 [2] NCCL INFO Channel 00 : 66[ca000] -> 65[4b000] via P2P/IPC/read
 26: hkn0410:1166945:1167042 [2] NCCL INFO Channel 00 : 26[ca000] -> 25[4b000] via P2P/IPC/read
206: hkn0532:932510:932820 [2] NCCL INFO Channel 01 : 206[ca000] -> 205[4b000] via P2P/IPC/read
438: hkn0731:1393942:1394083 [2] NCCL INFO Channel 01 : 438[ca000] -> 437[4b000] via P2P/IPC/read
226: hkn0603:1420466:1420571 [2] NCCL INFO Channel 00 : 226[ca000] -> 225[4b000] via P2P/IPC/read
478: hkn0806:1061550:1061649 [2] NCCL INFO Channel 00 : 478[ca000] -> 477[4b000] via P2P/IPC/read
422: hkn0726:1555349:1555447 [2] NCCL INFO Channel 00 : 422[ca000] -> 421[4b000] via P2P/IPC/read
234: hkn0605:719352:719473 [2] NCCL INFO Channel 00 : 234[ca000] -> 233[4b000] via P2P/IPC/read
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
 74: hkn0423:1712179:1712289 [2] NCCL INFO Channel 01 : 74[ca000] -> 73[4b000] via P2P/IPC/read
470: hkn0804:1212841:1212966 [2] NCCL INFO Channel 00 : 470[ca000] -> 469[4b000] via P2P/IPC/read
250: hkn0609:718028:718154 [2] NCCL INFO Channel 00 : 250[ca000] -> 249[4b000] via P2P/IPC/read
190: hkn0528:1308903:1309021 [2] NCCL INFO Channel 01 : 190[ca000] -> 189[4b000] via P2P/IPC/read
482: hkn0807:1026293:1026403 [2] NCCL INFO Channel 00 : 482[ca000] -> 481[4b000] via P2P/IPC/read
210: hkn0534:1155637:1155744 [2] NCCL INFO Channel 01 : 210[ca000] -> 209[4b000] via P2P/IPC/read
238: hkn0606:2379355:2379460 [2] NCCL INFO Channel 00 : 238[ca000] -> 237[4b000] via P2P/IPC/read
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
108: hkn0504:48339:48431 [0] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
466: hkn0803:883795:883893 [2] NCCL INFO Channel 00 : 466[ca000] -> 465[4b000] via P2P/IPC/read
266: hkn0615:421558:421661 [2] NCCL INFO Channel 00 : 266[ca000] -> 265[4b000] via P2P/IPC/read
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
410: hkn0723:215325:215496 [2] NCCL INFO Channel 00 : 410[ca000] -> 409[4b000] via P2P/IPC/read
230: hkn0604:696451:696579 [2] NCCL INFO Channel 01 : 230[ca000] -> 229[4b000] via P2P/IPC/read
418: hkn0725:3119184:3119279 [2] NCCL INFO Channel 00 : 418[ca000] -> 417[4b000] via P2P/IPC/read
278: hkn0621:1998838:1998943 [2] NCCL INFO Channel 00 : 278[ca000] -> 277[4b000] via P2P/IPC/read
458: hkn0801:2247264:2247382 [2] NCCL INFO Channel 01 : 458[ca000] -> 457[4b000] via P2P/IPC/read
290: hkn0624:1780132:1780286 [2] NCCL INFO Channel 00 : 290[ca000] -> 289[4b000] via P2P/IPC/read
218: hkn0601:124988:125082 [2] NCCL INFO Channel 01 : 218[ca000] -> 217[4b000] via P2P/IPC/read
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
254: hkn0611:717063:717166 [2] NCCL INFO Channel 01 : 254[ca000] -> 253[4b000] via P2P/IPC/read
109: hkn0504:48319:48430 [1] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
270: hkn0616:412161:412288 [2] NCCL INFO Channel 01 : 270[ca000] -> 269[4b000] via P2P/IPC/read
474: hkn0805:1119317:1119439 [2] NCCL INFO Channel 00 : 474[ca000] -> 473[4b000] via P2P/IPC/read
454: hkn0736:1515545:1515656 [2] NCCL INFO Channel 01 : 454[ca000] -> 453[4b000] via P2P/IPC/read
149: hkn0514:2957959:2958071 [1] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
434: hkn0730:1408975:1409075 [2] NCCL INFO Channel 00 : 434[ca000] -> 433[4b000] via P2P/IPC/read
394: hkn0718:3924274:3924372 [2] NCCL INFO Channel 00 : 394[ca000] -> 393[4b000] via P2P/IPC/read
 22: hkn0409:2592882:2592991 [2] NCCL INFO Channel 00 : 22[ca000] -> 21[4b000] via P2P/IPC/read
462: hkn0802:1207559:1207696 [2] NCCL INFO Channel 01 : 462[ca000] -> 461[4b000] via P2P/IPC/read
414: hkn0724:1723187:1723325 [2] NCCL INFO Channel 00 : 414[ca000] -> 413[4b000] via P2P/IPC/read
274: hkn0617:2301935:2302046 [2] NCCL INFO Channel 00 : 274[ca000] -> 273[4b000] via P2P/IPC/read
 30: hkn0411:2323089:2323199 [2] NCCL INFO Channel 00 : 30[ca000] -> 29[4b000] via P2P/IPC/read
242: hkn0607:911587:911714 [2] NCCL INFO Channel 00 : 242[ca000] -> 241[4b000] via P2P/IPC/read
 62: hkn0420:3217428:3217558 [2] NCCL INFO Channel 00 : 62[ca000] -> 61[4b000] via P2P/IPC/read
262: hkn0613:909916:910043 [2] NCCL INFO Channel 01 : 262[ca000] -> 261[4b000] via P2P/IPC/read
258: hkn0612:924199:924320 [2] NCCL INFO Channel 01 : 258[ca000] -> 257[4b000] via P2P/IPC/read
490: hkn0809:944543:944669 [2] NCCL INFO Channel 00 : 490[ca000] -> 489[4b000] via P2P/IPC/read
442: hkn0732:1218881:1219002 [2] NCCL INFO Channel 01 : 442[ca000] -> 441[4b000] via P2P/IPC/read
222: hkn0602:3370898:3371093 [2] NCCL INFO Channel 01 : 222[ca000] -> 221[4b000] via P2P/IPC/read
486: hkn0808:977893:978014 [2] NCCL INFO Channel 00 : 486[ca000] -> 485[4b000] via P2P/IPC/read
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
 58: hkn0419:1551505:1551604 [2] NCCL INFO Channel 00 : 58[ca000] -> 57[4b000] via P2P/IPC/read
 66: hkn0421:2189220:2189406 [2] NCCL INFO Channel 01 : 66[ca000] -> 65[4b000] via P2P/IPC/read
 54: hkn0418:1876396:1876507 [2] NCCL INFO Channel 00 : 54[ca000] -> 53[4b000] via P2P/IPC/read
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
 26: hkn0410:1166945:1167042 [2] NCCL INFO Channel 01 : 26[ca000] -> 25[4b000] via P2P/IPC/read
406: hkn0721:2306498:2306623 [2] NCCL INFO Channel 00 : 406[ca000] -> 405[4b000] via P2P/IPC/read
246: hkn0608:492947:493073 [2] NCCL INFO Channel 01 : 246[ca000] -> 245[4b000] via P2P/IPC/read
214: hkn0535:2406234:2406334 [2] NCCL INFO Channel 01 : 214[ca000] -> 213[4b000] via P2P/IPC/read
 34: hkn0412:2269636:2269732 [2] NCCL INFO Channel 00 : 34[ca000] -> 33[4b000] via P2P/IPC/read
226: hkn0603:1420466:1420571 [2] NCCL INFO Channel 01 : 226[ca000] -> 225[4b000] via P2P/IPC/read
165: hkn0521:1205024:1205132 [1] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
422: hkn0726:1555349:1555447 [2] NCCL INFO Channel 01 : 422[ca000] -> 421[4b000] via P2P/IPC/read
234: hkn0605:719352:719473 [2] NCCL INFO Channel 01 : 234[ca000] -> 233[4b000] via P2P/IPC/read
 46: hkn0415:2503643:2503758 [2] NCCL INFO Channel 00 : 46[ca000] -> 45[4b000] via P2P/IPC/read
294: hkn0626:1305634:1305784 [2] NCCL INFO Channel 00 : 294[ca000] -> 293[4b000] via P2P/IPC/read
470: hkn0804:1212841:1212966 [2] NCCL INFO Channel 01 : 470[ca000] -> 469[4b000] via P2P/IPC/read
 38: hkn0413:2373948:2374057 [2] NCCL INFO Channel 00 : 38[ca000] -> 37[4b000] via P2P/IPC/read
450: hkn0734:1163781:1163870 [2] NCCL INFO Channel 00 : 450[ca000] -> 449[4b000] via P2P/IPC/read
100: hkn0502:236295:236412 [0] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
482: hkn0807:1026293:1026403 [2] NCCL INFO Channel 01 : 482[ca000] -> 481[4b000] via P2P/IPC/read
286: hkn0623:1879995:1880114 [2] NCCL INFO Channel 00 : 286[ca000] -> 285[4b000] via P2P/IPC/read
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
390: hkn0717:1487:1589 [2] NCCL INFO Channel 00 : 390[ca000] -> 389[4b000] via P2P/IPC/read
282: hkn0622:2027744:2027863 [2] NCCL INFO Channel 00 : 282[ca000] -> 281[4b000] via P2P/IPC/read
418: hkn0725:3119184:3119279 [2] NCCL INFO Channel 01 : 418[ca000] -> 417[4b000] via P2P/IPC/read
466: hkn0803:883795:883893 [2] NCCL INFO Channel 01 : 466[ca000] -> 465[4b000] via P2P/IPC/read
278: hkn0621:1998838:1998943 [2] NCCL INFO Channel 01 : 278[ca000] -> 277[4b000] via P2P/IPC/read
101: hkn0502:236287:236411 [1] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
 50: hkn0417:2274860:2274988 [2] NCCL INFO Channel 00 : 50[ca000] -> 49[4b000] via P2P/IPC/read
238: hkn0606:2379355:2379460 [2] NCCL INFO Channel 01 : 238[ca000] -> 237[4b000] via P2P/IPC/read
510: hkn0816:382843:382953 [2] NCCL INFO Channel 00 : 510[ca000] -> 509[4b000] via P2P/IPC/read
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
266: hkn0615:421558:421661 [2] NCCL INFO Channel 01 : 266[ca000] -> 265[4b000] via P2P/IPC/read
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
374: hkn0713:477468:477571 [2] NCCL INFO Channel 00 : 374[ca000] -> 373[4b000] via P2P/IPC/read
 22: hkn0409:2592882:2592991 [2] NCCL INFO Channel 01 : 22[ca000] -> 21[4b000] via P2P/IPC/read
242: hkn0607:911587:911714 [2] NCCL INFO Channel 01 : 242[ca000] -> 241[4b000] via P2P/IPC/read
274: hkn0617:2301935:2302046 [2] NCCL INFO Channel 01 : 274[ca000] -> 273[4b000] via P2P/IPC/read
382: hkn0715:409118:409228 [2] NCCL INFO Channel 00 : 382[ca000] -> 381[4b000] via P2P/IPC/read
446: hkn0733:1396572:1396700 [2] NCCL INFO Channel 01 : 446[ca000] -> 445[4b000] via P2P/IPC/read
426: hkn0727:1353002:1353113 [2] NCCL INFO Channel 00 : 426[ca000] -> 425[4b000] via P2P/IPC/read
474: hkn0805:1119317:1119439 [2] NCCL INFO Channel 01 : 474[ca000] -> 473[4b000] via P2P/IPC/read
378: hkn0714:439245:439363 [2] NCCL INFO Channel 00 : 378[ca000] -> 377[4b000] via P2P/IPC/read
 42: hkn0414:1988904:1989011 [2] NCCL INFO Channel 00 : 42[ca000] -> 41[4b000] via P2P/IPC/read
334: hkn0636:1661541:1661648 [2] NCCL INFO Channel 00 : 334[ca000] -> 333[4b000] via P2P/IPC/read
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
402: hkn0720:14310:14477 [2] NCCL INFO Channel 00 : 402[ca000] -> 401[4b000] via P2P/IPC/read
414: hkn0724:1723187:1723325 [2] NCCL INFO Channel 01 : 414[ca000] -> 413[4b000] via P2P/IPC/read
306: hkn0629:1599284:1599393 [2] NCCL INFO Channel 00 : 306[ca000] -> 305[4b000] via P2P/IPC/read
330: hkn0635:1232802:1232909 [2] NCCL INFO Channel 00 : 330[ca000] -> 329[4b000] via P2P/IPC/read
  2: hkn0403:1776577:1776939 [2] NCCL INFO Channel 00 : 2[ca000] -> 1[4b000] via P2P/IPC/read
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
 62: hkn0420:3217428:3217558 [2] NCCL INFO Channel 01 : 62[ca000] -> 61[4b000] via P2P/IPC/read
486: hkn0808:977893:978014 [2] NCCL INFO Channel 01 : 486[ca000] -> 485[4b000] via P2P/IPC/read
370: hkn0712:302281:302408 [2] NCCL INFO Channel 00 : 370[ca000] -> 369[4b000] via P2P/IPC/read
 54: hkn0418:1876396:1876507 [2] NCCL INFO Channel 01 : 54[ca000] -> 53[4b000] via P2P/IPC/read
406: hkn0721:2306498:2306623 [2] NCCL INFO Channel 01 : 406[ca000] -> 405[4b000] via P2P/IPC/read
290: hkn0624:1780132:1780286 [2] NCCL INFO Channel 01 : 290[ca000] -> 289[4b000] via P2P/IPC/read
 58: hkn0419:1551505:1551604 [2] NCCL INFO Channel 01 : 58[ca000] -> 57[4b000] via P2P/IPC/read
 30: hkn0411:2323089:2323199 [2] NCCL INFO Channel 01 : 30[ca000] -> 29[4b000] via P2P/IPC/read
 34: hkn0412:2269636:2269732 [2] NCCL INFO Channel 01 : 34[ca000] -> 33[4b000] via P2P/IPC/read
342: hkn0704:799243:799339 [2] NCCL INFO Channel 00 : 342[ca000] -> 341[4b000] via P2P/IPC/read
346: hkn0705:790431:790545 [2] NCCL INFO Channel 00 : 346[ca000] -> 345[4b000] via P2P/IPC/read
494: hkn0810:946736:946861 [2] NCCL INFO Channel 00 : 494[ca000] -> 493[4b000] via P2P/IPC/read
302: hkn0628:679139:679252 [2] NCCL INFO Channel 00 : 302[ca000] -> 301[4b000] via P2P/IPC/read
181: hkn0526:1435629:1435751 [1] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
 46: hkn0415:2503643:2503758 [2] NCCL INFO Channel 01 : 46[ca000] -> 45[4b000] via P2P/IPC/read
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
 38: hkn0413:2373948:2374057 [2] NCCL INFO Channel 01 : 38[ca000] -> 37[4b000] via P2P/IPC/read
390: hkn0717:1487:1589 [2] NCCL INFO Channel 01 : 390[ca000] -> 389[4b000] via P2P/IPC/read
394: hkn0718:3924274:3924372 [2] NCCL INFO Channel 01 : 394[ca000] -> 393[4b000] via P2P/IPC/read
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
 14: hkn0407:1823492:1823615 [2] NCCL INFO Channel 00 : 14[ca000] -> 13[4b000] via P2P/IPC/read
326: hkn0634:1528060:1528187 [2] NCCL INFO Channel 00 : 326[ca000] -> 325[4b000] via P2P/IPC/read
286: hkn0623:1879995:1880114 [2] NCCL INFO Channel 01 : 286[ca000] -> 285[4b000] via P2P/IPC/read
314: hkn0631:1029016:1029137 [2] NCCL INFO Channel 00 : 314[ca000] -> 313[4b000] via P2P/IPC/read
366: hkn0711:591185:591287 [2] NCCL INFO Channel 00 : 366[ca000] -> 365[4b000] via P2P/IPC/read
322: hkn0633:1533554:1533664 [2] NCCL INFO Channel 00 : 322[ca000] -> 321[4b000] via P2P/IPC/read
 85: hkn0426:821286:821409 [1] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
498: hkn0812:701043:701153 [2] NCCL INFO Channel 00 : 498[ca000] -> 497[4b000] via P2P/IPC/read
490: hkn0809:944543:944669 [2] NCCL INFO Channel 01 : 490[ca000] -> 489[4b000] via P2P/IPC/read
478: hkn0806:1061550:1061649 [2] NCCL INFO Channel 01 : 478[ca000] -> 477[4b000] via P2P/IPC/read
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
310: hkn0630:1605686:1605806 [2] NCCL INFO Channel 00 : 310[ca000] -> 309[4b000] via P2P/IPC/read
434: hkn0730:1408975:1409075 [2] NCCL INFO Channel 01 : 434[ca000] -> 433[4b000] via P2P/IPC/read
  6: hkn0404:1346665:1346763 [2] NCCL INFO Channel 00 : 6[ca000] -> 5[4b000] via P2P/IPC/read
502: hkn0814:683050:683175 [2] NCCL INFO Channel 00 : 502[ca000] -> 501[4b000] via P2P/IPC/read
250: hkn0609:718028:718154 [2] NCCL INFO Channel 01 : 250[ca000] -> 249[4b000] via P2P/IPC/read
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
 10: hkn0405:3214170:3214279 [2] NCCL INFO Channel 00 : 10[ca000] -> 9[4b000] via P2P/IPC/read
506: hkn0815:402341:402450 [2] NCCL INFO Channel 00 : 506[ca000] -> 505[4b000] via P2P/IPC/read
229: hkn0604:696459:696573 [1] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
410: hkn0723:215325:215496 [2] NCCL INFO Channel 01 : 410[ca000] -> 409[4b000] via P2P/IPC/read
402: hkn0720:14310:14477 [2] NCCL INFO Channel 01 : 402[ca000] -> 401[4b000] via P2P/IPC/read
334: hkn0636:1661541:1661648 [2] NCCL INFO Channel 01 : 334[ca000] -> 333[4b000] via P2P/IPC/read
213: hkn0535:2406206:2406337 [1] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
378: hkn0714:439245:439363 [2] NCCL INFO Channel 01 : 378[ca000] -> 377[4b000] via P2P/IPC/read
398: hkn0719:1312991:1313080 [2] NCCL INFO Channel 00 : 398[ca000] -> 397[4b000] via P2P/IPC/read
330: hkn0635:1232802:1232909 [2] NCCL INFO Channel 01 : 330[ca000] -> 329[4b000] via P2P/IPC/read
358: hkn0708:420458:420568 [2] NCCL INFO Channel 00 : 358[ca000] -> 357[4b000] via P2P/IPC/read
 50: hkn0417:2274860:2274988 [2] NCCL INFO Channel 01 : 50[ca000] -> 49[4b000] via P2P/IPC/read
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
386: hkn0716:115704:115853 [2] NCCL INFO Channel 00 : 386[ca000] -> 385[4b000] via P2P/IPC/read
282: hkn0622:2027744:2027863 [2] NCCL INFO Channel 01 : 282[ca000] -> 281[4b000] via P2P/IPC/read
382: hkn0715:409118:409228 [2] NCCL INFO Channel 01 : 382[ca000] -> 381[4b000] via P2P/IPC/read
374: hkn0713:477468:477571 [2] NCCL INFO Channel 01 : 374[ca000] -> 373[4b000] via P2P/IPC/read
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
318: hkn0632:1765851:1765965 [2] NCCL INFO Channel 00 : 318[ca000] -> 317[4b000] via P2P/IPC/read
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
370: hkn0712:302281:302408 [2] NCCL INFO Channel 01 : 370[ca000] -> 369[4b000] via P2P/IPC/read
298: hkn0627:1795166:1795271 [2] NCCL INFO Channel 00 : 298[ca000] -> 297[4b000] via P2P/IPC/read
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
 42: hkn0414:1988904:1989011 [2] NCCL INFO Channel 01 : 42[ca000] -> 41[4b000] via P2P/IPC/read
510: hkn0816:382843:382953 [2] NCCL INFO Channel 01 : 510[ca000] -> 509[4b000] via P2P/IPC/read
342: hkn0704:799243:799339 [2] NCCL INFO Channel 01 : 342[ca000] -> 341[4b000] via P2P/IPC/read
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
362: hkn0710:362764:362885 [2] NCCL INFO Channel 00 : 362[ca000] -> 361[4b000] via P2P/IPC/read
306: hkn0629:1599284:1599393 [2] NCCL INFO Channel 01 : 306[ca000] -> 305[4b000] via P2P/IPC/read
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
494: hkn0810:946736:946861 [2] NCCL INFO Channel 01 : 494[ca000] -> 493[4b000] via P2P/IPC/read
264: hkn0615:421550:421660 [0] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
354: hkn0707:4027145:4027255 [2] NCCL INFO Channel 00 : 354[ca000] -> 353[4b000] via P2P/IPC/read
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
294: hkn0626:1305634:1305784 [2] NCCL INFO Channel 01 : 294[ca000] -> 293[4b000] via P2P/IPC/read
 14: hkn0407:1823492:1823615 [2] NCCL INFO Channel 01 : 14[ca000] -> 13[4b000] via P2P/IPC/read
498: hkn0812:701043:701153 [2] NCCL INFO Channel 01 : 498[ca000] -> 497[4b000] via P2P/IPC/read
450: hkn0734:1163781:1163870 [2] NCCL INFO Channel 01 : 450[ca000] -> 449[4b000] via P2P/IPC/read
  2: hkn0403:1776577:1776939 [2] NCCL INFO Channel 01 : 2[ca000] -> 1[4b000] via P2P/IPC/read
322: hkn0633:1533554:1533664 [2] NCCL INFO Channel 01 : 322[ca000] -> 321[4b000] via P2P/IPC/read
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
426: hkn0727:1353002:1353113 [2] NCCL INFO Channel 01 : 426[ca000] -> 425[4b000] via P2P/IPC/read
430: hkn0728:1331266:1331371 [2] NCCL INFO Channel 00 : 430[ca000] -> 429[4b000] via P2P/IPC/read
502: hkn0814:683050:683175 [2] NCCL INFO Channel 01 : 502[ca000] -> 501[4b000] via P2P/IPC/read
350: hkn0706:759494:759603 [2] NCCL INFO Channel 00 : 350[ca000] -> 349[4b000] via P2P/IPC/read
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
  6: hkn0404:1346665:1346763 [2] NCCL INFO Channel 01 : 6[ca000] -> 5[4b000] via P2P/IPC/read
310: hkn0630:1605686:1605806 [2] NCCL INFO Channel 01 : 310[ca000] -> 309[4b000] via P2P/IPC/read
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
 10: hkn0405:3214170:3214279 [2] NCCL INFO Channel 01 : 10[ca000] -> 9[4b000] via P2P/IPC/read
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
260: hkn0613:909924:910036 [0] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
302: hkn0628:679139:679252 [2] NCCL INFO Channel 01 : 302[ca000] -> 301[4b000] via P2P/IPC/read
 69: hkn0422:4160356:4160471 [1] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
338: hkn0703:748322:748407 [2] NCCL INFO Channel 00 : 338[ca000] -> 337[4b000] via P2P/IPC/read
346: hkn0705:790431:790545 [2] NCCL INFO Channel 01 : 346[ca000] -> 345[4b000] via P2P/IPC/read
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
197: hkn0530:1265371:1265467 [1] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
326: hkn0634:1528060:1528187 [2] NCCL INFO Channel 01 : 326[ca000] -> 325[4b000] via P2P/IPC/read
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
366: hkn0711:591185:591287 [2] NCCL INFO Channel 01 : 366[ca000] -> 365[4b000] via P2P/IPC/read
358: hkn0708:420458:420568 [2] NCCL INFO Channel 01 : 358[ca000] -> 357[4b000] via P2P/IPC/read
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
318: hkn0632:1765851:1765965 [2] NCCL INFO Channel 01 : 318[ca000] -> 317[4b000] via P2P/IPC/read
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
506: hkn0815:402341:402450 [2] NCCL INFO Channel 01 : 506[ca000] -> 505[4b000] via P2P/IPC/read
245: hkn0608:492963:493070 [1] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
362: hkn0710:362764:362885 [2] NCCL INFO Channel 01 : 362[ca000] -> 361[4b000] via P2P/IPC/read
244: hkn0608:492975:493069 [0] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
298: hkn0627:1795166:1795271 [2] NCCL INFO Channel 01 : 298[ca000] -> 297[4b000] via P2P/IPC/read
354: hkn0707:4027145:4027255 [2] NCCL INFO Channel 01 : 354[ca000] -> 353[4b000] via P2P/IPC/read
437: hkn0731:1393941:1394086 [1] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
249: hkn0609:718036:718147 [1] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
409: hkn0723:215333:215489 [1] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
430: hkn0728:1331266:1331371 [2] NCCL INFO Channel 01 : 430[ca000] -> 429[4b000] via P2P/IPC/read
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
248: hkn0609:718056:718153 [0] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
261: hkn0613:909944:910037 [1] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
488: hkn0809:944559:944660 [0] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
338: hkn0703:748322:748407 [2] NCCL INFO Channel 01 : 338[ca000] -> 337[4b000] via P2P/IPC/read
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
314: hkn0631:1029016:1029137 [2] NCCL INFO Channel 01 : 314[ca000] -> 313[4b000] via P2P/IPC/read
398: hkn0719:1312991:1313080 [2] NCCL INFO Channel 01 : 398[ca000] -> 397[4b000] via P2P/IPC/read
386: hkn0716:115704:115853 [2] NCCL INFO Channel 01 : 386[ca000] -> 385[4b000] via P2P/IPC/read
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
233: hkn0605:719360:719472 [1] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
265: hkn0615:421570:421665 [1] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
257: hkn0612:924227:924322 [1] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
204: hkn0532:932494:932817 [0] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
232: hkn0605:719349:719471 [0] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
 21: hkn0409:2592894:2592992 [1] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
205: hkn0532:932522:932818 [1] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
256: hkn0612:924207:924324 [0] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
453: hkn0736:1515557:1515653 [1] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
350: hkn0706:759494:759603 [2] NCCL INFO Channel 01 : 350[ca000] -> 349[4b000] via P2P/IPC/read
421: hkn0726:1555337:1555444 [1] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
253: hkn0611:717051:717160 [1] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
293: hkn0626:1305645:1305779 [1] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
509: hkn0816:382855:382951 [1] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
469: hkn0804:1212849:1212967 [1] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
489: hkn0809:944571:944666 [1] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
465: hkn0803:883787:883894 [1] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
344: hkn0705:790415:790543 [0] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
177: hkn0525:994014:994129 [1] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
277: hkn0621:1998849:1998946 [1] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
301: hkn0628:679147:679253 [1] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
464: hkn0803:883779:883891 [0] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 00 : 128[31000] -> 131[e3000] via P2P/IPC/read
268: hkn0616:412169:412281 [0] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
405: hkn0721:2306514:2306619 [1] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
216: hkn0601:124960:125086 [0] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
349: hkn0706:759478:759608 [1] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
269: hkn0616:412177:412290 [1] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
372: hkn0713:477480:477575 [0] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
508: hkn0816:382834:382958 [0] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
 18: hkn0408:2898057:2898153 [2] NCCL INFO Channel 00 : 18[ca000] -> 17[4b000] via P2P/IPC/read
369: hkn0712:302289:302403 [1] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
217: hkn0601:124968:125085 [1] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
365: hkn0711:591174:591286 [1] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
377: hkn0714:439253:439365 [1] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
252: hkn0611:717035:717164 [0] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
373: hkn0713:477452:477574 [1] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
 53: hkn0418:1876404:1876515 [1] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
368: hkn0712:302297:302400 [0] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
  1: hkn0403:1776565:1776936 [1] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
381: hkn0715:409138:409236 [1] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
325: hkn0634:1528068:1528186 [1] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
300: hkn0628:679159:679255 [0] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
240: hkn0607:911595:911709 [0] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
492: hkn0810:946764:946863 [0] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
505: hkn0815:402333:402447 [1] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
388: hkn0717:1467:1586 [0] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 01 : 128[31000] -> 131[e3000] via P2P/IPC/read
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
385: hkn0716:115707:115856 [1] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
493: hkn0810:946752:946862 [1] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
484: hkn0808:977921:978021 [0] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
364: hkn0711:591166:591281 [0] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
389: hkn0717:1475:1580 [1] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
485: hkn0808:977901:978022 [1] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
384: hkn0716:115715:115850 [0] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 00 : 136[31000] -> 139[e3000] via P2P/IPC/read
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
496: hkn0812:701027:701151 [0] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
 18: hkn0408:2898057:2898153 [2] NCCL INFO Channel 01 : 18[ca000] -> 17[4b000] via P2P/IPC/read
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
360: hkn0710:362792:362882 [0] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
497: hkn0812:701035:701150 [1] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
117: hkn0506:845300:845411 [1] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
 37: hkn0413:2373940:2374062 [1] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
340: hkn0704:799215:799344 [0] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
309: hkn0630:1605694:1605798 [1] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
341: hkn0704:799223:799342 [1] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
500: hkn0814:683023:683174 [0] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 00 : 116[31000] -> 119[e3000] via P2P/IPC/read
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
501: hkn0814:683039:683170 [1] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
133: hkn0510:2769286:2769390 [1] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 01 : 136[31000] -> 139[e3000] via P2P/IPC/read
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
357: hkn0708:420450:420563 [1] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
176: hkn0525:994034:994135 [0] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
356: hkn0708:420442:420567 [0] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 00 : 120[31000] -> 123[e3000] via P2P/IPC/read
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
  5: hkn0404:1346653:1346760 [1] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
400: hkn0720:14302:14479 [0] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 01 : 116[31000] -> 119[e3000] via P2P/IPC/read
401: hkn0720:14318:14478 [1] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
337: hkn0703:748303:748410 [1] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 00 : 148[31000] -> 151[e3000] via P2P/IPC/read
241: hkn0607:911603:911711 [1] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 00 : 140[31000] -> 143[e3000] via P2P/IPC/read
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 01 : 120[31000] -> 123[e3000] via P2P/IPC/read
149: hkn0514:2957959:2958071 [1] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 00 : 164[31000] -> 167[e3000] via P2P/IPC/read
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 00 : 168[31000] -> 171[e3000] via P2P/IPC/read
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 00 : 132[31000] -> 135[e3000] via P2P/IPC/read
176: hkn0525:994034:994135 [0] NCCL INFO Channel 00 : 176[31000] -> 179[e3000] via P2P/IPC/read
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 00 : 104[31000] -> 107[e3000] via P2P/IPC/read
108: hkn0504:48339:48431 [0] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
345: hkn0705:790443:790544 [1] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
109: hkn0504:48319:48430 [1] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 01 : 148[31000] -> 151[e3000] via P2P/IPC/read
165: hkn0521:1205024:1205132 [1] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 01 : 140[31000] -> 143[e3000] via P2P/IPC/read
376: hkn0714:439237:439359 [0] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 01 : 164[31000] -> 167[e3000] via P2P/IPC/read
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 00 : 96[31000] -> 99[e3000] via P2P/IPC/read
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 01 : 132[31000] -> 135[e3000] via P2P/IPC/read
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 01 : 168[31000] -> 171[e3000] via P2P/IPC/read
176: hkn0525:994034:994135 [0] NCCL INFO Channel 01 : 176[31000] -> 179[e3000] via P2P/IPC/read
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
504: hkn0815:402353:402445 [0] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
100: hkn0502:236295:236412 [0] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 01 : 104[31000] -> 107[e3000] via P2P/IPC/read
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 00 : 112[31000] -> 115[e3000] via P2P/IPC/read
101: hkn0502:236287:236411 [1] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 00 : 160[31000] -> 163[e3000] via P2P/IPC/read
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 00 : 152[31000] -> 155[e3000] via P2P/IPC/read
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 00 : 92[31000] -> 95[e3000] via P2P/IPC/read
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 00 : 180[31000] -> 183[e3000] via P2P/IPC/read
108: hkn0504:48339:48431 [0] NCCL INFO Channel 00 : 108[31000] -> 111[e3000] via P2P/IPC/read
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
181: hkn0526:1435629:1435751 [1] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
213: hkn0535:2406206:2406337 [1] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
229: hkn0604:696459:696573 [1] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
361: hkn0710:362772:362881 [1] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 01 : 96[31000] -> 99[e3000] via P2P/IPC/read
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
 85: hkn0426:821286:821409 [1] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
264: hkn0615:421550:421660 [0] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 01 : 112[31000] -> 115[e3000] via P2P/IPC/read
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 01 : 160[31000] -> 163[e3000] via P2P/IPC/read
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 00 : 188[31000] -> 191[e3000] via P2P/IPC/read
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 01 : 152[31000] -> 155[e3000] via P2P/IPC/read
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
100: hkn0502:236295:236412 [0] NCCL INFO Channel 00 : 100[31000] -> 103[e3000] via P2P/IPC/read
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 01 : 92[31000] -> 95[e3000] via P2P/IPC/read
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 01 : 180[31000] -> 183[e3000] via P2P/IPC/read
108: hkn0504:48339:48431 [0] NCCL INFO Channel 01 : 108[31000] -> 111[e3000] via P2P/IPC/read
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 00 : 156[31000] -> 159[e3000] via P2P/IPC/read
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
260: hkn0613:909924:910036 [0] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 00 : 208[31000] -> 211[e3000] via P2P/IPC/read
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 00 : 472[31000] -> 475[e3000] via P2P/IPC/read
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 00 : 172[31000] -> 175[e3000] via P2P/IPC/read
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 01 : 188[31000] -> 191[e3000] via P2P/IPC/read
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
 69: hkn0422:4160356:4160471 [1] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
264: hkn0615:421550:421660 [0] NCCL INFO Channel 00 : 264[31000] -> 267[e3000] via P2P/IPC/read
100: hkn0502:236295:236412 [0] NCCL INFO Channel 01 : 100[31000] -> 103[e3000] via P2P/IPC/read
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 00 : 192[31000] -> 195[e3000] via P2P/IPC/read
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 00 : 84[31000] -> 87[e3000] via P2P/IPC/read
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 01 : 156[31000] -> 159[e3000] via P2P/IPC/read
197: hkn0530:1265371:1265467 [1] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 00 : 72[31000] -> 75[e3000] via P2P/IPC/read
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
245: hkn0608:492963:493070 [1] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
437: hkn0731:1393941:1394086 [1] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
488: hkn0809:944559:944660 [0] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
409: hkn0723:215333:215489 [1] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
244: hkn0608:492975:493069 [0] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 01 : 208[31000] -> 211[e3000] via P2P/IPC/read
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 00 : 88[31000] -> 91[e3000] via P2P/IPC/read
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
131: hkn0509:3131644:3131750 [3] NCCL INFO Channel 00 : 131[e3000] -> 130[ca000] via P2P/IPC/read
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 01 : 472[31000] -> 475[e3000] via P2P/IPC/read
260: hkn0613:909924:910036 [0] NCCL INFO Channel 00 : 260[31000] -> 263[e3000] via P2P/IPC/read
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 00 : 40[31000] -> 43[e3000] via P2P/IPC/read
139: hkn0511:3073664:3073769 [3] NCCL INFO Channel 00 : 139[e3000] -> 138[ca000] via P2P/IPC/read
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
265: hkn0615:421570:421665 [1] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 00 : 288[31000] -> 291[e3000] via P2P/IPC/read
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 01 : 172[31000] -> 175[e3000] via P2P/IPC/read
249: hkn0609:718036:718147 [1] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO Channel 00 : 228[31000] -> 231[e3000] via P2P/IPC/read
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 00 : 448[31000] -> 451[e3000] via P2P/IPC/read
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 00 : 444[31000] -> 447[e3000] via P2P/IPC/read
248: hkn0609:718056:718153 [0] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
264: hkn0615:421550:421660 [0] NCCL INFO Channel 01 : 264[31000] -> 267[e3000] via P2P/IPC/read
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 01 : 192[31000] -> 195[e3000] via P2P/IPC/read
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 00 : 76[31000] -> 79[e3000] via P2P/IPC/read
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 01 : 84[31000] -> 87[e3000] via P2P/IPC/read
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
135: hkn0510:2769298:2769389 [3] NCCL INFO Channel 00 : 135[e3000] -> 134[ca000] via P2P/IPC/read
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
 21: hkn0409:2592894:2592992 [1] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 00 : 220[31000] -> 223[e3000] via P2P/IPC/read
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 01 : 72[31000] -> 75[e3000] via P2P/IPC/read
253: hkn0611:717051:717160 [1] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
233: hkn0605:719360:719472 [1] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 00 : 224[31000] -> 227[e3000] via P2P/IPC/read
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
453: hkn0736:1515557:1515653 [1] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 00 : 68[31000] -> 71[e3000] via P2P/IPC/read
344: hkn0705:790415:790543 [0] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
131: hkn0509:3131644:3131750 [3] NCCL INFO Channel 01 : 131[e3000] -> 130[ca000] via P2P/IPC/read
119: hkn0506:845284:845410 [3] NCCL INFO Channel 00 : 119[e3000] -> 118[ca000] via P2P/IPC/read
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
205: hkn0532:932522:932818 [1] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 00 : 456[31000] -> 459[e3000] via P2P/IPC/read
257: hkn0612:924227:924322 [1] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
489: hkn0809:944571:944666 [1] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 01 : 88[31000] -> 91[e3000] via P2P/IPC/read
261: hkn0613:909944:910037 [1] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
256: hkn0612:924207:924324 [0] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
488: hkn0809:944559:944660 [0] NCCL INFO Channel 00 : 488[31000] -> 491[e3000] via P2P/IPC/read
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 00 : 476[31000] -> 479[e3000] via P2P/IPC/read
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
204: hkn0532:932494:932817 [0] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
232: hkn0605:719349:719471 [0] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 01 : 40[31000] -> 43[e3000] via P2P/IPC/read
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
139: hkn0511:3073664:3073769 [3] NCCL INFO Channel 01 : 139[e3000] -> 138[ca000] via P2P/IPC/read
260: hkn0613:909924:910036 [0] NCCL INFO Channel 01 : 260[31000] -> 263[e3000] via P2P/IPC/read
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 00 : 396[31000] -> 399[e3000] via P2P/IPC/read
244: hkn0608:492975:493069 [0] NCCL INFO Channel 00 : 244[31000] -> 247[e3000] via P2P/IPC/read
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 00 : 196[31000] -> 199[e3000] via P2P/IPC/read
421: hkn0726:1555337:1555444 [1] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
509: hkn0816:382855:382951 [1] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 01 : 288[31000] -> 291[e3000] via P2P/IPC/read
301: hkn0628:679147:679253 [1] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
293: hkn0626:1305645:1305779 [1] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
469: hkn0804:1212849:1212967 [1] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 00 : 184[31000] -> 187[e3000] via P2P/IPC/read
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 01 : 444[31000] -> 447[e3000] via P2P/IPC/read
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 01 : 448[31000] -> 451[e3000] via P2P/IPC/read
365: hkn0711:591174:591286 [1] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO Channel 01 : 228[31000] -> 231[e3000] via P2P/IPC/read
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 00 : 436[31000] -> 439[e3000] via P2P/IPC/read
465: hkn0803:883787:883894 [1] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
349: hkn0706:759478:759608 [1] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 01 : 76[31000] -> 79[e3000] via P2P/IPC/read
508: hkn0816:382834:382958 [0] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
123: hkn0507:3194313:3194412 [3] NCCL INFO Channel 00 : 123[e3000] -> 122[ca000] via P2P/IPC/read
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
377: hkn0714:439253:439365 [1] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
405: hkn0721:2306514:2306619 [1] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO Channel 00 : 408[31000] -> 411[e3000] via P2P/IPC/read
248: hkn0609:718056:718153 [0] NCCL INFO Channel 00 : 248[31000] -> 251[e3000] via P2P/IPC/read
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 01 : 220[31000] -> 223[e3000] via P2P/IPC/read
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 00 : 200[31000] -> 203[e3000] via P2P/IPC/read
252: hkn0611:717035:717164 [0] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
464: hkn0803:883779:883891 [0] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 01 : 224[31000] -> 227[e3000] via P2P/IPC/read
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
119: hkn0506:845284:845410 [3] NCCL INFO Channel 01 : 119[e3000] -> 118[ca000] via P2P/IPC/read
372: hkn0713:477480:477575 [0] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
  1: hkn0403:1776565:1776936 [1] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
505: hkn0815:402333:402447 [1] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 01 : 68[31000] -> 71[e3000] via P2P/IPC/read
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 00 : 296[31000] -> 299[e3000] via P2P/IPC/read
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 01 : 456[31000] -> 459[e3000] via P2P/IPC/read
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 01 : 476[31000] -> 479[e3000] via P2P/IPC/read
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
369: hkn0712:302289:302403 [1] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 00 : 452[31000] -> 455[e3000] via P2P/IPC/read
277: hkn0621:1998849:1998946 [1] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
135: hkn0510:2769298:2769389 [3] NCCL INFO Channel 01 : 135[e3000] -> 134[ca000] via P2P/IPC/read
373: hkn0713:477452:477574 [1] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 00 : 0[31000] -> 3[e3000] via P2P/IPC/read
268: hkn0616:412169:412281 [0] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
488: hkn0809:944559:944660 [0] NCCL INFO Channel 01 : 488[31000] -> 491[e3000] via P2P/IPC/read
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 00 : 428[31000] -> 431[e3000] via P2P/IPC/read
217: hkn0601:124968:125085 [1] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
344: hkn0705:790415:790543 [0] NCCL INFO Channel 00 : 344[31000] -> 347[e3000] via P2P/IPC/read
368: hkn0712:302297:302400 [0] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 00 : 432[31000] -> 435[e3000] via P2P/IPC/read
269: hkn0616:412177:412290 [1] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
183: hkn0526:1435657:1435750 [3] NCCL INFO Channel 00 : 183[e3000] -> 182[ca000] via P2P/IPC/read
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 00 : 280[31000] -> 283[e3000] via P2P/IPC/read
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 01 : 196[31000] -> 199[e3000] via P2P/IPC/read
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 00 : 460[31000] -> 463[e3000] via P2P/IPC/read
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 01 : 396[31000] -> 399[e3000] via P2P/IPC/read
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 00 : 392[31000] -> 395[e3000] via P2P/IPC/read
300: hkn0628:679159:679255 [0] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 00 : 480[31000] -> 483[e3000] via P2P/IPC/read
244: hkn0608:492975:493069 [0] NCCL INFO Channel 01 : 244[31000] -> 247[e3000] via P2P/IPC/read
 53: hkn0418:1876404:1876515 [1] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 00 : 20[31000] -> 23[e3000] via P2P/IPC/read
240: hkn0607:911595:911709 [0] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
151: hkn0514:2957951:2958068 [3] NCCL INFO Channel 00 : 151[e3000] -> 150[ca000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 01 : 184[31000] -> 187[e3000] via P2P/IPC/read
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 00 : 424[31000] -> 427[e3000] via P2P/IPC/read
256: hkn0612:924207:924324 [0] NCCL INFO Channel 00 : 256[31000] -> 259[e3000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
492: hkn0810:946764:946863 [0] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
204: hkn0532:932494:932817 [0] NCCL INFO Channel 00 : 204[31000] -> 207[e3000] via P2P/IPC/read
325: hkn0634:1528068:1528186 [1] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
360: hkn0710:362792:362882 [0] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
171: hkn0523:1555332:1555449 [3] NCCL INFO Channel 00 : 171[e3000] -> 170[ca000] via P2P/IPC/read
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 01 : 436[31000] -> 439[e3000] via P2P/IPC/read
123: hkn0507:3194313:3194412 [3] NCCL INFO Channel 01 : 123[e3000] -> 122[ca000] via P2P/IPC/read
381: hkn0715:409138:409236 [1] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 00 : 236[31000] -> 239[e3000] via P2P/IPC/read
167: hkn0521:1205008:1205131 [3] NCCL INFO Channel 00 : 167[e3000] -> 166[ca000] via P2P/IPC/read
408: hkn0723:215341:215495 [0] NCCL INFO Channel 01 : 408[31000] -> 411[e3000] via P2P/IPC/read
388: hkn0717:1467:1586 [0] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
232: hkn0605:719349:719471 [0] NCCL INFO Channel 00 : 232[31000] -> 235[e3000] via P2P/IPC/read
248: hkn0609:718056:718153 [0] NCCL INFO Channel 01 : 248[31000] -> 251[e3000] via P2P/IPC/read
216: hkn0601:124960:125086 [0] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 00 : 292[31000] -> 295[e3000] via P2P/IPC/read
380: hkn0715:409126:409232 [0] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 01 : 200[31000] -> 203[e3000] via P2P/IPC/read
384: hkn0716:115715:115850 [0] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
107: hkn0503:2906943:2907062 [3] NCCL INFO Channel 00 : 107[e3000] -> 106[ca000] via P2P/IPC/read
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 00 : 468[31000] -> 471[e3000] via P2P/IPC/read
493: hkn0810:946752:946862 [1] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
389: hkn0717:1475:1580 [1] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 01 : 296[31000] -> 299[e3000] via P2P/IPC/read
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 00 : 64[31000] -> 67[e3000] via P2P/IPC/read
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 00 : 124[31000] -> 127[e3000] via P2P/IPC/read
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 00 : 420[31000] -> 423[e3000] via P2P/IPC/read
508: hkn0816:382834:382958 [0] NCCL INFO Channel 00 : 508[31000] -> 511[e3000] via P2P/IPC/read
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 01 : 452[31000] -> 455[e3000] via P2P/IPC/read
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 00 : 404[31000] -> 407[e3000] via P2P/IPC/read
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
385: hkn0716:115707:115856 [1] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 01 : 428[31000] -> 431[e3000] via P2P/IPC/read
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 00 : 16[31000] -> 19[e3000] via P2P/IPC/read
344: hkn0705:790415:790543 [0] NCCL INFO Channel 01 : 344[31000] -> 347[e3000] via P2P/IPC/read
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
372: hkn0713:477480:477575 [0] NCCL INFO Channel 00 : 372[31000] -> 375[e3000] via P2P/IPC/read
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
484: hkn0808:977921:978021 [0] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 01 : 432[31000] -> 435[e3000] via P2P/IPC/read
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 01 : 0[31000] -> 3[e3000] via P2P/IPC/read
252: hkn0611:717035:717164 [0] NCCL INFO Channel 00 : 252[31000] -> 255[e3000] via P2P/IPC/read
183: hkn0526:1435657:1435750 [3] NCCL INFO Channel 01 : 183[e3000] -> 182[ca000] via P2P/IPC/read
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 01 : 280[31000] -> 283[e3000] via P2P/IPC/read
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 01 : 460[31000] -> 463[e3000] via P2P/IPC/read
 37: hkn0413:2373940:2374062 [1] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
485: hkn0808:977901:978022 [1] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
496: hkn0812:701027:701151 [0] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
464: hkn0803:883779:883891 [0] NCCL INFO Channel 00 : 464[31000] -> 467[e3000] via P2P/IPC/read
131: hkn0509:3131644:3131750 [3] NCCL INFO Connected all rings
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 01 : 480[31000] -> 483[e3000] via P2P/IPC/read
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 01 : 392[31000] -> 395[e3000] via P2P/IPC/read
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
368: hkn0712:302297:302400 [0] NCCL INFO Channel 00 : 368[31000] -> 371[e3000] via P2P/IPC/read
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 00 : 48[31000] -> 51[e3000] via P2P/IPC/read
268: hkn0616:412169:412281 [0] NCCL INFO Channel 00 : 268[31000] -> 271[e3000] via P2P/IPC/read
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 01 : 20[31000] -> 23[e3000] via P2P/IPC/read
256: hkn0612:924207:924324 [0] NCCL INFO Channel 01 : 256[31000] -> 259[e3000] via P2P/IPC/read
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 00 : 304[31000] -> 307[e3000] via P2P/IPC/read
340: hkn0704:799215:799344 [0] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
151: hkn0514:2957951:2958068 [3] NCCL INFO Channel 01 : 151[e3000] -> 150[ca000] via P2P/IPC/read
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 00 : 320[31000] -> 323[e3000] via P2P/IPC/read
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 00 : 24[31000] -> 27[e3000] via P2P/IPC/read
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
204: hkn0532:932494:932817 [0] NCCL INFO Channel 01 : 204[31000] -> 207[e3000] via P2P/IPC/read
497: hkn0812:701035:701150 [1] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 00 : 412[31000] -> 415[e3000] via P2P/IPC/read
232: hkn0605:719349:719471 [0] NCCL INFO Channel 01 : 232[31000] -> 235[e3000] via P2P/IPC/read
300: hkn0628:679159:679255 [0] NCCL INFO Channel 00 : 300[31000] -> 303[e3000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 00 : 312[31000] -> 315[e3000] via P2P/IPC/read
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
143: hkn0512:3051355:3051445 [3] NCCL INFO Channel 00 : 143[e3000] -> 142[ca000] via P2P/IPC/read
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 00 : 52[31000] -> 55[e3000] via P2P/IPC/read
139: hkn0511:3073664:3073769 [3] NCCL INFO Connected all rings
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
171: hkn0523:1555332:1555449 [3] NCCL INFO Channel 01 : 171[e3000] -> 170[ca000] via P2P/IPC/read
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 01 : 424[31000] -> 427[e3000] via P2P/IPC/read
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 00 : 276[31000] -> 279[e3000] via P2P/IPC/read
341: hkn0704:799223:799342 [1] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 01 : 292[31000] -> 295[e3000] via P2P/IPC/read
179: hkn0525:994006:994130 [3] NCCL INFO Channel 00 : 179[e3000] -> 178[ca000] via P2P/IPC/read
 99: hkn0501:1335147:1335272 [3] NCCL INFO Channel 00 : 99[e3000] -> 98[ca000] via P2P/IPC/read
500: hkn0814:683023:683174 [0] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
309: hkn0630:1605694:1605798 [1] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
364: hkn0711:591166:591281 [0] NCCL INFO Channel 00 : 364[31000] -> 367[e3000] via P2P/IPC/read
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 01 : 236[31000] -> 239[e3000] via P2P/IPC/read
107: hkn0503:2906943:2907062 [3] NCCL INFO Channel 01 : 107[e3000] -> 106[ca000] via P2P/IPC/read
216: hkn0601:124960:125086 [0] NCCL INFO Channel 00 : 216[31000] -> 219[e3000] via P2P/IPC/read
240: hkn0607:911595:911709 [0] NCCL INFO Channel 00 : 240[31000] -> 243[e3000] via P2P/IPC/read
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 00 : 380[31000] -> 383[e3000] via P2P/IPC/read
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 01 : 468[31000] -> 471[e3000] via P2P/IPC/read
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 01 : 420[31000] -> 423[e3000] via P2P/IPC/read
508: hkn0816:382834:382958 [0] NCCL INFO Channel 01 : 508[31000] -> 511[e3000] via P2P/IPC/read
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 01 : 404[31000] -> 407[e3000] via P2P/IPC/read
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 01 : 64[31000] -> 67[e3000] via P2P/IPC/read
501: hkn0814:683039:683170 [1] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 00 : 324[31000] -> 327[e3000] via P2P/IPC/read
360: hkn0710:362792:362882 [0] NCCL INFO Channel 00 : 360[31000] -> 363[e3000] via P2P/IPC/read
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
372: hkn0713:477480:477575 [0] NCCL INFO Channel 01 : 372[31000] -> 375[e3000] via P2P/IPC/read
388: hkn0717:1467:1586 [0] NCCL INFO Channel 00 : 388[31000] -> 391[e3000] via P2P/IPC/read
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 01 : 16[31000] -> 19[e3000] via P2P/IPC/read
115: hkn0505:2310997:2311121 [3] NCCL INFO Channel 00 : 115[e3000] -> 114[ca000] via P2P/IPC/read
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 01 : 124[31000] -> 127[e3000] via P2P/IPC/read
384: hkn0716:115715:115850 [0] NCCL INFO Channel 00 : 384[31000] -> 387[e3000] via P2P/IPC/read
348: hkn0706:759506:759606 [0] NCCL INFO Channel 00 : 348[31000] -> 351[e3000] via P2P/IPC/read
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
464: hkn0803:883779:883891 [0] NCCL INFO Channel 01 : 464[31000] -> 467[e3000] via P2P/IPC/read
357: hkn0708:420450:420563 [1] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
195: hkn0529:1548038:1548157 [3] NCCL INFO Channel 00 : 195[e3000] -> 194[ca000] via P2P/IPC/read
163: hkn0520:2720102:2720208 [3] NCCL INFO Channel 00 : 163[e3000] -> 162[ca000] via P2P/IPC/read
 95: hkn0428:674595:674697 [3] NCCL INFO Channel 00 : 95[e3000] -> 94[ca000] via P2P/IPC/read
252: hkn0611:717035:717164 [0] NCCL INFO Channel 01 : 252[31000] -> 255[e3000] via P2P/IPC/read
111: hkn0504:48327:48437 [3] NCCL INFO Channel 00 : 111[e3000] -> 110[ca000] via P2P/IPC/read
268: hkn0616:412169:412281 [0] NCCL INFO Channel 01 : 268[31000] -> 271[e3000] via P2P/IPC/read
368: hkn0712:302297:302400 [0] NCCL INFO Channel 01 : 368[31000] -> 371[e3000] via P2P/IPC/read
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 01 : 48[31000] -> 51[e3000] via P2P/IPC/read
356: hkn0708:420442:420567 [0] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 01 : 320[31000] -> 323[e3000] via P2P/IPC/read
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 00 : 352[31000] -> 355[e3000] via P2P/IPC/read
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 00 : 36[31000] -> 39[e3000] via P2P/IPC/read
484: hkn0808:977921:978021 [0] NCCL INFO Channel 00 : 484[31000] -> 487[e3000] via P2P/IPC/read
  5: hkn0404:1346653:1346760 [1] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 01 : 312[31000] -> 315[e3000] via P2P/IPC/read
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 01 : 304[31000] -> 307[e3000] via P2P/IPC/read
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 00 : 332[31000] -> 335[e3000] via P2P/IPC/read
143: hkn0512:3051355:3051445 [3] NCCL INFO Channel 01 : 143[e3000] -> 142[ca000] via P2P/IPC/read
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 01 : 52[31000] -> 55[e3000] via P2P/IPC/read
155: hkn0515:2904013:2904151 [3] NCCL INFO Channel 00 : 155[e3000] -> 154[ca000] via P2P/IPC/read
119: hkn0506:845284:845410 [3] NCCL INFO Connected all rings
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 01 : 24[31000] -> 27[e3000] via P2P/IPC/read
400: hkn0720:14302:14479 [0] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 01 : 412[31000] -> 415[e3000] via P2P/IPC/read
300: hkn0628:679159:679255 [0] NCCL INFO Channel 01 : 300[31000] -> 303[e3000] via P2P/IPC/read
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 01 : 276[31000] -> 279[e3000] via P2P/IPC/read
496: hkn0812:701027:701151 [0] NCCL INFO Channel 00 : 496[31000] -> 499[e3000] via P2P/IPC/read
179: hkn0525:994006:994130 [3] NCCL INFO Channel 01 : 179[e3000] -> 178[ca000] via P2P/IPC/read
337: hkn0703:748303:748410 [1] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
177: hkn0525:994014:994129 [1] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
 99: hkn0501:1335147:1335272 [3] NCCL INFO Channel 01 : 99[e3000] -> 98[ca000] via P2P/IPC/read
401: hkn0720:14318:14478 [1] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
340: hkn0704:799215:799344 [0] NCCL INFO Channel 00 : 340[31000] -> 343[e3000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO Channel 01 : 364[31000] -> 367[e3000] via P2P/IPC/read
336: hkn0703:748295:748408 [0] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 01 : 380[31000] -> 383[e3000] via P2P/IPC/read
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 00 : 32[31000] -> 35[e3000] via P2P/IPC/read
360: hkn0710:362792:362882 [0] NCCL INFO Channel 01 : 360[31000] -> 363[e3000] via P2P/IPC/read
123: hkn0507:3194313:3194412 [3] NCCL INFO Connected all rings
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 00 : 316[31000] -> 319[e3000] via P2P/IPC/read
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 00 : 272[31000] -> 275[e3000] via P2P/IPC/read
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 00 : 4[31000] -> 7[e3000] via P2P/IPC/read
115: hkn0505:2310997:2311121 [3] NCCL INFO Channel 01 : 115[e3000] -> 114[ca000] via P2P/IPC/read
384: hkn0716:115715:115850 [0] NCCL INFO Channel 01 : 384[31000] -> 387[e3000] via P2P/IPC/read
388: hkn0717:1467:1586 [0] NCCL INFO Channel 01 : 388[31000] -> 391[e3000] via P2P/IPC/read
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 01 : 324[31000] -> 327[e3000] via P2P/IPC/read
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 00 : 144[31000] -> 147[e3000] via P2P/IPC/read
348: hkn0706:759506:759606 [0] NCCL INFO Channel 01 : 348[31000] -> 351[e3000] via P2P/IPC/read
500: hkn0814:683023:683174 [0] NCCL INFO Channel 00 : 500[31000] -> 503[e3000] via P2P/IPC/read
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 00 : 44[31000] -> 47[e3000] via P2P/IPC/read
103: hkn0502:236303:236407 [3] NCCL INFO Channel 00 : 103[e3000] -> 102[ca000] via P2P/IPC/read
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 00 : 8[31000] -> 11[e3000] via P2P/IPC/read
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 00 : 308[31000] -> 311[e3000] via P2P/IPC/read
216: hkn0601:124960:125086 [0] NCCL INFO Channel 01 : 216[31000] -> 219[e3000] via P2P/IPC/read
195: hkn0529:1548038:1548157 [3] NCCL INFO Channel 01 : 195[e3000] -> 194[ca000] via P2P/IPC/read
163: hkn0520:2720102:2720208 [3] NCCL INFO Channel 01 : 163[e3000] -> 162[ca000] via P2P/IPC/read
492: hkn0810:946764:946863 [0] NCCL INFO Channel 00 : 492[31000] -> 495[e3000] via P2P/IPC/read
159: hkn0516:2923224:2923313 [3] NCCL INFO Channel 00 : 159[e3000] -> 158[ca000] via P2P/IPC/read
 95: hkn0428:674595:674697 [3] NCCL INFO Channel 01 : 95[e3000] -> 94[ca000] via P2P/IPC/read
111: hkn0504:48327:48437 [3] NCCL INFO Channel 01 : 111[e3000] -> 110[ca000] via P2P/IPC/read
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 01 : 352[31000] -> 355[e3000] via P2P/IPC/read
183: hkn0526:1435657:1435750 [3] NCCL INFO Connected all rings
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 01 : 36[31000] -> 39[e3000] via P2P/IPC/read
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 00 : 284[31000] -> 287[e3000] via P2P/IPC/read
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 01 : 332[31000] -> 335[e3000] via P2P/IPC/read
484: hkn0808:977921:978021 [0] NCCL INFO Channel 01 : 484[31000] -> 487[e3000] via P2P/IPC/read
211: hkn0534:1155652:1155751 [3] NCCL INFO Channel 00 : 211[e3000] -> 210[ca000] via P2P/IPC/read
496: hkn0812:701027:701151 [0] NCCL INFO Channel 01 : 496[31000] -> 499[e3000] via P2P/IPC/read
479: hkn0806:1061530:1061646 [3] NCCL INFO Channel 00 : 479[e3000] -> 478[ca000] via P2P/IPC/read
340: hkn0704:799215:799344 [0] NCCL INFO Channel 01 : 340[31000] -> 343[e3000] via P2P/IPC/read
151: hkn0514:2957951:2958068 [3] NCCL INFO Connected all rings
356: hkn0708:420442:420567 [0] NCCL INFO Channel 00 : 356[31000] -> 359[e3000] via P2P/IPC/read
240: hkn0607:911595:911709 [0] NCCL INFO Channel 01 : 240[31000] -> 243[e3000] via P2P/IPC/read
171: hkn0523:1555332:1555449 [3] NCCL INFO Connected all rings
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 01 : 32[31000] -> 35[e3000] via P2P/IPC/read
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 01 : 4[31000] -> 7[e3000] via P2P/IPC/read
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 01 : 316[31000] -> 319[e3000] via P2P/IPC/read
135: hkn0510:2769298:2769389 [3] NCCL INFO Connected all rings
400: hkn0720:14302:14479 [0] NCCL INFO Channel 00 : 400[31000] -> 403[e3000] via P2P/IPC/read
247: hkn0608:492955:493068 [3] NCCL INFO Channel 00 : 247[e3000] -> 246[ca000] via P2P/IPC/read
191: hkn0528:1308895:1309019 [3] NCCL INFO Channel 00 : 191[e3000] -> 190[ca000] via P2P/IPC/read
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 01 : 308[31000] -> 311[e3000] via P2P/IPC/read
175: hkn0524:1141030:1141123 [3] NCCL INFO Channel 00 : 175[e3000] -> 174[ca000] via P2P/IPC/read
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 01 : 272[31000] -> 275[e3000] via P2P/IPC/read
107: hkn0503:2906943:2907062 [3] NCCL INFO Connected all rings
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 01 : 8[31000] -> 11[e3000] via P2P/IPC/read
500: hkn0814:683023:683174 [0] NCCL INFO Channel 01 : 500[31000] -> 503[e3000] via P2P/IPC/read
336: hkn0703:748295:748408 [0] NCCL INFO Channel 00 : 336[31000] -> 339[e3000] via P2P/IPC/read
267: hkn0615:421542:421667 [3] NCCL INFO Channel 00 : 267[e3000] -> 266[ca000] via P2P/IPC/read
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 01 : 44[31000] -> 47[e3000] via P2P/IPC/read
167: hkn0521:1205008:1205131 [3] NCCL INFO Channel 01 : 167[e3000] -> 166[ca000] via P2P/IPC/read
 87: hkn0426:821258:821413 [3] NCCL INFO Channel 00 : 87[e3000] -> 86[ca000] via P2P/IPC/read
492: hkn0810:946764:946863 [0] NCCL INFO Channel 01 : 492[31000] -> 495[e3000] via P2P/IPC/read
103: hkn0502:236303:236407 [3] NCCL INFO Channel 01 : 103[e3000] -> 102[ca000] via P2P/IPC/read
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
 75: hkn0423:1712190:1712287 [3] NCCL INFO Channel 00 : 75[e3000] -> 74[ca000] via P2P/IPC/read
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 01 : 144[31000] -> 147[e3000] via P2P/IPC/read
159: hkn0516:2923224:2923313 [3] NCCL INFO Channel 01 : 159[e3000] -> 158[ca000] via P2P/IPC/read
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 01 : 284[31000] -> 287[e3000] via P2P/IPC/read
 91: hkn0427:1142357:1142467 [3] NCCL INFO Channel 00 : 91[e3000] -> 90[ca000] via P2P/IPC/read
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
211: hkn0534:1155652:1155751 [3] NCCL INFO Channel 01 : 211[e3000] -> 210[ca000] via P2P/IPC/read
155: hkn0515:2904013:2904151 [3] NCCL INFO Channel 01 : 155[e3000] -> 154[ca000] via P2P/IPC/read
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
356: hkn0708:420442:420567 [0] NCCL INFO Channel 01 : 356[31000] -> 359[e3000] via P2P/IPC/read
479: hkn0806:1061530:1061646 [3] NCCL INFO Channel 01 : 479[e3000] -> 478[ca000] via P2P/IPC/read
291: hkn0624:1780148:1780287 [3] NCCL INFO Channel 00 : 291[e3000] -> 290[ca000] via P2P/IPC/read
143: hkn0512:3051355:3051445 [3] NCCL INFO Connected all rings
263: hkn0613:909932:910042 [3] NCCL INFO Channel 00 : 263[e3000] -> 262[ca000] via P2P/IPC/read
475: hkn0805:1119325:1119448 [3] NCCL INFO Channel 00 : 475[e3000] -> 474[ca000] via P2P/IPC/read
179: hkn0525:994006:994130 [3] NCCL INFO Connected all rings
400: hkn0720:14302:14479 [0] NCCL INFO Channel 01 : 400[31000] -> 403[e3000] via P2P/IPC/read
191: hkn0528:1308895:1309019 [3] NCCL INFO Channel 01 : 191[e3000] -> 190[ca000] via P2P/IPC/read
247: hkn0608:492955:493068 [3] NCCL INFO Channel 01 : 247[e3000] -> 246[ca000] via P2P/IPC/read
175: hkn0524:1141030:1141123 [3] NCCL INFO Channel 01 : 175[e3000] -> 174[ca000] via P2P/IPC/read
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 00 : 80[31000] -> 83[e3000] via P2P/IPC/read
 99: hkn0501:1335147:1335272 [3] NCCL INFO Connected all rings
447: hkn0733:1396600:1396698 [3] NCCL INFO Channel 00 : 447[e3000] -> 446[ca000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Channel 01 : 336[31000] -> 339[e3000] via P2P/IPC/read
267: hkn0615:421542:421667 [3] NCCL INFO Channel 01 : 267[e3000] -> 266[ca000] via P2P/IPC/read
 79: hkn0424:2955186:2955299 [3] NCCL INFO Channel 00 : 79[e3000] -> 78[ca000] via P2P/IPC/read
 87: hkn0426:821258:821413 [3] NCCL INFO Channel 01 : 87[e3000] -> 86[ca000] via P2P/IPC/read
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 75: hkn0423:1712190:1712287 [3] NCCL INFO Channel 01 : 75[e3000] -> 74[ca000] via P2P/IPC/read
231: hkn0604:696467:696570 [3] NCCL INFO Channel 00 : 231[e3000] -> 230[ca000] via P2P/IPC/read
115: hkn0505:2310997:2311121 [3] NCCL INFO Connected all rings
223: hkn0602:3370906:3371095 [3] NCCL INFO Channel 00 : 223[e3000] -> 222[ca000] via P2P/IPC/read
451: hkn0734:1163769:1163876 [3] NCCL INFO Channel 00 : 451[e3000] -> 450[ca000] via P2P/IPC/read
459: hkn0801:2247280:2247386 [3] NCCL INFO Channel 00 : 459[e3000] -> 458[ca000] via P2P/IPC/read
227: hkn0603:1420478:1420573 [3] NCCL INFO Channel 00 : 227[e3000] -> 226[ca000] via P2P/IPC/read
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
163: hkn0520:2720102:2720208 [3] NCCL INFO Connected all rings
 91: hkn0427:1142357:1142467 [3] NCCL INFO Channel 01 : 91[e3000] -> 90[ca000] via P2P/IPC/read
 95: hkn0428:674595:674697 [3] NCCL INFO Connected all rings
111: hkn0504:48327:48437 [3] NCCL INFO Connected all rings
491: hkn0809:944551:944668 [3] NCCL INFO Channel 00 : 491[e3000] -> 490[ca000] via P2P/IPC/read
241: hkn0607:911603:911711 [1] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
 43: hkn0414:1988916:1989008 [3] NCCL INFO Channel 00 : 43[e3000] -> 42[ca000] via P2P/IPC/read
199: hkn0530:1265351:1265471 [3] NCCL INFO Channel 00 : 199[e3000] -> 198[ca000] via P2P/IPC/read
 71: hkn0422:4160348:4160470 [3] NCCL INFO Channel 00 : 71[e3000] -> 70[ca000] via P2P/IPC/read
291: hkn0624:1780148:1780287 [3] NCCL INFO Channel 01 : 291[e3000] -> 290[ca000] via P2P/IPC/read
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
263: hkn0613:909932:910042 [3] NCCL INFO Channel 01 : 263[e3000] -> 262[ca000] via P2P/IPC/read
475: hkn0805:1119325:1119448 [3] NCCL INFO Channel 01 : 475[e3000] -> 474[ca000] via P2P/IPC/read
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 00 : 212[31000] -> 215[e3000] via P2P/IPC/read
399: hkn0719:1312971:1313088 [3] NCCL INFO Channel 00 : 399[e3000] -> 398[ca000] via P2P/IPC/read
 79: hkn0424:2955186:2955299 [3] NCCL INFO Channel 01 : 79[e3000] -> 78[ca000] via P2P/IPC/read
447: hkn0733:1396600:1396698 [3] NCCL INFO Channel 01 : 447[e3000] -> 446[ca000] via P2P/IPC/read
439: hkn0731:1393950:1394081 [3] NCCL INFO Channel 00 : 439[e3000] -> 438[ca000] via P2P/IPC/read
303: hkn0628:679131:679256 [3] NCCL INFO Channel 00 : 303[e3000] -> 302[ca000] via P2P/IPC/read
195: hkn0529:1548038:1548157 [3] NCCL INFO Connected all rings
411: hkn0723:215353:215498 [3] NCCL INFO Channel 00 : 411[e3000] -> 410[ca000] via P2P/IPC/read
367: hkn0711:591158:591280 [3] NCCL INFO Channel 00 : 367[e3000] -> 366[ca000] via P2P/IPC/read
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 01 : 80[31000] -> 83[e3000] via P2P/IPC/read
231: hkn0604:696467:696570 [3] NCCL INFO Channel 01 : 231[e3000] -> 230[ca000] via P2P/IPC/read
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 00 : 440[31000] -> 443[e3000] via P2P/IPC/read
187: hkn0527:1356160:1356277 [3] NCCL INFO Channel 00 : 187[e3000] -> 186[ca000] via P2P/IPC/read
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 00 : 12[31000] -> 15[e3000] via P2P/IPC/read
251: hkn0609:718044:718148 [3] NCCL INFO Channel 00 : 251[e3000] -> 250[ca000] via P2P/IPC/read
223: hkn0602:3370906:3371095 [3] NCCL INFO Channel 01 : 223[e3000] -> 222[ca000] via P2P/IPC/read
451: hkn0734:1163769:1163876 [3] NCCL INFO Channel 01 : 451[e3000] -> 450[ca000] via P2P/IPC/read
459: hkn0801:2247280:2247386 [3] NCCL INFO Channel 01 : 459[e3000] -> 458[ca000] via P2P/IPC/read
227: hkn0603:1420478:1420573 [3] NCCL INFO Channel 01 : 227[e3000] -> 226[ca000] via P2P/IPC/read
455: hkn0736:1515543:1515649 [3] NCCL INFO Channel 00 : 455[e3000] -> 454[ca000] via P2P/IPC/read
376: hkn0714:439237:439359 [0] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
167: hkn0521:1205008:1205131 [3] NCCL INFO Connected all rings
351: hkn0706:759486:759602 [3] NCCL INFO Channel 00 : 351[e3000] -> 350[ca000] via P2P/IPC/read
491: hkn0809:944551:944668 [3] NCCL INFO Channel 01 : 491[e3000] -> 490[ca000] via P2P/IPC/read
103: hkn0502:236303:236407 [3] NCCL INFO Connected all rings
199: hkn0530:1265351:1265471 [3] NCCL INFO Channel 01 : 199[e3000] -> 198[ca000] via P2P/IPC/read
463: hkn0802:1207551:1207689 [3] NCCL INFO Channel 00 : 463[e3000] -> 462[ca000] via P2P/IPC/read
 43: hkn0414:1988916:1989008 [3] NCCL INFO Channel 01 : 43[e3000] -> 42[ca000] via P2P/IPC/read
283: hkn0622:2027736:2027858 [3] NCCL INFO Channel 00 : 283[e3000] -> 282[ca000] via P2P/IPC/read
203: hkn0531:1237894:1238018 [3] NCCL INFO Channel 00 : 203[e3000] -> 202[ca000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 00 : 416[31000] -> 419[e3000] via P2P/IPC/read
 71: hkn0422:4160348:4160470 [3] NCCL INFO Channel 01 : 71[e3000] -> 70[ca000] via P2P/IPC/read
435: hkn0730:1408947:1409077 [3] NCCL INFO Channel 00 : 435[e3000] -> 434[ca000] via P2P/IPC/read
395: hkn0718:3924254:3924371 [3] NCCL INFO Channel 00 : 395[e3000] -> 394[ca000] via P2P/IPC/read
159: hkn0516:2923224:2923313 [3] NCCL INFO Connected all rings
155: hkn0515:2904013:2904151 [3] NCCL INFO Connected all rings
399: hkn0719:1312971:1313088 [3] NCCL INFO Channel 01 : 399[e3000] -> 398[ca000] via P2P/IPC/read
483: hkn0807:1026305:1026402 [3] NCCL INFO Channel 00 : 483[e3000] -> 482[ca000] via P2P/IPC/read
259: hkn0612:924215:924321 [3] NCCL INFO Channel 00 : 259[e3000] -> 258[ca000] via P2P/IPC/read
431: hkn0728:1331257:1331376 [3] NCCL INFO Channel 00 : 431[e3000] -> 430[ca000] via P2P/IPC/read
 23: hkn0409:2592874:2592989 [3] NCCL INFO Channel 00 : 23[e3000] -> 22[ca000] via P2P/IPC/read
504: hkn0815:402353:402445 [0] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 00 : 28[31000] -> 31[e3000] via P2P/IPC/read
303: hkn0628:679131:679256 [3] NCCL INFO Channel 01 : 303[e3000] -> 302[ca000] via P2P/IPC/read
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 01 : 212[31000] -> 215[e3000] via P2P/IPC/read
439: hkn0731:1393950:1394081 [3] NCCL INFO Channel 01 : 439[e3000] -> 438[ca000] via P2P/IPC/read
335: hkn0636:1661521:1661639 [3] NCCL INFO Channel 00 : 335[e3000] -> 334[ca000] via P2P/IPC/read
211: hkn0534:1155652:1155751 [3] NCCL INFO Connected all rings
235: hkn0605:719372:719467 [3] NCCL INFO Channel 00 : 235[e3000] -> 234[ca000] via P2P/IPC/read
367: hkn0711:591158:591280 [3] NCCL INFO Channel 01 : 367[e3000] -> 366[ca000] via P2P/IPC/read
295: hkn0626:1305656:1305785 [3] NCCL INFO Channel 00 : 295[e3000] -> 294[ca000] via P2P/IPC/read
191: hkn0528:1308895:1309019 [3] NCCL INFO Connected all rings
411: hkn0723:215353:215498 [3] NCCL INFO Channel 01 : 411[e3000] -> 410[ca000] via P2P/IPC/read
427: hkn0727:1353022:1353120 [3] NCCL INFO Channel 00 : 427[e3000] -> 426[ca000] via P2P/IPC/read
407: hkn0721:2306506:2306615 [3] NCCL INFO Channel 00 : 407[e3000] -> 406[ca000] via P2P/IPC/read
175: hkn0524:1141030:1141123 [3] NCCL INFO Connected all rings
187: hkn0527:1356160:1356277 [3] NCCL INFO Channel 01 : 187[e3000] -> 186[ca000] via P2P/IPC/read
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 01 : 12[31000] -> 15[e3000] via P2P/IPC/read
251: hkn0609:718044:718148 [3] NCCL INFO Channel 01 : 251[e3000] -> 250[ca000] via P2P/IPC/read
 87: hkn0426:821258:821413 [3] NCCL INFO Connected all rings
471: hkn0804:1212857:1212971 [3] NCCL INFO Channel 00 : 471[e3000] -> 470[ca000] via P2P/IPC/read
423: hkn0726:1555329:1555441 [3] NCCL INFO Channel 00 : 423[e3000] -> 422[ca000] via P2P/IPC/read
511: hkn0816:382835:382955 [3] NCCL INFO Channel 00 : 511[e3000] -> 510[ca000] via P2P/IPC/read
267: hkn0615:421542:421667 [3] NCCL INFO Connected all rings
345: hkn0705:790443:790544 [1] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
299: hkn0627:1795186:1795268 [3] NCCL INFO Channel 00 : 299[e3000] -> 298[ca000] via P2P/IPC/read
 67: hkn0421:2189234:2189409 [3] NCCL INFO Channel 00 : 67[e3000] -> 66[ca000] via P2P/IPC/read
455: hkn0736:1515543:1515649 [3] NCCL INFO Channel 01 : 455[e3000] -> 454[ca000] via P2P/IPC/read
375: hkn0713:477460:477578 [3] NCCL INFO Channel 00 : 375[e3000] -> 374[ca000] via P2P/IPC/read
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 01 : 440[31000] -> 443[e3000] via P2P/IPC/read
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
239: hkn0606:2379367:2379465 [3] NCCL INFO Channel 00 : 239[e3000] -> 238[ca000] via P2P/IPC/read
207: hkn0532:932502:932816 [3] NCCL INFO Channel 00 : 207[e3000] -> 206[ca000] via P2P/IPC/read
 75: hkn0423:1712190:1712287 [3] NCCL INFO Connected all rings
351: hkn0706:759486:759602 [3] NCCL INFO Channel 01 : 351[e3000] -> 350[ca000] via P2P/IPC/read
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 00 : 56[31000] -> 59[e3000] via P2P/IPC/read
203: hkn0531:1237894:1238018 [3] NCCL INFO Channel 01 : 203[e3000] -> 202[ca000] via P2P/IPC/read
255: hkn0611:717043:717161 [3] NCCL INFO Channel 00 : 255[e3000] -> 254[ca000] via P2P/IPC/read
395: hkn0718:3924254:3924371 [3] NCCL INFO Channel 01 : 395[e3000] -> 394[ca000] via P2P/IPC/read
 91: hkn0427:1142357:1142467 [3] NCCL INFO Connected all rings
283: hkn0622:2027736:2027858 [3] NCCL INFO Channel 01 : 283[e3000] -> 282[ca000] via P2P/IPC/read
371: hkn0712:302309:302405 [3] NCCL INFO Channel 00 : 371[e3000] -> 370[ca000] via P2P/IPC/read
435: hkn0730:1408947:1409077 [3] NCCL INFO Channel 01 : 435[e3000] -> 434[ca000] via P2P/IPC/read
467: hkn0803:883807:883885 [3] NCCL INFO Channel 00 : 467[e3000] -> 466[ca000] via P2P/IPC/read
 19: hkn0408:2898037:2898154 [3] NCCL INFO Channel 00 : 19[e3000] -> 18[ca000] via P2P/IPC/read
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
323: hkn0633:1533566:1533658 [3] NCCL INFO Channel 00 : 323[e3000] -> 322[ca000] via P2P/IPC/read
463: hkn0802:1207551:1207689 [3] NCCL INFO Channel 01 : 463[e3000] -> 462[ca000] via P2P/IPC/read
483: hkn0807:1026305:1026402 [3] NCCL INFO Channel 01 : 483[e3000] -> 482[ca000] via P2P/IPC/read
 23: hkn0409:2592874:2592989 [3] NCCL INFO Channel 01 : 23[e3000] -> 22[ca000] via P2P/IPC/read
347: hkn0705:790423:790536 [3] NCCL INFO Channel 00 : 347[e3000] -> 346[ca000] via P2P/IPC/read
271: hkn0616:412189:412285 [3] NCCL INFO Channel 00 : 271[e3000] -> 270[ca000] via P2P/IPC/read
259: hkn0612:924215:924321 [3] NCCL INFO Channel 01 : 259[e3000] -> 258[ca000] via P2P/IPC/read
307: hkn0629:1599276:1599401 [3] NCCL INFO Channel 00 : 307[e3000] -> 306[ca000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 01 : 416[31000] -> 419[e3000] via P2P/IPC/read
291: hkn0624:1780148:1780287 [3] NCCL INFO Connected all rings
263: hkn0613:909932:910042 [3] NCCL INFO Connected all rings
475: hkn0805:1119325:1119448 [3] NCCL INFO Connected all rings
315: hkn0631:1029032:1029141 [3] NCCL INFO Channel 00 : 315[e3000] -> 314[ca000] via P2P/IPC/read
247: hkn0608:492955:493068 [3] NCCL INFO Connected all rings
295: hkn0626:1305656:1305785 [3] NCCL INFO Channel 01 : 295[e3000] -> 294[ca000] via P2P/IPC/read
 55: hkn0418:1876416:1876509 [3] NCCL INFO Channel 00 : 55[e3000] -> 54[ca000] via P2P/IPC/read
235: hkn0605:719372:719467 [3] NCCL INFO Channel 01 : 235[e3000] -> 234[ca000] via P2P/IPC/read
431: hkn0728:1331257:1331376 [3] NCCL INFO Channel 01 : 431[e3000] -> 430[ca000] via P2P/IPC/read
279: hkn0621:1998830:1998944 [3] NCCL INFO Channel 00 : 279[e3000] -> 278[ca000] via P2P/IPC/read
376: hkn0714:439237:439359 [0] NCCL INFO Channel 00 : 376[31000] -> 379[e3000] via P2P/IPC/read
 27: hkn0410:1166917:1167039 [3] NCCL INFO Channel 00 : 27[e3000] -> 26[ca000] via P2P/IPC/read
427: hkn0727:1353022:1353120 [3] NCCL INFO Channel 01 : 427[e3000] -> 426[ca000] via P2P/IPC/read
415: hkn0724:1723198:1723323 [3] NCCL INFO Channel 00 : 415[e3000] -> 414[ca000] via P2P/IPC/read
127: hkn0508:3146366:3146462 [3] NCCL INFO Channel 00 : 127[e3000] -> 126[ca000] via P2P/IPC/read
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 01 : 28[31000] -> 31[e3000] via P2P/IPC/read
447: hkn0733:1396600:1396698 [3] NCCL INFO Connected all rings
407: hkn0721:2306506:2306615 [3] NCCL INFO Channel 01 : 407[e3000] -> 406[ca000] via P2P/IPC/read
359: hkn0708:420470:420564 [3] NCCL INFO Channel 00 : 359[e3000] -> 358[ca000] via P2P/IPC/read
 79: hkn0424:2955186:2955299 [3] NCCL INFO Connected all rings
 51: hkn0417:2274868:2274989 [3] NCCL INFO Channel 00 : 51[e3000] -> 50[ca000] via P2P/IPC/read
471: hkn0804:1212857:1212971 [3] NCCL INFO Channel 01 : 471[e3000] -> 470[ca000] via P2P/IPC/read
423: hkn0726:1555329:1555441 [3] NCCL INFO Channel 01 : 423[e3000] -> 422[ca000] via P2P/IPC/read
511: hkn0816:382835:382955 [3] NCCL INFO Channel 01 : 511[e3000] -> 510[ca000] via P2P/IPC/read
479: hkn0806:1061530:1061646 [3] NCCL INFO Connected all rings
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
 67: hkn0421:2189234:2189409 [3] NCCL INFO Channel 01 : 67[e3000] -> 66[ca000] via P2P/IPC/read
231: hkn0604:696467:696570 [3] NCCL INFO Connected all rings
327: hkn0634:1528094:1528189 [3] NCCL INFO Channel 00 : 327[e3000] -> 326[ca000] via P2P/IPC/read
299: hkn0627:1795186:1795268 [3] NCCL INFO Channel 01 : 299[e3000] -> 298[ca000] via P2P/IPC/read
383: hkn0715:409110:409235 [3] NCCL INFO Channel 00 : 383[e3000] -> 382[ca000] via P2P/IPC/read
375: hkn0713:477460:477578 [3] NCCL INFO Channel 01 : 375[e3000] -> 374[ca000] via P2P/IPC/read
223: hkn0602:3370906:3371095 [3] NCCL INFO Connected all rings
239: hkn0606:2379367:2379465 [3] NCCL INFO Channel 01 : 239[e3000] -> 238[ca000] via P2P/IPC/read
504: hkn0815:402353:402445 [0] NCCL INFO Channel 00 : 504[31000] -> 507[e3000] via P2P/IPC/read
207: hkn0532:932502:932816 [3] NCCL INFO Channel 01 : 207[e3000] -> 206[ca000] via P2P/IPC/read
255: hkn0611:717043:717161 [3] NCCL INFO Channel 01 : 255[e3000] -> 254[ca000] via P2P/IPC/read
391: hkn0717:1459:1584 [3] NCCL INFO Channel 00 : 391[e3000] -> 390[ca000] via P2P/IPC/read
219: hkn0601:124976:125081 [3] NCCL INFO Channel 00 : 219[e3000] -> 218[ca000] via P2P/IPC/read
335: hkn0636:1661521:1661639 [3] NCCL INFO Channel 01 : 335[e3000] -> 334[ca000] via P2P/IPC/read
459: hkn0801:2247280:2247386 [3] NCCL INFO Connected all rings
387: hkn0716:115727:115858 [3] NCCL INFO Channel 00 : 387[e3000] -> 386[ca000] via P2P/IPC/read
451: hkn0734:1163769:1163876 [3] NCCL INFO Connected all rings
467: hkn0803:883807:883885 [3] NCCL INFO Channel 01 : 467[e3000] -> 466[ca000] via P2P/IPC/read
227: hkn0603:1420478:1420573 [3] NCCL INFO Connected all rings
 19: hkn0408:2898037:2898154 [3] NCCL INFO Channel 01 : 19[e3000] -> 18[ca000] via P2P/IPC/read
323: hkn0633:1533566:1533658 [3] NCCL INFO Channel 01 : 323[e3000] -> 322[ca000] via P2P/IPC/read
371: hkn0712:302309:302405 [3] NCCL INFO Channel 01 : 371[e3000] -> 370[ca000] via P2P/IPC/read
271: hkn0616:412189:412285 [3] NCCL INFO Channel 01 : 271[e3000] -> 270[ca000] via P2P/IPC/read
307: hkn0629:1599276:1599401 [3] NCCL INFO Channel 01 : 307[e3000] -> 306[ca000] via P2P/IPC/read
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 01 : 56[31000] -> 59[e3000] via P2P/IPC/read
 39: hkn0413:2373932:2374059 [3] NCCL INFO Channel 00 : 39[e3000] -> 38[ca000] via P2P/IPC/read
 43: hkn0414:1988916:1989008 [3] NCCL INFO Connected all rings
347: hkn0705:790423:790536 [3] NCCL INFO Channel 01 : 347[e3000] -> 346[ca000] via P2P/IPC/read
199: hkn0530:1265351:1265471 [3] NCCL INFO Connected all rings
 71: hkn0422:4160348:4160470 [3] NCCL INFO Connected all rings
361: hkn0710:362772:362881 [1] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
315: hkn0631:1029032:1029141 [3] NCCL INFO Channel 01 : 315[e3000] -> 314[ca000] via P2P/IPC/read
487: hkn0808:977909:978016 [3] NCCL INFO Channel 00 : 487[e3000] -> 486[ca000] via P2P/IPC/read
491: hkn0809:944551:944668 [3] NCCL INFO Connected all rings
 55: hkn0418:1876416:1876509 [3] NCCL INFO Channel 01 : 55[e3000] -> 54[ca000] via P2P/IPC/read
 27: hkn0410:1166917:1167039 [3] NCCL INFO Channel 01 : 27[e3000] -> 26[ca000] via P2P/IPC/read
399: hkn0719:1312971:1313088 [3] NCCL INFO Connected all rings
279: hkn0621:1998830:1998944 [3] NCCL INFO Channel 01 : 279[e3000] -> 278[ca000] via P2P/IPC/read
127: hkn0508:3146366:3146462 [3] NCCL INFO Channel 01 : 127[e3000] -> 126[ca000] via P2P/IPC/read
  3: hkn0403:1776560:1776937 [3] NCCL INFO Channel 00 : 3[e3000] -> 2[ca000] via P2P/IPC/read
415: hkn0724:1723198:1723323 [3] NCCL INFO Channel 01 : 415[e3000] -> 414[ca000] via P2P/IPC/read
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 00 : 328[31000] -> 331[e3000] via P2P/IPC/read
359: hkn0708:420470:420564 [3] NCCL INFO Channel 01 : 359[e3000] -> 358[ca000] via P2P/IPC/read
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
 51: hkn0417:2274868:2274989 [3] NCCL INFO Channel 01 : 51[e3000] -> 50[ca000] via P2P/IPC/read
439: hkn0731:1393950:1394081 [3] NCCL INFO Connected all rings
499: hkn0812:701057:701148 [3] NCCL INFO Channel 00 : 499[e3000] -> 498[ca000] via P2P/IPC/read
303: hkn0628:679131:679256 [3] NCCL INFO Connected all rings
327: hkn0634:1528094:1528189 [3] NCCL INFO Channel 01 : 327[e3000] -> 326[ca000] via P2P/IPC/read
343: hkn0704:799231:799343 [3] NCCL INFO Channel 00 : 343[e3000] -> 342[ca000] via P2P/IPC/read
319: hkn0632:1765859:1765969 [3] NCCL INFO Channel 00 : 319[e3000] -> 318[ca000] via P2P/IPC/read
376: hkn0714:439237:439359 [0] NCCL INFO Channel 01 : 376[31000] -> 379[e3000] via P2P/IPC/read
367: hkn0711:591158:591280 [3] NCCL INFO Connected all rings
383: hkn0715:409110:409235 [3] NCCL INFO Channel 01 : 383[e3000] -> 382[ca000] via P2P/IPC/read
 35: hkn0412:2269608:2269737 [3] NCCL INFO Channel 00 : 35[e3000] -> 34[ca000] via P2P/IPC/read
363: hkn0710:362780:362887 [3] NCCL INFO Channel 00 : 363[e3000] -> 362[ca000] via P2P/IPC/read
243: hkn0607:911615:911710 [3] NCCL INFO Channel 00 : 243[e3000] -> 242[ca000] via P2P/IPC/read
  7: hkn0404:1346645:1346762 [3] NCCL INFO Channel 00 : 7[e3000] -> 6[ca000] via P2P/IPC/read
503: hkn0814:683031:683177 [3] NCCL INFO Channel 00 : 503[e3000] -> 502[ca000] via P2P/IPC/read
311: hkn0630:1605706:1605807 [3] NCCL INFO Channel 00 : 311[e3000] -> 310[ca000] via P2P/IPC/read
275: hkn0617:2301957:2302052 [3] NCCL INFO Channel 00 : 275[e3000] -> 274[ca000] via P2P/IPC/read
 47: hkn0415:2503663:2503759 [3] NCCL INFO Channel 00 : 47[e3000] -> 46[ca000] via P2P/IPC/read
187: hkn0527:1356160:1356277 [3] NCCL INFO Connected all rings
411: hkn0723:215353:215498 [3] NCCL INFO Connected all rings
495: hkn0810:946744:946866 [3] NCCL INFO Channel 00 : 495[e3000] -> 494[ca000] via P2P/IPC/read
391: hkn0717:1459:1584 [3] NCCL INFO Channel 01 : 391[e3000] -> 390[ca000] via P2P/IPC/read
219: hkn0601:124976:125081 [3] NCCL INFO Channel 01 : 219[e3000] -> 218[ca000] via P2P/IPC/read
 11: hkn0405:3214162:3214281 [3] NCCL INFO Channel 00 : 11[e3000] -> 10[ca000] via P2P/IPC/read
387: hkn0716:115727:115858 [3] NCCL INFO Channel 01 : 387[e3000] -> 386[ca000] via P2P/IPC/read
504: hkn0815:402353:402445 [0] NCCL INFO Channel 01 : 504[31000] -> 507[e3000] via P2P/IPC/read
455: hkn0736:1515543:1515649 [3] NCCL INFO Connected all rings
355: hkn0707:4027153:4027260 [3] NCCL INFO Channel 00 : 355[e3000] -> 354[ca000] via P2P/IPC/read
 39: hkn0413:2373932:2374059 [3] NCCL INFO Channel 01 : 39[e3000] -> 38[ca000] via P2P/IPC/read
203: hkn0531:1237894:1238018 [3] NCCL INFO Connected all rings
395: hkn0718:3924254:3924371 [3] NCCL INFO Connected all rings
283: hkn0622:2027736:2027858 [3] NCCL INFO Connected all rings
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
487: hkn0808:977909:978016 [3] NCCL INFO Channel 01 : 487[e3000] -> 486[ca000] via P2P/IPC/read
287: hkn0623:1879987:1880116 [3] NCCL INFO Channel 00 : 287[e3000] -> 286[ca000] via P2P/IPC/read
435: hkn0730:1408947:1409077 [3] NCCL INFO Connected all rings
463: hkn0802:1207551:1207689 [3] NCCL INFO Connected all rings
 23: hkn0409:2592874:2592989 [3] NCCL INFO Connected all rings
147: hkn0513:3020216:3020303 [3] NCCL INFO Channel 00 : 147[e3000] -> 146[ca000] via P2P/IPC/read
483: hkn0807:1026305:1026402 [3] NCCL INFO Connected all rings
259: hkn0612:924215:924321 [3] NCCL INFO Connected all rings
  3: hkn0403:1776560:1776937 [3] NCCL INFO Channel 01 : 3[e3000] -> 2[ca000] via P2P/IPC/read
499: hkn0812:701057:701148 [3] NCCL INFO Channel 01 : 499[e3000] -> 498[ca000] via P2P/IPC/read
431: hkn0728:1331257:1331376 [3] NCCL INFO Connected all rings
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 01 : 328[31000] -> 331[e3000] via P2P/IPC/read
403: hkn0720:14330:14481 [3] NCCL INFO Channel 00 : 403[e3000] -> 402[ca000] via P2P/IPC/read
319: hkn0632:1765859:1765969 [3] NCCL INFO Channel 01 : 319[e3000] -> 318[ca000] via P2P/IPC/read
295: hkn0626:1305656:1305785 [3] NCCL INFO Connected all rings
 35: hkn0412:2269608:2269737 [3] NCCL INFO Channel 01 : 35[e3000] -> 34[ca000] via P2P/IPC/read
427: hkn0727:1353022:1353120 [3] NCCL INFO Connected all rings
235: hkn0605:719372:719467 [3] NCCL INFO Connected all rings
243: hkn0607:911615:911710 [3] NCCL INFO Channel 01 : 243[e3000] -> 242[ca000] via P2P/IPC/read
343: hkn0704:799231:799343 [3] NCCL INFO Channel 01 : 343[e3000] -> 342[ca000] via P2P/IPC/read
363: hkn0710:362780:362887 [3] NCCL INFO Channel 01 : 363[e3000] -> 362[ca000] via P2P/IPC/read
  7: hkn0404:1346645:1346762 [3] NCCL INFO Channel 01 : 7[e3000] -> 6[ca000] via P2P/IPC/read
503: hkn0814:683031:683177 [3] NCCL INFO Channel 01 : 503[e3000] -> 502[ca000] via P2P/IPC/read
311: hkn0630:1605706:1605807 [3] NCCL INFO Channel 01 : 311[e3000] -> 310[ca000] via P2P/IPC/read
339: hkn0703:748311:748409 [3] NCCL INFO Channel 00 : 339[e3000] -> 338[ca000] via P2P/IPC/read
 47: hkn0415:2503663:2503759 [3] NCCL INFO Channel 01 : 47[e3000] -> 46[ca000] via P2P/IPC/read
471: hkn0804:1212857:1212971 [3] NCCL INFO Connected all rings
423: hkn0726:1555329:1555441 [3] NCCL INFO Connected all rings
511: hkn0816:382835:382955 [3] NCCL INFO Connected all rings
407: hkn0721:2306506:2306615 [3] NCCL INFO Connected all rings
275: hkn0617:2301957:2302052 [3] NCCL INFO Channel 01 : 275[e3000] -> 274[ca000] via P2P/IPC/read
 11: hkn0405:3214162:3214281 [3] NCCL INFO Channel 01 : 11[e3000] -> 10[ca000] via P2P/IPC/read
495: hkn0810:946744:946866 [3] NCCL INFO Channel 01 : 495[e3000] -> 494[ca000] via P2P/IPC/read
251: hkn0609:718044:718148 [3] NCCL INFO Connected all rings
299: hkn0627:1795186:1795268 [3] NCCL INFO Connected all rings
 67: hkn0421:2189234:2189409 [3] NCCL INFO Connected all rings
375: hkn0713:477460:477578 [3] NCCL INFO Connected all rings
239: hkn0606:2379367:2379465 [3] NCCL INFO Connected all rings
355: hkn0707:4027153:4027260 [3] NCCL INFO Channel 01 : 355[e3000] -> 354[ca000] via P2P/IPC/read
255: hkn0611:717043:717161 [3] NCCL INFO Connected all rings
207: hkn0532:932502:932816 [3] NCCL INFO Connected all rings
287: hkn0623:1879987:1880116 [3] NCCL INFO Channel 01 : 287[e3000] -> 286[ca000] via P2P/IPC/read
467: hkn0803:883807:883885 [3] NCCL INFO Connected all rings
 19: hkn0408:2898037:2898154 [3] NCCL INFO Connected all rings
271: hkn0616:412189:412285 [3] NCCL INFO Connected all rings
307: hkn0629:1599276:1599401 [3] NCCL INFO Connected all rings
371: hkn0712:302309:302405 [3] NCCL INFO Connected all rings
323: hkn0633:1533566:1533658 [3] NCCL INFO Connected all rings
315: hkn0631:1029032:1029141 [3] NCCL INFO Connected all rings
403: hkn0720:14330:14481 [3] NCCL INFO Channel 01 : 403[e3000] -> 402[ca000] via P2P/IPC/read
 27: hkn0410:1166917:1167039 [3] NCCL INFO Connected all rings
279: hkn0621:1998830:1998944 [3] NCCL INFO Connected all rings
415: hkn0724:1723198:1723323 [3] NCCL INFO Connected all rings
339: hkn0703:748311:748409 [3] NCCL INFO Channel 01 : 339[e3000] -> 338[ca000] via P2P/IPC/read
 51: hkn0417:2274868:2274989 [3] NCCL INFO Connected all rings
347: hkn0705:790423:790536 [3] NCCL INFO Connected all rings
 55: hkn0418:1876416:1876509 [3] NCCL INFO Connected all rings
383: hkn0715:409110:409235 [3] NCCL INFO Connected all rings
127: hkn0508:3146366:3146462 [3] NCCL INFO Connected all rings
327: hkn0634:1528094:1528189 [3] NCCL INFO Connected all rings
391: hkn0717:1459:1584 [3] NCCL INFO Connected all rings
351: hkn0706:759486:759602 [3] NCCL INFO Connected all rings
219: hkn0601:124976:125081 [3] NCCL INFO Connected all rings
 83: hkn0425:2091271:2091395 [3] NCCL INFO Channel 00 : 83[e3000] -> 82[ca000] via P2P/IPC/read
 39: hkn0413:2373932:2374059 [3] NCCL INFO Connected all rings
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 00 : 60[31000] -> 63[e3000] via P2P/IPC/read
147: hkn0513:3020216:3020303 [3] NCCL INFO Channel 01 : 147[e3000] -> 146[ca000] via P2P/IPC/read
487: hkn0808:977909:978016 [3] NCCL INFO Connected all rings
387: hkn0716:115727:115858 [3] NCCL INFO Connected all rings
  3: hkn0403:1776560:1776937 [3] NCCL INFO Connected all rings
499: hkn0812:701057:701148 [3] NCCL INFO Connected all rings
319: hkn0632:1765859:1765969 [3] NCCL INFO Connected all rings
 35: hkn0412:2269608:2269737 [3] NCCL INFO Connected all rings
 15: hkn0407:1823508:1823614 [3] NCCL INFO Channel 00 : 15[e3000] -> 14[ca000] via P2P/IPC/read
243: hkn0607:911615:911710 [3] NCCL INFO Connected all rings
335: hkn0636:1661521:1661639 [3] NCCL INFO Connected all rings
343: hkn0704:799231:799343 [3] NCCL INFO Connected all rings
  7: hkn0404:1346645:1346762 [3] NCCL INFO Connected all rings
503: hkn0814:683031:683177 [3] NCCL INFO Connected all rings
363: hkn0710:362780:362887 [3] NCCL INFO Connected all rings
275: hkn0617:2301957:2302052 [3] NCCL INFO Connected all rings
 47: hkn0415:2503663:2503759 [3] NCCL INFO Connected all rings
495: hkn0810:946744:946866 [3] NCCL INFO Connected all rings
311: hkn0630:1605706:1605807 [3] NCCL INFO Connected all rings
359: hkn0708:420470:420564 [3] NCCL INFO Connected all rings
215: hkn0535:2406222:2406330 [3] NCCL INFO Channel 00 : 215[e3000] -> 214[ca000] via P2P/IPC/read
 11: hkn0405:3214162:3214281 [3] NCCL INFO Connected all rings
 83: hkn0425:2091271:2091395 [3] NCCL INFO Channel 01 : 83[e3000] -> 82[ca000] via P2P/IPC/read
355: hkn0707:4027153:4027260 [3] NCCL INFO Connected all rings
287: hkn0623:1879987:1880116 [3] NCCL INFO Connected all rings
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 01 : 60[31000] -> 63[e3000] via P2P/IPC/read
443: hkn0732:1218882:1219000 [3] NCCL INFO Channel 00 : 443[e3000] -> 442[ca000] via P2P/IPC/read
 15: hkn0407:1823508:1823614 [3] NCCL INFO Channel 01 : 15[e3000] -> 14[ca000] via P2P/IPC/read
403: hkn0720:14330:14481 [3] NCCL INFO Connected all rings
419: hkn0725:3119172:3119282 [3] NCCL INFO Channel 00 : 419[e3000] -> 418[ca000] via P2P/IPC/read
215: hkn0535:2406222:2406330 [3] NCCL INFO Channel 01 : 215[e3000] -> 214[ca000] via P2P/IPC/read
 31: hkn0411:2323097:2323204 [3] NCCL INFO Channel 00 : 31[e3000] -> 30[ca000] via P2P/IPC/read
133: hkn0510:2769286:2769390 [1] NCCL INFO Connected all rings
339: hkn0703:748311:748409 [3] NCCL INFO Connected all rings
443: hkn0732:1218882:1219000 [3] NCCL INFO Channel 01 : 443[e3000] -> 442[ca000] via P2P/IPC/read
419: hkn0725:3119172:3119282 [3] NCCL INFO Channel 01 : 419[e3000] -> 418[ca000] via P2P/IPC/read
 31: hkn0411:2323097:2323204 [3] NCCL INFO Channel 01 : 31[e3000] -> 30[ca000] via P2P/IPC/read
147: hkn0513:3020216:3020303 [3] NCCL INFO Connected all rings
379: hkn0714:439265:439360 [3] NCCL INFO Channel 00 : 379[e3000] -> 378[ca000] via P2P/IPC/read
 83: hkn0425:2091271:2091395 [3] NCCL INFO Connected all rings
507: hkn0815:402329:402444 [3] NCCL INFO Channel 00 : 507[e3000] -> 506[ca000] via P2P/IPC/read
116: hkn0506:845312:845412 [0] NCCL INFO Connected all rings
331: hkn0635:1232814:1232915 [3] NCCL INFO Channel 00 : 331[e3000] -> 330[ca000] via P2P/IPC/read
 15: hkn0407:1823508:1823614 [3] NCCL INFO Connected all rings
379: hkn0714:439265:439360 [3] NCCL INFO Channel 01 : 379[e3000] -> 378[ca000] via P2P/IPC/read
215: hkn0535:2406222:2406330 [3] NCCL INFO Connected all rings
113: hkn0505:2311005:2311114 [1] NCCL INFO Connected all rings
164: hkn0521:1205016:1205137 [0] NCCL INFO Connected all rings
507: hkn0815:402329:402444 [3] NCCL INFO Channel 01 : 507[e3000] -> 506[ca000] via P2P/IPC/read
331: hkn0635:1232814:1232915 [3] NCCL INFO Channel 01 : 331[e3000] -> 330[ca000] via P2P/IPC/read
161: hkn0520:2720094:2720215 [1] NCCL INFO Connected all rings
173: hkn0524:1141002:1141130 [1] NCCL INFO Connected all rings
443: hkn0732:1218882:1219000 [3] NCCL INFO Connected all rings
419: hkn0725:3119172:3119282 [3] NCCL INFO Connected all rings
136: hkn0511:3073654:3073767 [0] NCCL INFO Connected all rings
134: hkn0510:2769278:2769396 [2] NCCL INFO Connected all rings
148: hkn0514:2957971:2958065 [0] NCCL INFO Connected all rings
160: hkn0520:2720114:2720212 [0] NCCL INFO Connected all rings
101: hkn0502:236287:236411 [1] NCCL INFO Connected all rings
 31: hkn0411:2323097:2323204 [3] NCCL INFO Connected all rings
108: hkn0504:48339:48431 [0] NCCL INFO Connected all rings
104: hkn0503:2906963:2907057 [0] NCCL INFO Connected all rings
117: hkn0506:845300:845411 [1] NCCL INFO Connected all rings
112: hkn0505:2311025:2311118 [0] NCCL INFO Connected all rings
165: hkn0521:1205024:1205132 [1] NCCL INFO Connected all rings
 93: hkn0428:674567:674696 [1] NCCL INFO Connected all rings
379: hkn0714:439265:439360 [3] NCCL INFO Connected all rings
100: hkn0502:236295:236412 [0] NCCL INFO Connected all rings
152: hkn0515:2904005:2904143 [0] NCCL INFO Connected all rings
105: hkn0503:2906935:2907063 [1] NCCL INFO Connected all rings
125: hkn0508:3146338:3146460 [1] NCCL INFO Connected all rings
 92: hkn0428:674583:674690 [0] NCCL INFO Connected all rings
156: hkn0516:2923204:2923321 [0] NCCL INFO Connected all rings
507: hkn0815:402329:402444 [3] NCCL INFO Connected all rings
153: hkn0515:2903997:2904149 [1] NCCL INFO Connected all rings
 96: hkn0501:1335139:1335266 [0] NCCL INFO Connected all rings
331: hkn0635:1232814:1232915 [3] NCCL INFO Connected all rings
157: hkn0516:2923212:2923315 [1] NCCL INFO Connected all rings
168: hkn0523:1555352:1555443 [0] NCCL INFO Connected all rings
172: hkn0524:1141018:1141124 [0] NCCL INFO Connected all rings
109: hkn0504:48319:48430 [1] NCCL INFO Connected all rings
137: hkn0511:3073646:3073768 [1] NCCL INFO Connected all rings
162: hkn0520:2720086:2720209 [2] NCCL INFO Connected all rings
 88: hkn0427:1142349:1142466 [0] NCCL INFO Connected all rings
114: hkn0505:2311013:2311117 [2] NCCL INFO Connected all rings
 68: hkn0422:4160376:4160473 [0] NCCL INFO Connected all rings
128: hkn0509:3131628:3131753 [0] NCCL INFO Connected all rings
174: hkn0524:1141010:1141129 [2] NCCL INFO Connected all rings
 72: hkn0423:1712171:1712286 [0] NCCL INFO Connected all rings
 63: hkn0420:3217400:3217555 [3] NCCL INFO Channel 00 : 63[e3000] -> 62[ca000] via P2P/IPC/read
 59: hkn0419:1551517:1551600 [3] NCCL INFO Channel 00 : 59[e3000] -> 58[ca000] via P2P/IPC/read
260: hkn0613:909924:910036 [0] NCCL INFO Connected all rings
145: hkn0513:3020188:3020302 [1] NCCL INFO Connected all rings
184: hkn0527:1356168:1356280 [0] NCCL INFO Connected all rings
205: hkn0532:932522:932818 [1] NCCL INFO Connected all rings
185: hkn0527:1356176:1356285 [1] NCCL INFO Connected all rings
149: hkn0514:2957959:2958071 [1] NCCL INFO Connected all rings
 94: hkn0428:674575:674691 [2] NCCL INFO Connected all rings
 69: hkn0422:4160356:4160471 [1] NCCL INFO Connected all rings
132: hkn0510:2769270:2769395 [0] NCCL INFO Connected all rings
102: hkn0502:236315:236406 [2] NCCL INFO Connected all rings
444: hkn0733:1396588:1396702 [0] NCCL INFO Connected all rings
 85: hkn0426:821286:821409 [1] NCCL INFO Connected all rings
 59: hkn0419:1551517:1551600 [3] NCCL INFO Channel 01 : 59[e3000] -> 58[ca000] via P2P/IPC/read
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 00 : 160[31000] -> 161[4b000] via P2P/IPC/read
 97: hkn0501:1335155:1335273 [1] NCCL INFO Connected all rings
445: hkn0733:1396580:1396694 [1] NCCL INFO Connected all rings
448: hkn0734:1163761:1163871 [0] NCCL INFO Connected all rings
 89: hkn0427:1142369:1142461 [1] NCCL INFO Connected all rings
133: hkn0510:2769286:2769390 [1] NCCL INFO Channel 00 : 133[4b000] -> 134[ca000] via P2P/IPC/read
169: hkn0523:1555324:1555450 [1] NCCL INFO Connected all rings
405: hkn0721:2306514:2306619 [1] NCCL INFO Connected all rings
392: hkn0718:3924246:3924376 [0] NCCL INFO Connected all rings
224: hkn0603:1420450:1420575 [0] NCCL INFO Connected all rings
181: hkn0526:1435629:1435751 [1] NCCL INFO Connected all rings
469: hkn0804:1212849:1212967 [1] NCCL INFO Connected all rings
256: hkn0612:924207:924324 [0] NCCL INFO Connected all rings
452: hkn0736:1515544:1515654 [0] NCCL INFO Connected all rings
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 00 : 112[31000] -> 113[4b000] via P2P/IPC/read
118: hkn0506:845292:845415 [2] NCCL INFO Connected all rings
126: hkn0508:3146354:3146461 [2] NCCL INFO Connected all rings
166: hkn0521:1205036:1205135 [2] NCCL INFO Connected all rings
217: hkn0601:124968:125085 [1] NCCL INFO Connected all rings
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 00 : 128[31000] -> 129[4b000] via P2P/IPC/read
196: hkn0530:1265359:1265466 [0] NCCL INFO Connected all rings
257: hkn0612:924227:924322 [1] NCCL INFO Connected all rings
453: hkn0736:1515557:1515653 [1] NCCL INFO Connected all rings
116: hkn0506:845312:845412 [0] NCCL INFO Channel 00 : 116[31000] -> 117[4b000] via P2P/IPC/read
 63: hkn0420:3217400:3217555 [3] NCCL INFO Channel 01 : 63[e3000] -> 62[ca000] via P2P/IPC/read
220: hkn0602:3370918:3371090 [0] NCCL INFO Connected all rings
176: hkn0525:994034:994135 [0] NCCL INFO Connected all rings
232: hkn0605:719349:719471 [0] NCCL INFO Connected all rings
120: hkn0507:3194293:3194413 [0] NCCL INFO Connected all rings
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 00 : 164[31000] -> 165[4b000] via P2P/IPC/read
106: hkn0503:2906951:2907055 [2] NCCL INFO Connected all rings
261: hkn0613:909944:910037 [1] NCCL INFO Connected all rings
221: hkn0602:3370890:3371086 [1] NCCL INFO Connected all rings
245: hkn0608:492963:493070 [1] NCCL INFO Connected all rings
138: hkn0511:3073676:3073772 [2] NCCL INFO Connected all rings
228: hkn0604:696478:696578 [0] NCCL INFO Connected all rings
432: hkn0730:1408963:1409072 [0] NCCL INFO Connected all rings
 64: hkn0421:2189212:2189407 [0] NCCL INFO Connected all rings
100: hkn0502:236295:236412 [0] NCCL INFO Channel 00 : 100[31000] -> 101[4b000] via P2P/IPC/read
368: hkn0712:302297:302400 [0] NCCL INFO Connected all rings
200: hkn0531:1237922:1238019 [0] NCCL INFO Connected all rings
477: hkn0806:1061538:1061645 [1] NCCL INFO Connected all rings
248: hkn0609:718056:718153 [0] NCCL INFO Connected all rings
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 00 : 172[31000] -> 173[4b000] via P2P/IPC/read
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 00 : 92[31000] -> 93[4b000] via P2P/IPC/read
456: hkn0801:2247272:2247387 [0] NCCL INFO Connected all rings
 37: hkn0413:2373940:2374062 [1] NCCL INFO Connected all rings
425: hkn0727:1353010:1353119 [1] NCCL INFO Connected all rings
154: hkn0515:2904025:2904145 [2] NCCL INFO Connected all rings
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 00 : 104[31000] -> 105[4b000] via P2P/IPC/read
509: hkn0816:382855:382951 [1] NCCL INFO Connected all rings
 81: hkn0425:2091299:2091397 [1] NCCL INFO Connected all rings
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 00 : 136[31000] -> 137[4b000] via P2P/IPC/read
460: hkn0802:1207543:1207697 [0] NCCL INFO Connected all rings
204: hkn0532:932494:932817 [0] NCCL INFO Connected all rings
158: hkn0516:2923196:2923320 [2] NCCL INFO Connected all rings
252: hkn0611:717035:717164 [0] NCCL INFO Connected all rings
393: hkn0718:3924262:3924378 [1] NCCL INFO Connected all rings
140: hkn0512:3051343:3051451 [0] NCCL INFO Connected all rings
408: hkn0723:215341:215495 [0] NCCL INFO Connected all rings
193: hkn0529:1548066:1548163 [1] NCCL INFO Connected all rings
468: hkn0804:1212869:1212968 [0] NCCL INFO Connected all rings
225: hkn0603:1420458:1420572 [1] NCCL INFO Connected all rings
369: hkn0712:302289:302403 [1] NCCL INFO Connected all rings
420: hkn0726:1555321:1555442 [0] NCCL INFO Connected all rings
253: hkn0611:717051:717160 [1] NCCL INFO Connected all rings
388: hkn0717:1467:1586 [0] NCCL INFO Connected all rings
428: hkn0728:1331278:1331370 [0] NCCL INFO Connected all rings
 65: hkn0421:2189204:2189405 [1] NCCL INFO Connected all rings
 73: hkn0423:1712163:1712288 [1] NCCL INFO Connected all rings
146: hkn0513:3020196:3020300 [2] NCCL INFO Connected all rings
186: hkn0527:1356188:1356283 [2] NCCL INFO Connected all rings
110: hkn0504:48311:48436 [2] NCCL INFO Connected all rings
249: hkn0609:718036:718147 [1] NCCL INFO Connected all rings
197: hkn0530:1265371:1265467 [1] NCCL INFO Connected all rings
 17: hkn0408:2898045:2898159 [1] NCCL INFO Connected all rings
292: hkn0626:1305637:1305778 [0] NCCL INFO Connected all rings
 20: hkn0409:2592866:2592990 [0] NCCL INFO Connected all rings
288: hkn0624:1780140:1780284 [0] NCCL INFO Connected all rings
 86: hkn0426:821274:821408 [2] NCCL INFO Connected all rings
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 01 : 128[31000] -> 129[4b000] via P2P/IPC/read
 59: hkn0419:1551517:1551600 [3] NCCL INFO Connected all rings
108: hkn0504:48339:48431 [0] NCCL INFO Channel 00 : 108[31000] -> 109[4b000] via P2P/IPC/read
404: hkn0721:2306526:2306622 [0] NCCL INFO Connected all rings
150: hkn0514:2957943:2958073 [2] NCCL INFO Connected all rings
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 00 : 152[31000] -> 153[4b000] via P2P/IPC/read
293: hkn0626:1305645:1305779 [1] NCCL INFO Connected all rings
480: hkn0807:1026285:1026406 [0] NCCL INFO Connected all rings
424: hkn0727:1353001:1353114 [0] NCCL INFO Connected all rings
264: hkn0615:421550:421660 [0] NCCL INFO Connected all rings
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 00 : 148[31000] -> 149[4b000] via P2P/IPC/read
  0: hkn0403:1776559:1776930 [0] NCCL INFO Connected all rings
206: hkn0532:932510:932820 [2] NCCL INFO Connected all rings
508: hkn0816:382834:382958 [0] NCCL INFO Connected all rings
341: hkn0704:799223:799342 [1] NCCL INFO Connected all rings
176: hkn0525:994034:994135 [0] NCCL INFO Channel 00 : 176[31000] -> 177[4b000] via P2P/IPC/read
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 00 : 132[31000] -> 133[4b000] via P2P/IPC/read
433: hkn0730:1408955:1409068 [1] NCCL INFO Connected all rings
 36: hkn0413:2373960:2374058 [0] NCCL INFO Connected all rings
229: hkn0604:696459:696573 [1] NCCL INFO Connected all rings
233: hkn0605:719360:719472 [1] NCCL INFO Connected all rings
429: hkn0728:1331258:1331374 [1] NCCL INFO Connected all rings
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 00 : 156[31000] -> 157[4b000] via P2P/IPC/read
213: hkn0535:2406206:2406337 [1] NCCL INFO Connected all rings
449: hkn0734:1163753:1163873 [1] NCCL INFO Connected all rings
276: hkn0621:1998822:1998945 [0] NCCL INFO Connected all rings
320: hkn0633:1533538:1533659 [0] NCCL INFO Connected all rings
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 01 : 160[31000] -> 161[4b000] via P2P/IPC/read
134: hkn0510:2769278:2769396 [2] NCCL INFO Channel 00 : 134[ca000] -> 135[e3000] via P2P/IPC/read
389: hkn0717:1475:1580 [1] NCCL INFO Connected all rings
216: hkn0601:124960:125086 [0] NCCL INFO Connected all rings
484: hkn0808:977921:978021 [0] NCCL INFO Connected all rings
133: hkn0510:2769286:2769390 [1] NCCL INFO Channel 01 : 133[4b000] -> 134[ca000] via P2P/IPC/read
457: hkn0801:2247291:2247389 [1] NCCL INFO Connected all rings
277: hkn0621:1998849:1998946 [1] NCCL INFO Connected all rings
 32: hkn0412:2269616:2269733 [0] NCCL INFO Connected all rings
236: hkn0606:2379339:2379462 [0] NCCL INFO Connected all rings
188: hkn0528:1308911:1309016 [0] NCCL INFO Connected all rings
124: hkn0508:3146346:3146464 [0] NCCL INFO Connected all rings
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 01 : 112[31000] -> 113[4b000] via P2P/IPC/read
401: hkn0720:14318:14478 [1] NCCL INFO Connected all rings
121: hkn0507:3194285:3194409 [1] NCCL INFO Connected all rings
180: hkn0526:1435645:1435749 [0] NCCL INFO Connected all rings
365: hkn0711:591174:591286 [1] NCCL INFO Connected all rings
285: hkn0623:1880003:1880109 [1] NCCL INFO Connected all rings
380: hkn0715:409126:409232 [0] NCCL INFO Connected all rings
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 00 : 184[31000] -> 185[4b000] via P2P/IPC/read
201: hkn0531:1237902:1238024 [1] NCCL INFO Connected all rings
116: hkn0506:845312:845412 [0] NCCL INFO Channel 01 : 116[31000] -> 117[4b000] via P2P/IPC/read
409: hkn0723:215333:215489 [1] NCCL INFO Connected all rings
488: hkn0809:944559:944660 [0] NCCL INFO Connected all rings
182: hkn0526:1435637:1435754 [2] NCCL INFO Connected all rings
340: hkn0704:799215:799344 [0] NCCL INFO Connected all rings
441: hkn0732:1218890:1218999 [1] NCCL INFO Connected all rings
 98: hkn0501:1335167:1335267 [2] NCCL INFO Connected all rings
268: hkn0616:412169:412281 [0] NCCL INFO Connected all rings
301: hkn0628:679147:679253 [1] NCCL INFO Connected all rings
446: hkn0733:1396572:1396700 [2] NCCL INFO Connected all rings
 70: hkn0422:4160364:4160469 [2] NCCL INFO Connected all rings
237: hkn0606:2379347:2379461 [1] NCCL INFO Connected all rings
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 00 : 140[31000] -> 141[4b000] via P2P/IPC/read
470: hkn0804:1212841:1212966 [2] NCCL INFO Connected all rings
406: hkn0721:2306498:2306623 [2] NCCL INFO Connected all rings
357: hkn0708:420450:420563 [1] NCCL INFO Connected all rings
464: hkn0803:883779:883891 [0] NCCL INFO Connected all rings
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 01 : 164[31000] -> 165[4b000] via P2P/IPC/read
400: hkn0720:14302:14479 [0] NCCL INFO Connected all rings
218: hkn0601:124988:125082 [2] NCCL INFO Connected all rings
280: hkn0622:2027764:2027860 [0] NCCL INFO Connected all rings
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 00 : 96[31000] -> 97[4b000] via P2P/IPC/read
 48: hkn0417:2274888:2274985 [0] NCCL INFO Connected all rings
385: hkn0716:115707:115856 [1] NCCL INFO Connected all rings
496: hkn0812:701027:701151 [0] NCCL INFO Connected all rings
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 00 : 68[31000] -> 69[4b000] via P2P/IPC/read
317: hkn0632:1765843:1765966 [1] NCCL INFO Connected all rings
 90: hkn0427:1142341:1142458 [2] NCCL INFO Connected all rings
284: hkn0623:1880015:1880110 [0] NCCL INFO Connected all rings
273: hkn0617:2301927:2302047 [1] NCCL INFO Connected all rings
 29: hkn0411:2323109:2323200 [1] NCCL INFO Connected all rings
170: hkn0523:1555340:1555444 [2] NCCL INFO Connected all rings
417: hkn0725:3119163:3119280 [1] NCCL INFO Connected all rings
194: hkn0529:1548054:1548165 [2] NCCL INFO Connected all rings
304: hkn0629:1599292:1599400 [0] NCCL INFO Connected all rings
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 00 : 113[4b000] -> 114[ca000] via P2P/IPC/read
100: hkn0502:236295:236412 [0] NCCL INFO Channel 01 : 100[31000] -> 101[4b000] via P2P/IPC/read
 33: hkn0412:2269624:2269736 [1] NCCL INFO Connected all rings
 74: hkn0423:1712179:1712289 [2] NCCL INFO Connected all rings
421: hkn0726:1555337:1555444 [1] NCCL INFO Connected all rings
381: hkn0715:409138:409236 [1] NCCL INFO Connected all rings
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 01 : 172[31000] -> 173[4b000] via P2P/IPC/read
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 01 : 92[31000] -> 93[4b000] via P2P/IPC/read
396: hkn0719:1312979:1313087 [0] NCCL INFO Connected all rings
481: hkn0807:1026277:1026401 [1] NCCL INFO Connected all rings
492: hkn0810:946764:946863 [0] NCCL INFO Connected all rings
472: hkn0805:1119345:1119447 [0] NCCL INFO Connected all rings
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 00 : 88[31000] -> 89[4b000] via P2P/IPC/read
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 00 : 168[31000] -> 169[4b000] via P2P/IPC/read
321: hkn0633:1533546:1533662 [1] NCCL INFO Connected all rings
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 01 : 104[31000] -> 105[4b000] via P2P/IPC/read
176: hkn0525:994034:994135 [0] NCCL INFO Channel 01 : 176[31000] -> 177[4b000] via P2P/IPC/read
461: hkn0802:1207571:1207691 [1] NCCL INFO Connected all rings
454: hkn0736:1515545:1515656 [2] NCCL INFO Connected all rings
312: hkn0631:1029044:1029136 [0] NCCL INFO Connected all rings
246: hkn0608:492947:493073 [2] NCCL INFO Connected all rings
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 00 : 161[4b000] -> 162[ca000] via P2P/IPC/read
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 01 : 136[31000] -> 137[4b000] via P2P/IPC/read
258: hkn0612:924199:924320 [2] NCCL INFO Connected all rings
289: hkn0624:1780160:1780285 [1] NCCL INFO Connected all rings
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 01 : 132[31000] -> 133[4b000] via P2P/IPC/read
 63: hkn0420:3217400:3217555 [3] NCCL INFO Connected all rings
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 00 : 444[31000] -> 445[4b000] via P2P/IPC/read
485: hkn0808:977901:978022 [1] NCCL INFO Connected all rings
  4: hkn0404:1346644:1346761 [0] NCCL INFO Connected all rings
478: hkn0806:1061550:1061649 [2] NCCL INFO Connected all rings
 49: hkn0417:2274876:2274980 [1] NCCL INFO Connected all rings
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 00 : 72[31000] -> 73[4b000] via P2P/IPC/read
208: hkn0534:1155640:1155748 [0] NCCL INFO Connected all rings
309: hkn0630:1605694:1605798 [1] NCCL INFO Connected all rings
262: hkn0613:909916:910043 [2] NCCL INFO Connected all rings
134: hkn0510:2769278:2769396 [2] NCCL INFO Channel 01 : 134[ca000] -> 135[e3000] via P2P/IPC/read
384: hkn0716:115715:115850 [0] NCCL INFO Connected all rings
 21: hkn0409:2592894:2592992 [1] NCCL INFO Connected all rings
 82: hkn0425:2091279:2091402 [2] NCCL INFO Connected all rings
 66: hkn0421:2189220:2189406 [2] NCCL INFO Connected all rings
265: hkn0615:421570:421665 [1] NCCL INFO Connected all rings
349: hkn0706:759478:759608 [1] NCCL INFO Connected all rings
222: hkn0602:3370898:3371093 [2] NCCL INFO Connected all rings
 44: hkn0415:2503651:2503760 [0] NCCL INFO Connected all rings
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 01 : 152[31000] -> 153[4b000] via P2P/IPC/read
108: hkn0504:48339:48431 [0] NCCL INFO Channel 01 : 108[31000] -> 109[4b000] via P2P/IPC/read
344: hkn0705:790415:790543 [0] NCCL INFO Connected all rings
260: hkn0613:909924:910036 [0] NCCL INFO Channel 00 : 260[31000] -> 261[4b000] via P2P/IPC/read
204: hkn0532:932494:932817 [0] NCCL INFO Channel 00 : 204[31000] -> 205[4b000] via P2P/IPC/read
336: hkn0703:748295:748408 [0] NCCL INFO Connected all rings
316: hkn0632:1765871:1765970 [0] NCCL INFO Connected all rings
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 00 : 173[4b000] -> 174[ca000] via P2P/IPC/read
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 00 : 188[31000] -> 189[4b000] via P2P/IPC/read
 38: hkn0413:2373948:2374057 [2] NCCL INFO Connected all rings
510: hkn0816:382843:382953 [2] NCCL INFO Connected all rings
305: hkn0629:1599304:1599395 [1] NCCL INFO Connected all rings
377: hkn0714:439253:439365 [1] NCCL INFO Connected all rings
272: hkn0617:2301945:2302053 [0] NCCL INFO Connected all rings
 84: hkn0426:821266:821410 [0] NCCL INFO Connected all rings
  1: hkn0403:1776565:1776936 [1] NCCL INFO Connected all rings
426: hkn0727:1353002:1353113 [2] NCCL INFO Connected all rings
337: hkn0703:748303:748410 [1] NCCL INFO Connected all rings
192: hkn0529:1548046:1548160 [0] NCCL INFO Connected all rings
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 01 : 148[31000] -> 149[4b000] via P2P/IPC/read
 45: hkn0415:2503635:2503763 [1] NCCL INFO Connected all rings
101: hkn0502:236287:236411 [1] NCCL INFO Channel 00 : 101[4b000] -> 102[ca000] via P2P/IPC/read
162: hkn0520:2720086:2720209 [2] NCCL INFO Channel 00 : 162[ca000] -> 163[e3000] via P2P/IPC/read
505: hkn0815:402333:402447 [1] NCCL INFO Connected all rings
256: hkn0612:924207:924324 [0] NCCL INFO Channel 00 : 256[31000] -> 257[4b000] via P2P/IPC/read
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 00 : 452[31000] -> 453[4b000] via P2P/IPC/read
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 01 : 156[31000] -> 157[4b000] via P2P/IPC/read
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 00 : 125[4b000] -> 126[ca000] via P2P/IPC/read
493: hkn0810:946752:946862 [1] NCCL INFO Connected all rings
497: hkn0812:701035:701150 [1] NCCL INFO Connected all rings
394: hkn0718:3924274:3924372 [2] NCCL INFO Connected all rings
114: hkn0505:2311013:2311117 [2] NCCL INFO Channel 00 : 114[ca000] -> 115[e3000] via P2P/IPC/read
281: hkn0622:2027752:2027859 [1] NCCL INFO Connected all rings
370: hkn0712:302281:302408 [2] NCCL INFO Connected all rings
372: hkn0713:477480:477575 [0] NCCL INFO Connected all rings
390: hkn0717:1487:1589 [2] NCCL INFO Connected all rings
308: hkn0630:1605678:1605803 [0] NCCL INFO Connected all rings
 18: hkn0408:2898057:2898153 [2] NCCL INFO Connected all rings
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 00 : 468[31000] -> 469[4b000] via P2P/IPC/read
254: hkn0611:717063:717166 [2] NCCL INFO Connected all rings
  5: hkn0404:1346653:1346760 [1] NCCL INFO Connected all rings
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 00 : 404[31000] -> 405[4b000] via P2P/IPC/read
442: hkn0732:1218881:1219002 [2] NCCL INFO Connected all rings
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 00 : 93[4b000] -> 94[ca000] via P2P/IPC/read
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 00 : 392[31000] -> 393[4b000] via P2P/IPC/read
226: hkn0603:1420466:1420571 [2] NCCL INFO Connected all rings
240: hkn0607:911595:911709 [0] NCCL INFO Connected all rings
244: hkn0608:492975:493069 [0] NCCL INFO Connected all rings
 16: hkn0408:2898029:2898160 [0] NCCL INFO Connected all rings
269: hkn0616:412177:412290 [1] NCCL INFO Connected all rings
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 00 : 220[31000] -> 221[4b000] via P2P/IPC/read
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 01 : 113[4b000] -> 114[ca000] via P2P/IPC/read
165: hkn0521:1205024:1205132 [1] NCCL INFO Channel 00 : 165[4b000] -> 166[ca000] via P2P/IPC/read
250: hkn0609:718028:718154 [2] NCCL INFO Connected all rings
 40: hkn0414:1988896:1989013 [0] NCCL INFO Connected all rings
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 00 : 64[31000] -> 65[4b000] via P2P/IPC/read
174: hkn0524:1141010:1141129 [2] NCCL INFO Channel 00 : 174[ca000] -> 175[e3000] via P2P/IPC/read
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 00 : 472[31000] -> 473[4b000] via P2P/IPC/read
294: hkn0626:1305634:1305784 [2] NCCL INFO Connected all rings
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 01 : 184[31000] -> 185[4b000] via P2P/IPC/read
489: hkn0809:944571:944666 [1] NCCL INFO Connected all rings
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 00 : 224[31000] -> 225[4b000] via P2P/IPC/read
476: hkn0806:1061522:1061652 [0] NCCL INFO Connected all rings
198: hkn0530:1265343:1265469 [2] NCCL INFO Connected all rings
 24: hkn0410:1166925:1167041 [0] NCCL INFO Connected all rings
418: hkn0725:3119184:3119279 [2] NCCL INFO Connected all rings
342: hkn0704:799243:799339 [2] NCCL INFO Connected all rings
333: hkn0636:1661529:1661644 [1] NCCL INFO Connected all rings
214: hkn0535:2406234:2406334 [2] NCCL INFO Connected all rings
234: hkn0605:719352:719473 [2] NCCL INFO Connected all rings
465: hkn0803:883787:883894 [1] NCCL INFO Connected all rings
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 00 : 180[31000] -> 181[4b000] via P2P/IPC/read
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 01 : 161[4b000] -> 162[ca000] via P2P/IPC/read
508: hkn0816:382834:382958 [0] NCCL INFO Channel 00 : 508[31000] -> 509[4b000] via P2P/IPC/read
216: hkn0601:124960:125086 [0] NCCL INFO Channel 00 : 216[31000] -> 217[4b000] via P2P/IPC/read
313: hkn0631:1029024:1029139 [1] NCCL INFO Connected all rings
366: hkn0711:591185:591287 [2] NCCL INFO Connected all rings
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 00 : 196[31000] -> 197[4b000] via P2P/IPC/read
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 00 : 124[31000] -> 125[4b000] via P2P/IPC/read
118: hkn0506:845292:845415 [2] NCCL INFO Channel 00 : 118[ca000] -> 119[e3000] via P2P/IPC/read
434: hkn0730:1408975:1409075 [2] NCCL INFO Connected all rings
230: hkn0604:696451:696579 [2] NCCL INFO Connected all rings
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 00 : 208[31000] -> 209[4b000] via P2P/IPC/read
430: hkn0728:1331266:1331371 [2] NCCL INFO Connected all rings
368: hkn0712:302297:302400 [0] NCCL INFO Channel 00 : 368[31000] -> 369[4b000] via P2P/IPC/read
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 01 : 96[31000] -> 97[4b000] via P2P/IPC/read
 13: hkn0407:1823500:1823618 [1] NCCL INFO Connected all rings
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 00 : 36[31000] -> 37[4b000] via P2P/IPC/read
232: hkn0605:719349:719471 [0] NCCL INFO Channel 00 : 232[31000] -> 233[4b000] via P2P/IPC/read
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 01 : 68[31000] -> 69[4b000] via P2P/IPC/read
286: hkn0623:1879995:1880114 [2] NCCL INFO Connected all rings
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 00 : 137[4b000] -> 138[ca000] via P2P/IPC/read
 94: hkn0428:674575:674691 [2] NCCL INFO Channel 00 : 94[ca000] -> 95[e3000] via P2P/IPC/read
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 00 : 105[4b000] -> 106[ca000] via P2P/IPC/read
252: hkn0611:717035:717164 [0] NCCL INFO Channel 00 : 252[31000] -> 253[4b000] via P2P/IPC/read
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 00 : 424[31000] -> 425[4b000] via P2P/IPC/read
248: hkn0609:718056:718153 [0] NCCL INFO Channel 00 : 248[31000] -> 249[4b000] via P2P/IPC/read
302: hkn0628:679139:679252 [2] NCCL INFO Connected all rings
278: hkn0621:1998838:1998943 [2] NCCL INFO Connected all rings
129: hkn0509:3131636:3131744 [1] NCCL INFO Connected all rings
117: hkn0506:845300:845411 [1] NCCL INFO Channel 00 : 117[4b000] -> 118[ca000] via P2P/IPC/read
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 00 : 432[31000] -> 433[4b000] via P2P/IPC/read
 61: hkn0420:3217408:3217553 [1] NCCL INFO Connected all rings
436: hkn0731:1393962:1394080 [0] NCCL INFO Connected all rings
402: hkn0720:14310:14477 [2] NCCL INFO Connected all rings
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 00 : 448[31000] -> 449[4b000] via P2P/IPC/read
388: hkn0717:1467:1586 [0] NCCL INFO Channel 00 : 388[31000] -> 389[4b000] via P2P/IPC/read
348: hkn0706:759506:759606 [0] NCCL INFO Connected all rings
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 01 : 88[31000] -> 89[4b000] via P2P/IPC/read
344: hkn0705:790415:790543 [0] NCCL INFO Channel 00 : 344[31000] -> 345[4b000] via P2P/IPC/read
358: hkn0708:420458:420568 [2] NCCL INFO Connected all rings
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 01 : 173[4b000] -> 174[ca000] via P2P/IPC/read
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 01 : 168[31000] -> 169[4b000] via P2P/IPC/read
458: hkn0801:2247264:2247382 [2] NCCL INFO Connected all rings
228: hkn0604:696478:696578 [0] NCCL INFO Channel 00 : 228[31000] -> 229[4b000] via P2P/IPC/read
450: hkn0734:1163781:1163870 [2] NCCL INFO Connected all rings
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 00 : 157[4b000] -> 158[ca000] via P2P/IPC/read
122: hkn0507:3194301:3194415 [2] NCCL INFO Connected all rings
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 00 : 292[31000] -> 293[4b000] via P2P/IPC/read
296: hkn0627:1795174:1795274 [0] NCCL INFO Connected all rings
102: hkn0502:236315:236406 [2] NCCL INFO Channel 00 : 102[ca000] -> 103[e3000] via P2P/IPC/read
 30: hkn0411:2323089:2323199 [2] NCCL INFO Connected all rings
202: hkn0531:1237910:1238025 [2] NCCL INFO Connected all rings
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 00 : 145[4b000] -> 146[ca000] via P2P/IPC/read
462: hkn0802:1207559:1207696 [2] NCCL INFO Connected all rings
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 01 : 444[31000] -> 445[4b000] via P2P/IPC/read
397: hkn0719:1312963:1313082 [1] NCCL INFO Connected all rings
109: hkn0504:48319:48430 [1] NCCL INFO Channel 00 : 109[4b000] -> 110[ca000] via P2P/IPC/read
412: hkn0724:1723179:1723321 [0] NCCL INFO Connected all rings
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 00 : 120[31000] -> 121[4b000] via P2P/IPC/read
332: hkn0636:1661513:1661645 [0] NCCL INFO Connected all rings
101: hkn0502:236287:236411 [1] NCCL INFO Channel 01 : 101[4b000] -> 102[ca000] via P2P/IPC/read
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 00 : 153[4b000] -> 154[ca000] via P2P/IPC/read
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 01 : 72[31000] -> 73[4b000] via P2P/IPC/read
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 00 : 456[31000] -> 457[4b000] via P2P/IPC/read
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 00 : 428[31000] -> 429[4b000] via P2P/IPC/read
500: hkn0814:683023:683174 [0] NCCL INFO Connected all rings
310: hkn0630:1605686:1605806 [2] NCCL INFO Connected all rings
360: hkn0710:362792:362882 [0] NCCL INFO Connected all rings
238: hkn0606:2379355:2379460 [2] NCCL INFO Connected all rings
166: hkn0521:1205036:1205135 [2] NCCL INFO Channel 00 : 166[ca000] -> 167[e3000] via P2P/IPC/read
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 00 : 200[31000] -> 201[4b000] via P2P/IPC/read
372: hkn0713:477480:477575 [0] NCCL INFO Channel 00 : 372[31000] -> 373[4b000] via P2P/IPC/read
410: hkn0723:215325:215496 [2] NCCL INFO Connected all rings
 22: hkn0409:2592882:2592991 [2] NCCL INFO Connected all rings
340: hkn0704:799215:799344 [0] NCCL INFO Channel 00 : 340[31000] -> 341[4b000] via P2P/IPC/read
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 01 : 93[4b000] -> 94[ca000] via P2P/IPC/read
106: hkn0503:2906951:2907055 [2] NCCL INFO Channel 00 : 106[ca000] -> 107[e3000] via P2P/IPC/read
 85: hkn0426:821286:821409 [1] NCCL INFO Channel 00 : 85[4b000] -> 86[ca000] via P2P/IPC/read
274: hkn0617:2301935:2302046 [2] NCCL INFO Connected all rings
 52: hkn0418:1876388:1876514 [0] NCCL INFO Connected all rings
138: hkn0511:3073676:3073772 [2] NCCL INFO Channel 00 : 138[ca000] -> 139[e3000] via P2P/IPC/read
386: hkn0716:115704:115853 [2] NCCL INFO Connected all rings
318: hkn0632:1765851:1765965 [2] NCCL INFO Connected all rings
260: hkn0613:909924:910036 [0] NCCL INFO Channel 01 : 260[31000] -> 261[4b000] via P2P/IPC/read
165: hkn0521:1205024:1205132 [1] NCCL INFO Channel 01 : 165[4b000] -> 166[ca000] via P2P/IPC/read
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 00 : 460[31000] -> 461[4b000] via P2P/IPC/read
408: hkn0723:215341:215495 [0] NCCL INFO Channel 00 : 408[31000] -> 409[4b000] via P2P/IPC/read
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 00 : 276[31000] -> 277[4b000] via P2P/IPC/read
382: hkn0715:409118:409228 [2] NCCL INFO Connected all rings
422: hkn0726:1555349:1555447 [2] NCCL INFO Connected all rings
204: hkn0532:932494:932817 [0] NCCL INFO Channel 01 : 204[31000] -> 205[4b000] via P2P/IPC/read
126: hkn0508:3146354:3146461 [2] NCCL INFO Channel 00 : 126[ca000] -> 127[e3000] via P2P/IPC/read
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 01 : 188[31000] -> 189[4b000] via P2P/IPC/read
144: hkn0513:3020204:3020301 [0] NCCL INFO Connected all rings
482: hkn0807:1026293:1026403 [2] NCCL INFO Connected all rings
440: hkn0732:1218902:1218998 [0] NCCL INFO Connected all rings
338: hkn0703:748322:748407 [2] NCCL INFO Connected all rings
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 00 : 185[4b000] -> 186[ca000] via P2P/IPC/read
 34: hkn0412:2269636:2269732 [2] NCCL INFO Connected all rings
256: hkn0612:924207:924324 [0] NCCL INFO Channel 01 : 256[31000] -> 257[4b000] via P2P/IPC/read
464: hkn0803:883779:883891 [0] NCCL INFO Channel 00 : 464[31000] -> 465[4b000] via P2P/IPC/read
149: hkn0514:2957959:2958071 [1] NCCL INFO Channel 00 : 149[4b000] -> 150[ca000] via P2P/IPC/read
 80: hkn0425:2091287:2091403 [0] NCCL INFO Connected all rings
322: hkn0633:1533554:1533664 [2] NCCL INFO Connected all rings
352: hkn0707:4027165:4027259 [0] NCCL INFO Connected all rings
  8: hkn0405:3214154:3214272 [0] NCCL INFO Connected all rings
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 00 : 420[31000] -> 421[4b000] via P2P/IPC/read
400: hkn0720:14302:14479 [0] NCCL INFO Channel 00 : 400[31000] -> 401[4b000] via P2P/IPC/read
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 00 : 20[31000] -> 21[4b000] via P2P/IPC/read
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 00 : 284[31000] -> 285[4b000] via P2P/IPC/read
162: hkn0520:2720086:2720209 [2] NCCL INFO Channel 01 : 162[ca000] -> 163[e3000] via P2P/IPC/read
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 01 : 125[4b000] -> 126[ca000] via P2P/IPC/read
154: hkn0515:2904025:2904145 [2] NCCL INFO Channel 00 : 154[ca000] -> 155[e3000] via P2P/IPC/read
118: hkn0506:845292:845415 [2] NCCL INFO Channel 01 : 118[ca000] -> 119[e3000] via P2P/IPC/read
146: hkn0513:3020196:3020300 [2] NCCL INFO Channel 00 : 146[ca000] -> 147[e3000] via P2P/IPC/read
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 00 : 480[31000] -> 481[4b000] via P2P/IPC/read
494: hkn0810:946736:946861 [2] NCCL INFO Connected all rings
205: hkn0532:932522:932818 [1] NCCL INFO Channel 00 : 205[4b000] -> 206[ca000] via P2P/IPC/read
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 01 : 452[31000] -> 453[4b000] via P2P/IPC/read
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 00 : 192[31000] -> 193[4b000] via P2P/IPC/read
 50: hkn0417:2274860:2274988 [2] NCCL INFO Connected all rings
 12: hkn0407:1823520:1823613 [0] NCCL INFO Connected all rings
290: hkn0624:1780132:1780286 [2] NCCL INFO Connected all rings
350: hkn0706:759494:759603 [2] NCCL INFO Connected all rings
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 00 : 236[31000] -> 237[4b000] via P2P/IPC/read
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 00 : 320[31000] -> 321[4b000] via P2P/IPC/read
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 01 : 105[4b000] -> 106[ca000] via P2P/IPC/read
117: hkn0506:845300:845411 [1] NCCL INFO Channel 01 : 117[4b000] -> 118[ca000] via P2P/IPC/read
486: hkn0808:977893:978014 [2] NCCL INFO Connected all rings
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 01 : 404[31000] -> 405[4b000] via P2P/IPC/read
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 01 : 392[31000] -> 393[4b000] via P2P/IPC/read
266: hkn0615:421558:421661 [2] NCCL INFO Connected all rings
158: hkn0516:2923196:2923320 [2] NCCL INFO Channel 00 : 158[ca000] -> 159[e3000] via P2P/IPC/read
114: hkn0505:2311013:2311117 [2] NCCL INFO Channel 01 : 114[ca000] -> 115[e3000] via P2P/IPC/read
378: hkn0714:439245:439363 [2] NCCL INFO Connected all rings
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 01 : 137[4b000] -> 138[ca000] via P2P/IPC/read
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 00 : 32[31000] -> 33[4b000] via P2P/IPC/read
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 01 : 468[31000] -> 469[4b000] via P2P/IPC/read
506: hkn0815:402341:402450 [2] NCCL INFO Connected all rings
110: hkn0504:48311:48436 [2] NCCL INFO Channel 00 : 110[ca000] -> 111[e3000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Connected all rings
 69: hkn0422:4160356:4160471 [1] NCCL INFO Channel 00 : 69[4b000] -> 70[ca000] via P2P/IPC/read
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 01 : 220[31000] -> 221[4b000] via P2P/IPC/read
244: hkn0608:492975:493069 [0] NCCL INFO Channel 00 : 244[31000] -> 245[4b000] via P2P/IPC/read
174: hkn0524:1141010:1141129 [2] NCCL INFO Channel 01 : 174[ca000] -> 175[e3000] via P2P/IPC/read
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 00 : 84[31000] -> 85[4b000] via P2P/IPC/read
484: hkn0808:977921:978021 [0] NCCL INFO Channel 00 : 484[31000] -> 485[4b000] via P2P/IPC/read
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 01 : 472[31000] -> 473[4b000] via P2P/IPC/read
380: hkn0715:409126:409232 [0] NCCL INFO Channel 00 : 380[31000] -> 381[4b000] via P2P/IPC/read
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 01 : 64[31000] -> 65[4b000] via P2P/IPC/read
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via P2P/IPC/read
384: hkn0716:115715:115850 [0] NCCL INFO Channel 00 : 384[31000] -> 385[4b000] via P2P/IPC/read
109: hkn0504:48319:48430 [1] NCCL INFO Channel 01 : 109[4b000] -> 110[ca000] via P2P/IPC/read
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 01 : 224[31000] -> 225[4b000] via P2P/IPC/read
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 00 : 476[31000] -> 477[4b000] via P2P/IPC/read
216: hkn0601:124960:125086 [0] NCCL INFO Channel 01 : 216[31000] -> 217[4b000] via P2P/IPC/read
264: hkn0615:421550:421660 [0] NCCL INFO Channel 00 : 264[31000] -> 265[4b000] via P2P/IPC/read
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 01 : 157[4b000] -> 158[ca000] via P2P/IPC/read
150: hkn0514:2957943:2958073 [2] NCCL INFO Channel 00 : 150[ca000] -> 151[e3000] via P2P/IPC/read
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 00 : 89[4b000] -> 90[ca000] via P2P/IPC/read
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 01 : 140[31000] -> 141[4b000] via P2P/IPC/read
 76: hkn0424:2955170:2955294 [0] NCCL INFO Connected all rings
186: hkn0527:1356188:1356283 [2] NCCL INFO Channel 00 : 186[ca000] -> 187[e3000] via P2P/IPC/read
 86: hkn0426:821274:821408 [2] NCCL INFO Channel 00 : 86[ca000] -> 87[e3000] via P2P/IPC/read
  2: hkn0403:1776577:1776939 [2] NCCL INFO Connected all rings
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 00 : 288[31000] -> 289[4b000] via P2P/IPC/read
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 01 : 180[31000] -> 181[4b000] via P2P/IPC/read
306: hkn0629:1599284:1599393 [2] NCCL INFO Connected all rings
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 00 : 316[31000] -> 317[4b000] via P2P/IPC/read
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 00 : 16[31000] -> 17[4b000] via P2P/IPC/read
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 00 : 296[31000] -> 297[4b000] via P2P/IPC/read
 46: hkn0415:2503643:2503758 [2] NCCL INFO Connected all rings
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 01 : 196[31000] -> 197[4b000] via P2P/IPC/read
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 01 : 124[31000] -> 125[4b000] via P2P/IPC/read
 28: hkn0411:2323081:2323201 [0] NCCL INFO Connected all rings
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 01 : 153[4b000] -> 154[ca000] via P2P/IPC/read
177: hkn0525:994014:994129 [1] NCCL INFO Connected all rings
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 00 : 97[4b000] -> 98[ca000] via P2P/IPC/read
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 00 : 169[4b000] -> 170[ca000] via P2P/IPC/read
508: hkn0816:382834:382958 [0] NCCL INFO Channel 01 : 508[31000] -> 509[4b000] via P2P/IPC/read
413: hkn0724:1723172:1723322 [1] NCCL INFO Connected all rings
130: hkn0509:3131655:3131751 [2] NCCL INFO Connected all rings
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 00 : 272[31000] -> 273[4b000] via P2P/IPC/read
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 00 : 81[4b000] -> 82[ca000] via P2P/IPC/read
368: hkn0712:302297:302400 [0] NCCL INFO Channel 01 : 368[31000] -> 369[4b000] via P2P/IPC/read
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 00 : 445[4b000] -> 446[ca000] via P2P/IPC/read
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 01 : 36[31000] -> 37[4b000] via P2P/IPC/read
405: hkn0721:2306514:2306619 [1] NCCL INFO Channel 00 : 405[4b000] -> 406[ca000] via P2P/IPC/read
336: hkn0703:748295:748408 [0] NCCL INFO Channel 00 : 336[31000] -> 337[4b000] via P2P/IPC/read
360: hkn0710:362792:362882 [0] NCCL INFO Channel 00 : 360[31000] -> 361[4b000] via P2P/IPC/read
181: hkn0526:1435629:1435751 [1] NCCL INFO Channel 00 : 181[4b000] -> 182[ca000] via P2P/IPC/read
282: hkn0622:2027744:2027863 [2] NCCL INFO Connected all rings
 77: hkn0424:2955178:2955291 [1] NCCL INFO Connected all rings
 94: hkn0428:674575:674691 [2] NCCL INFO Channel 01 : 94[ca000] -> 95[e3000] via P2P/IPC/read
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 00 : 48[31000] -> 49[4b000] via P2P/IPC/read
492: hkn0810:946764:946863 [0] NCCL INFO Channel 00 : 492[31000] -> 493[4b000] via P2P/IPC/read
252: hkn0611:717035:717164 [0] NCCL INFO Channel 01 : 252[31000] -> 253[4b000] via P2P/IPC/read
437: hkn0731:1393941:1394086 [1] NCCL INFO Connected all rings
498: hkn0812:701043:701153 [2] NCCL INFO Connected all rings
  6: hkn0404:1346665:1346763 [2] NCCL INFO Connected all rings
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 01 : 424[31000] -> 425[4b000] via P2P/IPC/read
232: hkn0605:719349:719471 [0] NCCL INFO Channel 01 : 232[31000] -> 233[4b000] via P2P/IPC/read
248: hkn0609:718056:718153 [0] NCCL INFO Channel 01 : 248[31000] -> 249[4b000] via P2P/IPC/read
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 00 : 308[31000] -> 309[4b000] via P2P/IPC/read
217: hkn0601:124968:125085 [1] NCCL INFO Channel 00 : 217[4b000] -> 218[ca000] via P2P/IPC/read
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 00 : 304[31000] -> 305[4b000] via P2P/IPC/read
329: hkn0635:1232786:1232910 [1] NCCL INFO Connected all rings
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 01 : 432[31000] -> 433[4b000] via P2P/IPC/read
228: hkn0604:696478:696578 [0] NCCL INFO Channel 01 : 228[31000] -> 229[4b000] via P2P/IPC/read
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 01 : 448[31000] -> 449[4b000] via P2P/IPC/read
270: hkn0616:412161:412288 [2] NCCL INFO Connected all rings
388: hkn0717:1467:1586 [0] NCCL INFO Channel 01 : 388[31000] -> 389[4b000] via P2P/IPC/read
488: hkn0809:944559:944660 [0] NCCL INFO Channel 00 : 488[31000] -> 489[4b000] via P2P/IPC/read
466: hkn0803:883795:883893 [2] NCCL INFO Connected all rings
149: hkn0514:2957959:2958071 [1] NCCL INFO Channel 01 : 149[4b000] -> 150[ca000] via P2P/IPC/read
245: hkn0608:492963:493070 [1] NCCL INFO Channel 00 : 245[4b000] -> 246[ca000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO Connected all rings
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 00 : 280[31000] -> 281[4b000] via P2P/IPC/read
356: hkn0708:420442:420567 [0] NCCL INFO Connected all rings
141: hkn0512:3051327:3051449 [1] NCCL INFO Connected all rings
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 01 : 185[4b000] -> 186[ca000] via P2P/IPC/read
469: hkn0804:1212849:1212967 [1] NCCL INFO Channel 00 : 469[4b000] -> 470[ca000] via P2P/IPC/read
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 01 : 145[4b000] -> 146[ca000] via P2P/IPC/read
398: hkn0719:1312991:1313080 [2] NCCL INFO Connected all rings
 14: hkn0407:1823492:1823615 [2] NCCL INFO Connected all rings
206: hkn0532:932510:932820 [2] NCCL INFO Channel 00 : 206[ca000] -> 207[e3000] via P2P/IPC/read
496: hkn0812:701027:701151 [0] NCCL INFO Channel 00 : 496[31000] -> 497[4b000] via P2P/IPC/read
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 00 : 4[31000] -> 5[4b000] via P2P/IPC/read
490: hkn0809:944543:944669 [2] NCCL INFO Connected all rings
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 00 : 477[4b000] -> 478[ca000] via P2P/IPC/read
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 01 : 292[31000] -> 293[4b000] via P2P/IPC/read
344: hkn0705:790415:790543 [0] NCCL INFO Channel 01 : 344[31000] -> 345[4b000] via P2P/IPC/read
212: hkn0535:2406214:2406333 [0] NCCL INFO Connected all rings
102: hkn0502:236315:236406 [2] NCCL INFO Channel 01 : 102[ca000] -> 103[e3000] via P2P/IPC/read
261: hkn0613:909944:910037 [1] NCCL INFO Channel 00 : 261[4b000] -> 262[ca000] via P2P/IPC/read
 98: hkn0501:1335167:1335267 [2] NCCL INFO Channel 00 : 98[ca000] -> 99[e3000] via P2P/IPC/read
 25: hkn0410:1166933:1167040 [1] NCCL INFO Connected all rings
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 01 : 456[31000] -> 457[4b000] via P2P/IPC/read
205: hkn0532:932522:932818 [1] NCCL INFO Channel 01 : 205[4b000] -> 206[ca000] via P2P/IPC/read
268: hkn0616:412169:412281 [0] NCCL INFO Channel 00 : 268[31000] -> 269[4b000] via P2P/IPC/read
257: hkn0612:924227:924322 [1] NCCL INFO Channel 00 : 257[4b000] -> 258[ca000] via P2P/IPC/read
453: hkn0736:1515557:1515653 [1] NCCL INFO Channel 00 : 453[4b000] -> 454[ca000] via P2P/IPC/read
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 01 : 428[31000] -> 429[4b000] via P2P/IPC/read
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 01 : 120[31000] -> 121[4b000] via P2P/IPC/read
240: hkn0607:911595:911709 [0] NCCL INFO Channel 00 : 240[31000] -> 241[4b000] via P2P/IPC/read
 41: hkn0414:1988888:1989009 [1] NCCL INFO Connected all rings
334: hkn0636:1661541:1661648 [2] NCCL INFO Connected all rings
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 00 : 44[31000] -> 45[4b000] via P2P/IPC/read
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 00 : 352[31000] -> 353[4b000] via P2P/IPC/read
106: hkn0503:2906951:2907055 [2] NCCL INFO Channel 01 : 106[ca000] -> 107[e3000] via P2P/IPC/read
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 01 : 200[31000] -> 201[4b000] via P2P/IPC/read
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 00 : 73[4b000] -> 74[ca000] via P2P/IPC/read
 85: hkn0426:821286:821409 [1] NCCL INFO Channel 01 : 85[4b000] -> 86[ca000] via P2P/IPC/read
446: hkn0733:1396572:1396700 [2] NCCL INFO Channel 00 : 446[ca000] -> 447[e3000] via P2P/IPC/read
 70: hkn0422:4160364:4160469 [2] NCCL INFO Channel 00 : 70[ca000] -> 71[e3000] via P2P/IPC/read
314: hkn0631:1029016:1029137 [2] NCCL INFO Connected all rings
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 00 : 221[4b000] -> 222[ca000] via P2P/IPC/read
340: hkn0704:799215:799344 [0] NCCL INFO Channel 01 : 340[31000] -> 341[4b000] via P2P/IPC/read
138: hkn0511:3073676:3073772 [2] NCCL INFO Channel 01 : 138[ca000] -> 139[e3000] via P2P/IPC/read
  9: hkn0405:3214182:3214280 [1] NCCL INFO Connected all rings
 69: hkn0422:4160356:4160471 [1] NCCL INFO Channel 01 : 69[4b000] -> 70[ca000] via P2P/IPC/read
348: hkn0706:759506:759606 [0] NCCL INFO Channel 00 : 348[31000] -> 349[4b000] via P2P/IPC/read
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 00 : 193[4b000] -> 194[ca000] via P2P/IPC/read
166: hkn0521:1205036:1205135 [2] NCCL INFO Channel 01 : 166[ca000] -> 167[e3000] via P2P/IPC/read
135: hkn0510:2769298:2769389 [3] NCCL INFO Connected all trees
 74: hkn0423:1712179:1712289 [2] NCCL INFO Channel 00 : 74[ca000] -> 75[e3000] via P2P/IPC/read
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 00 : 396[31000] -> 397[4b000] via P2P/IPC/read
324: hkn0634:1528076:1528180 [0] NCCL INFO Connected all rings
300: hkn0628:679159:679255 [0] NCCL INFO Connected all rings
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 01 : 276[31000] -> 277[4b000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 00 : 312[31000] -> 313[4b000] via P2P/IPC/read
213: hkn0535:2406206:2406337 [1] NCCL INFO Channel 00 : 213[4b000] -> 214[ca000] via P2P/IPC/read
470: hkn0804:1212841:1212966 [2] NCCL INFO Channel 00 : 470[ca000] -> 471[e3000] via P2P/IPC/read
170: hkn0523:1555340:1555444 [2] NCCL INFO Channel 00 : 170[ca000] -> 171[e3000] via P2P/IPC/read
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 01 : 460[31000] -> 461[4b000] via P2P/IPC/read
408: hkn0723:215341:215495 [0] NCCL INFO Channel 01 : 408[31000] -> 409[4b000] via P2P/IPC/read
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 00 : 393[4b000] -> 394[ca000] via P2P/IPC/read
 90: hkn0427:1142341:1142458 [2] NCCL INFO Channel 00 : 90[ca000] -> 91[e3000] via P2P/IPC/read
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 00 : 65[4b000] -> 66[ca000] via P2P/IPC/read
135: hkn0510:2769298:2769389 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 62: hkn0420:3217428:3217558 [2] NCCL INFO Connected all rings
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 00 : 144[31000] -> 145[4b000] via P2P/IPC/read
504: hkn0815:402353:402445 [0] NCCL INFO Connected all rings
400: hkn0720:14302:14479 [0] NCCL INFO Channel 01 : 400[31000] -> 401[4b000] via P2P/IPC/read
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 01 : 20[31000] -> 21[4b000] via P2P/IPC/read
301: hkn0628:679147:679253 [1] NCCL INFO Channel 00 : 301[4b000] -> 302[ca000] via P2P/IPC/read
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 01 : 89[4b000] -> 90[ca000] via P2P/IPC/read
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 01 : 284[31000] -> 285[4b000] via P2P/IPC/read
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 01 : 296[31000] -> 297[4b000] via P2P/IPC/read
154: hkn0515:2904025:2904145 [2] NCCL INFO Channel 01 : 154[ca000] -> 155[e3000] via P2P/IPC/read
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 01 : 97[4b000] -> 98[ca000] via P2P/IPC/read
135: hkn0510:2769298:2769389 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 37: hkn0413:2373940:2374062 [1] NCCL INFO Channel 00 : 37[4b000] -> 38[ca000] via P2P/IPC/read
509: hkn0816:382855:382951 [1] NCCL INFO Channel 00 : 509[4b000] -> 510[ca000] via P2P/IPC/read
454: hkn0736:1515545:1515656 [2] NCCL INFO Channel 00 : 454[ca000] -> 455[e3000] via P2P/IPC/read
406: hkn0721:2306498:2306623 [2] NCCL INFO Channel 00 : 406[ca000] -> 407[e3000] via P2P/IPC/read
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 00 : 225[4b000] -> 226[ca000] via P2P/IPC/read
360: hkn0710:362792:362882 [0] NCCL INFO Channel 01 : 360[31000] -> 361[4b000] via P2P/IPC/read
182: hkn0526:1435637:1435754 [2] NCCL INFO Channel 00 : 182[ca000] -> 183[e3000] via P2P/IPC/read
376: hkn0714:439237:439359 [0] NCCL INFO Connected all rings
365: hkn0711:591174:591286 [1] NCCL INFO Channel 00 : 365[4b000] -> 366[ca000] via P2P/IPC/read
126: hkn0508:3146354:3146461 [2] NCCL INFO Channel 01 : 126[ca000] -> 127[e3000] via P2P/IPC/read
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 01 : 84[31000] -> 85[4b000] via P2P/IPC/read
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 01 : 169[4b000] -> 170[ca000] via P2P/IPC/read
146: hkn0513:3020196:3020300 [2] NCCL INFO Channel 01 : 146[ca000] -> 147[e3000] via P2P/IPC/read
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 01 : 420[31000] -> 421[4b000] via P2P/IPC/read
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 01 : 480[31000] -> 481[4b000] via P2P/IPC/read
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 00 : 425[4b000] -> 426[ca000] via P2P/IPC/read
218: hkn0601:124988:125082 [2] NCCL INFO Channel 00 : 218[ca000] -> 219[e3000] via P2P/IPC/read
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 01 : 192[31000] -> 193[4b000] via P2P/IPC/read
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 01 : 236[31000] -> 237[4b000] via P2P/IPC/read
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 01 : 320[31000] -> 321[4b000] via P2P/IPC/read
189: hkn0528:1308923:1309018 [1] NCCL INFO Connected all rings
 86: hkn0426:821274:821408 [2] NCCL INFO Channel 01 : 86[ca000] -> 87[e3000] via P2P/IPC/read
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 01 : 445[4b000] -> 446[ca000] via P2P/IPC/read
405: hkn0721:2306514:2306619 [1] NCCL INFO Channel 01 : 405[4b000] -> 406[ca000] via P2P/IPC/read
501: hkn0814:683039:683170 [1] NCCL INFO Connected all rings
249: hkn0609:718036:718147 [1] NCCL INFO Channel 00 : 249[4b000] -> 250[ca000] via P2P/IPC/read
181: hkn0526:1435629:1435751 [1] NCCL INFO Channel 01 : 181[4b000] -> 182[ca000] via P2P/IPC/read
244: hkn0608:492975:493069 [0] NCCL INFO Channel 01 : 244[31000] -> 245[4b000] via P2P/IPC/read
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 00 : 332[31000] -> 333[4b000] via P2P/IPC/read
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 00 : 80[31000] -> 81[4b000] via P2P/IPC/read
197: hkn0530:1265371:1265467 [1] NCCL INFO Channel 00 : 197[4b000] -> 198[ca000] via P2P/IPC/read
262: hkn0613:909916:910043 [2] NCCL INFO Channel 00 : 262[ca000] -> 263[e3000] via P2P/IPC/read
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 01 : 32[31000] -> 33[4b000] via P2P/IPC/read
178: hkn0525:994022:994132 [2] NCCL INFO Connected all rings
369: hkn0712:302289:302403 [1] NCCL INFO Channel 00 : 369[4b000] -> 370[ca000] via P2P/IPC/read
253: hkn0611:717051:717160 [1] NCCL INFO Channel 00 : 253[4b000] -> 254[ca000] via P2P/IPC/read
258: hkn0612:924199:924320 [2] NCCL INFO Channel 00 : 258[ca000] -> 259[e3000] via P2P/IPC/read
464: hkn0803:883779:883891 [0] NCCL INFO Channel 01 : 464[31000] -> 465[4b000] via P2P/IPC/read
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 00 : 440[31000] -> 441[4b000] via P2P/IPC/read
217: hkn0601:124968:125085 [1] NCCL INFO Channel 01 : 217[4b000] -> 218[ca000] via P2P/IPC/read
293: hkn0626:1305645:1305779 [1] NCCL INFO Channel 00 : 293[4b000] -> 294[ca000] via P2P/IPC/read
357: hkn0708:420450:420563 [1] NCCL INFO Channel 00 : 357[4b000] -> 358[ca000] via P2P/IPC/read
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via P2P/IPC/read
384: hkn0716:115715:115850 [0] NCCL INFO Channel 01 : 384[31000] -> 385[4b000] via P2P/IPC/read
389: hkn0717:1475:1580 [1] NCCL INFO Channel 00 : 389[4b000] -> 390[ca000] via P2P/IPC/read
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 01 : 476[31000] -> 477[4b000] via P2P/IPC/read
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 01 : 288[31000] -> 289[4b000] via P2P/IPC/read
194: hkn0529:1548054:1548165 [2] NCCL INFO Channel 00 : 194[ca000] -> 195[e3000] via P2P/IPC/read
150: hkn0514:2957943:2958073 [2] NCCL INFO Channel 01 : 150[ca000] -> 151[e3000] via P2P/IPC/read
380: hkn0715:409126:409232 [0] NCCL INFO Channel 01 : 380[31000] -> 381[4b000] via P2P/IPC/read
 66: hkn0421:2189220:2189406 [2] NCCL INFO Channel 00 : 66[ca000] -> 67[e3000] via P2P/IPC/read
186: hkn0527:1356188:1356283 [2] NCCL INFO Channel 01 : 186[ca000] -> 187[e3000] via P2P/IPC/read
261: hkn0613:909944:910037 [1] NCCL INFO Channel 01 : 261[4b000] -> 262[ca000] via P2P/IPC/read
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 00 : 433[4b000] -> 434[ca000] via P2P/IPC/read
469: hkn0804:1212849:1212967 [1] NCCL INFO Channel 01 : 469[4b000] -> 470[ca000] via P2P/IPC/read
229: hkn0604:696459:696573 [1] NCCL INFO Channel 00 : 229[4b000] -> 230[ca000] via P2P/IPC/read
110: hkn0504:48311:48436 [2] NCCL INFO Channel 01 : 110[ca000] -> 111[e3000] via P2P/IPC/read
209: hkn0534:1155638:1155749 [1] NCCL INFO Connected all rings
484: hkn0808:977921:978021 [0] NCCL INFO Channel 01 : 484[31000] -> 485[4b000] via P2P/IPC/read
233: hkn0605:719360:719472 [1] NCCL INFO Channel 00 : 233[4b000] -> 234[ca000] via P2P/IPC/read
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 00 : 441[4b000] -> 442[ca000] via P2P/IPC/read
264: hkn0615:421550:421660 [0] NCCL INFO Channel 01 : 264[31000] -> 265[4b000] via P2P/IPC/read
158: hkn0516:2923196:2923320 [2] NCCL INFO Channel 01 : 158[ca000] -> 159[e3000] via P2P/IPC/read
510: hkn0816:382843:382953 [2] NCCL INFO Channel 00 : 510[ca000] -> 511[e3000] via P2P/IPC/read
257: hkn0612:924227:924322 [1] NCCL INFO Channel 01 : 257[4b000] -> 258[ca000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 00 : 416[31000] -> 417[4b000] via P2P/IPC/read
453: hkn0736:1515557:1515653 [1] NCCL INFO Channel 01 : 453[4b000] -> 454[ca000] via P2P/IPC/read
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 00 : 429[4b000] -> 430[ca000] via P2P/IPC/read
241: hkn0607:911603:911711 [1] NCCL INFO Connected all rings
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 01 : 316[31000] -> 317[4b000] via P2P/IPC/read
246: hkn0608:492947:493073 [2] NCCL INFO Channel 00 : 246[ca000] -> 247[e3000] via P2P/IPC/read
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 01 : 272[31000] -> 273[4b000] via P2P/IPC/read
 82: hkn0425:2091279:2091402 [2] NCCL INFO Channel 00 : 82[ca000] -> 83[e3000] via P2P/IPC/read
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 01 : 48[31000] -> 49[4b000] via P2P/IPC/read
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 00 : 12[31000] -> 13[4b000] via P2P/IPC/read
426: hkn0727:1353002:1353113 [2] NCCL INFO Channel 00 : 426[ca000] -> 427[e3000] via P2P/IPC/read
473: hkn0805:1119333:1119444 [1] NCCL INFO Connected all rings
336: hkn0703:748295:748408 [0] NCCL INFO Channel 01 : 336[31000] -> 337[4b000] via P2P/IPC/read
222: hkn0602:3370898:3371093 [2] NCCL INFO Channel 00 : 222[ca000] -> 223[e3000] via P2P/IPC/read
341: hkn0704:799223:799342 [1] NCCL INFO Channel 00 : 341[4b000] -> 342[ca000] via P2P/IPC/read
245: hkn0608:492963:493070 [1] NCCL INFO Channel 01 : 245[4b000] -> 246[ca000] via P2P/IPC/read
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 01 : 16[31000] -> 17[4b000] via P2P/IPC/read
328: hkn0635:1232794:1232913 [0] NCCL INFO Connected all rings
345: hkn0705:790443:790544 [1] NCCL INFO Connected all rings
 53: hkn0418:1876404:1876515 [1] NCCL INFO Connected all rings
 78: hkn0424:2955198:2955298 [2] NCCL INFO Connected all rings
373: hkn0713:477452:477574 [1] NCCL INFO Connected all rings
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 01 : 73[4b000] -> 74[ca000] via P2P/IPC/read
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 00 : 457[4b000] -> 458[ca000] via P2P/IPC/read
438: hkn0731:1393942:1394083 [2] NCCL INFO Connected all rings
394: hkn0718:3924274:3924372 [2] NCCL INFO Channel 00 : 394[ca000] -> 395[e3000] via P2P/IPC/read
478: hkn0806:1061550:1061649 [2] NCCL INFO Channel 00 : 478[ca000] -> 479[e3000] via P2P/IPC/read
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 01 : 308[31000] -> 309[4b000] via P2P/IPC/read
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 00 : 121[4b000] -> 122[ca000] via P2P/IPC/read
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 01 : 221[4b000] -> 222[ca000] via P2P/IPC/read
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 01 : 304[31000] -> 305[4b000] via P2P/IPC/read
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 00 : 17[4b000] -> 18[ca000] via P2P/IPC/read
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 01 : 81[4b000] -> 82[ca000] via P2P/IPC/read
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 00 : 201[4b000] -> 202[ca000] via P2P/IPC/read
370: hkn0712:302281:302408 [2] NCCL INFO Channel 00 : 370[ca000] -> 371[e3000] via P2P/IPC/read
492: hkn0810:946764:946863 [0] NCCL INFO Channel 01 : 492[31000] -> 493[4b000] via P2P/IPC/read
254: hkn0611:717063:717166 [2] NCCL INFO Channel 00 : 254[ca000] -> 255[e3000] via P2P/IPC/read
 38: hkn0413:2373948:2374057 [2] NCCL INFO Channel 00 : 38[ca000] -> 39[e3000] via P2P/IPC/read
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 01 : 208[31000] -> 209[4b000] via P2P/IPC/read
390: hkn0717:1487:1589 [2] NCCL INFO Channel 00 : 390[ca000] -> 391[e3000] via P2P/IPC/read
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 00 : 417[4b000] -> 418[ca000] via P2P/IPC/read
488: hkn0809:944559:944660 [0] NCCL INFO Channel 01 : 488[31000] -> 489[4b000] via P2P/IPC/read
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 01 : 477[4b000] -> 478[ca000] via P2P/IPC/read
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 01 : 193[4b000] -> 194[ca000] via P2P/IPC/read
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 00 : 40[31000] -> 41[4b000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO Channel 00 : 364[31000] -> 365[4b000] via P2P/IPC/read
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 00 : 28[31000] -> 29[4b000] via P2P/IPC/read
372: hkn0713:477480:477575 [0] NCCL INFO Channel 01 : 372[31000] -> 373[4b000] via P2P/IPC/read
409: hkn0723:215333:215489 [1] NCCL INFO Channel 00 : 409[4b000] -> 410[ca000] via P2P/IPC/read
 37: hkn0413:2373940:2374062 [1] NCCL INFO Channel 01 : 37[4b000] -> 38[ca000] via P2P/IPC/read
401: hkn0720:14318:14478 [1] NCCL INFO Channel 00 : 401[4b000] -> 402[ca000] via P2P/IPC/read
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 01 : 4[31000] -> 5[4b000] via P2P/IPC/read
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 01 : 393[4b000] -> 394[ca000] via P2P/IPC/read
226: hkn0603:1420466:1420571 [2] NCCL INFO Channel 00 : 226[ca000] -> 227[e3000] via P2P/IPC/read
277: hkn0621:1998849:1998946 [1] NCCL INFO Channel 00 : 277[4b000] -> 278[ca000] via P2P/IPC/read
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 01 : 280[31000] -> 281[4b000] via P2P/IPC/read
356: hkn0708:420442:420567 [0] NCCL INFO Channel 00 : 356[31000] -> 357[4b000] via P2P/IPC/read
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 01 : 65[4b000] -> 66[ca000] via P2P/IPC/read
 98: hkn0501:1335167:1335267 [2] NCCL INFO Channel 01 : 98[ca000] -> 99[e3000] via P2P/IPC/read
206: hkn0532:932510:932820 [2] NCCL INFO Channel 01 : 206[ca000] -> 207[e3000] via P2P/IPC/read
496: hkn0812:701027:701151 [0] NCCL INFO Channel 01 : 496[31000] -> 497[4b000] via P2P/IPC/read
268: hkn0616:412169:412281 [0] NCCL INFO Channel 01 : 268[31000] -> 269[4b000] via P2P/IPC/read
234: hkn0605:719352:719473 [2] NCCL INFO Channel 00 : 234[ca000] -> 235[e3000] via P2P/IPC/read
250: hkn0609:718028:718154 [2] NCCL INFO Channel 00 : 250[ca000] -> 251[e3000] via P2P/IPC/read
330: hkn0635:1232802:1232909 [2] NCCL INFO Connected all rings
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 00 : 285[4b000] -> 286[ca000] via P2P/IPC/read
198: hkn0530:1265343:1265469 [2] NCCL INFO Channel 00 : 198[ca000] -> 199[e3000] via P2P/IPC/read
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 00 : 29[4b000] -> 30[ca000] via P2P/IPC/read
 74: hkn0423:1712179:1712289 [2] NCCL INFO Channel 01 : 74[ca000] -> 75[e3000] via P2P/IPC/read
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 00 : 461[4b000] -> 462[ca000] via P2P/IPC/read
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 00 : 436[31000] -> 437[4b000] via P2P/IPC/read
509: hkn0816:382855:382951 [1] NCCL INFO Channel 01 : 509[4b000] -> 510[ca000] via P2P/IPC/read
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 00 : 449[4b000] -> 450[ca000] via P2P/IPC/read
414: hkn0724:1723187:1723325 [2] NCCL INFO Connected all rings
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 01 : 225[4b000] -> 226[ca000] via P2P/IPC/read
342: hkn0704:799243:799339 [2] NCCL INFO Channel 00 : 342[ca000] -> 343[e3000] via P2P/IPC/read
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 01 : 44[31000] -> 45[4b000] via P2P/IPC/read
163: hkn0520:2720102:2720208 [3] NCCL INFO Connected all trees
163: hkn0520:2720102:2720208 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
119: hkn0506:845284:845410 [3] NCCL INFO Connected all trees
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 00 : 24[31000] -> 25[4b000] via P2P/IPC/read
446: hkn0733:1396572:1396700 [2] NCCL INFO Channel 01 : 446[ca000] -> 447[e3000] via P2P/IPC/read
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 01 : 425[4b000] -> 426[ca000] via P2P/IPC/read
115: hkn0505:2310997:2311121 [3] NCCL INFO Connected all trees
 42: hkn0414:1988904:1989011 [2] NCCL INFO Connected all rings
 56: hkn0419:1551497:1551601 [0] NCCL INFO Connected all rings
197: hkn0530:1265371:1265467 [1] NCCL INFO Channel 01 : 197[4b000] -> 198[ca000] via P2P/IPC/read
163: hkn0520:2720102:2720208 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
369: hkn0712:302289:302403 [1] NCCL INFO Channel 01 : 369[4b000] -> 370[ca000] via P2P/IPC/read
421: hkn0726:1555337:1555444 [1] NCCL INFO Channel 00 : 421[4b000] -> 422[ca000] via P2P/IPC/read
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 01 : 396[31000] -> 397[4b000] via P2P/IPC/read
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 00 : 481[4b000] -> 482[ca000] via P2P/IPC/read
253: hkn0611:717051:717160 [1] NCCL INFO Channel 01 : 253[4b000] -> 254[ca000] via P2P/IPC/read
230: hkn0604:696451:696579 [2] NCCL INFO Channel 00 : 230[ca000] -> 231[e3000] via P2P/IPC/read
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 00 : 412[31000] -> 413[4b000] via P2P/IPC/read
 70: hkn0422:4160364:4160469 [2] NCCL INFO Channel 01 : 70[ca000] -> 71[e3000] via P2P/IPC/read
249: hkn0609:718036:718147 [1] NCCL INFO Channel 01 : 249[4b000] -> 250[ca000] via P2P/IPC/read
 21: hkn0409:2592894:2592992 [1] NCCL INFO Channel 00 : 21[4b000] -> 22[ca000] via P2P/IPC/read
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 00 : 317[4b000] -> 318[ca000] via P2P/IPC/read
294: hkn0626:1305634:1305784 [2] NCCL INFO Channel 00 : 294[ca000] -> 295[e3000] via P2P/IPC/read
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 00 : 212[31000] -> 213[4b000] via P2P/IPC/read
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 00 : 237[4b000] -> 238[ca000] via P2P/IPC/read
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 00 : 33[4b000] -> 34[ca000] via P2P/IPC/read
119: hkn0506:845284:845410 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
434: hkn0730:1408975:1409075 [2] NCCL INFO Channel 00 : 434[ca000] -> 435[e3000] via P2P/IPC/read
389: hkn0717:1475:1580 [1] NCCL INFO Channel 01 : 389[4b000] -> 390[ca000] via P2P/IPC/read
430: hkn0728:1331266:1331371 [2] NCCL INFO Channel 00 : 430[ca000] -> 431[e3000] via P2P/IPC/read
309: hkn0630:1605694:1605798 [1] NCCL INFO Channel 00 : 309[4b000] -> 310[ca000] via P2P/IPC/read
278: hkn0621:1998838:1998943 [2] NCCL INFO Channel 00 : 278[ca000] -> 279[e3000] via P2P/IPC/read
348: hkn0706:759506:759606 [0] NCCL INFO Channel 01 : 348[31000] -> 349[4b000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 01 : 312[31000] -> 313[4b000] via P2P/IPC/read
115: hkn0505:2310997:2311121 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
366: hkn0711:591185:591287 [2] NCCL INFO Channel 00 : 366[ca000] -> 367[e3000] via P2P/IPC/read
293: hkn0626:1305645:1305779 [1] NCCL INFO Channel 01 : 293[4b000] -> 294[ca000] via P2P/IPC/read
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 00 : 273[4b000] -> 274[ca000] via P2P/IPC/read
214: hkn0535:2406234:2406334 [2] NCCL INFO Channel 00 : 214[ca000] -> 215[e3000] via P2P/IPC/read
142: hkn0512:3051335:3051453 [2] NCCL INFO Connected all rings
175: hkn0524:1141030:1141123 [3] NCCL INFO Connected all trees
119: hkn0506:845284:845410 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
470: hkn0804:1212841:1212966 [2] NCCL INFO Channel 01 : 470[ca000] -> 471[e3000] via P2P/IPC/read
229: hkn0604:696459:696573 [1] NCCL INFO Channel 01 : 229[4b000] -> 230[ca000] via P2P/IPC/read
402: hkn0720:14310:14477 [2] NCCL INFO Channel 00 : 402[ca000] -> 403[e3000] via P2P/IPC/read
233: hkn0605:719360:719472 [1] NCCL INFO Channel 01 : 233[4b000] -> 234[ca000] via P2P/IPC/read
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 01 : 429[4b000] -> 430[ca000] via P2P/IPC/read
442: hkn0732:1218881:1219002 [2] NCCL INFO Channel 00 : 442[ca000] -> 443[e3000] via P2P/IPC/read
300: hkn0628:679159:679255 [0] NCCL INFO Channel 00 : 300[31000] -> 301[4b000] via P2P/IPC/read
122: hkn0507:3194301:3194415 [2] NCCL INFO Channel 00 : 122[ca000] -> 123[e3000] via P2P/IPC/read
115: hkn0505:2310997:2311121 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 90: hkn0427:1142341:1142458 [2] NCCL INFO Channel 01 : 90[ca000] -> 91[e3000] via P2P/IPC/read
286: hkn0623:1879995:1880114 [2] NCCL INFO Channel 00 : 286[ca000] -> 287[e3000] via P2P/IPC/read
381: hkn0715:409138:409236 [1] NCCL INFO Channel 00 : 381[4b000] -> 382[ca000] via P2P/IPC/read
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 01 : 80[31000] -> 81[4b000] via P2P/IPC/read
213: hkn0535:2406206:2406337 [1] NCCL INFO Channel 01 : 213[4b000] -> 214[ca000] via P2P/IPC/read
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 00 : 321[4b000] -> 322[ca000] via P2P/IPC/read
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 00 : 76[31000] -> 77[4b000] via P2P/IPC/read
190: hkn0528:1308903:1309021 [2] NCCL INFO Connected all rings
 26: hkn0410:1166945:1167042 [2] NCCL INFO Connected all rings
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 01 : 433[4b000] -> 434[ca000] via P2P/IPC/read
 60: hkn0420:3217416:3217549 [0] NCCL INFO Connected all rings
170: hkn0523:1555340:1555444 [2] NCCL INFO Channel 01 : 170[ca000] -> 171[e3000] via P2P/IPC/read
458: hkn0801:2247264:2247382 [2] NCCL INFO Channel 00 : 458[ca000] -> 459[e3000] via P2P/IPC/read
385: hkn0716:115707:115856 [1] NCCL INFO Channel 00 : 385[4b000] -> 386[ca000] via P2P/IPC/read
504: hkn0815:402353:402445 [0] NCCL INFO Channel 00 : 504[31000] -> 505[4b000] via P2P/IPC/read
485: hkn0808:977901:978022 [1] NCCL INFO Channel 00 : 485[4b000] -> 486[ca000] via P2P/IPC/read
418: hkn0725:3119184:3119279 [2] NCCL INFO Channel 00 : 418[ca000] -> 419[e3000] via P2P/IPC/read
454: hkn0736:1515545:1515656 [2] NCCL INFO Channel 01 : 454[ca000] -> 455[e3000] via P2P/IPC/read
302: hkn0628:679139:679252 [2] NCCL INFO Channel 00 : 302[ca000] -> 303[e3000] via P2P/IPC/read
341: hkn0704:799223:799342 [1] NCCL INFO Channel 01 : 341[4b000] -> 342[ca000] via P2P/IPC/read
365: hkn0711:591174:591286 [1] NCCL INFO Channel 01 : 365[4b000] -> 366[ca000] via P2P/IPC/read
358: hkn0708:420458:420568 [2] NCCL INFO Channel 00 : 358[ca000] -> 359[e3000] via P2P/IPC/read
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 00 : 52[31000] -> 53[4b000] via P2P/IPC/read
175: hkn0524:1141030:1141123 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
202: hkn0531:1237910:1238025 [2] NCCL INFO Channel 00 : 202[ca000] -> 203[e3000] via P2P/IPC/read
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 00 : 49[4b000] -> 50[ca000] via P2P/IPC/read
462: hkn0802:1207559:1207696 [2] NCCL INFO Channel 00 : 462[ca000] -> 463[e3000] via P2P/IPC/read
505: hkn0815:402333:402447 [1] NCCL INFO Channel 00 : 505[4b000] -> 506[ca000] via P2P/IPC/read
450: hkn0734:1163781:1163870 [2] NCCL INFO Channel 00 : 450[ca000] -> 451[e3000] via P2P/IPC/read
406: hkn0721:2306498:2306623 [2] NCCL INFO Channel 01 : 406[ca000] -> 407[e3000] via P2P/IPC/read
 22: hkn0409:2592882:2592991 [2] NCCL INFO Channel 00 : 22[ca000] -> 23[e3000] via P2P/IPC/read
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 00 : 289[4b000] -> 290[ca000] via P2P/IPC/read
337: hkn0703:748303:748410 [1] NCCL INFO Channel 00 : 337[4b000] -> 338[ca000] via P2P/IPC/read
301: hkn0628:679147:679253 [1] NCCL INFO Channel 01 : 301[4b000] -> 302[ca000] via P2P/IPC/read
265: hkn0615:421570:421665 [1] NCCL INFO Channel 00 : 265[4b000] -> 266[ca000] via P2P/IPC/read
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 01 : 121[4b000] -> 122[ca000] via P2P/IPC/read
182: hkn0526:1435637:1435754 [2] NCCL INFO Channel 01 : 182[ca000] -> 183[e3000] via P2P/IPC/read
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 01 : 332[31000] -> 333[4b000] via P2P/IPC/read
238: hkn0606:2379355:2379460 [2] NCCL INFO Channel 00 : 238[ca000] -> 239[e3000] via P2P/IPC/read
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 01 : 352[31000] -> 353[4b000] via P2P/IPC/read
175: hkn0524:1141030:1141123 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 10: hkn0405:3214170:3214279 [2] NCCL INFO Connected all rings
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 01 : 457[4b000] -> 458[ca000] via P2P/IPC/read
386: hkn0716:115704:115853 [2] NCCL INFO Channel 00 : 386[ca000] -> 387[e3000] via P2P/IPC/read
410: hkn0723:215325:215496 [2] NCCL INFO Channel 00 : 410[ca000] -> 411[e3000] via P2P/IPC/read
493: hkn0810:946752:946862 [1] NCCL INFO Channel 00 : 493[4b000] -> 494[ca000] via P2P/IPC/read
210: hkn0534:1155637:1155744 [2] NCCL INFO Connected all rings
465: hkn0803:883787:883894 [1] NCCL INFO Channel 00 : 465[4b000] -> 466[ca000] via P2P/IPC/read
500: hkn0814:683023:683174 [0] NCCL INFO Channel 00 : 500[31000] -> 501[4b000] via P2P/IPC/read
218: hkn0601:124988:125082 [2] NCCL INFO Channel 01 : 218[ca000] -> 219[e3000] via P2P/IPC/read
325: hkn0634:1528068:1528186 [1] NCCL INFO Connected all rings
277: hkn0621:1998849:1998946 [1] NCCL INFO Channel 01 : 277[4b000] -> 278[ca000] via P2P/IPC/read
349: hkn0706:759478:759608 [1] NCCL INFO Channel 00 : 349[4b000] -> 350[ca000] via P2P/IPC/read
194: hkn0529:1548054:1548165 [2] NCCL INFO Channel 01 : 194[ca000] -> 195[e3000] via P2P/IPC/read
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 00 : 305[4b000] -> 306[ca000] via P2P/IPC/read
 18: hkn0408:2898057:2898153 [2] NCCL INFO Channel 00 : 18[ca000] -> 19[e3000] via P2P/IPC/read
376: hkn0714:439237:439359 [0] NCCL INFO Channel 00 : 376[31000] -> 377[4b000] via P2P/IPC/read
357: hkn0708:420450:420563 [1] NCCL INFO Channel 01 : 357[4b000] -> 358[ca000] via P2P/IPC/read
 95: hkn0428:674595:674697 [3] NCCL INFO Connected all trees
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 01 : 201[4b000] -> 202[ca000] via P2P/IPC/read
  1: hkn0403:1776565:1776936 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[ca000] via P2P/IPC/read
409: hkn0723:215333:215489 [1] NCCL INFO Channel 01 : 409[4b000] -> 410[ca000] via P2P/IPC/read
401: hkn0720:14318:14478 [1] NCCL INFO Channel 01 : 401[4b000] -> 402[ca000] via P2P/IPC/read
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 01 : 440[31000] -> 441[4b000] via P2P/IPC/read
310: hkn0630:1605686:1605806 [2] NCCL INFO Channel 00 : 310[ca000] -> 311[e3000] via P2P/IPC/read
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 01 : 17[4b000] -> 18[ca000] via P2P/IPC/read
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 00 : 129[4b000] -> 130[ca000] via P2P/IPC/read
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 01 : 285[4b000] -> 286[ca000] via P2P/IPC/read
382: hkn0715:409118:409228 [2] NCCL INFO Channel 00 : 382[ca000] -> 383[e3000] via P2P/IPC/read
 82: hkn0425:2091279:2091402 [2] NCCL INFO Channel 01 : 82[ca000] -> 83[e3000] via P2P/IPC/read
322: hkn0633:1533554:1533664 [2] NCCL INFO Channel 00 : 322[ca000] -> 323[e3000] via P2P/IPC/read
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 00 : 45[4b000] -> 46[ca000] via P2P/IPC/read
 66: hkn0421:2189220:2189406 [2] NCCL INFO Channel 01 : 66[ca000] -> 67[e3000] via P2P/IPC/read
262: hkn0613:909916:910043 [2] NCCL INFO Channel 01 : 262[ca000] -> 263[e3000] via P2P/IPC/read
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 00 : 8[31000] -> 9[4b000] via P2P/IPC/read
147: hkn0513:3020216:3020303 [3] NCCL INFO Connected all trees
422: hkn0726:1555349:1555447 [2] NCCL INFO Channel 00 : 422[ca000] -> 423[e3000] via P2P/IPC/read
510: hkn0816:382843:382953 [2] NCCL INFO Channel 01 : 510[ca000] -> 511[e3000] via P2P/IPC/read
  5: hkn0404:1346653:1346760 [1] NCCL INFO Channel 00 : 5[4b000] -> 6[ca000] via P2P/IPC/read
258: hkn0612:924199:924320 [2] NCCL INFO Channel 01 : 258[ca000] -> 259[e3000] via P2P/IPC/read
474: hkn0805:1119317:1119439 [2] NCCL INFO Connected all rings
377: hkn0714:439253:439365 [1] NCCL INFO Channel 00 : 377[4b000] -> 378[ca000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO Channel 01 : 364[31000] -> 365[4b000] via P2P/IPC/read
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 00 : 281[4b000] -> 282[ca000] via P2P/IPC/read
274: hkn0617:2301935:2302046 [2] NCCL INFO Channel 00 : 274[ca000] -> 275[e3000] via P2P/IPC/read
 57: hkn0419:1551489:1551602 [1] NCCL INFO Connected all rings
 95: hkn0428:674595:674697 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 34: hkn0412:2269636:2269732 [2] NCCL INFO Channel 00 : 34[ca000] -> 35[e3000] via P2P/IPC/read
134: hkn0510:2769278:2769396 [2] NCCL INFO Connected all trees
482: hkn0807:1026293:1026403 [2] NCCL INFO Channel 00 : 482[ca000] -> 483[e3000] via P2P/IPC/read
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 01 : 12[31000] -> 13[4b000] via P2P/IPC/read
269: hkn0616:412177:412290 [1] NCCL INFO Channel 00 : 269[4b000] -> 270[ca000] via P2P/IPC/read
426: hkn0727:1353002:1353113 [2] NCCL INFO Channel 01 : 426[ca000] -> 427[e3000] via P2P/IPC/read
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 01 : 441[4b000] -> 442[ca000] via P2P/IPC/read
290: hkn0624:1780132:1780286 [2] NCCL INFO Channel 00 : 290[ca000] -> 291[e3000] via P2P/IPC/read
338: hkn0703:748322:748407 [2] NCCL INFO Channel 00 : 338[ca000] -> 339[e3000] via P2P/IPC/read
242: hkn0607:911587:911714 [2] NCCL INFO Connected all rings
318: hkn0632:1765851:1765965 [2] NCCL INFO Channel 00 : 318[ca000] -> 319[e3000] via P2P/IPC/read
246: hkn0608:492947:493073 [2] NCCL INFO Channel 01 : 246[ca000] -> 247[e3000] via P2P/IPC/read
356: hkn0708:420442:420567 [0] NCCL INFO Channel 01 : 356[31000] -> 357[4b000] via P2P/IPC/read
103: hkn0502:236303:236407 [3] NCCL INFO Connected all trees
 95: hkn0428:674595:674697 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
107: hkn0503:2906943:2907062 [3] NCCL INFO Connected all trees
147: hkn0513:3020216:3020303 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 01 : 461[4b000] -> 462[ca000] via P2P/IPC/read
421: hkn0726:1555337:1555444 [1] NCCL INFO Channel 01 : 421[4b000] -> 422[ca000] via P2P/IPC/read
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 01 : 481[4b000] -> 482[ca000] via P2P/IPC/read
254: hkn0611:717063:717166 [2] NCCL INFO Channel 01 : 254[ca000] -> 255[e3000] via P2P/IPC/read
497: hkn0812:701035:701150 [1] NCCL INFO Channel 00 : 497[4b000] -> 498[ca000] via P2P/IPC/read
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 01 : 449[4b000] -> 450[ca000] via P2P/IPC/read
390: hkn0717:1487:1589 [2] NCCL INFO Channel 01 : 390[ca000] -> 391[e3000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 01 : 416[31000] -> 417[4b000] via P2P/IPC/read
502: hkn0814:683050:683175 [2] NCCL INFO Connected all rings
478: hkn0806:1061550:1061649 [2] NCCL INFO Channel 01 : 478[ca000] -> 479[e3000] via P2P/IPC/read
 21: hkn0409:2592894:2592992 [1] NCCL INFO Channel 01 : 21[4b000] -> 22[ca000] via P2P/IPC/read
266: hkn0615:421558:421661 [2] NCCL INFO Channel 00 : 266[ca000] -> 267[e3000] via P2P/IPC/read
361: hkn0710:362772:362881 [1] NCCL INFO Connected all rings
222: hkn0602:3370898:3371093 [2] NCCL INFO Channel 01 : 222[ca000] -> 223[e3000] via P2P/IPC/read
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 01 : 317[4b000] -> 318[ca000] via P2P/IPC/read
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 01 : 273[4b000] -> 274[ca000] via P2P/IPC/read
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 01 : 237[4b000] -> 238[ca000] via P2P/IPC/read
 30: hkn0411:2323089:2323199 [2] NCCL INFO Channel 00 : 30[ca000] -> 31[e3000] via P2P/IPC/read
139: hkn0511:3073664:3073769 [3] NCCL INFO Connected all trees
139: hkn0511:3073664:3073769 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  2: hkn0403:1776577:1776939 [2] NCCL INFO Channel 00 : 2[ca000] -> 3[e3000] via P2P/IPC/read
494: hkn0810:946736:946861 [2] NCCL INFO Channel 00 : 494[ca000] -> 495[e3000] via P2P/IPC/read
 38: hkn0413:2373948:2374057 [2] NCCL INFO Channel 01 : 38[ca000] -> 39[e3000] via P2P/IPC/read
486: hkn0808:977893:978014 [2] NCCL INFO Channel 00 : 486[ca000] -> 487[e3000] via P2P/IPC/read
234: hkn0605:719352:719473 [2] NCCL INFO Channel 01 : 234[ca000] -> 235[e3000] via P2P/IPC/read
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 01 : 417[4b000] -> 418[ca000] via P2P/IPC/read
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 01 : 436[31000] -> 437[4b000] via P2P/IPC/read
489: hkn0809:944571:944666 [1] NCCL INFO Channel 00 : 489[4b000] -> 490[ca000] via P2P/IPC/read
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 00 : 397[4b000] -> 398[ca000] via P2P/IPC/read
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 00 : 13[4b000] -> 14[ca000] via P2P/IPC/read
385: hkn0716:115707:115856 [1] NCCL INFO Channel 01 : 385[4b000] -> 386[ca000] via P2P/IPC/read
485: hkn0808:977901:978022 [1] NCCL INFO Channel 01 : 485[4b000] -> 486[ca000] via P2P/IPC/read
466: hkn0803:883795:883893 [2] NCCL INFO Channel 00 : 466[ca000] -> 467[e3000] via P2P/IPC/read
394: hkn0718:3924274:3924372 [2] NCCL INFO Channel 01 : 394[ca000] -> 395[e3000] via P2P/IPC/read
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 01 : 412[31000] -> 413[4b000] via P2P/IPC/read
226: hkn0603:1420466:1420571 [2] NCCL INFO Channel 01 : 226[ca000] -> 227[e3000] via P2P/IPC/read
493: hkn0810:946752:946862 [1] NCCL INFO Channel 01 : 493[4b000] -> 494[ca000] via P2P/IPC/read
250: hkn0609:718028:718154 [2] NCCL INFO Channel 01 : 250[ca000] -> 251[e3000] via P2P/IPC/read
386: hkn0716:115704:115853 [2] NCCL INFO Channel 01 : 386[ca000] -> 387[e3000] via P2P/IPC/read
111: hkn0504:48327:48437 [3] NCCL INFO Connected all trees
  1: hkn0403:1776565:1776936 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[ca000] via P2P/IPC/read
230: hkn0604:696451:696579 [2] NCCL INFO Channel 01 : 230[ca000] -> 231[e3000] via P2P/IPC/read
111: hkn0504:48327:48437 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:14310:14477 [2] NCCL INFO Channel 01 : 402[ca000] -> 403[e3000] via P2P/IPC/read
111: hkn0504:48327:48437 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1346665:1346763 [2] NCCL INFO Channel 00 : 6[ca000] -> 7[e3000] via P2P/IPC/read
398: hkn0719:1312991:1313080 [2] NCCL INFO Channel 00 : 398[ca000] -> 399[e3000] via P2P/IPC/read
  5: hkn0404:1346653:1346760 [1] NCCL INFO Channel 01 : 5[4b000] -> 6[ca000] via P2P/IPC/read
506: hkn0815:402341:402450 [2] NCCL INFO Channel 00 : 506[ca000] -> 507[e3000] via P2P/IPC/read
498: hkn0812:701043:701153 [2] NCCL INFO Channel 00 : 498[ca000] -> 499[e3000] via P2P/IPC/read
270: hkn0616:412161:412288 [2] NCCL INFO Channel 00 : 270[ca000] -> 271[e3000] via P2P/IPC/read
490: hkn0809:944543:944669 [2] NCCL INFO Channel 00 : 490[ca000] -> 491[e3000] via P2P/IPC/read
497: hkn0812:701035:701150 [1] NCCL INFO Channel 01 : 497[4b000] -> 498[ca000] via P2P/IPC/read
269: hkn0616:412177:412290 [1] NCCL INFO Channel 01 : 269[4b000] -> 270[ca000] via P2P/IPC/read
504: hkn0815:402353:402445 [0] NCCL INFO Channel 01 : 504[31000] -> 505[4b000] via P2P/IPC/read
450: hkn0734:1163781:1163870 [2] NCCL INFO Channel 01 : 450[ca000] -> 451[e3000] via P2P/IPC/read
418: hkn0725:3119184:3119279 [2] NCCL INFO Channel 01 : 418[ca000] -> 419[e3000] via P2P/IPC/read
465: hkn0803:883787:883894 [1] NCCL INFO Channel 01 : 465[4b000] -> 466[ca000] via P2P/IPC/read
505: hkn0815:402333:402447 [1] NCCL INFO Channel 01 : 505[4b000] -> 506[ca000] via P2P/IPC/read
489: hkn0809:944571:944666 [1] NCCL INFO Channel 01 : 489[4b000] -> 490[ca000] via P2P/IPC/read
 14: hkn0407:1823492:1823615 [2] NCCL INFO Channel 00 : 14[ca000] -> 15[e3000] via P2P/IPC/read
430: hkn0728:1331266:1331371 [2] NCCL INFO Channel 01 : 430[ca000] -> 431[e3000] via P2P/IPC/read
442: hkn0732:1218881:1219002 [2] NCCL INFO Channel 01 : 442[ca000] -> 443[e3000] via P2P/IPC/read
 22: hkn0409:2592882:2592991 [2] NCCL INFO Channel 01 : 22[ca000] -> 23[e3000] via P2P/IPC/read
309: hkn0630:1605694:1605798 [1] NCCL INFO Channel 01 : 309[4b000] -> 310[ca000] via P2P/IPC/read
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 01 : 289[4b000] -> 290[ca000] via P2P/IPC/read
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 01 : 397[4b000] -> 398[ca000] via P2P/IPC/read
338: hkn0703:748322:748407 [2] NCCL INFO Channel 01 : 338[ca000] -> 339[e3000] via P2P/IPC/read
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 01 : 13[4b000] -> 14[ca000] via P2P/IPC/read
500: hkn0814:683023:683174 [0] NCCL INFO Channel 01 : 500[31000] -> 501[4b000] via P2P/IPC/read
310: hkn0630:1605686:1605806 [2] NCCL INFO Channel 01 : 310[ca000] -> 311[e3000] via P2P/IPC/read
337: hkn0703:748303:748410 [1] NCCL INFO Channel 01 : 337[4b000] -> 338[ca000] via P2P/IPC/read
422: hkn0726:1555349:1555447 [2] NCCL INFO Channel 01 : 422[ca000] -> 423[e3000] via P2P/IPC/read
482: hkn0807:1026293:1026403 [2] NCCL INFO Channel 01 : 482[ca000] -> 483[e3000] via P2P/IPC/read
494: hkn0810:946736:946861 [2] NCCL INFO Channel 01 : 494[ca000] -> 495[e3000] via P2P/IPC/read
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 00 : 324[31000] -> 325[4b000] via P2P/IPC/read
  2: hkn0403:1776577:1776939 [2] NCCL INFO Channel 01 : 2[ca000] -> 3[e3000] via P2P/IPC/read
290: hkn0624:1780132:1780286 [2] NCCL INFO Channel 01 : 290[ca000] -> 291[e3000] via P2P/IPC/read
 71: hkn0422:4160348:4160470 [3] NCCL INFO Connected all trees
326: hkn0634:1528060:1528187 [2] NCCL INFO Connected all rings
437: hkn0731:1393941:1394086 [1] NCCL INFO Channel 00 : 437[4b000] -> 438[ca000] via P2P/IPC/read
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 00 : 413[4b000] -> 414[ca000] via P2P/IPC/read
447: hkn0733:1396600:1396698 [3] NCCL INFO Connected all trees
 71: hkn0422:4160348:4160470 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
407: hkn0721:2306506:2306615 [3] NCCL INFO Connected all trees
 71: hkn0422:4160348:4160470 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
447: hkn0733:1396600:1396698 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
486: hkn0808:977893:978014 [2] NCCL INFO Channel 01 : 486[ca000] -> 487[e3000] via P2P/IPC/read
447: hkn0733:1396600:1396698 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
407: hkn0721:2306506:2306615 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
207: hkn0532:932502:932816 [3] NCCL INFO Connected all trees
407: hkn0721:2306506:2306615 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
455: hkn0736:1515543:1515649 [3] NCCL INFO Connected all trees
219: hkn0601:124976:125081 [3] NCCL INFO Connected all trees
207: hkn0532:932502:932816 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
455: hkn0736:1515543:1515649 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
207: hkn0532:932502:932816 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 00 : 209[4b000] -> 210[ca000] via P2P/IPC/read
455: hkn0736:1515543:1515649 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
466: hkn0803:883795:883893 [2] NCCL INFO Channel 01 : 466[ca000] -> 467[e3000] via P2P/IPC/read
438: hkn0731:1393942:1394083 [2] NCCL INFO Channel 00 : 438[ca000] -> 439[e3000] via P2P/IPC/read
490: hkn0809:944543:944669 [2] NCCL INFO Channel 01 : 490[ca000] -> 491[e3000] via P2P/IPC/read
219: hkn0601:124976:125081 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
339: hkn0703:748311:748409 [3] NCCL INFO Connected all trees
259: hkn0612:924215:924321 [3] NCCL INFO Connected all trees
219: hkn0601:124976:125081 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
398: hkn0719:1312991:1313080 [2] NCCL INFO Channel 01 : 398[ca000] -> 399[e3000] via P2P/IPC/read
  6: hkn0404:1346665:1346763 [2] NCCL INFO Channel 01 : 6[ca000] -> 7[e3000] via P2P/IPC/read
511: hkn0816:382835:382955 [3] NCCL INFO Connected all trees
270: hkn0616:412161:412288 [2] NCCL INFO Channel 01 : 270[ca000] -> 271[e3000] via P2P/IPC/read
511: hkn0816:382835:382955 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
259: hkn0612:924215:924321 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
511: hkn0816:382835:382955 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
259: hkn0612:924215:924321 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
479: hkn0806:1061530:1061646 [3] NCCL INFO Connected all trees
339: hkn0703:748311:748409 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
410: hkn0723:215325:215496 [2] NCCL INFO Channel 01 : 410[ca000] -> 411[e3000] via P2P/IPC/read
255: hkn0611:717043:717161 [3] NCCL INFO Connected all trees
210: hkn0534:1155637:1155744 [2] NCCL INFO Channel 00 : 210[ca000] -> 211[e3000] via P2P/IPC/read
498: hkn0812:701043:701153 [2] NCCL INFO Channel 01 : 498[ca000] -> 499[e3000] via P2P/IPC/read
255: hkn0611:717043:717161 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 39: hkn0413:2373932:2374059 [3] NCCL INFO Connected all trees
 39: hkn0413:2373932:2374059 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:402341:402450 [2] NCCL INFO Channel 01 : 506[ca000] -> 507[e3000] via P2P/IPC/read
255: hkn0611:717043:717161 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 39: hkn0413:2373932:2374059 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
437: hkn0731:1393941:1394086 [1] NCCL INFO Channel 01 : 437[4b000] -> 438[ca000] via P2P/IPC/read
427: hkn0727:1353022:1353120 [3] NCCL INFO Connected all trees
414: hkn0724:1723187:1723325 [2] NCCL INFO Channel 00 : 414[ca000] -> 415[e3000] via P2P/IPC/read
 14: hkn0407:1823492:1823615 [2] NCCL INFO Channel 01 : 14[ca000] -> 15[e3000] via P2P/IPC/read
391: hkn0717:1459:1584 [3] NCCL INFO Connected all trees
427: hkn0727:1353022:1353120 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 01 : 413[4b000] -> 414[ca000] via P2P/IPC/read
110: hkn0504:48311:48436 [2] NCCL INFO Connected all trees
391: hkn0717:1459:1584 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
391: hkn0717:1459:1584 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
427: hkn0727:1353022:1353120 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
110: hkn0504:48311:48436 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 00 : 473[4b000] -> 474[ca000] via P2P/IPC/read
231: hkn0604:696467:696570 [3] NCCL INFO Connected all trees
110: hkn0504:48311:48436 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 01 : 209[4b000] -> 210[ca000] via P2P/IPC/read
235: hkn0605:719372:719467 [3] NCCL INFO Connected all trees
231: hkn0604:696467:696570 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
431: hkn0728:1331257:1331376 [3] NCCL INFO Connected all trees
231: hkn0604:696467:696570 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
235: hkn0605:719372:719467 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
235: hkn0605:719372:719467 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
431: hkn0728:1331257:1331376 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
431: hkn0728:1331257:1331376 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
395: hkn0718:3924254:3924371 [3] NCCL INFO Connected all trees
395: hkn0718:3924254:3924371 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
474: hkn0805:1119317:1119439 [2] NCCL INFO Channel 00 : 474[ca000] -> 475[e3000] via P2P/IPC/read
395: hkn0718:3924254:3924371 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
108: hkn0504:48339:48431 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [receive] via NET/IBext/0
501: hkn0814:683039:683170 [1] NCCL INFO Channel 00 : 501[4b000] -> 502[ca000] via P2P/IPC/read
227: hkn0603:1420478:1420573 [3] NCCL INFO Connected all trees
479: hkn0806:1061530:1061646 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
479: hkn0806:1061530:1061646 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
403: hkn0720:14330:14481 [3] NCCL INFO Connected all trees
502: hkn0814:683050:683175 [2] NCCL INFO Channel 00 : 502[ca000] -> 503[e3000] via P2P/IPC/read
387: hkn0716:115727:115858 [3] NCCL INFO Connected all trees
227: hkn0603:1420478:1420573 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
403: hkn0720:14330:14481 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
227: hkn0603:1420478:1420573 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
387: hkn0716:115727:115858 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
403: hkn0720:14330:14481 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
387: hkn0716:115727:115858 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
438: hkn0731:1393942:1394083 [2] NCCL INFO Channel 01 : 438[ca000] -> 439[e3000] via P2P/IPC/read
451: hkn0734:1163769:1163876 [3] NCCL INFO Connected all trees
443: hkn0732:1218882:1219000 [3] NCCL INFO Connected all trees
451: hkn0734:1163769:1163876 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
251: hkn0609:718044:718148 [3] NCCL INFO Connected all trees
451: hkn0734:1163769:1163876 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
419: hkn0725:3119172:3119282 [3] NCCL INFO Connected all trees
423: hkn0726:1555329:1555441 [3] NCCL INFO Connected all trees
423: hkn0726:1555329:1555441 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
483: hkn0807:1026305:1026402 [3] NCCL INFO Connected all trees
423: hkn0726:1555329:1555441 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
206: hkn0532:932510:932820 [2] NCCL INFO Connected all trees
483: hkn0807:1026305:1026402 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 01 : 473[4b000] -> 474[ca000] via P2P/IPC/read
483: hkn0807:1026305:1026402 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
206: hkn0532:932510:932820 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
206: hkn0532:932510:932820 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
210: hkn0534:1155637:1155744 [2] NCCL INFO Channel 01 : 210[ca000] -> 211[e3000] via P2P/IPC/read
446: hkn0733:1396572:1396700 [2] NCCL INFO Connected all trees
495: hkn0810:946744:946866 [3] NCCL INFO Connected all trees
414: hkn0724:1723187:1723325 [2] NCCL INFO Channel 01 : 414[ca000] -> 415[e3000] via P2P/IPC/read
419: hkn0725:3119172:3119282 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
446: hkn0733:1396572:1396700 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
495: hkn0810:946744:946866 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  3: hkn0403:1776560:1776937 [3] NCCL INFO Connected all trees
446: hkn0733:1396572:1396700 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  3: hkn0403:1776560:1776937 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  3: hkn0403:1776560:1776937 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
495: hkn0810:946744:946866 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
419: hkn0725:3119172:3119282 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
454: hkn0736:1515545:1515656 [2] NCCL INFO Connected all trees
406: hkn0721:2306498:2306623 [2] NCCL INFO Connected all trees
501: hkn0814:683039:683170 [1] NCCL INFO Channel 01 : 501[4b000] -> 502[ca000] via P2P/IPC/read
454: hkn0736:1515545:1515656 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
406: hkn0721:2306498:2306623 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
454: hkn0736:1515545:1515656 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
406: hkn0721:2306498:2306623 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:932494:932817 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [receive] via NET/IBext/0
443: hkn0732:1218882:1219000 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
443: hkn0732:1218882:1219000 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 70: hkn0422:4160364:4160469 [2] NCCL INFO Connected all trees
510: hkn0816:382843:382953 [2] NCCL INFO Connected all trees
  7: hkn0404:1346645:1346762 [3] NCCL INFO Connected all trees
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [receive] via NET/IBext/0
510: hkn0816:382843:382953 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
510: hkn0816:382843:382953 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  7: hkn0404:1346645:1346762 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  7: hkn0404:1346645:1346762 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
271: hkn0616:412189:412285 [3] NCCL INFO Connected all trees
487: hkn0808:977909:978016 [3] NCCL INFO Connected all trees
426: hkn0727:1353002:1353113 [2] NCCL INFO Connected all trees
399: hkn0719:1312971:1313088 [3] NCCL INFO Connected all trees
254: hkn0611:717063:717166 [2] NCCL INFO Connected all trees
 38: hkn0413:2373948:2374057 [2] NCCL INFO Connected all trees
487: hkn0808:977909:978016 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
399: hkn0719:1312971:1313088 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
254: hkn0611:717063:717166 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
399: hkn0719:1312971:1313088 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:717063:717166 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 38: hkn0413:2373948:2374057 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
487: hkn0808:977909:978016 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
507: hkn0815:402329:402444 [3] NCCL INFO Connected all trees
 38: hkn0413:2373948:2374057 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
499: hkn0812:701057:701148 [3] NCCL INFO Connected all trees
271: hkn0616:412189:412285 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
411: hkn0723:215353:215498 [3] NCCL INFO Connected all trees
507: hkn0815:402329:402444 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
507: hkn0815:402329:402444 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1823508:1823614 [3] NCCL INFO Connected all trees
411: hkn0723:215353:215498 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
508: hkn0816:382834:382958 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [receive] via NET/IBext/0
411: hkn0723:215353:215498 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1823508:1823614 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 15: hkn0407:1823508:1823614 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [receive] via NET/IBext/0
252: hkn0611:717035:717164 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [receive] via NET/IBext/0
230: hkn0604:696451:696579 [2] NCCL INFO Connected all trees
499: hkn0812:701057:701148 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
271: hkn0616:412189:412285 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
230: hkn0604:696451:696579 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
509: hkn0816:382855:382951 [1] NCCL INFO Channel 00 : 509[4b000] -> 508[31000] via P2P/IPC/read
230: hkn0604:696451:696579 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
499: hkn0812:701057:701148 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
390: hkn0717:1487:1589 [2] NCCL INFO Connected all trees
426: hkn0727:1353002:1353113 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:14310:14477 [2] NCCL INFO Connected all trees
426: hkn0727:1353002:1353113 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
390: hkn0717:1487:1589 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [send] via NET/IBext/0
386: hkn0716:115704:115853 [2] NCCL INFO Connected all trees
402: hkn0720:14310:14477 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:14310:14477 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
390: hkn0717:1487:1589 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:115704:115853 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
388: hkn0717:1467:1586 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [receive] via NET/IBext/0
386: hkn0716:115704:115853 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:696478:696578 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [receive] via NET/IBext/0
258: hkn0612:924199:924320 [2] NCCL INFO Connected all trees
474: hkn0805:1119317:1119439 [2] NCCL INFO Channel 01 : 474[ca000] -> 475[e3000] via P2P/IPC/read
439: hkn0731:1393950:1394081 [3] NCCL INFO Connected all trees
439: hkn0731:1393950:1394081 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
234: hkn0605:719352:719473 [2] NCCL INFO Connected all trees
439: hkn0731:1393950:1394081 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
509: hkn0816:382855:382951 [1] NCCL INFO Channel 01 : 509[4b000] -> 508[31000] via P2P/IPC/read
258: hkn0612:924199:924320 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
234: hkn0605:719352:719473 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
482: hkn0807:1026293:1026403 [2] NCCL INFO Connected all trees
258: hkn0612:924199:924320 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
422: hkn0726:1555349:1555447 [2] NCCL INFO Connected all trees
256: hkn0612:924207:924324 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [send] via NET/IBext/0
482: hkn0807:1026293:1026403 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
234: hkn0605:719352:719473 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
422: hkn0726:1555349:1555447 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
482: hkn0807:1026293:1026403 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
422: hkn0726:1555349:1555447 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1163781:1163870 [2] NCCL INFO Connected all trees
494: hkn0810:946736:946861 [2] NCCL INFO Connected all trees
211: hkn0534:1155652:1155751 [3] NCCL INFO Connected all trees
450: hkn0734:1163781:1163870 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
418: hkn0725:3119184:3119279 [2] NCCL INFO Connected all trees
494: hkn0810:946736:946861 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
211: hkn0534:1155652:1155751 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
494: hkn0810:946736:946861 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
211: hkn0534:1155652:1155751 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1163781:1163870 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:719349:719471 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [send] via NET/IBext/0
418: hkn0725:3119184:3119279 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [receive] via NET/IBext/0
  2: hkn0403:1776577:1776939 [2] NCCL INFO Connected all trees
  2: hkn0403:1776577:1776939 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
418: hkn0725:3119184:3119279 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  2: hkn0403:1776577:1776939 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:14302:14479 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [send] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [send] via NET/IBext/0
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [send] via NET/IBext/0
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [receive] via NET/IBext/0
486: hkn0808:977893:978014 [2] NCCL INFO Connected all trees
491: hkn0809:944551:944668 [3] NCCL INFO Connected all trees
467: hkn0803:883807:883885 [3] NCCL INFO Connected all trees
486: hkn0808:977893:978014 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
415: hkn0724:1723198:1723323 [3] NCCL INFO Connected all trees
486: hkn0808:977893:978014 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
491: hkn0809:944551:944668 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  6: hkn0404:1346665:1346763 [2] NCCL INFO Connected all trees
415: hkn0724:1723198:1723323 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  6: hkn0404:1346665:1346763 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
415: hkn0724:1723198:1723323 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1346665:1346763 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
270: hkn0616:412161:412288 [2] NCCL INFO Connected all trees
270: hkn0616:412161:412288 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [send] via NET/IBext/0
506: hkn0815:402341:402450 [2] NCCL INFO Connected all trees
270: hkn0616:412161:412288 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
491: hkn0809:944551:944668 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
398: hkn0719:1312991:1313080 [2] NCCL INFO Connected all trees
506: hkn0815:402341:402450 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:402341:402450 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:977921:978021 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [receive] via NET/IBext/0
398: hkn0719:1312991:1313080 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
498: hkn0812:701043:701153 [2] NCCL INFO Connected all trees
398: hkn0719:1312991:1313080 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:946764:946863 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [receive] via NET/IBext/0
498: hkn0812:701043:701153 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
490: hkn0809:944543:944669 [2] NCCL INFO Connected all trees
 14: hkn0407:1823492:1823615 [2] NCCL INFO Connected all trees
498: hkn0812:701043:701153 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
490: hkn0809:944543:944669 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
467: hkn0803:883807:883885 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
467: hkn0803:883807:883885 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
410: hkn0723:215325:215496 [2] NCCL INFO Connected all trees
 14: hkn0407:1823492:1823615 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  1: hkn0403:1776565:1776936 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via P2P/IPC/read
 14: hkn0407:1823492:1823615 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
410: hkn0723:215325:215496 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [receive] via NET/IBext/0
410: hkn0723:215325:215496 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
109: hkn0504:48319:48430 [1] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [send] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [send] via NET/IBext/0
268: hkn0616:412169:412281 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [receive] via NET/IBext/0
490: hkn0809:944543:944669 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
466: hkn0803:883795:883893 [2] NCCL INFO Connected all trees
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [receive] via NET/IBext/0
475: hkn0805:1119325:1119448 [3] NCCL INFO Connected all trees
488: hkn0809:944559:944660 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [send] via NET/IBext/0
466: hkn0803:883795:883893 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
466: hkn0803:883795:883893 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
475: hkn0805:1119325:1119448 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [receive] via NET/IBext/0
205: hkn0532:932522:932818 [1] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [send] via NET/IBext/0
475: hkn0805:1119325:1119448 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
430: hkn0728:1331266:1331371 [2] NCCL INFO Connected all trees
394: hkn0718:3924274:3924372 [2] NCCL INFO Connected all trees
502: hkn0814:683050:683175 [2] NCCL INFO Channel 01 : 502[ca000] -> 503[e3000] via P2P/IPC/read
226: hkn0603:1420466:1420571 [2] NCCL INFO Connected all trees
  1: hkn0403:1776565:1776936 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via P2P/IPC/read
430: hkn0728:1331266:1331371 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
430: hkn0728:1331266:1331371 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
394: hkn0718:3924274:3924372 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [receive] via NET/IBext/0
394: hkn0718:3924274:3924372 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
464: hkn0803:883779:883891 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [send] via NET/IBext/0
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [send] via NET/IBext/0
496: hkn0812:701027:701151 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [send] via NET/IBext/0
503: hkn0814:683031:683177 [3] NCCL INFO Connected all trees
503: hkn0814:683031:683177 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
226: hkn0603:1420466:1420571 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
503: hkn0814:683031:683177 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
226: hkn0603:1420466:1420571 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [send] via NET/IBext/0
442: hkn0732:1218881:1219002 [2] NCCL INFO Connected all trees
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [receive] via NET/IBext/0
210: hkn0534:1155637:1155744 [2] NCCL INFO Connected all trees
210: hkn0534:1155637:1155744 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
210: hkn0534:1155637:1155744 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
438: hkn0731:1393942:1394083 [2] NCCL INFO Connected all trees
384: hkn0716:115715:115850 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [send] via NET/IBext/0
442: hkn0732:1218881:1219002 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
438: hkn0731:1393942:1394083 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
442: hkn0732:1218881:1219002 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
438: hkn0731:1393942:1394083 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [send] via NET/IBext/0
 70: hkn0422:4160364:4160469 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
478: hkn0806:1061550:1061649 [2] NCCL INFO Connected all trees
 70: hkn0422:4160364:4160469 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
251: hkn0609:718044:718148 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [send] via NET/IBext/0
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [receive] via NET/IBext/0
 69: hkn0422:4160356:4160471 [1] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [receive] via NET/IBext/0
478: hkn0806:1061550:1061649 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
405: hkn0721:2306514:2306619 [1] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [receive] via NET/IBext/0
478: hkn0806:1061550:1061649 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [receive] via NET/IBext/0
251: hkn0609:718044:718148 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [send] via NET/IBext/0
453: hkn0736:1515557:1515653 [1] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [receive] via NET/IBext/0
250: hkn0609:718028:718154 [2] NCCL INFO Connected all trees
 23: hkn0409:2592874:2592989 [3] NCCL INFO Connected all trees
504: hkn0815:402353:402445 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [send] via NET/IBext/0
311: hkn0630:1605706:1605807 [3] NCCL INFO Connected all trees
250: hkn0609:718028:718154 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 23: hkn0409:2592874:2592989 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
250: hkn0609:718028:718154 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 23: hkn0409:2592874:2592989 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:718056:718153 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [send] via NET/IBext/0
 22: hkn0409:2592882:2592991 [2] NCCL INFO Connected all trees
 22: hkn0409:2592882:2592991 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1723187:1723325 [2] NCCL INFO Connected all trees
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [receive] via NET/IBext/0
414: hkn0724:1723187:1723325 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 22: hkn0409:2592882:2592991 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
414: hkn0724:1723187:1723325 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [receive] via NET/IBext/0
311: hkn0630:1605706:1605807 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
291: hkn0624:1780148:1780287 [3] NCCL INFO Connected all trees
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [send] via NET/IBext/0
311: hkn0630:1605706:1605807 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
310: hkn0630:1605686:1605806 [2] NCCL INFO Connected all trees
291: hkn0624:1780148:1780287 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [send] via NET/IBext/0
310: hkn0630:1605686:1605806 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [receive] via NET/IBext/0
257: hkn0612:924227:924322 [1] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [receive] via NET/IBext/0
 37: hkn0413:2373940:2374062 [1] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [receive] via NET/IBext/0
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [receive] via NET/IBext/0
310: hkn0630:1605686:1605806 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
291: hkn0624:1780148:1780287 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [receive] via NET/IBext/0
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [receive] via NET/IBext/0
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [receive] via NET/IBext/0
290: hkn0624:1780132:1780286 [2] NCCL INFO Connected all trees
290: hkn0624:1780132:1780286 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
218: hkn0601:124988:125082 [2] NCCL INFO Connected all trees
502: hkn0814:683050:683175 [2] NCCL INFO Connected all trees
290: hkn0624:1780132:1780286 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [send] via NET/IBext/0
218: hkn0601:124988:125082 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:1475:1580 [1] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [receive] via NET/IBext/0
502: hkn0814:683050:683175 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
502: hkn0814:683050:683175 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
249: hkn0609:718036:718147 [1] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [receive] via NET/IBext/0
218: hkn0601:124988:125082 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
339: hkn0703:748311:748409 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
216: hkn0601:124960:125086 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [send] via NET/IBext/0
338: hkn0703:748322:748407 [2] NCCL INFO Connected all trees
229: hkn0604:696459:696573 [1] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [receive] via NET/IBext/0
233: hkn0605:719360:719472 [1] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [receive] via NET/IBext/0
217: hkn0601:124968:125085 [1] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [receive] via NET/IBext/0
338: hkn0703:748322:748407 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
474: hkn0805:1119317:1119439 [2] NCCL INFO Connected all trees
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [send] via NET/IBext/0
474: hkn0805:1119317:1119439 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
338: hkn0703:748322:748407 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:717051:717160 [1] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [send] via NET/IBext/0
474: hkn0805:1119317:1119439 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [receive] via NET/IBext/0
500: hkn0814:683023:683174 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [receive] via NET/IBext/0
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [receive] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [send] via NET/IBext/0
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 01 : 324[31000] -> 325[4b000] via P2P/IPC/read
300: hkn0628:679159:679255 [0] NCCL INFO Channel 01 : 300[31000] -> 301[4b000] via P2P/IPC/read
278: hkn0621:1998838:1998943 [2] NCCL INFO Channel 01 : 278[ca000] -> 279[e3000] via P2P/IPC/read
265: hkn0615:421570:421665 [1] NCCL INFO Channel 01 : 265[4b000] -> 266[ca000] via P2P/IPC/read
401: hkn0720:14318:14478 [1] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [receive] via NET/IBext/0
 21: hkn0409:2592894:2592992 [1] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [receive] via NET/IBext/0
325: hkn0634:1528068:1528186 [1] NCCL INFO Channel 00 : 325[4b000] -> 326[ca000] via P2P/IPC/read
302: hkn0628:679139:679252 [2] NCCL INFO Channel 01 : 302[ca000] -> 303[e3000] via P2P/IPC/read
326: hkn0634:1528060:1528187 [2] NCCL INFO Channel 00 : 326[ca000] -> 327[e3000] via P2P/IPC/read
303: hkn0628:679131:679256 [3] NCCL INFO Connected all trees
385: hkn0716:115707:115856 [1] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [receive] via NET/IBext/0
325: hkn0634:1528068:1528186 [1] NCCL INFO Channel 01 : 325[4b000] -> 326[ca000] via P2P/IPC/read
326: hkn0634:1528060:1528187 [2] NCCL INFO Channel 01 : 326[ca000] -> 327[e3000] via P2P/IPC/read
303: hkn0628:679131:679256 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [send] via NET/IBext/0
327: hkn0634:1528094:1528189 [3] NCCL INFO Connected all trees
327: hkn0634:1528094:1528189 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
303: hkn0628:679131:679256 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
327: hkn0634:1528094:1528189 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
302: hkn0628:679139:679252 [2] NCCL INFO Connected all trees
302: hkn0628:679139:679252 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
279: hkn0621:1998830:1998944 [3] NCCL INFO Connected all trees
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [receive] via NET/IBext/0
337: hkn0703:748303:748410 [1] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [receive] via NET/IBext/0
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [receive] via NET/IBext/0
309: hkn0630:1605694:1605798 [1] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [receive] via NET/IBext/0
302: hkn0628:679139:679252 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
279: hkn0621:1998830:1998944 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:679159:679255 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [receive] via NET/IBext/0
279: hkn0621:1998830:1998944 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
421: hkn0726:1555337:1555444 [1] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [receive] via NET/IBext/0
326: hkn0634:1528060:1528187 [2] NCCL INFO Connected all trees
301: hkn0628:679147:679253 [1] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [send] via NET/IBext/0
278: hkn0621:1998838:1998943 [2] NCCL INFO Connected all trees
493: hkn0810:946752:946862 [1] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [send] via NET/IBext/0
326: hkn0634:1528060:1528187 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
326: hkn0634:1528060:1528187 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
278: hkn0621:1998838:1998943 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
278: hkn0621:1998838:1998943 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
266: hkn0615:421558:421661 [2] NCCL INFO Channel 01 : 266[ca000] -> 267[e3000] via P2P/IPC/read
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [receive] via NET/IBext/0
267: hkn0615:421542:421667 [3] NCCL INFO Connected all trees
277: hkn0621:1998849:1998946 [1] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [receive] via NET/IBext/0
267: hkn0615:421542:421667 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
267: hkn0615:421542:421667 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
159: hkn0516:2923224:2923313 [3] NCCL INFO Connected all trees
266: hkn0615:421558:421661 [2] NCCL INFO Connected all trees
362: hkn0710:362764:362885 [2] NCCL INFO Connected all rings
409: hkn0723:215333:215489 [1] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [receive] via NET/IBext/0
266: hkn0615:421558:421661 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:883787:883894 [1] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [receive] via NET/IBext/0
266: hkn0615:421558:421661 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:977901:978022 [1] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [receive] via NET/IBext/0
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [receive] via NET/IBext/0
264: hkn0615:421550:421660 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [send] via NET/IBext/0
159: hkn0516:2923224:2923313 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:48339:48431 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [receive] via NET/IBext/0
265: hkn0615:421570:421665 [1] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [receive] via NET/IBext/0
159: hkn0516:2923224:2923313 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:362772:362881 [1] NCCL INFO Channel 00 : 361[4b000] -> 362[ca000] via P2P/IPC/read
158: hkn0516:2923196:2923320 [2] NCCL INFO Connected all trees
362: hkn0710:362764:362885 [2] NCCL INFO Channel 00 : 362[ca000] -> 363[e3000] via P2P/IPC/read
  5: hkn0404:1346653:1346760 [1] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [receive] via NET/IBext/0
269: hkn0616:412177:412290 [1] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [send] via NET/IBext/0
256: hkn0612:924207:924324 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [send] via NET/IBext/0
158: hkn0516:2923196:2923320 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [send] via NET/IBext/0
158: hkn0516:2923196:2923320 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
505: hkn0815:402333:402447 [1] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [receive] via NET/IBext/0
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [receive] via NET/IBext/0
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [send] via NET/IBext/0
361: hkn0710:362772:362881 [1] NCCL INFO Channel 01 : 361[4b000] -> 362[ca000] via P2P/IPC/read
489: hkn0809:944571:944666 [1] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [receive] via NET/IBext/0
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [receive] via NET/IBext/0
362: hkn0710:362764:362885 [2] NCCL INFO Channel 01 : 362[ca000] -> 363[e3000] via P2P/IPC/read
122: hkn0507:3194301:3194415 [2] NCCL INFO Channel 01 : 122[ca000] -> 123[e3000] via P2P/IPC/read
497: hkn0812:701035:701150 [1] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [receive] via NET/IBext/0
363: hkn0710:362780:362887 [3] NCCL INFO Connected all trees
363: hkn0710:362780:362887 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
123: hkn0507:3194313:3194412 [3] NCCL INFO Connected all trees
363: hkn0710:362780:362887 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
123: hkn0507:3194313:3194412 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [send] via NET/IBext/0
123: hkn0507:3194313:3194412 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:718056:718153 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [receive] via NET/IBext/0
122: hkn0507:3194301:3194415 [2] NCCL INFO Connected all trees
216: hkn0601:124960:125086 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [receive] via NET/IBext/0
122: hkn0507:3194301:3194415 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [receive] via NET/IBext/0
122: hkn0507:3194301:3194415 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [send] via NET/IBext/0
350: hkn0706:759494:759603 [2] NCCL INFO Channel 00 : 350[ca000] -> 351[e3000] via P2P/IPC/read
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [receive] via NET/IBext/0
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 00 : 313[4b000] -> 314[ca000] via P2P/IPC/read
349: hkn0706:759478:759608 [1] NCCL INFO Channel 01 : 349[4b000] -> 350[ca000] via P2P/IPC/read
240: hkn0607:911595:911709 [0] NCCL INFO Channel 01 : 240[31000] -> 241[4b000] via P2P/IPC/read
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [send] via NET/IBext/0
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [send] via NET/IBext/0
350: hkn0706:759494:759603 [2] NCCL INFO Channel 01 : 350[ca000] -> 351[e3000] via P2P/IPC/read
314: hkn0631:1029016:1029137 [2] NCCL INFO Channel 00 : 314[ca000] -> 315[e3000] via P2P/IPC/read
351: hkn0706:759486:759602 [3] NCCL INFO Connected all trees
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 01 : 313[4b000] -> 314[ca000] via P2P/IPC/read
351: hkn0706:759486:759602 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
314: hkn0631:1029016:1029137 [2] NCCL INFO Channel 01 : 314[ca000] -> 315[e3000] via P2P/IPC/read
362: hkn0710:362764:362885 [2] NCCL INFO Connected all trees
362: hkn0710:362764:362885 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
351: hkn0706:759486:759602 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
362: hkn0710:362764:362885 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
350: hkn0706:759494:759603 [2] NCCL INFO Connected all trees
350: hkn0706:759494:759603 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
315: hkn0631:1029032:1029141 [3] NCCL INFO Connected all trees
350: hkn0706:759494:759603 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
315: hkn0631:1029032:1029141 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [receive] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [receive] via NET/IBext/0
349: hkn0706:759478:759608 [1] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [send] via NET/IBext/0
315: hkn0631:1029032:1029141 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
314: hkn0631:1029016:1029137 [2] NCCL INFO Connected all trees
241: hkn0607:911603:911711 [1] NCCL INFO Channel 00 : 241[4b000] -> 242[ca000] via P2P/IPC/read
314: hkn0631:1029016:1029137 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
242: hkn0607:911587:911714 [2] NCCL INFO Channel 00 : 242[ca000] -> 243[e3000] via P2P/IPC/read
314: hkn0631:1029016:1029137 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
241: hkn0607:911603:911711 [1] NCCL INFO Channel 01 : 241[4b000] -> 242[ca000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [send] via NET/IBext/0
242: hkn0607:911587:911714 [2] NCCL INFO Channel 01 : 242[ca000] -> 243[e3000] via P2P/IPC/read
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [send] via NET/IBext/0
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [receive] via NET/IBext/0
243: hkn0607:911615:911710 [3] NCCL INFO Connected all trees
195: hkn0529:1548038:1548157 [3] NCCL INFO Connected all trees
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [send] via NET/IBext/0
243: hkn0607:911615:911710 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
243: hkn0607:911615:911710 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
195: hkn0529:1548038:1548157 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
195: hkn0529:1548038:1548157 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:719349:719471 [0] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [send] via NET/IBext/0
242: hkn0607:911587:911714 [2] NCCL INFO Connected all trees
242: hkn0607:911587:911714 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
194: hkn0529:1548054:1548165 [2] NCCL INFO Connected all trees
194: hkn0529:1548054:1548165 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
242: hkn0607:911587:911714 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
194: hkn0529:1548054:1548165 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:911595:911709 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [send] via NET/IBext/0
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [send] via NET/IBext/0
437: hkn0731:1393941:1394086 [1] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [receive] via NET/IBext/0
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [receive] via NET/IBext/0
400: hkn0720:14302:14479 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [send] via NET/IBext/0
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [send] via NET/IBext/0
183: hkn0526:1435657:1435750 [3] NCCL INFO Connected all trees
223: hkn0602:3370906:3371095 [3] NCCL INFO Connected all trees
306: hkn0629:1599284:1599393 [2] NCCL INFO Channel 00 : 306[ca000] -> 307[e3000] via P2P/IPC/read
342: hkn0704:799243:799339 [2] NCCL INFO Channel 01 : 342[ca000] -> 343[e3000] via P2P/IPC/read
183: hkn0526:1435657:1435750 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
223: hkn0602:3370906:3371095 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
183: hkn0526:1435657:1435750 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
223: hkn0602:3370906:3371095 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
182: hkn0526:1435637:1435754 [2] NCCL INFO Connected all trees
222: hkn0602:3370898:3371093 [2] NCCL INFO Connected all trees
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [receive] via NET/IBext/0
182: hkn0526:1435637:1435754 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
182: hkn0526:1435637:1435754 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3370898:3371093 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:717035:717164 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [receive] via NET/IBext/0
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [receive] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [send] via NET/IBext/0
181: hkn0526:1435629:1435751 [1] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [receive] via NET/IBext/0
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [receive] via NET/IBext/0
222: hkn0602:3370898:3371093 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [send] via NET/IBext/0
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [receive] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [send] via NET/IBext/0
488: hkn0809:944559:944660 [0] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [send] via NET/IBext/0
264: hkn0615:421550:421660 [0] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [send] via NET/IBext/0
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [send] via NET/IBext/0
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [send] via NET/IBext/0
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [receive] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [receive] via NET/IBext/0
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 01 : 305[4b000] -> 306[ca000] via P2P/IPC/read
306: hkn0629:1599284:1599393 [2] NCCL INFO Channel 01 : 306[ca000] -> 307[e3000] via P2P/IPC/read
343: hkn0704:799231:799343 [3] NCCL INFO Connected all trees
307: hkn0629:1599276:1599401 [3] NCCL INFO Connected all trees
343: hkn0704:799231:799343 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
307: hkn0629:1599276:1599401 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
343: hkn0704:799231:799343 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
307: hkn0629:1599276:1599401 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
342: hkn0704:799243:799339 [2] NCCL INFO Connected all trees
306: hkn0629:1599284:1599393 [2] NCCL INFO Connected all trees
342: hkn0704:799243:799339 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
306: hkn0629:1599284:1599393 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
342: hkn0704:799243:799339 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
306: hkn0629:1599284:1599393 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:799215:799344 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [receive] via NET/IBext/0
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [receive] via NET/IBext/0
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [send] via NET/IBext/0
204: hkn0532:932494:932817 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [receive] via NET/IBext/0
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [receive] via NET/IBext/0
501: hkn0814:683039:683170 [1] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [receive] via NET/IBext/0
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [send] via NET/IBext/0
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [send] via NET/IBext/0
341: hkn0704:799223:799342 [1] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [receive] via NET/IBext/0
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [send] via NET/IBext/0
318: hkn0632:1765851:1765965 [2] NCCL INFO Channel 01 : 318[ca000] -> 319[e3000] via P2P/IPC/read
151: hkn0514:2957951:2958068 [3] NCCL INFO Connected all trees
247: hkn0608:492955:493068 [3] NCCL INFO Connected all trees
384: hkn0716:115715:115850 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [send] via NET/IBext/0
319: hkn0632:1765859:1765969 [3] NCCL INFO Connected all trees
319: hkn0632:1765859:1765969 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
151: hkn0514:2957951:2958068 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
319: hkn0632:1765859:1765969 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
151: hkn0514:2957951:2958068 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
318: hkn0632:1765851:1765965 [2] NCCL INFO Connected all trees
150: hkn0514:2957943:2958073 [2] NCCL INFO Connected all trees
464: hkn0803:883779:883891 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [send] via NET/IBext/0
318: hkn0632:1765851:1765965 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
318: hkn0632:1765851:1765965 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
150: hkn0514:2957943:2958073 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [receive] via NET/IBext/0
150: hkn0514:2957943:2958073 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [send] via NET/IBext/0
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [receive] via NET/IBext/0
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [send] via NET/IBext/0
149: hkn0514:2957959:2958071 [1] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [receive] via NET/IBext/0
247: hkn0608:492955:493068 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 18: hkn0408:2898057:2898153 [2] NCCL INFO Channel 01 : 18[ca000] -> 19[e3000] via P2P/IPC/read
247: hkn0608:492955:493068 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
114: hkn0505:2311013:2311117 [2] NCCL INFO Connected all trees
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [send] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [send] via NET/IBext/0
246: hkn0608:492947:493073 [2] NCCL INFO Connected all trees
246: hkn0608:492947:493073 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 19: hkn0408:2898037:2898154 [3] NCCL INFO Connected all trees
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [send] via NET/IBext/0
246: hkn0608:492947:493073 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
244: hkn0608:492975:493069 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [receive] via NET/IBext/0
 19: hkn0408:2898037:2898154 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:492963:493070 [1] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [receive] via NET/IBext/0
 19: hkn0408:2898037:2898154 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [receive] via NET/IBext/0
360: hkn0710:362792:362882 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [send] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [send] via NET/IBext/0
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [send] via NET/IBext/0
492: hkn0810:946764:946863 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [receive] via NET/IBext/0
 18: hkn0408:2898057:2898153 [2] NCCL INFO Connected all trees
 18: hkn0408:2898057:2898153 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
114: hkn0505:2311013:2311117 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
114: hkn0505:2311013:2311117 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:977921:978021 [0] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [send] via NET/IBext/0
 18: hkn0408:2898057:2898153 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [receive] via NET/IBext/0
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [receive] via NET/IBext/0
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [receive] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [send] via NET/IBext/0
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [send] via NET/IBext/0
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 00 : 328[31000] -> 329[4b000] via P2P/IPC/read
378: hkn0714:439245:439363 [2] NCCL INFO Channel 00 : 378[ca000] -> 379[e3000] via P2P/IPC/read
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 01 : 40[31000] -> 41[4b000] via P2P/IPC/read
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [receive] via NET/IBext/0
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [send] via NET/IBext/0
268: hkn0616:412169:412281 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [receive] via NET/IBext/0
325: hkn0634:1528068:1528186 [1] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [receive] via NET/IBext/0
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 01 : 328[31000] -> 329[4b000] via P2P/IPC/read
377: hkn0714:439253:439365 [1] NCCL INFO Channel 01 : 377[4b000] -> 378[ca000] via P2P/IPC/read
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [send] via NET/IBext/0
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 00 : 329[4b000] -> 330[ca000] via P2P/IPC/read
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [receive] via NET/IBext/0
330: hkn0635:1232802:1232909 [2] NCCL INFO Channel 00 : 330[ca000] -> 331[e3000] via P2P/IPC/read
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 01 : 329[4b000] -> 330[ca000] via P2P/IPC/read
376: hkn0714:439237:439359 [0] NCCL INFO Channel 01 : 376[31000] -> 377[4b000] via P2P/IPC/read
330: hkn0635:1232802:1232909 [2] NCCL INFO Channel 01 : 330[ca000] -> 331[e3000] via P2P/IPC/read
378: hkn0714:439245:439363 [2] NCCL INFO Channel 01 : 378[ca000] -> 379[e3000] via P2P/IPC/read
331: hkn0635:1232814:1232915 [3] NCCL INFO Connected all trees
379: hkn0714:439265:439360 [3] NCCL INFO Connected all trees
408: hkn0723:215341:215495 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [receive] via NET/IBext/0
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [send] via NET/IBext/0
331: hkn0635:1232814:1232915 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
379: hkn0714:439265:439360 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
331: hkn0635:1232814:1232915 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
379: hkn0714:439265:439360 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
330: hkn0635:1232802:1232909 [2] NCCL INFO Connected all trees
378: hkn0714:439245:439363 [2] NCCL INFO Connected all trees
378: hkn0714:439245:439363 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
330: hkn0635:1232802:1232909 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
378: hkn0714:439245:439363 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
330: hkn0635:1232802:1232909 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:439237:439359 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [send] via NET/IBext/0
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [send] via NET/IBext/0
377: hkn0714:439253:439365 [1] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [receive] via NET/IBext/0
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [send] via NET/IBext/0
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [receive] via NET/IBext/0
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 00 : 41[4b000] -> 42[ca000] via P2P/IPC/read
366: hkn0711:591185:591287 [2] NCCL INFO Channel 01 : 366[ca000] -> 367[e3000] via P2P/IPC/read
 42: hkn0414:1988904:1989011 [2] NCCL INFO Channel 00 : 42[ca000] -> 43[e3000] via P2P/IPC/read
294: hkn0626:1305634:1305784 [2] NCCL INFO Channel 01 : 294[ca000] -> 295[e3000] via P2P/IPC/read
241: hkn0607:911603:911711 [1] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [receive] via NET/IBext/0
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 01 : 41[4b000] -> 42[ca000] via P2P/IPC/read
388: hkn0717:1467:1586 [0] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [send] via NET/IBext/0
 42: hkn0414:1988904:1989011 [2] NCCL INFO Channel 01 : 42[ca000] -> 43[e3000] via P2P/IPC/read
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [receive] via NET/IBext/0
 43: hkn0414:1988916:1989008 [3] NCCL INFO Connected all trees
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [send] via NET/IBext/0
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [send] via NET/IBext/0
496: hkn0812:701027:701151 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [send] via NET/IBext/0
 43: hkn0414:1988916:1989008 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:799215:799344 [0] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [send] via NET/IBext/0
 43: hkn0414:1988916:1989008 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 42: hkn0414:1988904:1989011 [2] NCCL INFO Connected all trees
 42: hkn0414:1988904:1989011 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
367: hkn0711:591158:591280 [3] NCCL INFO Connected all trees
 42: hkn0414:1988904:1989011 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
367: hkn0711:591158:591280 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [send] via NET/IBext/0
367: hkn0711:591158:591280 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [receive] via NET/IBext/0
366: hkn0711:591185:591287 [2] NCCL INFO Connected all trees
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [send] via NET/IBext/0
366: hkn0711:591185:591287 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
366: hkn0711:591185:591287 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
295: hkn0626:1305656:1305785 [3] NCCL INFO Connected all trees
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [send] via NET/IBext/0
364: hkn0711:591166:591281 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [receive] via NET/IBext/0
365: hkn0711:591174:591286 [1] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [send] via NET/IBext/0
295: hkn0626:1305656:1305785 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
295: hkn0626:1305656:1305785 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 91: hkn0427:1142357:1142467 [3] NCCL INFO Connected all trees
294: hkn0626:1305634:1305784 [2] NCCL INFO Connected all trees
282: hkn0622:2027744:2027863 [2] NCCL INFO Channel 00 : 282[ca000] -> 283[e3000] via P2P/IPC/read
508: hkn0816:382834:382958 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [receive] via NET/IBext/0
294: hkn0626:1305634:1305784 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [receive] via NET/IBext/0
376: hkn0714:439237:439359 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [receive] via NET/IBext/0
294: hkn0626:1305634:1305784 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 91: hkn0427:1142357:1142467 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [receive] via NET/IBext/0
 91: hkn0427:1142357:1142467 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [send] via NET/IBext/0
293: hkn0626:1305645:1305779 [1] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [receive] via NET/IBext/0
504: hkn0815:402353:402445 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [receive] via NET/IBext/0
240: hkn0607:911595:911709 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [send] via NET/IBext/0
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [send] via NET/IBext/0
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [send] via NET/IBext/0
 90: hkn0427:1142341:1142458 [2] NCCL INFO Connected all trees
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 01 : 281[4b000] -> 282[ca000] via P2P/IPC/read
 90: hkn0427:1142341:1142458 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
282: hkn0622:2027744:2027863 [2] NCCL INFO Channel 01 : 282[ca000] -> 283[e3000] via P2P/IPC/read
 90: hkn0427:1142341:1142458 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
283: hkn0622:2027736:2027858 [3] NCCL INFO Connected all trees
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [receive] via NET/IBext/0
283: hkn0622:2027736:2027858 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [receive] via NET/IBext/0
283: hkn0622:2027736:2027858 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
282: hkn0622:2027744:2027863 [2] NCCL INFO Connected all trees
346: hkn0705:790431:790545 [2] NCCL INFO Connected all rings
282: hkn0622:2027744:2027863 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
358: hkn0708:420458:420568 [2] NCCL INFO Channel 01 : 358[ca000] -> 359[e3000] via P2P/IPC/read
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [send] via NET/IBext/0
282: hkn0622:2027744:2027863 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [send] via NET/IBext/0
345: hkn0705:790443:790544 [1] NCCL INFO Channel 00 : 345[4b000] -> 346[ca000] via P2P/IPC/read
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [receive] via NET/IBext/0
346: hkn0705:790431:790545 [2] NCCL INFO Channel 00 : 346[ca000] -> 347[e3000] via P2P/IPC/read
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [receive] via NET/IBext/0
345: hkn0705:790443:790544 [1] NCCL INFO Channel 01 : 345[4b000] -> 346[ca000] via P2P/IPC/read
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [receive] via NET/IBext/0
346: hkn0705:790431:790545 [2] NCCL INFO Channel 01 : 346[ca000] -> 347[e3000] via P2P/IPC/read
347: hkn0705:790423:790536 [3] NCCL INFO Connected all trees
359: hkn0708:420470:420564 [3] NCCL INFO Connected all trees
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [receive] via NET/IBext/0
347: hkn0705:790423:790536 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
347: hkn0705:790423:790536 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
359: hkn0708:420470:420564 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
346: hkn0705:790431:790545 [2] NCCL INFO Connected all trees
359: hkn0708:420470:420564 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
346: hkn0705:790431:790545 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
358: hkn0708:420458:420568 [2] NCCL INFO Connected all trees
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [send] via NET/IBext/0
346: hkn0705:790431:790545 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
344: hkn0705:790415:790543 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [send] via NET/IBext/0
358: hkn0708:420458:420568 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [send] via NET/IBext/0
345: hkn0705:790443:790544 [1] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [receive] via NET/IBext/0
344: hkn0705:790415:790543 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [receive] via NET/IBext/0
358: hkn0708:420458:420568 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:420442:420567 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [receive] via NET/IBext/0
130: hkn0509:3131655:3131751 [2] NCCL INFO Channel 00 : 130[ca000] -> 131[e3000] via P2P/IPC/read
357: hkn0708:420450:420563 [1] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [receive] via NET/IBext/0
286: hkn0623:1879995:1880114 [2] NCCL INFO Channel 01 : 286[ca000] -> 287[e3000] via P2P/IPC/read
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [receive] via NET/IBext/0
244: hkn0608:492975:493069 [0] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [send] via NET/IBext/0
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 01 : 129[4b000] -> 130[ca000] via P2P/IPC/read
287: hkn0623:1879987:1880116 [3] NCCL INFO Connected all trees
130: hkn0509:3131655:3131751 [2] NCCL INFO Channel 01 : 130[ca000] -> 131[e3000] via P2P/IPC/read
287: hkn0623:1879987:1880116 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
131: hkn0509:3131644:3131750 [3] NCCL INFO Connected all trees
287: hkn0623:1879987:1880116 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [receive] via NET/IBext/0
131: hkn0509:3131644:3131750 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:759506:759606 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [receive] via NET/IBext/0
131: hkn0509:3131644:3131750 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
130: hkn0509:3131655:3131751 [2] NCCL INFO Connected all trees
286: hkn0623:1879995:1880114 [2] NCCL INFO Connected all trees
500: hkn0814:683023:683174 [0] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [send] via NET/IBext/0
130: hkn0509:3131655:3131751 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
130: hkn0509:3131655:3131751 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
286: hkn0623:1879995:1880114 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [receive] via NET/IBext/0
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [send] via NET/IBext/0
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [receive] via NET/IBext/0
286: hkn0623:1879995:1880114 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [send] via NET/IBext/0
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [receive] via NET/IBext/0
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [send] via NET/IBext/0
297: hkn0627:1795158:1795270 [1] NCCL INFO Connected all rings
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [receive] via NET/IBext/0
274: hkn0617:2301935:2302046 [2] NCCL INFO Channel 01 : 274[ca000] -> 275[e3000] via P2P/IPC/read
298: hkn0627:1795166:1795271 [2] NCCL INFO Connected all rings
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 00 : 333[4b000] -> 334[ca000] via P2P/IPC/read
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 00 : 297[4b000] -> 298[ca000] via P2P/IPC/read
275: hkn0617:2301957:2302052 [3] NCCL INFO Connected all trees
298: hkn0627:1795166:1795271 [2] NCCL INFO Channel 00 : 298[ca000] -> 299[e3000] via P2P/IPC/read
275: hkn0617:2301957:2302052 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 01 : 297[4b000] -> 298[ca000] via P2P/IPC/read
275: hkn0617:2301957:2302052 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
298: hkn0627:1795166:1795271 [2] NCCL INFO Channel 01 : 298[ca000] -> 299[e3000] via P2P/IPC/read
274: hkn0617:2301935:2302046 [2] NCCL INFO Connected all trees
361: hkn0710:362772:362881 [1] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [receive] via NET/IBext/0
299: hkn0627:1795186:1795268 [3] NCCL INFO Connected all trees
299: hkn0627:1795186:1795268 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
299: hkn0627:1795186:1795268 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
274: hkn0617:2301935:2302046 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
298: hkn0627:1795166:1795271 [2] NCCL INFO Connected all trees
274: hkn0617:2301935:2302046 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
298: hkn0627:1795166:1795271 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
298: hkn0627:1795166:1795271 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [send] via NET/IBext/0
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [send] via NET/IBext/0
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [receive] via NET/IBext/0
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [receive] via NET/IBext/0
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [send] via NET/IBext/0
334: hkn0636:1661541:1661648 [2] NCCL INFO Channel 00 : 334[ca000] -> 335[e3000] via P2P/IPC/read
381: hkn0715:409138:409236 [1] NCCL INFO Channel 01 : 381[4b000] -> 382[ca000] via P2P/IPC/read
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [send] via NET/IBext/0
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 01 : 333[4b000] -> 334[ca000] via P2P/IPC/read
334: hkn0636:1661541:1661648 [2] NCCL INFO Channel 01 : 334[ca000] -> 335[e3000] via P2P/IPC/read
382: hkn0715:409118:409228 [2] NCCL INFO Channel 01 : 382[ca000] -> 383[e3000] via P2P/IPC/read
335: hkn0636:1661521:1661639 [3] NCCL INFO Connected all trees
383: hkn0715:409110:409235 [3] NCCL INFO Connected all trees
335: hkn0636:1661521:1661639 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
383: hkn0715:409110:409235 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
335: hkn0636:1661521:1661639 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
383: hkn0715:409110:409235 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
334: hkn0636:1661541:1661648 [2] NCCL INFO Connected all trees
382: hkn0715:409118:409228 [2] NCCL INFO Connected all trees
334: hkn0636:1661541:1661648 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
382: hkn0715:409118:409228 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:420442:420567 [0] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [send] via NET/IBext/0
334: hkn0636:1661541:1661648 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [receive] via NET/IBext/0
382: hkn0715:409118:409228 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [send] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [receive] via NET/IBext/0
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [receive] via NET/IBext/0
381: hkn0715:409138:409236 [1] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [send] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [send] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [receive] via NET/IBext/0
 83: hkn0425:2091271:2091395 [3] NCCL INFO Connected all trees
214: hkn0535:2406234:2406334 [2] NCCL INFO Channel 01 : 214[ca000] -> 215[e3000] via P2P/IPC/read
264: hkn0615:421550:421660 [0] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [receive] via NET/IBext/0
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 00 : 113[4b000] -> 112[31000] via P2P/IPC/read
488: hkn0809:944559:944660 [0] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [receive] via NET/IBext/0
 83: hkn0425:2091271:2091395 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 83: hkn0425:2091271:2091395 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 01 : 212[31000] -> 213[4b000] via P2P/IPC/read
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [receive] via NET/IBext/0
 82: hkn0425:2091279:2091402 [2] NCCL INFO Connected all trees
 82: hkn0425:2091279:2091402 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 82: hkn0425:2091279:2091402 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
215: hkn0535:2406222:2406330 [3] NCCL INFO Connected all trees
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [send] via NET/IBext/0
215: hkn0535:2406222:2406330 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [receive] via NET/IBext/0
215: hkn0535:2406222:2406330 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
214: hkn0535:2406234:2406334 [2] NCCL INFO Connected all trees
238: hkn0606:2379355:2379460 [2] NCCL INFO Channel 01 : 238[ca000] -> 239[e3000] via P2P/IPC/read
214: hkn0535:2406234:2406334 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 01 : 321[4b000] -> 322[ca000] via P2P/IPC/read
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [send] via NET/IBext/0
214: hkn0535:2406234:2406334 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [receive] via NET/IBext/0
239: hkn0606:2379367:2379465 [3] NCCL INFO Connected all trees
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [send] via NET/IBext/0
213: hkn0535:2406206:2406337 [1] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [receive] via NET/IBext/0
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [receive] via NET/IBext/0
113: hkn0505:2311005:2311114 [1] NCCL INFO Channel 01 : 113[4b000] -> 112[31000] via P2P/IPC/read
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [send] via NET/IBext/0
239: hkn0606:2379367:2379465 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
239: hkn0606:2379367:2379465 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
322: hkn0633:1533554:1533664 [2] NCCL INFO Channel 01 : 322[ca000] -> 323[e3000] via P2P/IPC/read
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [send] via NET/IBext/0
238: hkn0606:2379355:2379460 [2] NCCL INFO Connected all trees
238: hkn0606:2379355:2379460 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
238: hkn0606:2379355:2379460 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
323: hkn0633:1533566:1533658 [3] NCCL INFO Connected all trees
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [send] via NET/IBext/0
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [send] via NET/IBext/0
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [receive] via NET/IBext/0
323: hkn0633:1533566:1533658 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [send] via NET/IBext/0
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [send] via NET/IBext/0
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [receive] via NET/IBext/0
323: hkn0633:1533566:1533658 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
322: hkn0633:1533554:1533664 [2] NCCL INFO Connected all trees
 46: hkn0415:2503643:2503758 [2] NCCL INFO Channel 00 : 46[ca000] -> 47[e3000] via P2P/IPC/read
322: hkn0633:1533554:1533664 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 58: hkn0419:1551505:1551604 [2] NCCL INFO Connected all rings
300: hkn0628:679159:679255 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [receive] via NET/IBext/0
322: hkn0633:1533554:1533664 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [receive] via NET/IBext/0
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [send] via NET/IBext/0
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [receive] via NET/IBext/0
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 01 : 45[4b000] -> 46[ca000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [send] via NET/IBext/0
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [send] via NET/IBext/0
 46: hkn0415:2503643:2503758 [2] NCCL INFO Channel 01 : 46[ca000] -> 47[e3000] via P2P/IPC/read
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 00 : 56[31000] -> 57[4b000] via P2P/IPC/read
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [receive] via NET/IBext/0
 47: hkn0415:2503663:2503759 [3] NCCL INFO Connected all trees
465: hkn0803:883787:883894 [1] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [send] via NET/IBext/0
 47: hkn0415:2503663:2503759 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [receive] via NET/IBext/0
 47: hkn0415:2503663:2503759 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 46: hkn0415:2503643:2503758 [2] NCCL INFO Connected all trees
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 01 : 56[31000] -> 57[4b000] via P2P/IPC/read
508: hkn0816:382834:382958 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [send] via NET/IBext/0
 46: hkn0415:2503643:2503758 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 46: hkn0415:2503643:2503758 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 00 : 57[4b000] -> 58[ca000] via P2P/IPC/read
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [receive] via NET/IBext/0
 58: hkn0419:1551505:1551604 [2] NCCL INFO Channel 00 : 58[ca000] -> 59[e3000] via P2P/IPC/read
484: hkn0808:977921:978021 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [send] via NET/IBext/0
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [send] via NET/IBext/0
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [receive] via NET/IBext/0
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 01 : 57[4b000] -> 58[ca000] via P2P/IPC/read
 58: hkn0419:1551505:1551604 [2] NCCL INFO Channel 01 : 58[ca000] -> 59[e3000] via P2P/IPC/read
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 00 : 141[4b000] -> 142[ca000] via P2P/IPC/read
 59: hkn0419:1551517:1551600 [3] NCCL INFO Connected all trees
103: hkn0502:236303:236407 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 59: hkn0419:1551517:1551600 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
142: hkn0512:3051335:3051453 [2] NCCL INFO Channel 00 : 142[ca000] -> 143[e3000] via P2P/IPC/read
497: hkn0812:701035:701150 [1] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [send] via NET/IBext/0
 59: hkn0419:1551517:1551600 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:362792:362882 [0] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [send] via NET/IBext/0
 58: hkn0419:1551505:1551604 [2] NCCL INFO Connected all trees
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [send] via NET/IBext/0
 58: hkn0419:1551505:1551604 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 58: hkn0419:1551505:1551604 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 01 : 141[4b000] -> 142[ca000] via P2P/IPC/read
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [send] via NET/IBext/0
142: hkn0512:3051335:3051453 [2] NCCL INFO Channel 01 : 142[ca000] -> 143[e3000] via P2P/IPC/read
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [send] via NET/IBext/0
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [receive] via NET/IBext/0
233: hkn0605:719360:719472 [1] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [send] via NET/IBext/0
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [receive] via NET/IBext/0
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [receive] via NET/IBext/0
143: hkn0512:3051355:3051445 [3] NCCL INFO Connected all trees
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [send] via NET/IBext/0
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [send] via NET/IBext/0
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [send] via NET/IBext/0
143: hkn0512:3051355:3051445 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
143: hkn0512:3051355:3051445 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
103: hkn0502:236303:236407 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
142: hkn0512:3051335:3051453 [2] NCCL INFO Connected all trees
102: hkn0502:236315:236406 [2] NCCL INFO Connected all trees
142: hkn0512:3051335:3051453 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
198: hkn0530:1265343:1265469 [2] NCCL INFO Channel 01 : 198[ca000] -> 199[e3000] via P2P/IPC/read
142: hkn0512:3051335:3051453 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
102: hkn0502:236315:236406 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
102: hkn0502:236315:236406 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [receive] via NET/IBext/0
100: hkn0502:236295:236412 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [receive] via NET/IBext/0
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [send] via NET/IBext/0
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [send] via NET/IBext/0
388: hkn0717:1467:1586 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [send] via NET/IBext/0
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [receive] via NET/IBext/0
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [receive] via NET/IBext/0
101: hkn0502:236287:236411 [1] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [receive] via NET/IBext/0
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [send] via NET/IBext/0
100: hkn0502:236295:236412 [0] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [send] via NET/IBext/0
100: hkn0502:236295:236412 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [send] via NET/IBext/0
199: hkn0530:1265351:1265471 [3] NCCL INFO Connected all trees
401: hkn0720:14318:14478 [1] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [send] via NET/IBext/0
199: hkn0530:1265351:1265471 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
199: hkn0530:1265351:1265471 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 67: hkn0421:2189234:2189409 [3] NCCL INFO Connected all trees
400: hkn0720:14302:14479 [0] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [send] via NET/IBext/0
340: hkn0704:799215:799344 [0] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [receive] via NET/IBext/0
198: hkn0530:1265343:1265469 [2] NCCL INFO Connected all trees
 67: hkn0421:2189234:2189409 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [receive] via NET/IBext/0
198: hkn0530:1265343:1265469 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [send] via NET/IBext/0
198: hkn0530:1265343:1265469 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [receive] via NET/IBext/0
 67: hkn0421:2189234:2189409 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
197: hkn0530:1265371:1265467 [1] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [receive] via NET/IBext/0
 66: hkn0421:2189220:2189406 [2] NCCL INFO Connected all trees
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [send] via NET/IBext/0
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [send] via NET/IBext/0
409: hkn0723:215333:215489 [1] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [send] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [send] via NET/IBext/0
232: hkn0605:719349:719471 [0] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [receive] via NET/IBext/0
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [send] via NET/IBext/0
 66: hkn0421:2189220:2189406 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
353: hkn0707:4027137:4027262 [1] NCCL INFO Connected all rings
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [send] via NET/IBext/0
 66: hkn0421:2189220:2189406 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [send] via NET/IBext/0
354: hkn0707:4027145:4027255 [2] NCCL INFO Connected all rings
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [send] via NET/IBext/0
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [receive] via NET/IBext/0
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [send] via NET/IBext/0
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 00 : 353[4b000] -> 354[ca000] via P2P/IPC/read
354: hkn0707:4027145:4027255 [2] NCCL INFO Channel 00 : 354[ca000] -> 355[e3000] via P2P/IPC/read
162: hkn0520:2720086:2720209 [2] NCCL INFO Connected all trees
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 01 : 353[4b000] -> 354[ca000] via P2P/IPC/read
 54: hkn0418:1876396:1876507 [2] NCCL INFO Connected all rings
489: hkn0809:944571:944666 [1] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [send] via NET/IBext/0
354: hkn0707:4027145:4027255 [2] NCCL INFO Channel 01 : 354[ca000] -> 355[e3000] via P2P/IPC/read
336: hkn0703:748295:748408 [0] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [send] via NET/IBext/0
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [receive] via NET/IBext/0
355: hkn0707:4027153:4027260 [3] NCCL INFO Connected all trees
162: hkn0520:2720086:2720209 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
355: hkn0707:4027153:4027260 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
355: hkn0707:4027153:4027260 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
162: hkn0520:2720086:2720209 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
464: hkn0803:883779:883891 [0] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [send] via NET/IBext/0
354: hkn0707:4027145:4027255 [2] NCCL INFO Connected all trees
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [receive] via NET/IBext/0
354: hkn0707:4027145:4027255 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:701027:701151 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [receive] via NET/IBext/0
354: hkn0707:4027145:4027255 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:883787:883894 [1] NCCL INFO Channel 00 : 465[4b000] -> 464[31000] via P2P/IPC/read
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [send] via NET/IBext/0
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [receive] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [send] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [send] via NET/IBext/0
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [receive] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [send] via NET/IBext/0
240: hkn0607:911595:911709 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [receive] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [send] via NET/IBext/0
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 01 : 52[31000] -> 53[4b000] via P2P/IPC/read
 53: hkn0418:1876404:1876515 [1] NCCL INFO Channel 00 : 53[4b000] -> 54[ca000] via P2P/IPC/read
127: hkn0508:3146366:3146462 [3] NCCL INFO Connected all trees
364: hkn0711:591166:591281 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [receive] via NET/IBext/0
 54: hkn0418:1876396:1876507 [2] NCCL INFO Channel 00 : 54[ca000] -> 55[e3000] via P2P/IPC/read
 53: hkn0418:1876404:1876515 [1] NCCL INFO Channel 01 : 53[4b000] -> 54[ca000] via P2P/IPC/read
127: hkn0508:3146366:3146462 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:701035:701150 [1] NCCL INFO Channel 00 : 497[4b000] -> 496[31000] via P2P/IPC/read
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [send] via NET/IBext/0
 54: hkn0418:1876396:1876507 [2] NCCL INFO Channel 01 : 54[ca000] -> 55[e3000] via P2P/IPC/read
127: hkn0508:3146366:3146462 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 55: hkn0418:1876416:1876509 [3] NCCL INFO Connected all trees
126: hkn0508:3146354:3146461 [2] NCCL INFO Connected all trees
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 00 : 209[4b000] -> 208[31000] via P2P/IPC/read
 55: hkn0418:1876416:1876509 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 55: hkn0418:1876416:1876509 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
126: hkn0508:3146354:3146461 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:883787:883894 [1] NCCL INFO Channel 01 : 465[4b000] -> 464[31000] via P2P/IPC/read
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [send] via NET/IBext/0
265: hkn0615:421570:421665 [1] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [send] via NET/IBext/0
 54: hkn0418:1876396:1876507 [2] NCCL INFO Connected all trees
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [receive] via NET/IBext/0
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [send] via NET/IBext/0
216: hkn0601:124960:125086 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [send] via NET/IBext/0
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 00 : 273[4b000] -> 272[31000] via P2P/IPC/read
 54: hkn0418:1876396:1876507 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
126: hkn0508:3146354:3146461 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 54: hkn0418:1876396:1876507 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [receive] via NET/IBext/0
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [receive] via NET/IBext/0
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [send] via NET/IBext/0
497: hkn0812:701035:701150 [1] NCCL INFO Channel 01 : 497[4b000] -> 496[31000] via P2P/IPC/read
244: hkn0608:492975:493069 [0] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [receive] via NET/IBext/0
 53: hkn0418:1876404:1876515 [1] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [receive] via NET/IBext/0
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [receive] via NET/IBext/0
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [send] via NET/IBext/0
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 01 : 29[4b000] -> 30[ca000] via P2P/IPC/read
209: hkn0534:1155638:1155749 [1] NCCL INFO Channel 01 : 209[4b000] -> 208[31000] via P2P/IPC/read
337: hkn0703:748303:748410 [1] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [send] via NET/IBext/0
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 01 : 28[31000] -> 29[4b000] via P2P/IPC/read
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 01 : 76[31000] -> 77[4b000] via P2P/IPC/read
 30: hkn0411:2323089:2323199 [2] NCCL INFO Channel 01 : 30[ca000] -> 31[e3000] via P2P/IPC/read
174: hkn0524:1141010:1141129 [2] NCCL INFO Connected all trees
 31: hkn0411:2323097:2323204 [3] NCCL INFO Connected all trees
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 00 : 77[4b000] -> 78[ca000] via P2P/IPC/read
 31: hkn0411:2323097:2323204 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 78: hkn0424:2955198:2955298 [2] NCCL INFO Channel 00 : 78[ca000] -> 79[e3000] via P2P/IPC/read
273: hkn0617:2301927:2302047 [1] NCCL INFO Channel 01 : 273[4b000] -> 272[31000] via P2P/IPC/read
 31: hkn0411:2323097:2323204 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 30: hkn0411:2323089:2323199 [2] NCCL INFO Connected all trees
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 01 : 77[4b000] -> 78[ca000] via P2P/IPC/read
 30: hkn0411:2323089:2323199 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 78: hkn0424:2955198:2955298 [2] NCCL INFO Channel 01 : 78[ca000] -> 79[e3000] via P2P/IPC/read
 30: hkn0411:2323089:2323199 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 79: hkn0424:2955186:2955299 [3] NCCL INFO Connected all trees
401: hkn0720:14318:14478 [1] NCCL INFO Channel 00 : 401[4b000] -> 400[31000] via P2P/IPC/read
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [receive] via NET/IBext/0
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [send] via NET/IBext/0
 79: hkn0424:2955186:2955299 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [send] via NET/IBext/0
344: hkn0705:790415:790543 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [send] via NET/IBext/0
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [receive] via NET/IBext/0
 79: hkn0424:2955186:2955299 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:718056:718153 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [send] via NET/IBext/0
 78: hkn0424:2955198:2955298 [2] NCCL INFO Connected all trees
 78: hkn0424:2955198:2955298 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
174: hkn0524:1141010:1141129 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [send] via NET/IBext/0
 78: hkn0424:2955198:2955298 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [send] via NET/IBext/0
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [receive] via NET/IBext/0
500: hkn0814:683023:683174 [0] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [receive] via NET/IBext/0
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [send] via NET/IBext/0
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [receive] via NET/IBext/0
174: hkn0524:1141010:1141129 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [receive] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [receive] via NET/IBext/0
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [send] via NET/IBext/0
139: hkn0511:3073664:3073769 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:14318:14478 [1] NCCL INFO Channel 01 : 401[4b000] -> 400[31000] via P2P/IPC/read
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [receive] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [receive] via NET/IBext/0
138: hkn0511:3073676:3073772 [2] NCCL INFO Connected all trees
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [send] via NET/IBext/0
138: hkn0511:3073676:3073772 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
138: hkn0511:3073676:3073772 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
187: hkn0527:1356160:1356277 [3] NCCL INFO Connected all trees
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [send] via NET/IBext/0
263: hkn0613:909932:910042 [3] NCCL INFO Connected all trees
100: hkn0502:236295:236412 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [receive] via NET/IBext/0
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [receive] via NET/IBext/0
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [send] via NET/IBext/0
187: hkn0527:1356160:1356277 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [receive] via NET/IBext/0
187: hkn0527:1356160:1356277 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [send] via NET/IBext/0
186: hkn0527:1356188:1356283 [2] NCCL INFO Connected all trees
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [send] via NET/IBext/0
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [receive] via NET/IBext/0
186: hkn0527:1356188:1356283 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
263: hkn0613:909932:910042 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:696478:696578 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [receive] via NET/IBext/0
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [receive] via NET/IBext/0
377: hkn0714:439253:439365 [1] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [send] via NET/IBext/0
186: hkn0527:1356188:1356283 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [send] via NET/IBext/0
263: hkn0613:909932:910042 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:420442:420567 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [send] via NET/IBext/0
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [receive] via NET/IBext/0
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [receive] via NET/IBext/0
262: hkn0613:909916:910043 [2] NCCL INFO Connected all trees
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [send] via NET/IBext/0
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [send] via NET/IBext/0
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [send] via NET/IBext/0
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [send] via NET/IBext/0
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [receive] via NET/IBext/0
262: hkn0613:909916:910043 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
262: hkn0613:909916:910043 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
167: hkn0521:1205008:1205131 [3] NCCL INFO Connected all trees
241: hkn0607:911603:911711 [1] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [send] via NET/IBext/0
260: hkn0613:909924:910036 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [receive] via NET/IBext/0
261: hkn0613:909944:910037 [1] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [receive] via NET/IBext/0
167: hkn0521:1205008:1205131 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:718036:718147 [1] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [send] via NET/IBext/0
260: hkn0613:909924:910036 [0] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [send] via NET/IBext/0
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 00 : 17[4b000] -> 16[31000] via P2P/IPC/read
260: hkn0613:909924:910036 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [send] via NET/IBext/0
260: hkn0613:909924:910036 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [receive] via NET/IBext/0
167: hkn0521:1205008:1205131 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 00 : 81[4b000] -> 80[31000] via P2P/IPC/read
166: hkn0521:1205036:1205135 [2] NCCL INFO Connected all trees
505: hkn0815:402333:402447 [1] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [send] via NET/IBext/0
166: hkn0521:1205036:1205135 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
166: hkn0521:1205036:1205135 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 00 : 189[4b000] -> 190[ca000] via P2P/IPC/read
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [receive] via NET/IBext/0
 94: hkn0428:674575:674691 [2] NCCL INFO Connected all trees
 94: hkn0428:674575:674691 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
165: hkn0521:1205024:1205132 [1] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [receive] via NET/IBext/0
190: hkn0528:1308903:1309021 [2] NCCL INFO Channel 00 : 190[ca000] -> 191[e3000] via P2P/IPC/read
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [send] via NET/IBext/0
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 01 : 189[4b000] -> 190[ca000] via P2P/IPC/read
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [send] via NET/IBext/0
337: hkn0703:748303:748410 [1] NCCL INFO Channel 00 : 337[4b000] -> 336[31000] via P2P/IPC/read
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [send] via NET/IBext/0
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [send] via NET/IBext/0
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [receive] via NET/IBext/0
190: hkn0528:1308903:1309021 [2] NCCL INFO Channel 01 : 190[ca000] -> 191[e3000] via P2P/IPC/read
108: hkn0504:48339:48431 [0] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [receive] via NET/IBext/0
191: hkn0528:1308895:1309019 [3] NCCL INFO Connected all trees
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [send] via NET/IBext/0
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [receive] via NET/IBext/0
 17: hkn0408:2898045:2898159 [1] NCCL INFO Channel 01 : 17[4b000] -> 16[31000] via P2P/IPC/read
345: hkn0705:790443:790544 [1] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [send] via NET/IBext/0
 81: hkn0425:2091299:2091397 [1] NCCL INFO Channel 01 : 81[4b000] -> 80[31000] via P2P/IPC/read
191: hkn0528:1308895:1309019 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [send] via NET/IBext/0
191: hkn0528:1308895:1309019 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:439237:439359 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [send] via NET/IBext/0
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [send] via NET/IBext/0
190: hkn0528:1308903:1309021 [2] NCCL INFO Connected all trees
 94: hkn0428:674575:674691 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:412169:412281 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [send] via NET/IBext/0
190: hkn0528:1308903:1309021 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:402353:402445 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [send] via NET/IBext/0
190: hkn0528:1308903:1309021 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
109: hkn0504:48319:48430 [1] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [receive] via NET/IBext/0
337: hkn0703:748303:748410 [1] NCCL INFO Channel 01 : 337[4b000] -> 336[31000] via P2P/IPC/read
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [receive] via NET/IBext/0
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [receive] via NET/IBext/0
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [receive] via NET/IBext/0
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [receive] via NET/IBext/0
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [send] via NET/IBext/0
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [send] via NET/IBext/0
301: hkn0628:679147:679253 [1] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [receive] via NET/IBext/0
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [receive] via NET/IBext/0
155: hkn0515:2904013:2904151 [3] NCCL INFO Connected all trees
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 01 : 33[4b000] -> 34[ca000] via P2P/IPC/read
107: hkn0503:2906943:2907062 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:994014:994129 [1] NCCL INFO Channel 00 : 177[4b000] -> 178[ca000] via P2P/IPC/read
155: hkn0515:2904013:2904151 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 34: hkn0412:2269636:2269732 [2] NCCL INFO Channel 01 : 34[ca000] -> 35[e3000] via P2P/IPC/read
155: hkn0515:2904013:2904151 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 35: hkn0412:2269608:2269737 [3] NCCL INFO Connected all trees
 35: hkn0412:2269608:2269737 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [send] via NET/IBext/0
154: hkn0515:2904025:2904145 [2] NCCL INFO Connected all trees
154: hkn0515:2904025:2904145 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 35: hkn0412:2269608:2269737 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:977921:978021 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [receive] via NET/IBext/0
154: hkn0515:2904025:2904145 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [receive] via NET/IBext/0
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [send] via NET/IBext/0
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [receive] via NET/IBext/0
 34: hkn0412:2269636:2269732 [2] NCCL INFO Connected all trees
 34: hkn0412:2269636:2269732 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [receive] via NET/IBext/0
 34: hkn0412:2269636:2269732 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
269: hkn0616:412177:412290 [1] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [receive] via NET/IBext/0
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [receive] via NET/IBext/0
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [send] via NET/IBext/0
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [send] via NET/IBext/0
360: hkn0710:362792:362882 [0] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [receive] via NET/IBext/0
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [send] via NET/IBext/0
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [receive] via NET/IBext/0
107: hkn0503:2906943:2907062 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [send] via NET/IBext/0
106: hkn0503:2906951:2907055 [2] NCCL INFO Connected all trees
178: hkn0525:994022:994132 [2] NCCL INFO Channel 00 : 178[ca000] -> 179[e3000] via P2P/IPC/read
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 01 : 8[31000] -> 9[4b000] via P2P/IPC/read
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [receive] via NET/IBext/0
106: hkn0503:2906951:2907055 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
106: hkn0503:2906951:2907055 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
177: hkn0525:994014:994129 [1] NCCL INFO Channel 01 : 177[4b000] -> 178[ca000] via P2P/IPC/read
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [send] via NET/IBext/0
178: hkn0525:994022:994132 [2] NCCL INFO Channel 01 : 178[ca000] -> 179[e3000] via P2P/IPC/read
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [receive] via NET/IBext/0
179: hkn0525:994006:994130 [3] NCCL INFO Connected all trees
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [send] via NET/IBext/0
179: hkn0525:994006:994130 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [receive] via NET/IBext/0
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [send] via NET/IBext/0
388: hkn0717:1467:1586 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [receive] via NET/IBext/0
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [receive] via NET/IBext/0
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [receive] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [receive] via NET/IBext/0
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [send] via NET/IBext/0
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [send] via NET/IBext/0
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [receive] via NET/IBext/0
217: hkn0601:124968:125085 [1] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [send] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [receive] via NET/IBext/0
179: hkn0525:994006:994130 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
178: hkn0525:994022:994132 [2] NCCL INFO Connected all trees
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 00 : 9[4b000] -> 10[ca000] via P2P/IPC/read
178: hkn0525:994022:994132 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 10: hkn0405:3214170:3214279 [2] NCCL INFO Channel 00 : 10[ca000] -> 11[e3000] via P2P/IPC/read
178: hkn0525:994022:994132 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 01 : 9[4b000] -> 10[ca000] via P2P/IPC/read
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [send] via NET/IBext/0
176: hkn0525:994034:994135 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [send] via NET/IBext/0
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [receive] via NET/IBext/0
400: hkn0720:14302:14479 [0] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [receive] via NET/IBext/0
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [receive] via NET/IBext/0
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [send] via NET/IBext/0
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [send] via NET/IBext/0
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [receive] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [receive] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [send] via NET/IBext/0
177: hkn0525:994014:994129 [1] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [receive] via NET/IBext/0
 10: hkn0405:3214170:3214279 [2] NCCL INFO Channel 01 : 10[ca000] -> 11[e3000] via P2P/IPC/read
176: hkn0525:994034:994135 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [send] via NET/IBext/0
 11: hkn0405:3214162:3214281 [3] NCCL INFO Connected all trees
176: hkn0525:994034:994135 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [receive] via NET/IBext/0
 11: hkn0405:3214162:3214281 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:994014:994129 [1] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [send] via NET/IBext/0
 11: hkn0405:3214162:3214281 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [send] via NET/IBext/0
177: hkn0525:994014:994129 [1] NCCL INFO Channel 00 : 177[4b000] -> 176[31000] via P2P/IPC/read
488: hkn0809:944559:944660 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [receive] via NET/IBext/0
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [send] via NET/IBext/0
241: hkn0607:911603:911711 [1] NCCL INFO Channel 00 : 241[4b000] -> 240[31000] via P2P/IPC/read
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [send] via NET/IBext/0
177: hkn0525:994014:994129 [1] NCCL INFO Channel 01 : 177[4b000] -> 176[31000] via P2P/IPC/read
 10: hkn0405:3214170:3214279 [2] NCCL INFO Connected all trees
 10: hkn0405:3214170:3214279 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
202: hkn0531:1237910:1238025 [2] NCCL INFO Channel 01 : 202[ca000] -> 203[e3000] via P2P/IPC/read
492: hkn0810:946764:946863 [0] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [receive] via NET/IBext/0
264: hkn0615:421550:421660 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [receive] via NET/IBext/0
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [send] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [receive] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [receive] via NET/IBext/0
 10: hkn0405:3214170:3214279 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [receive] via NET/IBext/0
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [send] via NET/IBext/0
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [receive] via NET/IBext/0
203: hkn0531:1237894:1238018 [3] NCCL INFO Connected all trees
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [send] via NET/IBext/0
203: hkn0531:1237894:1238018 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [receive] via NET/IBext/0
203: hkn0531:1237894:1238018 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [send] via NET/IBext/0
202: hkn0531:1237910:1238025 [2] NCCL INFO Connected all trees
202: hkn0531:1237910:1238025 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
118: hkn0506:845292:845415 [2] NCCL INFO Connected all trees
202: hkn0531:1237910:1238025 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
370: hkn0712:302281:302408 [2] NCCL INFO Channel 01 : 370[ca000] -> 371[e3000] via P2P/IPC/read
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [send] via NET/IBext/0
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [send] via NET/IBext/0
241: hkn0607:911603:911711 [1] NCCL INFO Channel 01 : 241[4b000] -> 240[31000] via P2P/IPC/read
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [send] via NET/IBext/0
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [receive] via NET/IBext/0
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [receive] via NET/IBext/0
464: hkn0803:883779:883891 [0] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [receive] via NET/IBext/0
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [receive] via NET/IBext/0
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 00 : 305[4b000] -> 304[31000] via P2P/IPC/read
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [send] via NET/IBext/0
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [send] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [receive] via NET/IBext/0
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [send] via NET/IBext/0
361: hkn0710:362772:362881 [1] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [send] via NET/IBext/0
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [receive] via NET/IBext/0
118: hkn0506:845292:845415 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
118: hkn0506:845292:845415 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
371: hkn0712:302309:302405 [3] NCCL INFO Connected all trees
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [receive] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [receive] via NET/IBext/0
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [receive] via NET/IBext/0
117: hkn0506:845300:845411 [1] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [receive] via NET/IBext/0
204: hkn0532:932494:932817 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [send] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [send] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [receive] via NET/IBext/0
371: hkn0712:302309:302405 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [receive] via NET/IBext/0
340: hkn0704:799215:799344 [0] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [send] via NET/IBext/0
365: hkn0711:591174:591286 [1] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [receive] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [send] via NET/IBext/0
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [receive] via NET/IBext/0
371: hkn0712:302309:302405 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1599304:1599395 [1] NCCL INFO Channel 01 : 305[4b000] -> 304[31000] via P2P/IPC/read
370: hkn0712:302281:302408 [2] NCCL INFO Connected all trees
370: hkn0712:302281:302408 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 99: hkn0501:1335147:1335272 [3] NCCL INFO Connected all trees
370: hkn0712:302281:302408 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 50: hkn0417:2274860:2274988 [2] NCCL INFO Channel 00 : 50[ca000] -> 51[e3000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [send] via NET/IBext/0
368: hkn0712:302297:302400 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [send] via NET/IBext/0
369: hkn0712:302289:302403 [1] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [receive] via NET/IBext/0
 99: hkn0501:1335147:1335272 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [send] via NET/IBext/0
368: hkn0712:302297:302400 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [send] via NET/IBext/0
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [receive] via NET/IBext/0
368: hkn0712:302297:302400 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [receive] via NET/IBext/0
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [send] via NET/IBext/0
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [send] via NET/IBext/0
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [send] via NET/IBext/0
369: hkn0712:302289:302403 [1] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [send] via NET/IBext/0
176: hkn0525:994034:994135 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [send] via NET/IBext/0
 99: hkn0501:1335147:1335272 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:302297:302400 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [send] via NET/IBext/0
 98: hkn0501:1335167:1335267 [2] NCCL INFO Connected all trees
 98: hkn0501:1335167:1335267 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 98: hkn0501:1335167:1335267 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 01 : 49[4b000] -> 50[ca000] via P2P/IPC/read
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [receive] via NET/IBext/0
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [send] via NET/IBext/0
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [receive] via NET/IBext/0
 50: hkn0417:2274860:2274988 [2] NCCL INFO Channel 01 : 50[ca000] -> 51[e3000] via P2P/IPC/read
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [send] via NET/IBext/0
 51: hkn0417:2274868:2274989 [3] NCCL INFO Connected all trees
109: hkn0504:48319:48430 [1] NCCL INFO Channel 00 : 109[4b000] -> 108[31000] via P2P/IPC/read
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [receive] via NET/IBext/0
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [send] via NET/IBext/0
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [send] via NET/IBext/0
496: hkn0812:701027:701151 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [send] via NET/IBext/0
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [send] via NET/IBext/0
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [receive] via NET/IBext/0
 51: hkn0417:2274868:2274989 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 51: hkn0417:2274868:2274989 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 01 : 24[31000] -> 25[4b000] via P2P/IPC/read
 50: hkn0417:2274860:2274988 [2] NCCL INFO Connected all trees
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 00 : 25[4b000] -> 26[ca000] via P2P/IPC/read
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [send] via NET/IBext/0
 50: hkn0417:2274860:2274988 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 50: hkn0417:2274860:2274988 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 26: hkn0410:1166945:1167042 [2] NCCL INFO Channel 00 : 26[ca000] -> 27[e3000] via P2P/IPC/read
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [send] via NET/IBext/0
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [send] via NET/IBext/0
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [receive] via NET/IBext/0
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 01 : 25[4b000] -> 26[ca000] via P2P/IPC/read
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [receive] via NET/IBext/0
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [send] via NET/IBext/0
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [send] via NET/IBext/0
493: hkn0810:946752:946862 [1] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [receive] via NET/IBext/0
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [send] via NET/IBext/0
 26: hkn0410:1166945:1167042 [2] NCCL INFO Channel 01 : 26[ca000] -> 27[e3000] via P2P/IPC/read
109: hkn0504:48319:48430 [1] NCCL INFO Channel 01 : 109[4b000] -> 108[31000] via P2P/IPC/read
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 00 : 49[4b000] -> 48[31000] via P2P/IPC/read
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [receive] via NET/IBext/0
 49: hkn0417:2274876:2274980 [1] NCCL INFO Channel 01 : 49[4b000] -> 48[31000] via P2P/IPC/read
240: hkn0607:911595:911709 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [send] via NET/IBext/0
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [receive] via NET/IBext/0
 27: hkn0410:1166917:1167039 [3] NCCL INFO Connected all trees
134: hkn0510:2769278:2769396 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 27: hkn0410:1166917:1167039 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
134: hkn0510:2769278:2769396 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 27: hkn0410:1166917:1167039 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [receive] via NET/IBext/0
369: hkn0712:302289:302403 [1] NCCL INFO Channel 00 : 369[4b000] -> 368[31000] via P2P/IPC/read
 26: hkn0410:1166945:1167042 [2] NCCL INFO Connected all trees
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [receive] via NET/IBext/0
 26: hkn0410:1166945:1167042 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [send] via NET/IBext/0
 26: hkn0410:1166945:1167042 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [send] via NET/IBext/0
133: hkn0510:2769286:2769390 [1] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [receive] via NET/IBext/0
244: hkn0608:492975:493069 [0] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [send] via NET/IBext/0
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [receive] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [receive] via NET/IBext/0
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [receive] via NET/IBext/0
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [receive] via NET/IBext/0
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [send] via NET/IBext/0
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [send] via NET/IBext/0
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [send] via NET/IBext/0
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [send] via NET/IBext/0
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [receive] via NET/IBext/0
374: hkn0713:477468:477571 [2] NCCL INFO Connected all rings
 75: hkn0423:1712190:1712287 [3] NCCL INFO Connected all trees
 75: hkn0423:1712190:1712287 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
373: hkn0713:477452:477574 [1] NCCL INFO Channel 00 : 373[4b000] -> 374[ca000] via P2P/IPC/read
 75: hkn0423:1712190:1712287 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
374: hkn0713:477468:477571 [2] NCCL INFO Channel 00 : 374[ca000] -> 375[e3000] via P2P/IPC/read
434: hkn0730:1408975:1409075 [2] NCCL INFO Channel 01 : 434[ca000] -> 435[e3000] via P2P/IPC/read
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [receive] via NET/IBext/0
373: hkn0713:477452:477574 [1] NCCL INFO Channel 01 : 373[4b000] -> 374[ca000] via P2P/IPC/read
369: hkn0712:302289:302403 [1] NCCL INFO Channel 01 : 369[4b000] -> 368[31000] via P2P/IPC/read
374: hkn0713:477468:477571 [2] NCCL INFO Channel 01 : 374[ca000] -> 375[e3000] via P2P/IPC/read
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [receive] via NET/IBext/0
375: hkn0713:477460:477578 [3] NCCL INFO Connected all trees
356: hkn0708:420442:420567 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [receive] via NET/IBext/0
375: hkn0713:477460:477578 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
375: hkn0713:477460:477578 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 74: hkn0423:1712179:1712289 [2] NCCL INFO Connected all trees
374: hkn0713:477468:477571 [2] NCCL INFO Connected all trees
 74: hkn0423:1712179:1712289 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
374: hkn0713:477468:477571 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 74: hkn0423:1712179:1712289 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
301: hkn0628:679147:679253 [1] NCCL INFO Channel 00 : 301[4b000] -> 300[31000] via P2P/IPC/read
374: hkn0713:477468:477571 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
372: hkn0713:477480:477575 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [receive] via NET/IBext/0
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [send] via NET/IBext/0
373: hkn0713:477452:477574 [1] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [receive] via NET/IBext/0
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [receive] via NET/IBext/0
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [send] via NET/IBext/0
372: hkn0713:477480:477575 [0] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [send] via NET/IBext/0
372: hkn0713:477480:477575 [0] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [receive] via NET/IBext/0
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [send] via NET/IBext/0
269: hkn0616:412177:412290 [1] NCCL INFO Channel 00 : 269[4b000] -> 268[31000] via P2P/IPC/read
372: hkn0713:477480:477575 [0] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [send] via NET/IBext/0
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [send] via NET/IBext/0
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [receive] via NET/IBext/0
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [send] via NET/IBext/0
435: hkn0730:1408947:1409077 [3] NCCL INFO Connected all trees
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 00 : 397[4b000] -> 396[31000] via P2P/IPC/read
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [receive] via NET/IBext/0
500: hkn0814:683023:683174 [0] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [send] via NET/IBext/0
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 00 : 225[4b000] -> 224[31000] via P2P/IPC/read
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [receive] via NET/IBext/0
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [receive] via NET/IBext/0
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 00 : 417[4b000] -> 416[31000] via P2P/IPC/read
300: hkn0628:679159:679255 [0] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [receive] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [send] via NET/IBext/0
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 00 : 33[4b000] -> 32[31000] via P2P/IPC/read
301: hkn0628:679147:679253 [1] NCCL INFO Channel 01 : 301[4b000] -> 300[31000] via P2P/IPC/read
435: hkn0730:1408947:1409077 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [send] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [receive] via NET/IBext/0
435: hkn0730:1408947:1409077 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 00 : 60[31000] -> 61[4b000] via P2P/IPC/read
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 00 : 353[4b000] -> 352[31000] via P2P/IPC/read
434: hkn0730:1408975:1409075 [2] NCCL INFO Connected all trees
269: hkn0616:412177:412290 [1] NCCL INFO Channel 01 : 269[4b000] -> 268[31000] via P2P/IPC/read
434: hkn0730:1408975:1409075 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [receive] via NET/IBext/0
434: hkn0730:1408975:1409075 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [send] via NET/IBext/0
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 00 : 61[4b000] -> 62[ca000] via P2P/IPC/read
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [receive] via NET/IBext/0
 62: hkn0420:3217428:3217558 [2] NCCL INFO Channel 00 : 62[ca000] -> 63[e3000] via P2P/IPC/read
397: hkn0719:1312963:1313082 [1] NCCL INFO Channel 01 : 397[4b000] -> 396[31000] via P2P/IPC/read
225: hkn0603:1420458:1420572 [1] NCCL INFO Channel 01 : 225[4b000] -> 224[31000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [receive] via NET/IBext/0
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 00 : 77[4b000] -> 76[31000] via P2P/IPC/read
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 00 : 289[4b000] -> 288[31000] via P2P/IPC/read
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [send] via NET/IBext/0
417: hkn0725:3119163:3119280 [1] NCCL INFO Channel 01 : 417[4b000] -> 416[31000] via P2P/IPC/read
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [send] via NET/IBext/0
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [receive] via NET/IBext/0
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 01 : 60[31000] -> 61[4b000] via P2P/IPC/read
 33: hkn0412:2269624:2269736 [1] NCCL INFO Channel 01 : 33[4b000] -> 32[31000] via P2P/IPC/read
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 00 : 433[4b000] -> 432[31000] via P2P/IPC/read
433: hkn0730:1408955:1409068 [1] NCCL INFO Channel 01 : 433[4b000] -> 432[31000] via P2P/IPC/read
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 01 : 61[4b000] -> 62[ca000] via P2P/IPC/read
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 00 : 481[4b000] -> 480[31000] via P2P/IPC/read
353: hkn0707:4027137:4027262 [1] NCCL INFO Channel 01 : 353[4b000] -> 352[31000] via P2P/IPC/read
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [send] via NET/IBext/0
 62: hkn0420:3217428:3217558 [2] NCCL INFO Channel 01 : 62[ca000] -> 63[e3000] via P2P/IPC/read
 63: hkn0420:3217400:3217555 [3] NCCL INFO Connected all trees
 87: hkn0426:821258:821413 [3] NCCL INFO Connected all trees
 63: hkn0420:3217400:3217555 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
471: hkn0804:1212857:1212971 [3] NCCL INFO Connected all trees
 63: hkn0420:3217400:3217555 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 87: hkn0426:821258:821413 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [send] via NET/IBext/0
 62: hkn0420:3217428:3217558 [2] NCCL INFO Connected all trees
 62: hkn0420:3217428:3217558 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 87: hkn0426:821258:821413 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:719349:719471 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [receive] via NET/IBext/0
289: hkn0624:1780160:1780285 [1] NCCL INFO Channel 01 : 289[4b000] -> 288[31000] via P2P/IPC/read
 77: hkn0424:2955178:2955291 [1] NCCL INFO Channel 01 : 77[4b000] -> 76[31000] via P2P/IPC/read
 62: hkn0420:3217428:3217558 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [send] via NET/IBext/0
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [receive] via NET/IBext/0
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [send] via NET/IBext/0
 86: hkn0426:821274:821408 [2] NCCL INFO Connected all trees
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [send] via NET/IBext/0
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [receive] via NET/IBext/0
481: hkn0807:1026277:1026401 [1] NCCL INFO Channel 01 : 481[4b000] -> 480[31000] via P2P/IPC/read
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [receive] via NET/IBext/0
 86: hkn0426:821274:821408 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
471: hkn0804:1212857:1212971 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 86: hkn0426:821274:821408 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1212857:1212971 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [receive] via NET/IBext/0
470: hkn0804:1212841:1212966 [2] NCCL INFO Connected all trees
 85: hkn0426:821286:821409 [1] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [receive] via NET/IBext/0
470: hkn0804:1212841:1212966 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [send] via NET/IBext/0
470: hkn0804:1212841:1212966 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [receive] via NET/IBext/0
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [receive] via NET/IBext/0
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [send] via NET/IBext/0
469: hkn0804:1212849:1212967 [1] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [receive] via NET/IBext/0
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [send] via NET/IBext/0
171: hkn0523:1555332:1555449 [3] NCCL INFO Connected all trees
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 00 : 333[4b000] -> 332[31000] via P2P/IPC/read
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [receive] via NET/IBext/0
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [send] via NET/IBext/0
171: hkn0523:1555332:1555449 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
205: hkn0532:932522:932818 [1] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [receive] via NET/IBext/0
108: hkn0504:48339:48431 [0] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [send] via NET/IBext/0
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [receive] via NET/IBext/0
171: hkn0523:1555332:1555449 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [receive] via NET/IBext/0
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [send] via NET/IBext/0
170: hkn0523:1555340:1555444 [2] NCCL INFO Connected all trees
147: hkn0513:3020216:3020303 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [send] via NET/IBext/0
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 01 : 144[31000] -> 145[4b000] via P2P/IPC/read
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 00 : 173[4b000] -> 172[31000] via P2P/IPC/read
170: hkn0523:1555340:1555444 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 00 : 141[4b000] -> 140[31000] via P2P/IPC/read
170: hkn0523:1555340:1555444 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [receive] via NET/IBext/0
146: hkn0513:3020196:3020300 [2] NCCL INFO Connected all trees
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [receive] via NET/IBext/0
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [send] via NET/IBext/0
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [receive] via NET/IBext/0
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [send] via NET/IBext/0
333: hkn0636:1661529:1661644 [1] NCCL INFO Channel 01 : 333[4b000] -> 332[31000] via P2P/IPC/read
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [receive] via NET/IBext/0
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [send] via NET/IBext/0
146: hkn0513:3020196:3020300 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [receive] via NET/IBext/0
146: hkn0513:3020196:3020300 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [receive] via NET/IBext/0
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [send] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [receive] via NET/IBext/0
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [receive] via NET/IBext/0
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [send] via NET/IBext/0
458: hkn0801:2247264:2247382 [2] NCCL INFO Channel 01 : 458[ca000] -> 459[e3000] via P2P/IPC/read
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [send] via NET/IBext/0
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [send] via NET/IBext/0
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 00 : 13[4b000] -> 12[31000] via P2P/IPC/read
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 00 : 145[4b000] -> 144[31000] via P2P/IPC/read
365: hkn0711:591174:591286 [1] NCCL INFO Channel 00 : 365[4b000] -> 364[31000] via P2P/IPC/read
141: hkn0512:3051327:3051449 [1] NCCL INFO Channel 01 : 141[4b000] -> 140[31000] via P2P/IPC/read
173: hkn0524:1141002:1141130 [1] NCCL INFO Channel 01 : 173[4b000] -> 172[31000] via P2P/IPC/read
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [send] via NET/IBext/0
145: hkn0513:3020188:3020302 [1] NCCL INFO Channel 01 : 145[4b000] -> 144[31000] via P2P/IPC/read
459: hkn0801:2247280:2247386 [3] NCCL INFO Connected all trees
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 00 : 237[4b000] -> 236[31000] via P2P/IPC/read
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [receive] via NET/IBext/0
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [receive] via NET/IBext/0
459: hkn0801:2247280:2247386 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
459: hkn0801:2247280:2247386 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
462: hkn0802:1207559:1207696 [2] NCCL INFO Channel 01 : 462[ca000] -> 463[e3000] via P2P/IPC/read
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [send] via NET/IBext/0
458: hkn0801:2247264:2247382 [2] NCCL INFO Connected all trees
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 00 : 121[4b000] -> 120[31000] via P2P/IPC/read
458: hkn0801:2247264:2247382 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [send] via NET/IBext/0
458: hkn0801:2247264:2247382 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [send] via NET/IBext/0
463: hkn0802:1207551:1207689 [3] NCCL INFO Connected all trees
463: hkn0802:1207551:1207689 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [receive] via NET/IBext/0
463: hkn0802:1207551:1207689 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1823500:1823618 [1] NCCL INFO Channel 01 : 13[4b000] -> 12[31000] via P2P/IPC/read
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [send] via NET/IBext/0
365: hkn0711:591174:591286 [1] NCCL INFO Channel 01 : 365[4b000] -> 364[31000] via P2P/IPC/read
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [receive] via NET/IBext/0
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [receive] via NET/IBext/0
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [send] via NET/IBext/0
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [receive] via NET/IBext/0
462: hkn0802:1207559:1207696 [2] NCCL INFO Connected all trees
462: hkn0802:1207559:1207696 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [receive] via NET/IBext/0
462: hkn0802:1207559:1207696 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
237: hkn0606:2379347:2379461 [1] NCCL INFO Channel 01 : 237[4b000] -> 236[31000] via P2P/IPC/read
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [receive] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [receive] via NET/IBext/0
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [send] via NET/IBext/0
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [receive] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [receive] via NET/IBext/0
268: hkn0616:412169:412281 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [receive] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [send] via NET/IBext/0
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [receive] via NET/IBext/0
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [receive] via NET/IBext/0
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 00 : 429[4b000] -> 428[31000] via P2P/IPC/read
121: hkn0507:3194285:3194409 [1] NCCL INFO Channel 01 : 121[4b000] -> 120[31000] via P2P/IPC/read
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 00 : 161[4b000] -> 160[31000] via P2P/IPC/read
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 00 : 461[4b000] -> 460[31000] via P2P/IPC/read
204: hkn0532:932494:932817 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [receive] via NET/IBext/0
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [receive] via NET/IBext/0
461: hkn0802:1207571:1207691 [1] NCCL INFO Channel 01 : 461[4b000] -> 460[31000] via P2P/IPC/read
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [receive] via NET/IBext/0
493: hkn0810:946752:946862 [1] NCCL INFO Channel 00 : 493[4b000] -> 492[31000] via P2P/IPC/read
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 00 : 157[4b000] -> 156[31000] via P2P/IPC/read
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [receive] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [send] via NET/IBext/0
161: hkn0520:2720094:2720215 [1] NCCL INFO Channel 01 : 161[4b000] -> 160[31000] via P2P/IPC/read
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [receive] via NET/IBext/0
429: hkn0728:1331258:1331374 [1] NCCL INFO Channel 01 : 429[4b000] -> 428[31000] via P2P/IPC/read
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [send] via NET/IBext/0
340: hkn0704:799215:799344 [0] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [receive] via NET/IBext/0
360: hkn0710:362792:362882 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [receive] via NET/IBext/0
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [send] via NET/IBext/0
409: hkn0723:215333:215489 [1] NCCL INFO Channel 00 : 409[4b000] -> 408[31000] via P2P/IPC/read
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [receive] via NET/IBext/0
493: hkn0810:946752:946862 [1] NCCL INFO Channel 01 : 493[4b000] -> 492[31000] via P2P/IPC/read
157: hkn0516:2923212:2923315 [1] NCCL INFO Channel 01 : 157[4b000] -> 156[31000] via P2P/IPC/read
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [receive] via NET/IBext/0
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [receive] via NET/IBext/0
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [receive] via NET/IBext/0
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 00 : 313[4b000] -> 312[31000] via P2P/IPC/read
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [receive] via NET/IBext/0
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 00 : 281[4b000] -> 280[31000] via P2P/IPC/read
409: hkn0723:215333:215489 [1] NCCL INFO Channel 01 : 409[4b000] -> 408[31000] via P2P/IPC/read
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [receive] via NET/IBext/0
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 00 : 321[4b000] -> 320[31000] via P2P/IPC/read
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [receive] via NET/IBext/0
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [receive] via NET/IBext/0
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 00 : 45[4b000] -> 44[31000] via P2P/IPC/read
372: hkn0713:477480:477575 [0] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [receive] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [receive] via NET/IBext/0
492: hkn0810:946764:946863 [0] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [send] via NET/IBext/0
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [send] via NET/IBext/0
313: hkn0631:1029024:1029139 [1] NCCL INFO Channel 01 : 313[4b000] -> 312[31000] via P2P/IPC/read
244: hkn0608:492975:493069 [0] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [receive] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [send] via NET/IBext/0
281: hkn0622:2027752:2027859 [1] NCCL INFO Channel 01 : 281[4b000] -> 280[31000] via P2P/IPC/read
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [receive] via NET/IBext/0
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 00 : 89[4b000] -> 88[31000] via P2P/IPC/read
321: hkn0633:1533546:1533662 [1] NCCL INFO Channel 01 : 321[4b000] -> 320[31000] via P2P/IPC/read
400: hkn0720:14302:14479 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [receive] via NET/IBext/0
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [receive] via NET/IBext/0
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [send] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [receive] via NET/IBext/0
 45: hkn0415:2503635:2503763 [1] NCCL INFO Channel 01 : 45[4b000] -> 44[31000] via P2P/IPC/read
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [send] via NET/IBext/0
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 00 : 93[4b000] -> 92[31000] via P2P/IPC/read
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [send] via NET/IBext/0
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [send] via NET/IBext/0
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [send] via NET/IBext/0
 89: hkn0427:1142369:1142461 [1] NCCL INFO Channel 01 : 89[4b000] -> 88[31000] via P2P/IPC/read
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [receive] via NET/IBext/0
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [receive] via NET/IBext/0
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [receive] via NET/IBext/0
500: hkn0814:683023:683174 [0] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [receive] via NET/IBext/0
 93: hkn0428:674567:674696 [1] NCCL INFO Channel 01 : 93[4b000] -> 92[31000] via P2P/IPC/read
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 00 : 473[4b000] -> 472[31000] via P2P/IPC/read
464: hkn0803:883779:883891 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [receive] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [send] via NET/IBext/0
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [receive] via NET/IBext/0
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [receive] via NET/IBext/0
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 00 : 221[4b000] -> 220[31000] via P2P/IPC/read
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 00 : 185[4b000] -> 184[31000] via P2P/IPC/read
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 00 : 97[4b000] -> 96[31000] via P2P/IPC/read
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [send] via NET/IBext/0
473: hkn0805:1119333:1119444 [1] NCCL INFO Channel 01 : 473[4b000] -> 472[31000] via P2P/IPC/read
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [send] via NET/IBext/0
221: hkn0602:3370890:3371086 [1] NCCL INFO Channel 01 : 221[4b000] -> 220[31000] via P2P/IPC/read
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 00 : 25[4b000] -> 24[31000] via P2P/IPC/read
349: hkn0706:759478:759608 [1] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [receive] via NET/IBext/0
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 00 : 153[4b000] -> 152[31000] via P2P/IPC/read
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [receive] via NET/IBext/0
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [receive] via NET/IBext/0
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 00 : 193[4b000] -> 192[31000] via P2P/IPC/read
185: hkn0527:1356176:1356285 [1] NCCL INFO Channel 01 : 185[4b000] -> 184[31000] via P2P/IPC/read
 97: hkn0501:1335155:1335273 [1] NCCL INFO Channel 01 : 97[4b000] -> 96[31000] via P2P/IPC/read
249: hkn0609:718036:718147 [1] NCCL INFO Channel 00 : 249[4b000] -> 248[31000] via P2P/IPC/read
345: hkn0705:790443:790544 [1] NCCL INFO Channel 00 : 345[4b000] -> 344[31000] via P2P/IPC/read
377: hkn0714:439253:439365 [1] NCCL INFO Channel 00 : 377[4b000] -> 376[31000] via P2P/IPC/read
 25: hkn0410:1166933:1167040 [1] NCCL INFO Channel 01 : 25[4b000] -> 24[31000] via P2P/IPC/read
300: hkn0628:679159:679255 [0] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [send] via NET/IBext/0
153: hkn0515:2903997:2904149 [1] NCCL INFO Channel 01 : 153[4b000] -> 152[31000] via P2P/IPC/read
193: hkn0529:1548066:1548163 [1] NCCL INFO Channel 01 : 193[4b000] -> 192[31000] via P2P/IPC/read
249: hkn0609:718036:718147 [1] NCCL INFO Channel 01 : 249[4b000] -> 248[31000] via P2P/IPC/read
108: hkn0504:48339:48431 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [send] via NET/IBext/0
116: hkn0506:845312:845412 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [send] via NET/IBext/0
345: hkn0705:790443:790544 [1] NCCL INFO Channel 01 : 345[4b000] -> 344[31000] via P2P/IPC/read
377: hkn0714:439253:439365 [1] NCCL INFO Channel 01 : 377[4b000] -> 376[31000] via P2P/IPC/read
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [receive] via NET/IBext/0
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [send] via NET/IBext/0
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 00 : 449[4b000] -> 448[31000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [send] via NET/IBext/0
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 00 : 441[4b000] -> 440[31000] via P2P/IPC/read
505: hkn0815:402333:402447 [1] NCCL INFO Channel 00 : 505[4b000] -> 504[31000] via P2P/IPC/read
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [send] via NET/IBext/0
441: hkn0732:1218890:1218999 [1] NCCL INFO Channel 01 : 441[4b000] -> 440[31000] via P2P/IPC/read
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [send] via NET/IBext/0
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 00 : 477[4b000] -> 476[31000] via P2P/IPC/read
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [receive] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [receive] via NET/IBext/0
505: hkn0815:402333:402447 [1] NCCL INFO Channel 01 : 505[4b000] -> 504[31000] via P2P/IPC/read
449: hkn0734:1163753:1163873 [1] NCCL INFO Channel 01 : 449[4b000] -> 448[31000] via P2P/IPC/read
205: hkn0532:932522:932818 [1] NCCL INFO Channel 00 : 205[4b000] -> 204[31000] via P2P/IPC/read
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 00 : 29[4b000] -> 28[31000] via P2P/IPC/read
404: hkn0721:2306526:2306622 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [send] via NET/IBext/0
477: hkn0806:1061538:1061645 [1] NCCL INFO Channel 01 : 477[4b000] -> 476[31000] via P2P/IPC/read
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [send] via NET/IBext/0
308: hkn0630:1605678:1605803 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [send] via NET/IBext/0
205: hkn0532:932522:932818 [1] NCCL INFO Channel 01 : 205[4b000] -> 204[31000] via P2P/IPC/read
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [receive] via NET/IBext/0
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [receive] via NET/IBext/0
 29: hkn0411:2323109:2323200 [1] NCCL INFO Channel 01 : 29[4b000] -> 28[31000] via P2P/IPC/read
276: hkn0621:1998822:1998945 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [send] via NET/IBext/0
 84: hkn0426:821266:821410 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [send] via NET/IBext/0
384: hkn0716:115715:115850 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [receive] via NET/IBext/0
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [receive] via NET/IBext/0
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [receive] via NET/IBext/0
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 00 : 57[4b000] -> 56[31000] via P2P/IPC/read
492: hkn0810:946764:946863 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [send] via NET/IBext/0
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [receive] via NET/IBext/0
385: hkn0716:115707:115856 [1] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [send] via NET/IBext/0
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 00 : 129[4b000] -> 128[31000] via P2P/IPC/read
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 00 : 413[4b000] -> 412[31000] via P2P/IPC/read
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 00 : 65[4b000] -> 64[31000] via P2P/IPC/read
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [send] via NET/IBext/0
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [receive] via NET/IBext/0
468: hkn0804:1212869:1212968 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [send] via NET/IBext/0
 57: hkn0419:1551489:1551602 [1] NCCL INFO Channel 01 : 57[4b000] -> 56[31000] via P2P/IPC/read
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [send] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [receive] via NET/IBext/0
413: hkn0724:1723172:1723322 [1] NCCL INFO Channel 01 : 413[4b000] -> 412[31000] via P2P/IPC/read
344: hkn0705:790415:790543 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [receive] via NET/IBext/0
129: hkn0509:3131636:3131744 [1] NCCL INFO Channel 01 : 129[4b000] -> 128[31000] via P2P/IPC/read
 65: hkn0421:2189204:2189405 [1] NCCL INFO Channel 01 : 65[4b000] -> 64[31000] via P2P/IPC/read
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 00 : 285[4b000] -> 284[31000] via P2P/IPC/read
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [receive] via NET/IBext/0
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [receive] via NET/IBext/0
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [send] via NET/IBext/0
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [send] via NET/IBext/0
216: hkn0601:124960:125086 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [receive] via NET/IBext/0
340: hkn0704:799215:799344 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [send] via NET/IBext/0
 16: hkn0408:2898029:2898160 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [receive] via NET/IBext/0
349: hkn0706:759478:759608 [1] NCCL INFO Channel 00 : 349[4b000] -> 348[31000] via P2P/IPC/read
180: hkn0526:1435645:1435749 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [send] via NET/IBext/0
285: hkn0623:1880003:1880109 [1] NCCL INFO Channel 01 : 285[4b000] -> 284[31000] via P2P/IPC/read
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [receive] via NET/IBext/0
 20: hkn0409:2592866:2592990 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [send] via NET/IBext/0
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [send] via NET/IBext/0
244: hkn0608:492975:493069 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [send] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [receive] via NET/IBext/0
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [receive] via NET/IBext/0
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [send] via NET/IBext/0
349: hkn0706:759478:759608 [1] NCCL INFO Channel 01 : 349[4b000] -> 348[31000] via P2P/IPC/read
372: hkn0713:477480:477575 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [send] via NET/IBext/0
400: hkn0720:14302:14479 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [receive] via NET/IBext/0
148: hkn0514:2957971:2958065 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [send] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [send] via NET/IBext/0
208: hkn0534:1155640:1155748 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [receive] via NET/IBext/0
272: hkn0617:2301945:2302053 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [receive] via NET/IBext/0
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [receive] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [send] via NET/IBext/0
385: hkn0716:115707:115856 [1] NCCL INFO Channel 00 : 385[4b000] -> 384[31000] via P2P/IPC/read
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [receive] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [receive] via NET/IBext/0
436: hkn0731:1393962:1394080 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [send] via NET/IBext/0
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [receive] via NET/IBext/0
500: hkn0814:683023:683174 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [send] via NET/IBext/0
385: hkn0716:115707:115856 [1] NCCL INFO Channel 01 : 385[4b000] -> 384[31000] via P2P/IPC/read
108: hkn0504:48339:48431 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [send] via NET/IBext/0
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [receive] via NET/IBext/0
300: hkn0628:679159:679255 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [send] via NET/IBext/0
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [receive] via NET/IBext/0
 52: hkn0418:1876388:1876514 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [send] via NET/IBext/0
364: hkn0711:591166:591281 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [send] via NET/IBext/0
464: hkn0803:883779:883891 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [receive] via NET/IBext/0
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [send] via NET/IBext/0
236: hkn0606:2379339:2379462 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [send] via NET/IBext/0
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [receive] via NET/IBext/0
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 00 : 445[4b000] -> 444[31000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [receive] via NET/IBext/0
100: hkn0502:236295:236412 [0] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [receive] via NET/IBext/0
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [receive] via NET/IBext/0
445: hkn0733:1396580:1396694 [1] NCCL INFO Channel 01 : 445[4b000] -> 444[31000] via P2P/IPC/read
217: hkn0601:124968:125085 [1] NCCL INFO Channel 00 : 217[4b000] -> 216[31000] via P2P/IPC/read
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [receive] via NET/IBext/0
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [receive] via NET/IBext/0
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 00 : 61[4b000] -> 60[31000] via P2P/IPC/read
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [receive] via NET/IBext/0
217: hkn0601:124968:125085 [1] NCCL INFO Channel 01 : 217[4b000] -> 216[31000] via P2P/IPC/read
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 00 : 169[4b000] -> 168[31000] via P2P/IPC/read
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [send] via NET/IBext/0
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [receive] via NET/IBext/0
 61: hkn0420:3217408:3217553 [1] NCCL INFO Channel 01 : 61[4b000] -> 60[31000] via P2P/IPC/read
492: hkn0810:946764:946863 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [send] via NET/IBext/0
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [receive] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [send] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [receive] via NET/IBext/0
169: hkn0523:1555324:1555450 [1] NCCL INFO Channel 01 : 169[4b000] -> 168[31000] via P2P/IPC/read
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [receive] via NET/IBext/0
173: hkn0524:1141002:1141130 [1] NCCL INFO Connected all trees
173: hkn0524:1141002:1141130 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1141002:1141130 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:924207:924324 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [receive] via NET/IBext/0
288: hkn0624:1780140:1780284 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [receive] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [receive] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO Connected all trees
172: hkn0524:1141018:1141124 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1141018:1141124 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [send] via NET/IBext/0
 44: hkn0415:2503651:2503760 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [send] via NET/IBext/0
172: hkn0524:1141018:1141124 [0] NCCL INFO comm 0x14f324008fb0 rank 172 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 16: hkn0408:2898029:2898160 [0] NCCL INFO Connected all trees
175: hkn0524:1141030:1141123 [3] NCCL INFO comm 0x14e6a0008fb0 rank 175 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 16: hkn0408:2898029:2898160 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1141002:1141130 [1] NCCL INFO comm 0x153558008fb0 rank 173 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 16: hkn0408:2898029:2898160 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 00 : 189[4b000] -> 188[31000] via P2P/IPC/read
174: hkn0524:1141010:1141129 [2] NCCL INFO comm 0x14c160008fb0 rank 174 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 00 : 105[4b000] -> 104[31000] via P2P/IPC/read
109: hkn0504:48319:48430 [1] NCCL INFO Connected all trees
109: hkn0504:48319:48430 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
109: hkn0504:48319:48430 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [send] via NET/IBext/0
 17: hkn0408:2898045:2898159 [1] NCCL INFO Connected all trees
484: hkn0808:977921:978021 [0] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [receive] via NET/IBext/0
108: hkn0504:48339:48431 [0] NCCL INFO Connected all trees
 17: hkn0408:2898045:2898159 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2898045:2898159 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
108: hkn0504:48339:48431 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:48339:48431 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:115715:115850 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [send] via NET/IBext/0
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [receive] via NET/IBext/0
400: hkn0720:14302:14479 [0] NCCL INFO Connected all trees
400: hkn0720:14302:14479 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
105: hkn0503:2906935:2907063 [1] NCCL INFO Channel 01 : 105[4b000] -> 104[31000] via P2P/IPC/read
400: hkn0720:14302:14479 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 17: hkn0408:2898045:2898159 [1] NCCL INFO comm 0x1501e8008fb0 rank 17 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
189: hkn0528:1308923:1309018 [1] NCCL INFO Channel 01 : 189[4b000] -> 188[31000] via P2P/IPC/read
111: hkn0504:48327:48437 [3] NCCL INFO comm 0x14e448008fb0 rank 111 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
108: hkn0504:48339:48431 [0] NCCL INFO comm 0x14bb54008fb0 rank 108 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
109: hkn0504:48319:48430 [1] NCCL INFO comm 0x149ab8008fb0 rank 109 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 16: hkn0408:2898029:2898160 [0] NCCL INFO comm 0x154580008fb0 rank 16 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 19: hkn0408:2898037:2898154 [3] NCCL INFO comm 0x1504f0008fb0 rank 19 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 18: hkn0408:2898057:2898153 [2] NCCL INFO comm 0x1484fc008fb0 rank 18 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
401: hkn0720:14318:14478 [1] NCCL INFO Connected all trees
110: hkn0504:48311:48436 [2] NCCL INFO comm 0x1484c8008fb0 rank 110 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
401: hkn0720:14318:14478 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
272: hkn0617:2301945:2302053 [0] NCCL INFO Connected all trees
401: hkn0720:14318:14478 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2301945:2302053 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
272: hkn0617:2301945:2302053 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1331278:1331370 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [send] via NET/IBext/0
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [receive] via NET/IBext/0
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [receive] via NET/IBext/0
237: hkn0606:2379347:2379461 [1] NCCL INFO Connected all trees
233: hkn0605:719360:719472 [1] NCCL INFO Channel 00 : 233[4b000] -> 232[31000] via P2P/IPC/read
273: hkn0617:2301927:2302047 [1] NCCL INFO Connected all trees
237: hkn0606:2379347:2379461 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
337: hkn0703:748303:748410 [1] NCCL INFO Connected all trees
337: hkn0703:748303:748410 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
237: hkn0606:2379347:2379461 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:14318:14478 [1] NCCL INFO comm 0x148860008fb0 rank 401 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
273: hkn0617:2301927:2302047 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
273: hkn0617:2301927:2302047 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
176: hkn0525:994034:994135 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [receive] via NET/IBext/0
403: hkn0720:14330:14481 [3] NCCL INFO comm 0x152064008fb0 rank 403 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
337: hkn0703:748303:748410 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:14302:14479 [0] NCCL INFO comm 0x147e6c008fb0 rank 400 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
236: hkn0606:2379339:2379462 [0] NCCL INFO Connected all trees
381: hkn0715:409138:409236 [1] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [receive] via NET/IBext/0
336: hkn0703:748295:748408 [0] NCCL INFO Connected all trees
236: hkn0606:2379339:2379462 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2379339:2379462 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
336: hkn0703:748295:748408 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:14310:14477 [2] NCCL INFO comm 0x14692c008fb0 rank 402 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
336: hkn0703:748295:748408 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2301945:2302053 [0] NCCL INFO comm 0x14c458008fb0 rank 272 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
233: hkn0605:719360:719472 [1] NCCL INFO Channel 01 : 233[4b000] -> 232[31000] via P2P/IPC/read
274: hkn0617:2301935:2302046 [2] NCCL INFO comm 0x152714008fb0 rank 274 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [send] via NET/IBext/0
273: hkn0617:2301927:2302047 [1] NCCL INFO comm 0x14e9dc008fb0 rank 273 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
275: hkn0617:2301957:2302052 [3] NCCL INFO comm 0x14b7d4008fb0 rank 275 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
300: hkn0628:679159:679255 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [send] via NET/IBext/0
237: hkn0606:2379347:2379461 [1] NCCL INFO comm 0x148a7c008fb0 rank 237 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
336: hkn0703:748295:748408 [0] NCCL INFO comm 0x151f18008fb0 rank 336 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
338: hkn0703:748322:748407 [2] NCCL INFO comm 0x152cf8008fb0 rank 338 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
236: hkn0606:2379339:2379462 [0] NCCL INFO comm 0x147a80008fb0 rank 236 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
339: hkn0703:748311:748409 [3] NCCL INFO comm 0x150a18008fb0 rank 339 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
239: hkn0606:2379367:2379465 [3] NCCL INFO comm 0x14722c008fb0 rank 239 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
238: hkn0606:2379355:2379460 [2] NCCL INFO comm 0x14b830008fb0 rank 238 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
337: hkn0703:748303:748410 [1] NCCL INFO comm 0x1550d8008fb0 rank 337 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
144: hkn0513:3020204:3020301 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [receive] via NET/IBext/0
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [receive] via NET/IBext/0
364: hkn0711:591166:591281 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [send] via NET/IBext/0
168: hkn0523:1555352:1555443 [0] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [send] via NET/IBext/0
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [send] via NET/IBext/0
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 00 : 317[4b000] -> 316[31000] via P2P/IPC/read
489: hkn0809:944571:944666 [1] NCCL INFO Channel 00 : 489[4b000] -> 488[31000] via P2P/IPC/read
465: hkn0803:883787:883894 [1] NCCL INFO Connected all trees
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [receive] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [receive] via NET/IBext/0
493: hkn0810:946752:946862 [1] NCCL INFO Connected all trees
493: hkn0810:946752:946862 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:883787:883894 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:946752:946862 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:883787:883894 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
464: hkn0803:883779:883891 [0] NCCL INFO Connected all trees
492: hkn0810:946764:946863 [0] NCCL INFO Connected all trees
492: hkn0810:946764:946863 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
464: hkn0803:883779:883891 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
492: hkn0810:946764:946863 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
464: hkn0803:883779:883891 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
317: hkn0632:1765843:1765966 [1] NCCL INFO Channel 01 : 317[4b000] -> 316[31000] via P2P/IPC/read
489: hkn0809:944571:944666 [1] NCCL INFO Channel 01 : 489[4b000] -> 488[31000] via P2P/IPC/read
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [send] via NET/IBext/0
464: hkn0803:883779:883891 [0] NCCL INFO comm 0x14b8b0008fb0 rank 464 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
493: hkn0810:946752:946862 [1] NCCL INFO comm 0x14b814008fb0 rank 493 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [receive] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [send] via NET/IBext/0
492: hkn0810:946764:946863 [0] NCCL INFO comm 0x14591c008fb0 rank 492 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
257: hkn0612:924227:924322 [1] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [send] via NET/IBext/0
164: hkn0521:1205016:1205137 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [send] via NET/IBext/0
467: hkn0803:883807:883885 [3] NCCL INFO comm 0x14583c008fb0 rank 467 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
465: hkn0803:883787:883894 [1] NCCL INFO comm 0x14d660008fb0 rank 465 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
466: hkn0803:883795:883893 [2] NCCL INFO comm 0x151488008fb0 rank 466 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
256: hkn0612:924207:924324 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [send] via NET/IBext/0
494: hkn0810:946736:946861 [2] NCCL INFO comm 0x154dc8008fb0 rank 494 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 45: hkn0415:2503635:2503763 [1] NCCL INFO Connected all trees
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [receive] via NET/IBext/0
495: hkn0810:946744:946866 [3] NCCL INFO comm 0x14b208008fb0 rank 495 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 45: hkn0415:2503635:2503763 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 45: hkn0415:2503635:2503763 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 44: hkn0415:2503651:2503760 [0] NCCL INFO Connected all trees
 44: hkn0415:2503651:2503760 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2503651:2503760 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [receive] via NET/IBext/0
356: hkn0708:420442:420567 [0] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [receive] via NET/IBext/0
 47: hkn0415:2503663:2503759 [3] NCCL INFO comm 0x146bb0008fb0 rank 47 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 45: hkn0415:2503635:2503763 [1] NCCL INFO comm 0x14c7c4008fb0 rank 45 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 46: hkn0415:2503643:2503758 [2] NCCL INFO comm 0x147998008fb0 rank 46 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 44: hkn0415:2503651:2503760 [0] NCCL INFO comm 0x14fc90008fb0 rank 44 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [receive] via NET/IBext/0
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 00 : 41[4b000] -> 40[31000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [receive] via NET/IBext/0
232: hkn0605:719349:719471 [0] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [send] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [send] via NET/IBext/0
212: hkn0535:2406214:2406333 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [send] via NET/IBext/0
429: hkn0728:1331258:1331374 [1] NCCL INFO Connected all trees
429: hkn0728:1331258:1331374 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
429: hkn0728:1331258:1331374 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1331278:1331370 [0] NCCL INFO Connected all trees
 41: hkn0414:1988888:1989009 [1] NCCL INFO Channel 01 : 41[4b000] -> 40[31000] via P2P/IPC/read
100: hkn0502:236295:236412 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [send] via NET/IBext/0
476: hkn0806:1061522:1061652 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [send] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
428: hkn0728:1331278:1331370 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 00 : 425[4b000] -> 424[31000] via P2P/IPC/read
 64: hkn0421:2189212:2189407 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [receive] via NET/IBext/0
428: hkn0728:1331278:1331370 [0] NCCL INFO comm 0x14dad0008fb0 rank 428 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 80: hkn0425:2091287:2091403 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [receive] via NET/IBext/0
431: hkn0728:1331257:1331376 [3] NCCL INFO comm 0x149634008fb0 rank 431 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
430: hkn0728:1331266:1331371 [2] NCCL INFO comm 0x1530a4008fb0 rank 430 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
429: hkn0728:1331258:1331374 [1] NCCL INFO comm 0x147998008fb0 rank 429 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
301: hkn0628:679147:679253 [1] NCCL INFO Connected all trees
253: hkn0611:717051:717160 [1] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [receive] via NET/IBext/0
301: hkn0628:679147:679253 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 92: hkn0428:674583:674690 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [send] via NET/IBext/0
301: hkn0628:679147:679253 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1353010:1353119 [1] NCCL INFO Channel 01 : 425[4b000] -> 424[31000] via P2P/IPC/read
257: hkn0612:924227:924322 [1] NCCL INFO Channel 00 : 257[4b000] -> 256[31000] via P2P/IPC/read
488: hkn0809:944559:944660 [0] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [send] via NET/IBext/0
381: hkn0715:409138:409236 [1] NCCL INFO Channel 00 : 381[4b000] -> 380[31000] via P2P/IPC/read
 32: hkn0412:2269616:2269733 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [receive] via NET/IBext/0
304: hkn0629:1599292:1599400 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [receive] via NET/IBext/0
300: hkn0628:679159:679255 [0] NCCL INFO Connected all trees
228: hkn0604:696478:696578 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [send] via NET/IBext/0
300: hkn0628:679159:679255 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
364: hkn0711:591166:591281 [0] NCCL INFO Connected all trees
300: hkn0628:679159:679255 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:591166:591281 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
364: hkn0711:591166:591281 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
165: hkn0521:1205024:1205132 [1] NCCL INFO Channel 00 : 165[4b000] -> 164[31000] via P2P/IPC/read
169: hkn0523:1555324:1555450 [1] NCCL INFO Connected all trees
169: hkn0523:1555324:1555450 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
169: hkn0523:1555324:1555450 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [receive] via NET/IBext/0
257: hkn0612:924227:924322 [1] NCCL INFO Channel 01 : 257[4b000] -> 256[31000] via P2P/IPC/read
365: hkn0711:591174:591286 [1] NCCL INFO Connected all trees
365: hkn0711:591174:591286 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:679159:679255 [0] NCCL INFO comm 0x14e174008fb0 rank 300 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
365: hkn0711:591174:591286 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 00 : 297[4b000] -> 296[31000] via P2P/IPC/read
168: hkn0523:1555352:1555443 [0] NCCL INFO Connected all trees
301: hkn0628:679147:679253 [1] NCCL INFO comm 0x14c9fc008fb0 rank 301 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
302: hkn0628:679139:679252 [2] NCCL INFO comm 0x1497a8008fb0 rank 302 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
168: hkn0523:1555352:1555443 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
303: hkn0628:679131:679256 [3] NCCL INFO comm 0x1542c8008fb0 rank 303 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
168: hkn0523:1555352:1555443 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
381: hkn0715:409138:409236 [1] NCCL INFO Channel 01 : 381[4b000] -> 380[31000] via P2P/IPC/read
364: hkn0711:591166:591281 [0] NCCL INFO comm 0x147bc0008fb0 rank 364 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
365: hkn0711:591174:591286 [1] NCCL INFO comm 0x14b318008fb0 rank 365 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
165: hkn0521:1205024:1205132 [1] NCCL INFO Channel 01 : 165[4b000] -> 164[31000] via P2P/IPC/read
171: hkn0523:1555332:1555449 [3] NCCL INFO comm 0x14ca4c008fb0 rank 171 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
366: hkn0711:591185:591287 [2] NCCL INFO comm 0x148864008fb0 rank 366 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
361: hkn0710:362772:362881 [1] NCCL INFO Channel 00 : 361[4b000] -> 360[31000] via P2P/IPC/read
367: hkn0711:591158:591280 [3] NCCL INFO comm 0x153a4c008fb0 rank 367 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
168: hkn0523:1555352:1555443 [0] NCCL INFO comm 0x14f028008fb0 rank 168 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
169: hkn0523:1555324:1555450 [1] NCCL INFO comm 0x154a2c008fb0 rank 169 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 40: hkn0414:1988896:1989013 [0] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [send] via NET/IBext/0
170: hkn0523:1555340:1555444 [2] NCCL INFO comm 0x14bb18008fb0 rank 170 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [send] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [receive] via NET/IBext/0
297: hkn0627:1795158:1795270 [1] NCCL INFO Channel 01 : 297[4b000] -> 296[31000] via P2P/IPC/read
101: hkn0502:236287:236411 [1] NCCL INFO Channel 00 : 101[4b000] -> 100[31000] via P2P/IPC/read
416: hkn0725:3119164:3119281 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [receive] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [send] via NET/IBext/0
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 00 : 125[4b000] -> 124[31000] via P2P/IPC/read
105: hkn0503:2906935:2907063 [1] NCCL INFO Connected all trees
105: hkn0503:2906935:2907063 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [receive] via NET/IBext/0
105: hkn0503:2906935:2907063 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3370918:3371090 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [send] via NET/IBext/0
361: hkn0710:362772:362881 [1] NCCL INFO Channel 01 : 361[4b000] -> 360[31000] via P2P/IPC/read
101: hkn0502:236287:236411 [1] NCCL INFO Channel 01 : 101[4b000] -> 100[31000] via P2P/IPC/read
484: hkn0808:977921:978021 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [send] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO Connected all trees
104: hkn0503:2906963:2907057 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [send] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
125: hkn0508:3146338:3146460 [1] NCCL INFO Channel 01 : 125[4b000] -> 124[31000] via P2P/IPC/read
107: hkn0503:2906943:2907062 [3] NCCL INFO comm 0x1544e0008fb0 rank 107 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [send] via NET/IBext/0
104: hkn0503:2906963:2907057 [0] NCCL INFO comm 0x151e7c008fb0 rank 104 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [send] via NET/IBext/0
105: hkn0503:2906935:2907063 [1] NCCL INFO comm 0x1527e0008fb0 rank 105 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
164: hkn0521:1205016:1205137 [0] NCCL INFO Connected all trees
106: hkn0503:2906951:2907055 [2] NCCL INFO comm 0x146648008fb0 rank 106 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
164: hkn0521:1205016:1205137 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
164: hkn0521:1205016:1205137 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:696459:696573 [1] NCCL INFO Channel 00 : 229[4b000] -> 228[31000] via P2P/IPC/read
165: hkn0521:1205024:1205132 [1] NCCL INFO Connected all trees
165: hkn0521:1205024:1205132 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 36: hkn0413:2373960:2374058 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [send] via NET/IBext/0
165: hkn0521:1205024:1205132 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
145: hkn0513:3020188:3020302 [1] NCCL INFO Connected all trees
320: hkn0633:1533538:1533659 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [receive] via NET/IBext/0
145: hkn0513:3020188:3020302 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
145: hkn0513:3020188:3020302 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
161: hkn0520:2720094:2720215 [1] NCCL INFO Connected all trees
144: hkn0513:3020204:3020301 [0] NCCL INFO Connected all trees
161: hkn0520:2720094:2720215 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
164: hkn0521:1205016:1205137 [0] NCCL INFO comm 0x14b56c008fb0 rank 164 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
161: hkn0520:2720094:2720215 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
144: hkn0513:3020204:3020301 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
424: hkn0727:1353001:1353114 [0] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [send] via NET/IBext/0
167: hkn0521:1205008:1205131 [3] NCCL INFO comm 0x153e18008fb0 rank 167 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
176: hkn0525:994034:994135 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [receive] via NET/IBext/0
229: hkn0604:696459:696573 [1] NCCL INFO Channel 01 : 229[4b000] -> 228[31000] via P2P/IPC/read
233: hkn0605:719360:719472 [1] NCCL INFO Connected all trees
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [send] via NET/IBext/0
144: hkn0513:3020204:3020301 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
165: hkn0521:1205024:1205132 [1] NCCL INFO comm 0x14af6c008fb0 rank 165 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
233: hkn0605:719360:719472 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
166: hkn0521:1205036:1205135 [2] NCCL INFO comm 0x152b04008fb0 rank 166 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
233: hkn0605:719360:719472 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2720114:2720212 [0] NCCL INFO Connected all trees
160: hkn0520:2720114:2720212 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
160: hkn0520:2720114:2720212 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:932494:932817 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [send] via NET/IBext/0
232: hkn0605:719349:719471 [0] NCCL INFO Connected all trees
232: hkn0605:719349:719471 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
232: hkn0605:719349:719471 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1061538:1061645 [1] NCCL INFO Connected all trees
145: hkn0513:3020188:3020302 [1] NCCL INFO comm 0x153c98008fb0 rank 145 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
144: hkn0513:3020204:3020301 [0] NCCL INFO comm 0x14eedc008fb0 rank 144 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
477: hkn0806:1061538:1061645 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2720094:2720215 [1] NCCL INFO comm 0x152f48008fb0 rank 161 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
477: hkn0806:1061538:1061645 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
296: hkn0627:1795174:1795274 [0] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [send] via NET/IBext/0
146: hkn0513:3020196:3020300 [2] NCCL INFO comm 0x14b318008fb0 rank 146 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
162: hkn0520:2720086:2720209 [2] NCCL INFO comm 0x152470008fb0 rank 162 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
147: hkn0513:3020216:3020303 [3] NCCL INFO comm 0x151fc0008fb0 rank 147 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
163: hkn0520:2720102:2720208 [3] NCCL INFO comm 0x14d51c008fb0 rank 163 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
476: hkn0806:1061522:1061652 [0] NCCL INFO Connected all trees
360: hkn0710:362792:362882 [0] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [send] via NET/IBext/0
160: hkn0520:2720114:2720212 [0] NCCL INFO comm 0x149728008fb0 rank 160 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
234: hkn0605:719352:719473 [2] NCCL INFO comm 0x14b82c008fb0 rank 234 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
485: hkn0808:977901:978022 [1] NCCL INFO Channel 00 : 485[4b000] -> 484[31000] via P2P/IPC/read
232: hkn0605:719349:719471 [0] NCCL INFO comm 0x14864c008fb0 rank 232 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
476: hkn0806:1061522:1061652 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 92: hkn0428:674583:674690 [0] NCCL INFO Connected all trees
476: hkn0806:1061522:1061652 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:674583:674690 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
233: hkn0605:719360:719472 [1] NCCL INFO comm 0x14e1bc008fb0 rank 233 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 92: hkn0428:674583:674690 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
235: hkn0605:719372:719467 [3] NCCL INFO comm 0x1543e0008fb0 rank 235 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
476: hkn0806:1061522:1061652 [0] NCCL INFO comm 0x145a14008fb0 rank 476 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
489: hkn0809:944571:944666 [1] NCCL INFO Connected all trees
485: hkn0808:977901:978022 [1] NCCL INFO Channel 01 : 485[4b000] -> 484[31000] via P2P/IPC/read
489: hkn0809:944571:944666 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
489: hkn0809:944571:944666 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1061538:1061645 [1] NCCL INFO comm 0x1549fc008fb0 rank 477 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [receive] via NET/IBext/0
478: hkn0806:1061550:1061649 [2] NCCL INFO comm 0x14da90008fb0 rank 478 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
479: hkn0806:1061530:1061646 [3] NCCL INFO comm 0x1483b8008fb0 rank 479 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
420: hkn0726:1555321:1555442 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [send] via NET/IBext/0
488: hkn0809:944559:944660 [0] NCCL INFO Connected all trees
488: hkn0809:944559:944660 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:944559:944660 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
208: hkn0534:1155640:1155748 [0] NCCL INFO Connected all trees
208: hkn0534:1155640:1155748 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1155640:1155748 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:759506:759606 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [send] via NET/IBext/0
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [receive] via NET/IBext/0
488: hkn0809:944559:944660 [0] NCCL INFO comm 0x14d2d8008fb0 rank 488 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
209: hkn0534:1155638:1155749 [1] NCCL INFO Connected all trees
491: hkn0809:944551:944668 [3] NCCL INFO comm 0x1462c8008fb0 rank 491 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
209: hkn0534:1155638:1155749 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
489: hkn0809:944571:944666 [1] NCCL INFO comm 0x153bf8008fb0 rank 489 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
209: hkn0534:1155638:1155749 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
490: hkn0809:944543:944669 [2] NCCL INFO comm 0x154eb8008fb0 rank 490 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
292: hkn0626:1305637:1305778 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [send] via NET/IBext/0
253: hkn0611:717051:717160 [1] NCCL INFO Channel 00 : 253[4b000] -> 252[31000] via P2P/IPC/read
256: hkn0612:924207:924324 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [receive] via NET/IBext/0
432: hkn0730:1408963:1409072 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [receive] via NET/IBext/0
 37: hkn0413:2373940:2374062 [1] NCCL INFO Channel 00 : 37[4b000] -> 36[31000] via P2P/IPC/read
210: hkn0534:1155637:1155744 [2] NCCL INFO comm 0x14bef0008fb0 rank 210 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
211: hkn0534:1155652:1155751 [3] NCCL INFO comm 0x150968008fb0 rank 211 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
209: hkn0534:1155638:1155749 [1] NCCL INFO comm 0x155234008fb0 rank 209 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  0: hkn0403:1776559:1776930 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [receive] via NET/IBext/0
208: hkn0534:1155640:1155748 [0] NCCL INFO comm 0x14aff4008fb0 rank 208 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 40: hkn0414:1988896:1989013 [0] NCCL INFO Connected all trees
 40: hkn0414:1988896:1989013 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 40: hkn0414:1988896:1989013 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [receive] via NET/IBext/0
253: hkn0611:717051:717160 [1] NCCL INFO Channel 01 : 253[4b000] -> 252[31000] via P2P/IPC/read
220: hkn0602:3370918:3371090 [0] NCCL INFO Connected all trees
356: hkn0708:420442:420567 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [send] via NET/IBext/0
 41: hkn0414:1988888:1989009 [1] NCCL INFO Connected all trees
 93: hkn0428:674567:674696 [1] NCCL INFO Connected all trees
 41: hkn0414:1988888:1989009 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 41: hkn0414:1988888:1989009 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 93: hkn0428:674567:674696 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 93: hkn0428:674567:674696 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3370918:3371090 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
220: hkn0602:3370918:3371090 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1599304:1599395 [1] NCCL INFO Connected all trees
305: hkn0629:1599304:1599395 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
305: hkn0629:1599304:1599395 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
221: hkn0602:3370890:3371086 [1] NCCL INFO Connected all trees
 48: hkn0417:2274888:2274985 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [receive] via NET/IBext/0
 37: hkn0413:2373940:2374062 [1] NCCL INFO Channel 01 : 37[4b000] -> 36[31000] via P2P/IPC/read
 96: hkn0501:1335139:1335266 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [receive] via NET/IBext/0
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [send] via NET/IBext/0
304: hkn0629:1599292:1599400 [0] NCCL INFO Connected all trees
221: hkn0602:3370890:3371086 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 92: hkn0428:674583:674690 [0] NCCL INFO comm 0x1516ec008fb0 rank 92 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
221: hkn0602:3370890:3371086 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
304: hkn0629:1599292:1599400 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
304: hkn0629:1599292:1599400 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 94: hkn0428:674575:674691 [2] NCCL INFO comm 0x154824008fb0 rank 94 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 42: hkn0414:1988904:1989011 [2] NCCL INFO comm 0x153408008fb0 rank 42 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 93: hkn0428:674567:674696 [1] NCCL INFO comm 0x14bbd8008fb0 rank 93 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 41: hkn0414:1988888:1989009 [1] NCCL INFO comm 0x147ffc008fb0 rank 41 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 95: hkn0428:674595:674697 [3] NCCL INFO comm 0x154f48008fb0 rank 95 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
220: hkn0602:3370918:3371090 [0] NCCL INFO comm 0x14acc8008fb0 rank 220 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 40: hkn0414:1988896:1989013 [0] NCCL INFO comm 0x1535f0008fb0 rank 40 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
305: hkn0629:1599304:1599395 [1] NCCL INFO comm 0x154714008fb0 rank 305 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 43: hkn0414:1988916:1989008 [3] NCCL INFO comm 0x149bf4008fb0 rank 43 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 81: hkn0425:2091299:2091397 [1] NCCL INFO Connected all trees
307: hkn0629:1599276:1599401 [3] NCCL INFO comm 0x14aad4008fb0 rank 307 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [receive] via NET/IBext/0
221: hkn0602:3370890:3371086 [1] NCCL INFO comm 0x14a9f8008fb0 rank 221 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
304: hkn0629:1599292:1599400 [0] NCCL INFO comm 0x14f144008fb0 rank 304 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 81: hkn0425:2091299:2091397 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
223: hkn0602:3370906:3371095 [3] NCCL INFO comm 0x14c118008fb0 rank 223 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
306: hkn0629:1599284:1599393 [2] NCCL INFO comm 0x14de0c008fb0 rank 306 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 81: hkn0425:2091299:2091397 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3370898:3371093 [2] NCCL INFO comm 0x14ae74008fb0 rank 222 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 80: hkn0425:2091287:2091403 [0] NCCL INFO Connected all trees
 80: hkn0425:2091287:2091403 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2091287:2091403 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
460: hkn0802:1207543:1207697 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [send] via NET/IBext/0
425: hkn0727:1353010:1353119 [1] NCCL INFO Connected all trees
368: hkn0712:302297:302400 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [receive] via NET/IBext/0
472: hkn0805:1119345:1119447 [0] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [send] via NET/IBext/0
 88: hkn0427:1142349:1142466 [0] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [send] via NET/IBext/0
380: hkn0715:409126:409232 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [send] via NET/IBext/0
421: hkn0726:1555337:1555444 [1] NCCL INFO Channel 00 : 421[4b000] -> 420[31000] via P2P/IPC/read
425: hkn0727:1353010:1353119 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
425: hkn0727:1353010:1353119 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 82: hkn0425:2091279:2091402 [2] NCCL INFO comm 0x152a88008fb0 rank 82 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 81: hkn0425:2091299:2091397 [1] NCCL INFO comm 0x146dac008fb0 rank 81 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 37: hkn0413:2373940:2374062 [1] NCCL INFO Connected all trees
357: hkn0708:420450:420563 [1] NCCL INFO Channel 00 : 357[4b000] -> 356[31000] via P2P/IPC/read
 83: hkn0425:2091271:2091395 [3] NCCL INFO comm 0x1534b8008fb0 rank 83 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 37: hkn0413:2373940:2374062 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2091287:2091403 [0] NCCL INFO comm 0x1493b8008fb0 rank 80 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 37: hkn0413:2373940:2374062 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2955170:2955294 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [send] via NET/IBext/0
 36: hkn0413:2373960:2374058 [0] NCCL INFO Connected all trees
444: hkn0733:1396588:1396702 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [send] via NET/IBext/0
 36: hkn0413:2373960:2374058 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 36: hkn0413:2373960:2374058 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1305645:1305779 [1] NCCL INFO Channel 00 : 293[4b000] -> 292[31000] via P2P/IPC/read
296: hkn0627:1795174:1795274 [0] NCCL INFO Connected all trees
360: hkn0710:362792:362882 [0] NCCL INFO Connected all trees
296: hkn0627:1795174:1795274 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
296: hkn0627:1795174:1795274 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:362792:362882 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:362792:362882 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:420450:420563 [1] NCCL INFO Channel 01 : 357[4b000] -> 356[31000] via P2P/IPC/read
421: hkn0726:1555337:1555444 [1] NCCL INFO Channel 01 : 421[4b000] -> 420[31000] via P2P/IPC/read
 33: hkn0412:2269624:2269736 [1] NCCL INFO Connected all trees
 37: hkn0413:2373940:2374062 [1] NCCL INFO comm 0x14ec20008fb0 rank 37 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
424: hkn0727:1353001:1353114 [0] NCCL INFO Connected all trees
 33: hkn0412:2269624:2269736 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 38: hkn0413:2373948:2374057 [2] NCCL INFO comm 0x14b558008fb0 rank 38 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
424: hkn0727:1353001:1353114 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
297: hkn0627:1795158:1795270 [1] NCCL INFO Connected all trees
 33: hkn0412:2269624:2269736 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
424: hkn0727:1353001:1353114 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 39: hkn0413:2373932:2374059 [3] NCCL INFO comm 0x145cf8008fb0 rank 39 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
297: hkn0627:1795158:1795270 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
361: hkn0710:362772:362881 [1] NCCL INFO Connected all trees
 36: hkn0413:2373960:2374058 [0] NCCL INFO comm 0x14657c008fb0 rank 36 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
297: hkn0627:1795158:1795270 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:362772:362881 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2269616:2269733 [0] NCCL INFO Connected all trees
361: hkn0710:362772:362881 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2269616:2269733 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2269616:2269733 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1353010:1353119 [1] NCCL INFO comm 0x15107c008fb0 rank 425 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
424: hkn0727:1353001:1353114 [0] NCCL INFO comm 0x15110c008fb0 rank 424 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
426: hkn0727:1353002:1353113 [2] NCCL INFO comm 0x152778008fb0 rank 426 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
293: hkn0626:1305645:1305779 [1] NCCL INFO Channel 01 : 293[4b000] -> 292[31000] via P2P/IPC/read
352: hkn0707:4027165:4027259 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [receive] via NET/IBext/0
 32: hkn0412:2269616:2269733 [0] NCCL INFO comm 0x14e37c008fb0 rank 32 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
298: hkn0627:1795166:1795271 [2] NCCL INFO comm 0x145dac008fb0 rank 298 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
188: hkn0528:1308911:1309016 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [send] via NET/IBext/0
 33: hkn0412:2269624:2269736 [1] NCCL INFO comm 0x146ab4008fb0 rank 33 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
176: hkn0525:994034:994135 [0] NCCL INFO Connected all trees
349: hkn0706:759478:759608 [1] NCCL INFO Connected all trees
296: hkn0627:1795174:1795274 [0] NCCL INFO comm 0x153290008fb0 rank 296 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 34: hkn0412:2269636:2269732 [2] NCCL INFO comm 0x14adec008fb0 rank 34 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
297: hkn0627:1795158:1795270 [1] NCCL INFO comm 0x152ce0008fb0 rank 297 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
176: hkn0525:994034:994135 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
349: hkn0706:759478:759608 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
299: hkn0627:1795186:1795268 [3] NCCL INFO comm 0x14aa8c008fb0 rank 299 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
176: hkn0525:994034:994135 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
349: hkn0706:759478:759608 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 35: hkn0412:2269608:2269737 [3] NCCL INFO comm 0x153734008fb0 rank 35 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [receive] via NET/IBext/0
362: hkn0710:362764:362885 [2] NCCL INFO comm 0x151c40008fb0 rank 362 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
363: hkn0710:362780:362887 [3] NCCL INFO comm 0x151520008fb0 rank 363 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
360: hkn0710:362792:362882 [0] NCCL INFO comm 0x1491c0008fb0 rank 360 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
361: hkn0710:362772:362881 [1] NCCL INFO comm 0x14b934008fb0 rank 361 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
348: hkn0706:759506:759606 [0] NCCL INFO Connected all trees
348: hkn0706:759506:759606 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
204: hkn0532:932494:932817 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [send] via NET/IBext/0
216: hkn0601:124960:125086 [0] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [send] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
177: hkn0525:994014:994129 [1] NCCL INFO Connected all trees
177: hkn0525:994014:994129 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:994014:994129 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [send] via NET/IBext/0
420: hkn0726:1555321:1555442 [0] NCCL INFO Connected all trees
420: hkn0726:1555321:1555442 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
420: hkn0726:1555321:1555442 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
349: hkn0706:759478:759608 [1] NCCL INFO comm 0x149134008fb0 rank 349 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
252: hkn0611:717035:717164 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [receive] via NET/IBext/0
350: hkn0706:759494:759603 [2] NCCL INFO comm 0x14e3c0008fb0 rank 350 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
351: hkn0706:759486:759602 [3] NCCL INFO comm 0x15473c008fb0 rank 351 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [receive] via NET/IBext/0
348: hkn0706:759506:759606 [0] NCCL INFO comm 0x153a68008fb0 rank 348 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
421: hkn0726:1555337:1555444 [1] NCCL INFO Connected all trees
178: hkn0525:994022:994132 [2] NCCL INFO comm 0x148230008fb0 rank 178 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
421: hkn0726:1555337:1555444 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
427: hkn0727:1353022:1353120 [3] NCCL INFO comm 0x154b30008fb0 rank 427 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
421: hkn0726:1555337:1555444 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
179: hkn0525:994006:994130 [3] NCCL INFO comm 0x149084008fb0 rank 179 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
176: hkn0525:994034:994135 [0] NCCL INFO comm 0x14877c008fb0 rank 176 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
177: hkn0525:994014:994129 [1] NCCL INFO comm 0x14c814008fb0 rank 177 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
293: hkn0626:1305645:1305779 [1] NCCL INFO Connected all trees
293: hkn0626:1305645:1305779 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
420: hkn0726:1555321:1555442 [0] NCCL INFO comm 0x14e6f0008fb0 rank 420 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
293: hkn0626:1305645:1305779 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
423: hkn0726:1555329:1555441 [3] NCCL INFO comm 0x1545fc008fb0 rank 423 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
421: hkn0726:1555337:1555444 [1] NCCL INFO comm 0x150f54008fb0 rank 421 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
101: hkn0502:236287:236411 [1] NCCL INFO Connected all trees
292: hkn0626:1305637:1305778 [0] NCCL INFO Connected all trees
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [receive] via NET/IBext/0
422: hkn0726:1555349:1555447 [2] NCCL INFO comm 0x155194008fb0 rank 422 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [receive] via NET/IBext/0
101: hkn0502:236287:236411 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1305637:1305778 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:236287:236411 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1305637:1305778 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
100: hkn0502:236295:236412 [0] NCCL INFO Connected all trees
100: hkn0502:236295:236412 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:236295:236412 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1305637:1305778 [0] NCCL INFO comm 0x1492d8008fb0 rank 292 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [send] via NET/IBext/0
293: hkn0626:1305645:1305779 [1] NCCL INFO comm 0x148384008fb0 rank 293 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
294: hkn0626:1305634:1305784 [2] NCCL INFO comm 0x148c74008fb0 rank 294 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
295: hkn0626:1305656:1305785 [3] NCCL INFO comm 0x150e64008fb0 rank 295 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [receive] via NET/IBext/0
100: hkn0502:236295:236412 [0] NCCL INFO comm 0x14b0f0008fb0 rank 100 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
417: hkn0725:3119163:3119280 [1] NCCL INFO Connected all trees
 85: hkn0426:821286:821409 [1] NCCL INFO Channel 00 : 85[4b000] -> 84[31000] via P2P/IPC/read
101: hkn0502:236287:236411 [1] NCCL INFO comm 0x14c938008fb0 rank 101 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
417: hkn0725:3119163:3119280 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
289: hkn0624:1780160:1780285 [1] NCCL INFO Connected all trees
103: hkn0502:236303:236407 [3] NCCL INFO comm 0x1545f0008fb0 rank 103 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
417: hkn0725:3119163:3119280 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
102: hkn0502:236315:236406 [2] NCCL INFO comm 0x147fe0008fb0 rank 102 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
289: hkn0624:1780160:1780285 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1212849:1212967 [1] NCCL INFO Channel 00 : 469[4b000] -> 468[31000] via P2P/IPC/read
289: hkn0624:1780160:1780285 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [receive] via NET/IBext/0
461: hkn0802:1207571:1207691 [1] NCCL INFO Connected all trees
433: hkn0730:1408955:1409068 [1] NCCL INFO Connected all trees
416: hkn0725:3119164:3119281 [0] NCCL INFO Connected all trees
433: hkn0730:1408955:1409068 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
384: hkn0716:115715:115850 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [receive] via NET/IBext/0
288: hkn0624:1780140:1780284 [0] NCCL INFO Connected all trees
433: hkn0730:1408955:1409068 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
461: hkn0802:1207571:1207691 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
416: hkn0725:3119164:3119281 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1207571:1207691 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
416: hkn0725:3119164:3119281 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1780140:1780284 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 89: hkn0427:1142369:1142461 [1] NCCL INFO Connected all trees
472: hkn0805:1119345:1119447 [0] NCCL INFO Connected all trees
288: hkn0624:1780140:1780284 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
460: hkn0802:1207543:1207697 [0] NCCL INFO Connected all trees
 89: hkn0427:1142369:1142461 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1119345:1119447 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 89: hkn0427:1142369:1142461 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1119345:1119447 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
432: hkn0730:1408963:1409072 [0] NCCL INFO Connected all trees
 85: hkn0426:821286:821409 [1] NCCL INFO Channel 01 : 85[4b000] -> 84[31000] via P2P/IPC/read
432: hkn0730:1408963:1409072 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
460: hkn0802:1207543:1207697 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1408963:1409072 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
460: hkn0802:1207543:1207697 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
469: hkn0804:1212849:1212967 [1] NCCL INFO Channel 01 : 469[4b000] -> 468[31000] via P2P/IPC/read
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 00 : 457[4b000] -> 456[31000] via P2P/IPC/read
 88: hkn0427:1142349:1142466 [0] NCCL INFO Connected all trees
288: hkn0624:1780140:1780284 [0] NCCL INFO comm 0x1538f0008fb0 rank 288 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 88: hkn0427:1142349:1142466 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
473: hkn0805:1119333:1119444 [1] NCCL INFO Connected all trees
 88: hkn0427:1142349:1142466 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
291: hkn0624:1780148:1780287 [3] NCCL INFO comm 0x148ff0008fb0 rank 291 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
445: hkn0733:1396580:1396694 [1] NCCL INFO Connected all trees
473: hkn0805:1119333:1119444 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
289: hkn0624:1780160:1780285 [1] NCCL INFO comm 0x14b1fc008fb0 rank 289 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
473: hkn0805:1119333:1119444 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3119163:3119280 [1] NCCL INFO comm 0x148424008fb0 rank 417 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
290: hkn0624:1780132:1780286 [2] NCCL INFO comm 0x14e118008fb0 rank 290 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
462: hkn0802:1207559:1207696 [2] NCCL INFO comm 0x152f94008fb0 rank 462 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
112: hkn0505:2311025:2311118 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [receive] via NET/IBext/0
 49: hkn0417:2274876:2274980 [1] NCCL INFO Connected all trees
419: hkn0725:3119172:3119282 [3] NCCL INFO comm 0x14dad0008fb0 rank 419 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
418: hkn0725:3119184:3119279 [2] NCCL INFO comm 0x150f54008fb0 rank 418 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 49: hkn0417:2274876:2274980 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
435: hkn0730:1408947:1409077 [3] NCCL INFO comm 0x1544ac008fb0 rank 435 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
445: hkn0733:1396580:1396694 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
416: hkn0725:3119164:3119281 [0] NCCL INFO comm 0x145f14008fb0 rank 416 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 49: hkn0417:2274876:2274980 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
445: hkn0733:1396580:1396694 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
432: hkn0730:1408963:1409072 [0] NCCL INFO comm 0x14fc98008fb0 rank 432 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
463: hkn0802:1207551:1207689 [3] NCCL INFO comm 0x150d40008fb0 rank 463 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
433: hkn0730:1408955:1409068 [1] NCCL INFO comm 0x148f2c008fb0 rank 433 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
460: hkn0802:1207543:1207697 [0] NCCL INFO comm 0x1457c0008fb0 rank 460 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 97: hkn0501:1335155:1335273 [1] NCCL INFO Connected all trees
461: hkn0802:1207571:1207691 [1] NCCL INFO comm 0x14add0008fb0 rank 461 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
444: hkn0733:1396588:1396702 [0] NCCL INFO Connected all trees
 88: hkn0427:1142349:1142466 [0] NCCL INFO comm 0x14728c008fb0 rank 88 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
332: hkn0636:1661513:1661645 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [send] via NET/IBext/0
 97: hkn0501:1335155:1335273 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 77: hkn0424:2955178:2955291 [1] NCCL INFO Connected all trees
 97: hkn0501:1335155:1335273 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2274888:2274985 [0] NCCL INFO Connected all trees
 89: hkn0427:1142369:1142461 [1] NCCL INFO comm 0x148ea0008fb0 rank 89 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 91: hkn0427:1142357:1142467 [3] NCCL INFO comm 0x14e9fc008fb0 rank 91 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 77: hkn0424:2955178:2955291 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 48: hkn0417:2274888:2274985 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2247291:2247389 [1] NCCL INFO Channel 01 : 457[4b000] -> 456[31000] via P2P/IPC/read
 90: hkn0427:1142341:1142458 [2] NCCL INFO comm 0x14fae8008fb0 rank 90 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 77: hkn0424:2955178:2955291 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2274888:2274985 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
434: hkn0730:1408975:1409075 [2] NCCL INFO comm 0x154eec008fb0 rank 434 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
444: hkn0733:1396588:1396702 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1396588:1396702 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1119345:1119447 [0] NCCL INFO comm 0x14f550008fb0 rank 472 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
128: hkn0509:3131628:3131753 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [receive] via NET/IBext/0
 96: hkn0501:1335139:1335266 [0] NCCL INFO Connected all trees
 96: hkn0501:1335139:1335266 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 76: hkn0424:2955170:2955294 [0] NCCL INFO Connected all trees
 96: hkn0501:1335139:1335266 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
344: hkn0705:790415:790543 [0] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [send] via NET/IBext/0
 76: hkn0424:2955170:2955294 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 76: hkn0424:2955170:2955294 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 49: hkn0417:2274876:2274980 [1] NCCL INFO comm 0x145ee4008fb0 rank 49 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
474: hkn0805:1119317:1119439 [2] NCCL INFO comm 0x152640008fb0 rank 474 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
444: hkn0733:1396588:1396702 [0] NCCL INFO comm 0x152440008fb0 rank 444 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 50: hkn0417:2274860:2274988 [2] NCCL INFO comm 0x14a9b4008fb0 rank 50 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
473: hkn0805:1119333:1119444 [1] NCCL INFO comm 0x14d700008fb0 rank 473 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 48: hkn0417:2274888:2274985 [0] NCCL INFO comm 0x14fcb4008fb0 rank 48 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 51: hkn0417:2274868:2274989 [3] NCCL INFO comm 0x14bda0008fb0 rank 51 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
475: hkn0805:1119325:1119448 [3] NCCL INFO comm 0x14a6ac008fb0 rank 475 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 96: hkn0501:1335139:1335266 [0] NCCL INFO comm 0x1494f4008fb0 rank 96 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
445: hkn0733:1396580:1396694 [1] NCCL INFO comm 0x154398008fb0 rank 445 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 98: hkn0501:1335167:1335267 [2] NCCL INFO comm 0x1487d4008fb0 rank 98 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
447: hkn0733:1396600:1396698 [3] NCCL INFO comm 0x14c7a4008fb0 rank 447 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 77: hkn0424:2955178:2955291 [1] NCCL INFO comm 0x14c8c0008fb0 rank 77 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 99: hkn0501:1335147:1335272 [3] NCCL INFO comm 0x14a0e0008fb0 rank 99 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
446: hkn0733:1396572:1396700 [2] NCCL INFO comm 0x149514008fb0 rank 446 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 97: hkn0501:1335155:1335273 [1] NCCL INFO comm 0x14ab80008fb0 rank 97 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 76: hkn0424:2955170:2955294 [0] NCCL INFO comm 0x14f220008fb0 rank 76 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 84: hkn0426:821266:821410 [0] NCCL INFO Connected all trees
 78: hkn0424:2955198:2955298 [2] NCCL INFO comm 0x14af9c008fb0 rank 78 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 79: hkn0424:2955186:2955299 [3] NCCL INFO comm 0x146678008fb0 rank 79 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 84: hkn0426:821266:821410 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
256: hkn0612:924207:924324 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [receive] via NET/IBext/0
 84: hkn0426:821266:821410 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:420450:420563 [1] NCCL INFO Connected all trees
357: hkn0708:420450:420563 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 00 : 73[4b000] -> 72[31000] via P2P/IPC/read
357: hkn0708:420450:420563 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1308923:1309018 [1] NCCL INFO Connected all trees
469: hkn0804:1212849:1212967 [1] NCCL INFO Connected all trees
189: hkn0528:1308923:1309018 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:821286:821409 [1] NCCL INFO Connected all trees
189: hkn0528:1308923:1309018 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
469: hkn0804:1212849:1212967 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:821286:821409 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1212849:1212967 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:420442:420567 [0] NCCL INFO Connected all trees
 85: hkn0426:821286:821409 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:420442:420567 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:409126:409232 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [send] via NET/IBext/0
205: hkn0532:932522:932818 [1] NCCL INFO Connected all trees
205: hkn0532:932522:932818 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:420442:420567 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1308911:1309016 [0] NCCL INFO Connected all trees
205: hkn0532:932522:932818 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1308911:1309016 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
188: hkn0528:1308911:1309016 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
468: hkn0804:1212869:1212968 [0] NCCL INFO Connected all trees
468: hkn0804:1212869:1212968 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
213: hkn0535:2406206:2406337 [1] NCCL INFO Channel 00 : 213[4b000] -> 212[31000] via P2P/IPC/read
468: hkn0804:1212869:1212968 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
217: hkn0601:124968:125085 [1] NCCL INFO Connected all trees
217: hkn0601:124968:125085 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1712163:1712288 [1] NCCL INFO Channel 01 : 73[4b000] -> 72[31000] via P2P/IPC/read
 85: hkn0426:821286:821409 [1] NCCL INFO comm 0x1531b4008fb0 rank 85 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
204: hkn0532:932494:932817 [0] NCCL INFO Connected all trees
217: hkn0601:124968:125085 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:420450:420563 [1] NCCL INFO comm 0x14ad80008fb0 rank 357 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
204: hkn0532:932494:932817 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 87: hkn0426:821258:821413 [3] NCCL INFO comm 0x14e60c008fb0 rank 87 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
204: hkn0532:932494:932817 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
358: hkn0708:420458:420568 [2] NCCL INFO comm 0x14fbc0008fb0 rank 358 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
359: hkn0708:420470:420564 [3] NCCL INFO comm 0x153384008fb0 rank 359 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 84: hkn0426:821266:821410 [0] NCCL INFO comm 0x15528c008fb0 rank 84 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
356: hkn0708:420442:420567 [0] NCCL INFO comm 0x146d48008fb0 rank 356 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 86: hkn0426:821274:821408 [2] NCCL INFO comm 0x146b1c008fb0 rank 86 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 00 : 201[4b000] -> 200[31000] via P2P/IPC/read
216: hkn0601:124960:125086 [0] NCCL INFO Connected all trees
188: hkn0528:1308911:1309016 [0] NCCL INFO comm 0x14a9e8008fb0 rank 188 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
471: hkn0804:1212857:1212971 [3] NCCL INFO comm 0x14cb0c008fb0 rank 471 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
216: hkn0601:124960:125086 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
190: hkn0528:1308903:1309021 [2] NCCL INFO comm 0x146838008fb0 rank 190 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
469: hkn0804:1212849:1212967 [1] NCCL INFO comm 0x14cea8008fb0 rank 469 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
216: hkn0601:124960:125086 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
191: hkn0528:1308895:1309019 [3] NCCL INFO comm 0x14a5c0008fb0 rank 191 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
470: hkn0804:1212841:1212966 [2] NCCL INFO comm 0x14f538008fb0 rank 470 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
468: hkn0804:1212869:1212968 [0] NCCL INFO comm 0x148bc4008fb0 rank 468 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
252: hkn0611:717035:717164 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [send] via NET/IBext/0
205: hkn0532:932522:932818 [1] NCCL INFO comm 0x146c10008fb0 rank 205 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
213: hkn0535:2406206:2406337 [1] NCCL INFO Channel 01 : 213[4b000] -> 212[31000] via P2P/IPC/read
189: hkn0528:1308923:1309018 [1] NCCL INFO comm 0x1457f8008fb0 rank 189 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
204: hkn0532:932494:932817 [0] NCCL INFO comm 0x146140008fb0 rank 204 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
206: hkn0532:932510:932820 [2] NCCL INFO comm 0x14f844008fb0 rank 206 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
207: hkn0532:932502:932816 [3] NCCL INFO comm 0x154b2c008fb0 rank 207 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
219: hkn0601:124976:125081 [3] NCCL INFO comm 0x15316c008fb0 rank 219 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
216: hkn0601:124960:125086 [0] NCCL INFO comm 0x14d200008fb0 rank 216 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
218: hkn0601:124988:125082 [2] NCCL INFO comm 0x14eed4008fb0 rank 218 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
201: hkn0531:1237902:1238024 [1] NCCL INFO Channel 01 : 201[4b000] -> 200[31000] via P2P/IPC/read
217: hkn0601:124968:125085 [1] NCCL INFO comm 0x14d324008fb0 rank 217 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
353: hkn0707:4027137:4027262 [1] NCCL INFO Connected all trees
353: hkn0707:4027137:4027262 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
353: hkn0707:4027137:4027262 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [send] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO Connected all trees
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [receive] via NET/IBext/0
352: hkn0707:4027165:4027259 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4027165:4027259 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
456: hkn0801:2247272:2247387 [0] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [send] via NET/IBext/0
368: hkn0712:302297:302400 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [receive] via NET/IBext/0
353: hkn0707:4027137:4027262 [1] NCCL INFO comm 0x1478a0008fb0 rank 353 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
412: hkn0724:1723179:1723321 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [send] via NET/IBext/0
354: hkn0707:4027145:4027255 [2] NCCL INFO comm 0x14dff4008fb0 rank 354 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
355: hkn0707:4027153:4027260 [3] NCCL INFO comm 0x14cbbc008fb0 rank 355 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
352: hkn0707:4027165:4027259 [0] NCCL INFO comm 0x15346c008fb0 rank 352 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
376: hkn0714:439237:439359 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [receive] via NET/IBext/0
212: hkn0535:2406214:2406333 [0] NCCL INFO Connected all trees
212: hkn0535:2406214:2406333 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
212: hkn0535:2406214:2406333 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
213: hkn0535:2406206:2406337 [1] NCCL INFO Connected all trees
213: hkn0535:2406206:2406337 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
213: hkn0535:2406206:2406337 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 72: hkn0423:1712171:1712286 [0] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [send] via NET/IBext/0
213: hkn0535:2406206:2406337 [1] NCCL INFO comm 0x14ce10008fb0 rank 213 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
214: hkn0535:2406234:2406334 [2] NCCL INFO comm 0x154168008fb0 rank 214 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
215: hkn0535:2406222:2406330 [3] NCCL INFO comm 0x14a7e4008fb0 rank 215 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
333: hkn0636:1661529:1661644 [1] NCCL INFO Connected all trees
212: hkn0535:2406214:2406333 [0] NCCL INFO comm 0x148660008fb0 rank 212 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
333: hkn0636:1661529:1661644 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
333: hkn0636:1661529:1661644 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:799223:799342 [1] NCCL INFO Channel 00 : 341[4b000] -> 340[31000] via P2P/IPC/read
332: hkn0636:1661513:1661645 [0] NCCL INFO Connected all trees
332: hkn0636:1661513:1661645 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
184: hkn0527:1356168:1356280 [0] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [send] via NET/IBext/0
332: hkn0636:1661513:1661645 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
344: hkn0705:790415:790543 [0] NCCL INFO Connected all trees
344: hkn0705:790415:790543 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
344: hkn0705:790415:790543 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1661513:1661645 [0] NCCL INFO comm 0x14e19c008fb0 rank 332 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
333: hkn0636:1661529:1661644 [1] NCCL INFO comm 0x14a8d4008fb0 rank 333 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
345: hkn0705:790443:790544 [1] NCCL INFO Connected all trees
334: hkn0636:1661541:1661648 [2] NCCL INFO comm 0x1512a4008fb0 rank 334 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
341: hkn0704:799223:799342 [1] NCCL INFO Channel 01 : 341[4b000] -> 340[31000] via P2P/IPC/read
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [send] via NET/IBext/0
200: hkn0531:1237922:1238019 [0] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [send] via NET/IBext/0
345: hkn0705:790443:790544 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
335: hkn0636:1661521:1661639 [3] NCCL INFO comm 0x146a20008fb0 rank 335 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
345: hkn0705:790443:790544 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1218902:1218998 [0] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [send] via NET/IBext/0
156: hkn0516:2923204:2923321 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [send] via NET/IBext/0
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [receive] via NET/IBext/0
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 00 : 329[4b000] -> 328[31000] via P2P/IPC/read
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [receive] via NET/IBext/0
 68: hkn0422:4160376:4160473 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [send] via NET/IBext/0
452: hkn0736:1515544:1515654 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [send] via NET/IBext/0
344: hkn0705:790415:790543 [0] NCCL INFO comm 0x14de38008fb0 rank 344 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
347: hkn0705:790423:790536 [3] NCCL INFO comm 0x14911c008fb0 rank 347 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
345: hkn0705:790443:790544 [1] NCCL INFO comm 0x147650008fb0 rank 345 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
346: hkn0705:790431:790545 [2] NCCL INFO comm 0x14e4f8008fb0 rank 346 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
329: hkn0635:1232786:1232910 [1] NCCL INFO Channel 01 : 329[4b000] -> 328[31000] via P2P/IPC/read
340: hkn0704:799215:799344 [0] NCCL INFO Connected all trees
340: hkn0704:799215:799344 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:799215:799344 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:799223:799342 [1] NCCL INFO Connected all trees
341: hkn0704:799223:799342 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
341: hkn0704:799223:799342 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1265359:1265466 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [send] via NET/IBext/0
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [send] via NET/IBext/0
384: hkn0716:115715:115850 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [receive] via NET/IBext/0
192: hkn0529:1548046:1548160 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [receive] via NET/IBext/0
453: hkn0736:1515557:1515653 [1] NCCL INFO Channel 00 : 453[4b000] -> 452[31000] via P2P/IPC/read
340: hkn0704:799215:799344 [0] NCCL INFO comm 0x154dc0008fb0 rank 340 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
341: hkn0704:799223:799342 [1] NCCL INFO comm 0x15209c008fb0 rank 341 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
343: hkn0704:799231:799343 [3] NCCL INFO comm 0x145c44008fb0 rank 343 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
342: hkn0704:799243:799339 [2] NCCL INFO comm 0x145e70008fb0 rank 342 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
112: hkn0505:2311025:2311118 [0] NCCL INFO Connected all trees
457: hkn0801:2247291:2247389 [1] NCCL INFO Connected all trees
457: hkn0801:2247291:2247389 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2311025:2311118 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2247291:2247389 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1515557:1515653 [1] NCCL INFO Channel 01 : 453[4b000] -> 452[31000] via P2P/IPC/read
112: hkn0505:2311025:2311118 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
413: hkn0724:1723172:1723322 [1] NCCL INFO Connected all trees
113: hkn0505:2311005:2311114 [1] NCCL INFO Connected all trees
456: hkn0801:2247272:2247387 [0] NCCL INFO Connected all trees
413: hkn0724:1723172:1723322 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1723172:1723322 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
456: hkn0801:2247272:2247387 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
456: hkn0801:2247272:2247387 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
113: hkn0505:2311005:2311114 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2311005:2311114 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
381: hkn0715:409138:409236 [1] NCCL INFO Connected all trees
412: hkn0724:1723179:1723321 [0] NCCL INFO Connected all trees
381: hkn0715:409138:409236 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
412: hkn0724:1723179:1723321 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
381: hkn0715:409138:409236 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
412: hkn0724:1723179:1723321 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 72: hkn0423:1712171:1712286 [0] NCCL INFO Connected all trees
112: hkn0505:2311025:2311118 [0] NCCL INFO comm 0x145c20008fb0 rank 112 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
380: hkn0715:409126:409232 [0] NCCL INFO Connected all trees
 72: hkn0423:1712171:1712286 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
456: hkn0801:2247272:2247387 [0] NCCL INFO comm 0x149d5c008fb0 rank 456 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 72: hkn0423:1712171:1712286 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:409126:409232 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:409126:409232 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
459: hkn0801:2247280:2247386 [3] NCCL INFO comm 0x147578008fb0 rank 459 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
457: hkn0801:2247291:2247389 [1] NCCL INFO comm 0x14a210008fb0 rank 457 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
113: hkn0505:2311005:2311114 [1] NCCL INFO comm 0x15464c008fb0 rank 113 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
458: hkn0801:2247264:2247382 [2] NCCL INFO comm 0x14e680008fb0 rank 458 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 69: hkn0422:4160356:4160471 [1] NCCL INFO Channel 00 : 69[4b000] -> 68[31000] via P2P/IPC/read
114: hkn0505:2311013:2311117 [2] NCCL INFO comm 0x1528c8008fb0 rank 114 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
413: hkn0724:1723172:1723322 [1] NCCL INFO comm 0x14d260008fb0 rank 413 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
414: hkn0724:1723187:1723325 [2] NCCL INFO comm 0x153da8008fb0 rank 414 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 73: hkn0423:1712163:1712288 [1] NCCL INFO Connected all trees
415: hkn0724:1723198:1723323 [3] NCCL INFO comm 0x151f48008fb0 rank 415 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
115: hkn0505:2310997:2311121 [3] NCCL INFO comm 0x152664008fb0 rank 115 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
412: hkn0724:1723179:1723321 [0] NCCL INFO comm 0x14b584008fb0 rank 412 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 73: hkn0423:1712163:1712288 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1712163:1712288 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
383: hkn0715:409110:409235 [3] NCCL INFO comm 0x154058008fb0 rank 383 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
181: hkn0526:1435629:1435751 [1] NCCL INFO Channel 00 : 181[4b000] -> 180[31000] via P2P/IPC/read
381: hkn0715:409138:409236 [1] NCCL INFO comm 0x14e8c0008fb0 rank 381 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
382: hkn0715:409118:409228 [2] NCCL INFO comm 0x1494dc008fb0 rank 382 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
380: hkn0715:409126:409232 [0] NCCL INFO comm 0x14a15c008fb0 rank 380 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
328: hkn0635:1232794:1232913 [0] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [send] via NET/IBext/0
185: hkn0527:1356176:1356285 [1] NCCL INFO Connected all trees
 72: hkn0423:1712171:1712286 [0] NCCL INFO comm 0x15408c008fb0 rank 72 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
185: hkn0527:1356176:1356285 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1765871:1765970 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [send] via NET/IBext/0
185: hkn0527:1356176:1356285 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 74: hkn0423:1712179:1712289 [2] NCCL INFO comm 0x14b574008fb0 rank 74 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 73: hkn0423:1712163:1712288 [1] NCCL INFO comm 0x15479c008fb0 rank 73 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 75: hkn0423:1712190:1712287 [3] NCCL INFO comm 0x14cb44008fb0 rank 75 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
181: hkn0526:1435629:1435751 [1] NCCL INFO Channel 01 : 181[4b000] -> 180[31000] via P2P/IPC/read
 69: hkn0422:4160356:4160471 [1] NCCL INFO Channel 01 : 69[4b000] -> 68[31000] via P2P/IPC/read
368: hkn0712:302297:302400 [0] NCCL INFO Connected all trees
368: hkn0712:302297:302400 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:302297:302400 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1356168:1356280 [0] NCCL INFO Connected all trees
157: hkn0516:2923212:2923315 [1] NCCL INFO Connected all trees
157: hkn0516:2923212:2923315 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
437: hkn0731:1393941:1394086 [1] NCCL INFO Channel 00 : 437[4b000] -> 436[31000] via P2P/IPC/read
184: hkn0527:1356168:1356280 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
157: hkn0516:2923212:2923315 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1356168:1356280 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
197: hkn0530:1265371:1265467 [1] NCCL INFO Channel 00 : 197[4b000] -> 196[31000] via P2P/IPC/read
201: hkn0531:1237902:1238024 [1] NCCL INFO Connected all trees
156: hkn0516:2923204:2923321 [0] NCCL INFO Connected all trees
201: hkn0531:1237902:1238024 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2923204:2923321 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
201: hkn0531:1237902:1238024 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
156: hkn0516:2923204:2923321 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
185: hkn0527:1356176:1356285 [1] NCCL INFO comm 0x1522fc008fb0 rank 185 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
187: hkn0527:1356160:1356277 [3] NCCL INFO comm 0x147738008fb0 rank 187 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
184: hkn0527:1356168:1356280 [0] NCCL INFO comm 0x14e6ec008fb0 rank 184 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
200: hkn0531:1237922:1238019 [0] NCCL INFO Connected all trees
186: hkn0527:1356188:1356283 [2] NCCL INFO comm 0x151a94008fb0 rank 186 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
200: hkn0531:1237922:1238019 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
437: hkn0731:1393941:1394086 [1] NCCL INFO Channel 01 : 437[4b000] -> 436[31000] via P2P/IPC/read
200: hkn0531:1237922:1238019 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:717035:717164 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [send] via NET/IBext/0
157: hkn0516:2923212:2923315 [1] NCCL INFO comm 0x154c50008fb0 rank 157 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
180: hkn0526:1435645:1435749 [0] NCCL INFO Connected all trees
441: hkn0732:1218890:1218999 [1] NCCL INFO Connected all trees
441: hkn0732:1218890:1218999 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
158: hkn0516:2923196:2923320 [2] NCCL INFO comm 0x154bfc008fb0 rank 158 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
180: hkn0526:1435645:1435749 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
159: hkn0516:2923224:2923313 [3] NCCL INFO comm 0x14be34008fb0 rank 159 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
180: hkn0526:1435645:1435749 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
156: hkn0516:2923204:2923321 [0] NCCL INFO comm 0x149e98008fb0 rank 156 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
441: hkn0732:1218890:1218999 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
203: hkn0531:1237894:1238018 [3] NCCL INFO comm 0x14c8f4008fb0 rank 203 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 69: hkn0422:4160356:4160471 [1] NCCL INFO Connected all trees
201: hkn0531:1237902:1238024 [1] NCCL INFO comm 0x152618008fb0 rank 201 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 69: hkn0422:4160356:4160471 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 69: hkn0422:4160356:4160471 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1435629:1435751 [1] NCCL INFO Connected all trees
200: hkn0531:1237922:1238019 [0] NCCL INFO comm 0x15154c008fb0 rank 200 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
440: hkn0732:1218902:1218998 [0] NCCL INFO Connected all trees
181: hkn0526:1435629:1435751 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [send] via NET/IBext/0
181: hkn0526:1435629:1435751 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
197: hkn0530:1265371:1265467 [1] NCCL INFO Channel 01 : 197[4b000] -> 196[31000] via P2P/IPC/read
202: hkn0531:1237910:1238025 [2] NCCL INFO comm 0x14bce8008fb0 rank 202 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 68: hkn0422:4160376:4160473 [0] NCCL INFO Connected all trees
440: hkn0732:1218902:1218998 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 68: hkn0422:4160376:4160473 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1218902:1218998 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4160376:4160473 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1528076:1528180 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [send] via NET/IBext/0
180: hkn0526:1435645:1435749 [0] NCCL INFO comm 0x14f56c008fb0 rank 180 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
396: hkn0719:1312979:1313087 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [send] via NET/IBext/0
181: hkn0526:1435629:1435751 [1] NCCL INFO comm 0x14b174008fb0 rank 181 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 68: hkn0422:4160376:4160473 [0] NCCL INFO comm 0x14ba58008fb0 rank 68 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
182: hkn0526:1435637:1435754 [2] NCCL INFO comm 0x150f78008fb0 rank 182 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
441: hkn0732:1218890:1218999 [1] NCCL INFO comm 0x152b30008fb0 rank 441 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
183: hkn0526:1435657:1435750 [3] NCCL INFO comm 0x152f3c008fb0 rank 183 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 69: hkn0422:4160356:4160471 [1] NCCL INFO comm 0x14d87c008fb0 rank 69 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
408: hkn0723:215341:215495 [0] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [send] via NET/IBext/0
 71: hkn0422:4160348:4160470 [3] NCCL INFO comm 0x145b10008fb0 rank 71 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 70: hkn0422:4160364:4160469 [2] NCCL INFO comm 0x149cb8008fb0 rank 70 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
369: hkn0712:302289:302403 [1] NCCL INFO Connected all trees
440: hkn0732:1218902:1218998 [0] NCCL INFO comm 0x14a2a8008fb0 rank 440 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
369: hkn0712:302289:302403 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:302289:302403 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
443: hkn0732:1218882:1219000 [3] NCCL INFO comm 0x14ae30008fb0 rank 443 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
442: hkn0732:1218881:1219002 [2] NCCL INFO comm 0x1516bc008fb0 rank 442 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
436: hkn0731:1393962:1394080 [0] NCCL INFO Connected all trees
436: hkn0731:1393962:1394080 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1393962:1394080 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 64: hkn0421:2189212:2189407 [0] NCCL INFO Connected all trees
 64: hkn0421:2189212:2189407 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 64: hkn0421:2189212:2189407 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:302297:302400 [0] NCCL INFO comm 0x14cef4008fb0 rank 368 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
369: hkn0712:302289:302403 [1] NCCL INFO comm 0x146ef8008fb0 rank 369 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
437: hkn0731:1393941:1394086 [1] NCCL INFO Connected all trees
370: hkn0712:302281:302408 [2] NCCL INFO comm 0x14ab08008fb0 rank 370 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
437: hkn0731:1393941:1394086 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
437: hkn0731:1393941:1394086 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
371: hkn0712:302309:302405 [3] NCCL INFO comm 0x154848008fb0 rank 371 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 65: hkn0421:2189204:2189405 [1] NCCL INFO Connected all trees
 65: hkn0421:2189204:2189405 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [receive] via NET/IBext/0
240: hkn0607:911595:911709 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [receive] via NET/IBext/0
 65: hkn0421:2189204:2189405 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1265359:1265466 [0] NCCL INFO Connected all trees
196: hkn0530:1265359:1265466 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
196: hkn0530:1265359:1265466 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
436: hkn0731:1393962:1394080 [0] NCCL INFO comm 0x153418008fb0 rank 436 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
437: hkn0731:1393941:1394086 [1] NCCL INFO comm 0x1482d8008fb0 rank 437 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 66: hkn0421:2189220:2189406 [2] NCCL INFO comm 0x1471f4008fb0 rank 66 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
439: hkn0731:1393950:1394081 [3] NCCL INFO comm 0x149bec008fb0 rank 439 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
438: hkn0731:1393942:1394083 [2] NCCL INFO comm 0x14cdc8008fb0 rank 438 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
508: hkn0816:382834:382958 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [send] via NET/IBext/0
197: hkn0530:1265371:1265467 [1] NCCL INFO Connected all trees
 67: hkn0421:2189234:2189409 [3] NCCL INFO comm 0x153714008fb0 rank 67 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 64: hkn0421:2189212:2189407 [0] NCCL INFO comm 0x151f28008fb0 rank 64 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 65: hkn0421:2189204:2189405 [1] NCCL INFO comm 0x14702c008fb0 rank 65 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
197: hkn0530:1265371:1265467 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
197: hkn0530:1265371:1265467 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
325: hkn0634:1528068:1528186 [1] NCCL INFO Channel 00 : 325[4b000] -> 324[31000] via P2P/IPC/read
193: hkn0529:1548066:1548163 [1] NCCL INFO Connected all trees
193: hkn0529:1548066:1548163 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
193: hkn0529:1548066:1548163 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1265359:1265466 [0] NCCL INFO comm 0x1517f8008fb0 rank 196 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
317: hkn0632:1765843:1765966 [1] NCCL INFO Connected all trees
140: hkn0512:3051343:3051451 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [send] via NET/IBext/0
197: hkn0530:1265371:1265467 [1] NCCL INFO comm 0x1539ac008fb0 rank 197 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
317: hkn0632:1765843:1765966 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1548046:1548160 [0] NCCL INFO Connected all trees
317: hkn0632:1765843:1765966 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
199: hkn0530:1265351:1265471 [3] NCCL INFO comm 0x14bddc008fb0 rank 199 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
192: hkn0529:1548046:1548160 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1548046:1548160 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
198: hkn0530:1265343:1265469 [2] NCCL INFO comm 0x15533c008fb0 rank 198 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
329: hkn0635:1232786:1232910 [1] NCCL INFO Connected all trees
376: hkn0714:439237:439359 [0] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [send] via NET/IBext/0
316: hkn0632:1765871:1765970 [0] NCCL INFO Connected all trees
329: hkn0635:1232786:1232910 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
329: hkn0635:1232786:1232910 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
152: hkn0515:2904005:2904143 [0] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [send] via NET/IBext/0
388: hkn0717:1467:1586 [0] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [receive] via NET/IBext/0
316: hkn0632:1765871:1765970 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1765871:1765970 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
193: hkn0529:1548066:1548163 [1] NCCL INFO comm 0x14c1f4008fb0 rank 193 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
328: hkn0635:1232794:1232913 [0] NCCL INFO Connected all trees
194: hkn0529:1548054:1548165 [2] NCCL INFO comm 0x14c01c008fb0 rank 194 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
328: hkn0635:1232794:1232913 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1548046:1548160 [0] NCCL INFO comm 0x14bca8008fb0 rank 192 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
328: hkn0635:1232794:1232913 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
195: hkn0529:1548038:1548157 [3] NCCL INFO comm 0x14fcec008fb0 rank 195 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
325: hkn0634:1528068:1528186 [1] NCCL INFO Channel 01 : 325[4b000] -> 324[31000] via P2P/IPC/read
316: hkn0632:1765871:1765970 [0] NCCL INFO comm 0x14ba48008fb0 rank 316 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
317: hkn0632:1765843:1765966 [1] NCCL INFO comm 0x153e1c008fb0 rank 317 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
448: hkn0734:1163761:1163871 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [receive] via NET/IBext/0
329: hkn0635:1232786:1232910 [1] NCCL INFO comm 0x147f4c008fb0 rank 329 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
318: hkn0632:1765851:1765965 [2] NCCL INFO comm 0x153f40008fb0 rank 318 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
328: hkn0635:1232794:1232913 [0] NCCL INFO comm 0x14adbc008fb0 rank 328 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
331: hkn0635:1232814:1232915 [3] NCCL INFO comm 0x14c1b0008fb0 rank 331 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
224: hkn0603:1420450:1420575 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [receive] via NET/IBext/0
319: hkn0632:1765859:1765969 [3] NCCL INFO comm 0x146bec008fb0 rank 319 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
330: hkn0635:1232802:1232909 [2] NCCL INFO comm 0x14a890008fb0 rank 330 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [receive] via NET/IBext/0
396: hkn0719:1312979:1313087 [0] NCCL INFO Connected all trees
396: hkn0719:1312979:1313087 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1528076:1528180 [0] NCCL INFO Connected all trees
396: hkn0719:1312979:1313087 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1528076:1528180 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1528076:1528180 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
397: hkn0719:1312963:1313082 [1] NCCL INFO Connected all trees
325: hkn0634:1528068:1528186 [1] NCCL INFO Connected all trees
397: hkn0719:1312963:1313082 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
397: hkn0719:1312963:1313082 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
325: hkn0634:1528068:1528186 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1528068:1528186 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 00 : 393[4b000] -> 392[31000] via P2P/IPC/read
324: hkn0634:1528076:1528180 [0] NCCL INFO comm 0x14e3bc008fb0 rank 324 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
398: hkn0719:1312991:1313080 [2] NCCL INFO comm 0x14f600008fb0 rank 398 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
409: hkn0723:215333:215489 [1] NCCL INFO Connected all trees
325: hkn0634:1528068:1528186 [1] NCCL INFO comm 0x15055c008fb0 rank 325 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
399: hkn0719:1312971:1313088 [3] NCCL INFO comm 0x155090008fb0 rank 399 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
409: hkn0723:215333:215489 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
397: hkn0719:1312963:1313082 [1] NCCL INFO comm 0x153f94008fb0 rank 397 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
409: hkn0723:215333:215489 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2306514:2306619 [1] NCCL INFO Channel 00 : 405[4b000] -> 404[31000] via P2P/IPC/read
326: hkn0634:1528060:1528187 [2] NCCL INFO comm 0x146590008fb0 rank 326 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
396: hkn0719:1312979:1313087 [0] NCCL INFO comm 0x14c3d4008fb0 rank 396 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
327: hkn0634:1528094:1528189 [3] NCCL INFO comm 0x150060008fb0 rank 327 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
252: hkn0611:717035:717164 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [send] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO Connected all trees
393: hkn0718:3924262:3924378 [1] NCCL INFO Channel 01 : 393[4b000] -> 392[31000] via P2P/IPC/read
408: hkn0723:215341:215495 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:215341:215495 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2306514:2306619 [1] NCCL INFO Channel 01 : 405[4b000] -> 404[31000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [send] via NET/IBext/0
408: hkn0723:215341:215495 [0] NCCL INFO comm 0x153e30008fb0 rank 408 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
410: hkn0723:215325:215496 [2] NCCL INFO comm 0x14577c008fb0 rank 410 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
409: hkn0723:215333:215489 [1] NCCL INFO comm 0x1548bc008fb0 rank 409 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
411: hkn0723:215353:215498 [3] NCCL INFO comm 0x14d8f4008fb0 rank 411 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
141: hkn0512:3051327:3051449 [1] NCCL INFO Connected all trees
320: hkn0633:1533538:1533659 [0] NCCL INFO Connected all trees
141: hkn0512:3051327:3051449 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
320: hkn0633:1533538:1533659 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
141: hkn0512:3051327:3051449 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
320: hkn0633:1533538:1533659 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1880015:1880110 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [send] via NET/IBext/0
373: hkn0713:477452:477574 [1] NCCL INFO Channel 00 : 373[4b000] -> 372[31000] via P2P/IPC/read
153: hkn0515:2903997:2904149 [1] NCCL INFO Connected all trees
140: hkn0512:3051343:3051451 [0] NCCL INFO Connected all trees
153: hkn0515:2903997:2904149 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
153: hkn0515:2903997:2904149 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
140: hkn0512:3051343:3051451 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
140: hkn0512:3051343:3051451 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
152: hkn0515:2904005:2904143 [0] NCCL INFO Connected all trees
152: hkn0515:2904005:2904143 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
152: hkn0515:2904005:2904143 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 00 : 137[4b000] -> 136[31000] via P2P/IPC/read
453: hkn0736:1515557:1515653 [1] NCCL INFO Connected all trees
141: hkn0512:3051327:3051449 [1] NCCL INFO comm 0x149edc008fb0 rank 141 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
373: hkn0713:477452:477574 [1] NCCL INFO Channel 01 : 373[4b000] -> 372[31000] via P2P/IPC/read
149: hkn0514:2957959:2958071 [1] NCCL INFO Channel 00 : 149[4b000] -> 148[31000] via P2P/IPC/read
453: hkn0736:1515557:1515653 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2306526:2306622 [0] NCCL INFO Connected all trees
453: hkn0736:1515557:1515653 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
377: hkn0714:439253:439365 [1] NCCL INFO Connected all trees
140: hkn0512:3051343:3051451 [0] NCCL INFO comm 0x148060008fb0 rank 140 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
404: hkn0721:2306526:2306622 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2306526:2306622 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
377: hkn0714:439253:439365 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
142: hkn0512:3051335:3051453 [2] NCCL INFO comm 0x14eb74008fb0 rank 142 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
377: hkn0714:439253:439365 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
143: hkn0512:3051355:3051445 [3] NCCL INFO comm 0x14c700008fb0 rank 143 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
153: hkn0515:2903997:2904149 [1] NCCL INFO comm 0x14f1cc008fb0 rank 153 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
452: hkn0736:1515544:1515654 [0] NCCL INFO Connected all trees
152: hkn0515:2904005:2904143 [0] NCCL INFO comm 0x152d40008fb0 rank 152 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
452: hkn0736:1515544:1515654 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
154: hkn0515:2904025:2904145 [2] NCCL INFO comm 0x14d734008fb0 rank 154 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
452: hkn0736:1515544:1515654 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
155: hkn0515:2904013:2904151 [3] NCCL INFO comm 0x147dc8008fb0 rank 155 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
229: hkn0604:696459:696573 [1] NCCL INFO Connected all trees
229: hkn0604:696459:696573 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
405: hkn0721:2306514:2306619 [1] NCCL INFO Connected all trees
229: hkn0604:696459:696573 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2306514:2306619 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
405: hkn0721:2306514:2306619 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:439237:439359 [0] NCCL INFO Connected all trees
137: hkn0511:3073646:3073768 [1] NCCL INFO Channel 01 : 137[4b000] -> 136[31000] via P2P/IPC/read
248: hkn0609:718056:718153 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [receive] via NET/IBext/0
376: hkn0714:439237:439359 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
376: hkn0714:439237:439359 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
149: hkn0514:2957959:2958071 [1] NCCL INFO Channel 01 : 149[4b000] -> 148[31000] via P2P/IPC/read
228: hkn0604:696478:696578 [0] NCCL INFO Connected all trees
496: hkn0812:701027:701151 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [receive] via NET/IBext/0
228: hkn0604:696478:696578 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:696478:696578 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1515557:1515653 [1] NCCL INFO comm 0x152e3c008fb0 rank 453 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
454: hkn0736:1515545:1515656 [2] NCCL INFO comm 0x148730008fb0 rank 454 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
404: hkn0721:2306526:2306622 [0] NCCL INFO comm 0x147800008fb0 rank 404 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
455: hkn0736:1515543:1515649 [3] NCCL INFO comm 0x148f9c008fb0 rank 455 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
452: hkn0736:1515544:1515654 [0] NCCL INFO comm 0x154f64008fb0 rank 452 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
407: hkn0721:2306506:2306615 [3] NCCL INFO comm 0x1459dc008fb0 rank 407 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
405: hkn0721:2306514:2306619 [1] NCCL INFO comm 0x14549c008fb0 rank 405 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
406: hkn0721:2306498:2306623 [2] NCCL INFO comm 0x1548e0008fb0 rank 406 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
229: hkn0604:696459:696573 [1] NCCL INFO comm 0x152f3c008fb0 rank 229 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
230: hkn0604:696451:696579 [2] NCCL INFO comm 0x145f68008fb0 rank 230 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
377: hkn0714:439253:439365 [1] NCCL INFO comm 0x14c69c008fb0 rank 377 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
228: hkn0604:696478:696578 [0] NCCL INFO comm 0x147e3c008fb0 rank 228 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
378: hkn0714:439245:439363 [2] NCCL INFO comm 0x14ec44008fb0 rank 378 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
231: hkn0604:696467:696570 [3] NCCL INFO comm 0x14e2d0008fb0 rank 231 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
376: hkn0714:439237:439359 [0] NCCL INFO comm 0x147434008fb0 rank 376 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
379: hkn0714:439265:439360 [3] NCCL INFO comm 0x154ee8008fb0 rank 379 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
372: hkn0713:477480:477575 [0] NCCL INFO Connected all trees
448: hkn0734:1163761:1163871 [0] NCCL INFO Connected all trees
372: hkn0713:477480:477575 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:477480:477575 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
448: hkn0734:1163761:1163871 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1163761:1163871 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3924246:3924376 [0] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [send] via NET/IBext/0
268: hkn0616:412169:412281 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [send] via NET/IBext/0
224: hkn0603:1420450:1420575 [0] NCCL INFO Connected all trees
373: hkn0713:477452:477574 [1] NCCL INFO Connected all trees
373: hkn0713:477452:477574 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1420450:1420575 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1420450:1420575 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:477452:477574 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
449: hkn0734:1163753:1163873 [1] NCCL INFO Connected all trees
449: hkn0734:1163753:1163873 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2957971:2958065 [0] NCCL INFO Connected all trees
148: hkn0514:2957971:2958065 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2957971:2958065 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
449: hkn0734:1163753:1163873 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
321: hkn0633:1533546:1533662 [1] NCCL INFO Connected all trees
321: hkn0633:1533546:1533662 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
321: hkn0633:1533546:1533662 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
225: hkn0603:1420458:1420572 [1] NCCL INFO Connected all trees
373: hkn0713:477452:477574 [1] NCCL INFO comm 0x147ed0008fb0 rank 373 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
225: hkn0603:1420458:1420572 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
374: hkn0713:477468:477571 [2] NCCL INFO comm 0x1477d4008fb0 rank 374 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
480: hkn0807:1026285:1026406 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [receive] via NET/IBext/0
225: hkn0603:1420458:1420572 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
149: hkn0514:2957959:2958071 [1] NCCL INFO Connected all trees
449: hkn0734:1163753:1163873 [1] NCCL INFO comm 0x1520f8008fb0 rank 449 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
149: hkn0514:2957959:2958071 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [send] via NET/IBext/0
372: hkn0713:477480:477575 [0] NCCL INFO comm 0x146a28008fb0 rank 372 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
149: hkn0514:2957959:2958071 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:911595:911709 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [receive] via NET/IBext/0
375: hkn0713:477460:477578 [3] NCCL INFO comm 0x153bf0008fb0 rank 375 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
322: hkn0633:1533554:1533664 [2] NCCL INFO comm 0x14f7f4008fb0 rank 322 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
448: hkn0734:1163761:1163871 [0] NCCL INFO comm 0x15484c008fb0 rank 448 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
323: hkn0633:1533566:1533658 [3] NCCL INFO comm 0x153e3c008fb0 rank 323 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
320: hkn0633:1533538:1533659 [0] NCCL INFO comm 0x14ea28008fb0 rank 320 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
450: hkn0734:1163781:1163870 [2] NCCL INFO comm 0x14fc68008fb0 rank 450 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
321: hkn0633:1533546:1533662 [1] NCCL INFO comm 0x14d528008fb0 rank 321 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
451: hkn0734:1163769:1163876 [3] NCCL INFO comm 0x1490a8008fb0 rank 451 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
224: hkn0603:1420450:1420575 [0] NCCL INFO comm 0x14850c008fb0 rank 224 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
227: hkn0603:1420478:1420573 [3] NCCL INFO comm 0x1511c8008fb0 rank 227 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
151: hkn0514:2957951:2958068 [3] NCCL INFO comm 0x14a770008fb0 rank 151 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
225: hkn0603:1420458:1420572 [1] NCCL INFO comm 0x147444008fb0 rank 225 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
226: hkn0603:1420466:1420571 [2] NCCL INFO comm 0x149e80008fb0 rank 226 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
149: hkn0514:2957959:2958071 [1] NCCL INFO comm 0x14cb98008fb0 rank 149 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
148: hkn0514:2957971:2958065 [0] NCCL INFO comm 0x153c04008fb0 rank 148 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
150: hkn0514:2957943:2958073 [2] NCCL INFO comm 0x152a80008fb0 rank 150 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
136: hkn0511:3073654:3073767 [0] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [send] via NET/IBext/0
388: hkn0717:1467:1586 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [send] via NET/IBext/0
309: hkn0630:1605694:1605798 [1] NCCL INFO Channel 00 : 309[4b000] -> 308[31000] via P2P/IPC/read
313: hkn0631:1029024:1029139 [1] NCCL INFO Connected all trees
313: hkn0631:1029024:1029139 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
313: hkn0631:1029024:1029139 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
285: hkn0623:1880003:1880109 [1] NCCL INFO Connected all trees
285: hkn0623:1880003:1880109 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
312: hkn0631:1029044:1029136 [0] NCCL INFO Connected all trees
285: hkn0623:1880003:1880109 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1029044:1029136 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1605694:1605798 [1] NCCL INFO Channel 01 : 309[4b000] -> 308[31000] via P2P/IPC/read
312: hkn0631:1029044:1029136 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1880015:1880110 [0] NCCL INFO Connected all trees
284: hkn0623:1880015:1880110 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1880015:1880110 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
315: hkn0631:1029032:1029141 [3] NCCL INFO comm 0x154b44008fb0 rank 315 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
312: hkn0631:1029044:1029136 [0] NCCL INFO comm 0x1475e4008fb0 rank 312 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
313: hkn0631:1029024:1029139 [1] NCCL INFO comm 0x148164008fb0 rank 313 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
314: hkn0631:1029016:1029137 [2] NCCL INFO comm 0x14a3e0008fb0 rank 314 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
286: hkn0623:1879995:1880114 [2] NCCL INFO comm 0x154334008fb0 rank 286 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
287: hkn0623:1879987:1880116 [3] NCCL INFO comm 0x150f04008fb0 rank 287 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
285: hkn0623:1880003:1880109 [1] NCCL INFO comm 0x14966c008fb0 rank 285 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
284: hkn0623:1880015:1880110 [0] NCCL INFO comm 0x14d628008fb0 rank 284 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
253: hkn0611:717051:717160 [1] NCCL INFO Connected all trees
253: hkn0611:717051:717160 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
253: hkn0611:717051:717160 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:717035:717164 [0] NCCL INFO Connected all trees
252: hkn0611:717035:717164 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:717035:717164 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2769270:2769395 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [send] via NET/IBext/0
309: hkn0630:1605694:1605798 [1] NCCL INFO Connected all trees
309: hkn0630:1605694:1605798 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1605694:1605798 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
255: hkn0611:717043:717161 [3] NCCL INFO comm 0x14a76c008fb0 rank 255 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
252: hkn0611:717035:717164 [0] NCCL INFO comm 0x14f1b4008fb0 rank 252 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
253: hkn0611:717051:717160 [1] NCCL INFO comm 0x152ba4008fb0 rank 253 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
308: hkn0630:1605678:1605803 [0] NCCL INFO Connected all trees
254: hkn0611:717063:717166 [2] NCCL INFO comm 0x14a5c4008fb0 rank 254 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
308: hkn0630:1605678:1605803 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
308: hkn0630:1605678:1605803 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3924262:3924378 [1] NCCL INFO Connected all trees
393: hkn0718:3924262:3924378 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3924262:3924378 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
308: hkn0630:1605678:1605803 [0] NCCL INFO comm 0x147608008fb0 rank 308 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
389: hkn0717:1475:1580 [1] NCCL INFO Channel 00 : 389[4b000] -> 388[31000] via P2P/IPC/read
309: hkn0630:1605694:1605798 [1] NCCL INFO comm 0x14daec008fb0 rank 309 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
392: hkn0718:3924246:3924376 [0] NCCL INFO Connected all trees
310: hkn0630:1605686:1605806 [2] NCCL INFO comm 0x151dc4008fb0 rank 310 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
311: hkn0630:1605706:1605807 [3] NCCL INFO comm 0x14b9c4008fb0 rank 311 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
392: hkn0718:3924246:3924376 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3924246:3924376 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3924246:3924376 [0] NCCL INFO comm 0x1510c4008fb0 rank 392 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
393: hkn0718:3924262:3924378 [1] NCCL INFO comm 0x14b480008fb0 rank 393 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
394: hkn0718:3924274:3924372 [2] NCCL INFO comm 0x1508ec008fb0 rank 394 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
395: hkn0718:3924254:3924371 [3] NCCL INFO comm 0x14c840008fb0 rank 395 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
389: hkn0717:1475:1580 [1] NCCL INFO Channel 01 : 389[4b000] -> 388[31000] via P2P/IPC/read
485: hkn0808:977901:978022 [1] NCCL INFO Connected all trees
485: hkn0808:977901:978022 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
485: hkn0808:977901:978022 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:977921:978021 [0] NCCL INFO Connected all trees
484: hkn0808:977921:978021 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:977921:978021 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
487: hkn0808:977909:978016 [3] NCCL INFO comm 0x147a28008fb0 rank 487 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
133: hkn0510:2769286:2769390 [1] NCCL INFO Channel 00 : 133[4b000] -> 132[31000] via P2P/IPC/read
485: hkn0808:977901:978022 [1] NCCL INFO comm 0x1518a8008fb0 rank 485 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
484: hkn0808:977921:978021 [0] NCCL INFO comm 0x14882c008fb0 rank 484 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
486: hkn0808:977893:978014 [2] NCCL INFO comm 0x1539c8008fb0 rank 486 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
137: hkn0511:3073646:3073768 [1] NCCL INFO Connected all trees
137: hkn0511:3073646:3073768 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
268: hkn0616:412169:412281 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [send] via NET/IBext/0
137: hkn0511:3073646:3073768 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2027764:2027860 [0] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [send] via NET/IBext/0
136: hkn0511:3073654:3073767 [0] NCCL INFO Connected all trees
136: hkn0511:3073654:3073767 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3073654:3073767 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:718056:718153 [0] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [send] via NET/IBext/0
481: hkn0807:1026277:1026401 [1] NCCL INFO Connected all trees
389: hkn0717:1475:1580 [1] NCCL INFO Connected all trees
481: hkn0807:1026277:1026401 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
137: hkn0511:3073646:3073768 [1] NCCL INFO comm 0x14584c008fb0 rank 137 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
481: hkn0807:1026277:1026401 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
389: hkn0717:1475:1580 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:1475:1580 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
136: hkn0511:3073654:3073767 [0] NCCL INFO comm 0x14c36c008fb0 rank 136 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
138: hkn0511:3073676:3073772 [2] NCCL INFO comm 0x14df54008fb0 rank 138 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
139: hkn0511:3073664:3073769 [3] NCCL INFO comm 0x14c0d0008fb0 rank 139 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
133: hkn0510:2769286:2769390 [1] NCCL INFO Channel 01 : 133[4b000] -> 132[31000] via P2P/IPC/read
480: hkn0807:1026285:1026406 [0] NCCL INFO Connected all trees
388: hkn0717:1467:1586 [0] NCCL INFO Connected all trees
480: hkn0807:1026285:1026406 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1026285:1026406 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:1467:1586 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
388: hkn0717:1467:1586 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
481: hkn0807:1026277:1026401 [1] NCCL INFO comm 0x146890008fb0 rank 481 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
496: hkn0812:701027:701151 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [receive] via NET/IBext/0
480: hkn0807:1026285:1026406 [0] NCCL INFO comm 0x1475c8008fb0 rank 480 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
389: hkn0717:1475:1580 [1] NCCL INFO comm 0x14a2ec008fb0 rank 389 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
482: hkn0807:1026293:1026403 [2] NCCL INFO comm 0x14b194008fb0 rank 482 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
391: hkn0717:1459:1584 [3] NCCL INFO comm 0x148b70008fb0 rank 391 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
240: hkn0607:911595:911709 [0] NCCL INFO Connected all trees
483: hkn0807:1026305:1026402 [3] NCCL INFO comm 0x14919c008fb0 rank 483 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
388: hkn0717:1467:1586 [0] NCCL INFO comm 0x14df08008fb0 rank 388 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
390: hkn0717:1487:1589 [2] NCCL INFO comm 0x146944008fb0 rank 390 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
240: hkn0607:911595:911709 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
240: hkn0607:911595:911709 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:115715:115850 [0] NCCL INFO Connected all trees
504: hkn0815:402353:402445 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [receive] via NET/IBext/0
384: hkn0716:115715:115850 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
384: hkn0716:115715:115850 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
241: hkn0607:911603:911711 [1] NCCL INFO Connected all trees
241: hkn0607:911603:911711 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
241: hkn0607:911603:911711 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
385: hkn0716:115707:115856 [1] NCCL INFO Connected all trees
385: hkn0716:115707:115856 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
385: hkn0716:115707:115856 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:909924:910036 [0] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [receive] via NET/IBext/0
133: hkn0510:2769286:2769390 [1] NCCL INFO Connected all trees
384: hkn0716:115715:115850 [0] NCCL INFO comm 0x151500008fb0 rank 384 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
240: hkn0607:911595:911709 [0] NCCL INFO comm 0x148d70008fb0 rank 240 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
133: hkn0510:2769286:2769390 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
133: hkn0510:2769286:2769390 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
242: hkn0607:911587:911714 [2] NCCL INFO comm 0x14e92c008fb0 rank 242 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
241: hkn0607:911603:911711 [1] NCCL INFO comm 0x1502d0008fb0 rank 241 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
243: hkn0607:911615:911710 [3] NCCL INFO comm 0x14b364008fb0 rank 243 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
385: hkn0716:115707:115856 [1] NCCL INFO comm 0x14a354008fb0 rank 385 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
386: hkn0716:115704:115853 [2] NCCL INFO comm 0x152540008fb0 rank 386 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
132: hkn0510:2769270:2769395 [0] NCCL INFO Connected all trees
132: hkn0510:2769270:2769395 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
132: hkn0510:2769270:2769395 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
387: hkn0716:115727:115858 [3] NCCL INFO comm 0x153b94008fb0 rank 387 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
124: hkn0508:3146346:3146464 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [send] via NET/IBext/0
132: hkn0510:2769270:2769395 [0] NCCL INFO comm 0x1468c0008fb0 rank 132 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
134: hkn0510:2769278:2769396 [2] NCCL INFO comm 0x148c50008fb0 rank 134 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
133: hkn0510:2769286:2769390 [1] NCCL INFO comm 0x152d50008fb0 rank 133 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
135: hkn0510:2769298:2769389 [3] NCCL INFO comm 0x14f174008fb0 rank 135 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
128: hkn0509:3131628:3131753 [0] NCCL INFO Connected all trees
128: hkn0509:3131628:3131753 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
128: hkn0509:3131628:3131753 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
129: hkn0509:3131636:3131744 [1] NCCL INFO Connected all trees
129: hkn0509:3131636:3131744 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
129: hkn0509:3131636:3131744 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:412169:412281 [0] NCCL INFO Connected all trees
268: hkn0616:412169:412281 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
128: hkn0509:3131628:3131753 [0] NCCL INFO comm 0x14bac4008fb0 rank 128 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
268: hkn0616:412169:412281 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:492963:493070 [1] NCCL INFO Channel 00 : 245[4b000] -> 244[31000] via P2P/IPC/read
130: hkn0509:3131655:3131751 [2] NCCL INFO comm 0x153ed8008fb0 rank 130 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
131: hkn0509:3131644:3131750 [3] NCCL INFO comm 0x150e30008fb0 rank 131 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
129: hkn0509:3131636:3131744 [1] NCCL INFO comm 0x1465a8008fb0 rank 129 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
281: hkn0622:2027752:2027859 [1] NCCL INFO Connected all trees
277: hkn0621:1998849:1998946 [1] NCCL INFO Channel 00 : 277[4b000] -> 276[31000] via P2P/IPC/read
281: hkn0622:2027752:2027859 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:718036:718147 [1] NCCL INFO Connected all trees
281: hkn0622:2027752:2027859 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
269: hkn0616:412177:412290 [1] NCCL INFO Connected all trees
249: hkn0609:718036:718147 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [send] via NET/IBext/0
249: hkn0609:718036:718147 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
269: hkn0616:412177:412290 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
269: hkn0616:412177:412290 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2027764:2027860 [0] NCCL INFO Connected all trees
280: hkn0622:2027764:2027860 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:718056:718153 [0] NCCL INFO Connected all trees
280: hkn0622:2027764:2027860 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:492963:493070 [1] NCCL INFO Channel 01 : 245[4b000] -> 244[31000] via P2P/IPC/read
248: hkn0609:718056:718153 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:718056:718153 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
270: hkn0616:412161:412288 [2] NCCL INFO comm 0x14b988008fb0 rank 270 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
277: hkn0621:1998849:1998946 [1] NCCL INFO Channel 01 : 277[4b000] -> 276[31000] via P2P/IPC/read
271: hkn0616:412189:412285 [3] NCCL INFO comm 0x1524cc008fb0 rank 271 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
269: hkn0616:412177:412290 [1] NCCL INFO comm 0x1478c0008fb0 rank 269 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
268: hkn0616:412169:412281 [0] NCCL INFO comm 0x14f13c008fb0 rank 268 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
265: hkn0615:421570:421665 [1] NCCL INFO Channel 00 : 265[4b000] -> 264[31000] via P2P/IPC/read
281: hkn0622:2027752:2027859 [1] NCCL INFO comm 0x14d584008fb0 rank 281 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
283: hkn0622:2027736:2027858 [3] NCCL INFO comm 0x146f14008fb0 rank 283 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
249: hkn0609:718036:718147 [1] NCCL INFO comm 0x1550ac008fb0 rank 249 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
282: hkn0622:2027744:2027863 [2] NCCL INFO comm 0x14f944008fb0 rank 282 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
280: hkn0622:2027764:2027860 [0] NCCL INFO comm 0x145d1c008fb0 rank 280 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
248: hkn0609:718056:718153 [0] NCCL INFO comm 0x148374008fb0 rank 248 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
251: hkn0609:718044:718148 [3] NCCL INFO comm 0x1498e4008fb0 rank 251 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
250: hkn0609:718028:718154 [2] NCCL INFO comm 0x1462b0008fb0 rank 250 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
265: hkn0615:421570:421665 [1] NCCL INFO Channel 01 : 265[4b000] -> 264[31000] via P2P/IPC/read
509: hkn0816:382855:382951 [1] NCCL INFO Connected all trees
509: hkn0816:382855:382951 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
244: hkn0608:492975:493069 [0] NCCL INFO Connected all trees
509: hkn0816:382855:382951 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
244: hkn0608:492975:493069 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
244: hkn0608:492975:493069 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
276: hkn0621:1998822:1998945 [0] NCCL INFO Connected all trees
508: hkn0816:382834:382958 [0] NCCL INFO Connected all trees
276: hkn0621:1998822:1998945 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
508: hkn0816:382834:382958 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
276: hkn0621:1998822:1998945 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:492963:493070 [1] NCCL INFO Connected all trees
508: hkn0816:382834:382958 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:492963:493070 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:492963:493070 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:1998849:1998946 [1] NCCL INFO Connected all trees
277: hkn0621:1998849:1998946 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
277: hkn0621:1998849:1998946 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
509: hkn0816:382855:382951 [1] NCCL INFO comm 0x146430008fb0 rank 509 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
511: hkn0816:382835:382955 [3] NCCL INFO comm 0x14ef88008fb0 rank 511 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
245: hkn0608:492963:493070 [1] NCCL INFO comm 0x1521b4008fb0 rank 245 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
246: hkn0608:492947:493073 [2] NCCL INFO comm 0x1536d4008fb0 rank 246 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
244: hkn0608:492975:493069 [0] NCCL INFO comm 0x151880008fb0 rank 244 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
508: hkn0816:382834:382958 [0] NCCL INFO comm 0x152040008fb0 rank 508 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
247: hkn0608:492955:493068 [3] NCCL INFO comm 0x1520d4008fb0 rank 247 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
510: hkn0816:382843:382953 [2] NCCL INFO comm 0x145a0c008fb0 rank 510 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
278: hkn0621:1998838:1998943 [2] NCCL INFO comm 0x1461f8008fb0 rank 278 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
279: hkn0621:1998830:1998944 [3] NCCL INFO comm 0x14befc008fb0 rank 279 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
277: hkn0621:1998849:1998946 [1] NCCL INFO comm 0x14b240008fb0 rank 277 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
276: hkn0621:1998822:1998945 [0] NCCL INFO comm 0x1463a8008fb0 rank 276 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
497: hkn0812:701035:701150 [1] NCCL INFO Connected all trees
497: hkn0812:701035:701150 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:701035:701150 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
496: hkn0812:701027:701151 [0] NCCL INFO Connected all trees
496: hkn0812:701027:701151 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:701027:701151 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
125: hkn0508:3146338:3146460 [1] NCCL INFO Connected all trees
125: hkn0508:3146338:3146460 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
125: hkn0508:3146338:3146460 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
496: hkn0812:701027:701151 [0] NCCL INFO comm 0x14f480008fb0 rank 496 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
499: hkn0812:701057:701148 [3] NCCL INFO comm 0x149efc008fb0 rank 499 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
497: hkn0812:701035:701150 [1] NCCL INFO comm 0x14a654008fb0 rank 497 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
124: hkn0508:3146346:3146464 [0] NCCL INFO Connected all trees
498: hkn0812:701043:701153 [2] NCCL INFO comm 0x14d164008fb0 rank 498 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
124: hkn0508:3146346:3146464 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
124: hkn0508:3146346:3146464 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
264: hkn0615:421550:421660 [0] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [send] via NET/IBext/0
125: hkn0508:3146338:3146460 [1] NCCL INFO comm 0x14b984008fb0 rank 125 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
126: hkn0508:3146354:3146461 [2] NCCL INFO comm 0x1504b8008fb0 rank 126 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
127: hkn0508:3146366:3146462 [3] NCCL INFO comm 0x147560008fb0 rank 127 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
124: hkn0508:3146346:3146464 [0] NCCL INFO comm 0x14af14008fb0 rank 124 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
260: hkn0613:909924:910036 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [send] via NET/IBext/0
120: hkn0507:3194293:3194413 [0] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [send] via NET/IBext/0
504: hkn0815:402353:402445 [0] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [send] via NET/IBext/0
265: hkn0615:421570:421665 [1] NCCL INFO Connected all trees
265: hkn0615:421570:421665 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 60: hkn0420:3217416:3217549 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [send] via NET/IBext/0
265: hkn0615:421570:421665 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
264: hkn0615:421550:421660 [0] NCCL INFO Connected all trees
264: hkn0615:421550:421660 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
264: hkn0615:421550:421660 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
264: hkn0615:421550:421660 [0] NCCL INFO comm 0x151e50008fb0 rank 264 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
266: hkn0615:421558:421661 [2] NCCL INFO comm 0x146de4008fb0 rank 266 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
261: hkn0613:909944:910037 [1] NCCL INFO Channel 00 : 261[4b000] -> 260[31000] via P2P/IPC/read
265: hkn0615:421570:421665 [1] NCCL INFO comm 0x146ce0008fb0 rank 265 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
267: hkn0615:421542:421667 [3] NCCL INFO comm 0x1517b0008fb0 rank 267 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
261: hkn0613:909944:910037 [1] NCCL INFO Channel 01 : 261[4b000] -> 260[31000] via P2P/IPC/read
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [send] via NET/IBext/0
121: hkn0507:3194285:3194409 [1] NCCL INFO Connected all trees
260: hkn0613:909924:910036 [0] NCCL INFO Connected all trees
121: hkn0507:3194285:3194409 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
121: hkn0507:3194285:3194409 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:909924:910036 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
260: hkn0613:909924:910036 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
120: hkn0507:3194293:3194413 [0] NCCL INFO Connected all trees
120: hkn0507:3194293:3194413 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
261: hkn0613:909944:910037 [1] NCCL INFO Connected all trees
120: hkn0507:3194293:3194413 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
261: hkn0613:909944:910037 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
501: hkn0814:683039:683170 [1] NCCL INFO Channel 00 : 501[4b000] -> 500[31000] via P2P/IPC/read
261: hkn0613:909944:910037 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
117: hkn0506:845300:845411 [1] NCCL INFO Channel 00 : 117[4b000] -> 116[31000] via P2P/IPC/read
120: hkn0507:3194293:3194413 [0] NCCL INFO comm 0x149b8c008fb0 rank 120 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
260: hkn0613:909924:910036 [0] NCCL INFO comm 0x14cc10008fb0 rank 260 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
121: hkn0507:3194285:3194409 [1] NCCL INFO comm 0x147e9c008fb0 rank 121 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
262: hkn0613:909916:910043 [2] NCCL INFO comm 0x14e05c008fb0 rank 262 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
123: hkn0507:3194313:3194412 [3] NCCL INFO comm 0x14ae58008fb0 rank 123 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
261: hkn0613:909944:910037 [1] NCCL INFO comm 0x14795c008fb0 rank 261 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
122: hkn0507:3194301:3194415 [2] NCCL INFO comm 0x1525b4008fb0 rank 122 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
501: hkn0814:683039:683170 [1] NCCL INFO Channel 01 : 501[4b000] -> 500[31000] via P2P/IPC/read
263: hkn0613:909932:910042 [3] NCCL INFO comm 0x152670008fb0 rank 263 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
257: hkn0612:924227:924322 [1] NCCL INFO Connected all trees
117: hkn0506:845300:845411 [1] NCCL INFO Channel 01 : 117[4b000] -> 116[31000] via P2P/IPC/read
257: hkn0612:924227:924322 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:924227:924322 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:924207:924324 [0] NCCL INFO Connected all trees
256: hkn0612:924207:924324 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
256: hkn0612:924207:924324 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
505: hkn0815:402333:402447 [1] NCCL INFO Connected all trees
505: hkn0815:402333:402447 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
505: hkn0815:402333:402447 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:924207:924324 [0] NCCL INFO comm 0x149500008fb0 rank 256 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
258: hkn0612:924199:924320 [2] NCCL INFO comm 0x14e0d4008fb0 rank 258 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
257: hkn0612:924227:924322 [1] NCCL INFO comm 0x1538a8008fb0 rank 257 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
504: hkn0815:402353:402445 [0] NCCL INFO Connected all trees
504: hkn0815:402353:402445 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:402353:402445 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
259: hkn0612:924215:924321 [3] NCCL INFO comm 0x1543c4008fb0 rank 259 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 61: hkn0420:3217408:3217553 [1] NCCL INFO Connected all trees
501: hkn0814:683039:683170 [1] NCCL INFO Connected all trees
501: hkn0814:683039:683170 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 61: hkn0420:3217408:3217553 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 61: hkn0420:3217408:3217553 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:683039:683170 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
116: hkn0506:845312:845412 [0] NCCL INFO Connected all trees
505: hkn0815:402333:402447 [1] NCCL INFO comm 0x147a24008fb0 rank 505 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
500: hkn0814:683023:683174 [0] NCCL INFO Connected all trees
116: hkn0506:845312:845412 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:845312:845412 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3217416:3217549 [0] NCCL INFO Connected all trees
500: hkn0814:683023:683174 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
500: hkn0814:683023:683174 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3217416:3217549 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 60: hkn0420:3217416:3217549 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
506: hkn0815:402341:402450 [2] NCCL INFO comm 0x147f50008fb0 rank 506 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
507: hkn0815:402329:402444 [3] NCCL INFO comm 0x152aa4008fb0 rank 507 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
117: hkn0506:845300:845411 [1] NCCL INFO Connected all trees
504: hkn0815:402353:402445 [0] NCCL INFO comm 0x14644c008fb0 rank 504 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
117: hkn0506:845300:845411 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
117: hkn0506:845300:845411 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
503: hkn0814:683031:683177 [3] NCCL INFO comm 0x149b24008fb0 rank 503 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
501: hkn0814:683039:683170 [1] NCCL INFO comm 0x14d5dc008fb0 rank 501 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
500: hkn0814:683023:683174 [0] NCCL INFO comm 0x14893c008fb0 rank 500 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 61: hkn0420:3217408:3217553 [1] NCCL INFO comm 0x14c6f4008fb0 rank 61 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
116: hkn0506:845312:845412 [0] NCCL INFO comm 0x14b98c008fb0 rank 116 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 63: hkn0420:3217400:3217555 [3] NCCL INFO comm 0x14edd0008fb0 rank 63 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
117: hkn0506:845300:845411 [1] NCCL INFO comm 0x1551f4008fb0 rank 117 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
502: hkn0814:683050:683175 [2] NCCL INFO comm 0x1477c4008fb0 rank 502 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
118: hkn0506:845292:845415 [2] NCCL INFO comm 0x14e6e8008fb0 rank 118 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 62: hkn0420:3217428:3217558 [2] NCCL INFO comm 0x14c534008fb0 rank 62 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
119: hkn0506:845284:845410 [3] NCCL INFO comm 0x150cbc008fb0 rank 119 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 60: hkn0420:3217416:3217549 [0] NCCL INFO comm 0x14d648008fb0 rank 60 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 28: hkn0411:2323081:2323201 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [send] via NET/IBext/0
 56: hkn0419:1551497:1551601 [0] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [send] via NET/IBext/0
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [send] via NET/IBext/0
 29: hkn0411:2323109:2323200 [1] NCCL INFO Connected all trees
 29: hkn0411:2323109:2323200 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 29: hkn0411:2323109:2323200 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2323081:2323201 [0] NCCL INFO Connected all trees
 28: hkn0411:2323081:2323201 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 28: hkn0411:2323081:2323201 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2323109:2323200 [1] NCCL INFO comm 0x14828c008fb0 rank 29 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 30: hkn0411:2323089:2323199 [2] NCCL INFO comm 0x154020008fb0 rank 30 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 28: hkn0411:2323081:2323201 [0] NCCL INFO comm 0x149480008fb0 rank 28 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 53: hkn0418:1876404:1876515 [1] NCCL INFO Channel 00 : 53[4b000] -> 52[31000] via P2P/IPC/read
 31: hkn0411:2323097:2323204 [3] NCCL INFO comm 0x145b84008fb0 rank 31 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 57: hkn0419:1551489:1551602 [1] NCCL INFO Connected all trees
 57: hkn0419:1551489:1551602 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 57: hkn0419:1551489:1551602 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 56: hkn0419:1551497:1551601 [0] NCCL INFO Connected all trees
 56: hkn0419:1551497:1551601 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 53: hkn0418:1876404:1876515 [1] NCCL INFO Channel 01 : 53[4b000] -> 52[31000] via P2P/IPC/read
 56: hkn0419:1551497:1551601 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 59: hkn0419:1551517:1551600 [3] NCCL INFO comm 0x154390008fb0 rank 59 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 57: hkn0419:1551489:1551602 [1] NCCL INFO comm 0x152fcc008fb0 rank 57 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 56: hkn0419:1551497:1551601 [0] NCCL INFO comm 0x14dc24008fb0 rank 56 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 12: hkn0407:1823520:1823613 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [send] via NET/IBext/0
 58: hkn0419:1551505:1551604 [2] NCCL INFO comm 0x147880008fb0 rank 58 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 52: hkn0418:1876388:1876514 [0] NCCL INFO Connected all trees
 52: hkn0418:1876388:1876514 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1876388:1876514 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1876404:1876515 [1] NCCL INFO Connected all trees
 53: hkn0418:1876404:1876515 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 53: hkn0418:1876404:1876515 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1166925:1167041 [0] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [send] via NET/IBext/0
 52: hkn0418:1876388:1876514 [0] NCCL INFO comm 0x14a294008fb0 rank 52 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 53: hkn0418:1876404:1876515 [1] NCCL INFO comm 0x14784c008fb0 rank 53 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 54: hkn0418:1876396:1876507 [2] NCCL INFO comm 0x148420008fb0 rank 54 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 55: hkn0418:1876416:1876509 [3] NCCL INFO comm 0x152aa0008fb0 rank 55 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [receive] via NET/IBext/0
 13: hkn0407:1823500:1823618 [1] NCCL INFO Connected all trees
 13: hkn0407:1823500:1823618 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 13: hkn0407:1823500:1823618 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1823520:1823613 [0] NCCL INFO Connected all trees
 12: hkn0407:1823520:1823613 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 12: hkn0407:1823520:1823613 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 14: hkn0407:1823492:1823615 [2] NCCL INFO comm 0x145b94008fb0 rank 14 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 15: hkn0407:1823508:1823614 [3] NCCL INFO comm 0x14bc34008fb0 rank 15 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 12: hkn0407:1823520:1823613 [0] NCCL INFO comm 0x151650008fb0 rank 12 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 13: hkn0407:1823500:1823618 [1] NCCL INFO comm 0x153d84008fb0 rank 13 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 00 : 9[4b000] -> 8[31000] via P2P/IPC/read
 25: hkn0410:1166933:1167040 [1] NCCL INFO Connected all trees
 25: hkn0410:1166933:1167040 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 25: hkn0410:1166933:1167040 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3214182:3214280 [1] NCCL INFO Channel 01 : 9[4b000] -> 8[31000] via P2P/IPC/read
 24: hkn0410:1166925:1167041 [0] NCCL INFO Connected all trees
 24: hkn0410:1166925:1167041 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 24: hkn0410:1166925:1167041 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2592894:2592992 [1] NCCL INFO Channel 00 : 21[4b000] -> 20[31000] via P2P/IPC/read
 26: hkn0410:1166945:1167042 [2] NCCL INFO comm 0x14d8f8008fb0 rank 26 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 24: hkn0410:1166925:1167041 [0] NCCL INFO comm 0x146f2c008fb0 rank 24 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 27: hkn0410:1166917:1167039 [3] NCCL INFO comm 0x151104008fb0 rank 27 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 25: hkn0410:1166933:1167040 [1] NCCL INFO comm 0x14fda4008fb0 rank 25 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 21: hkn0409:2592894:2592992 [1] NCCL INFO Channel 01 : 21[4b000] -> 20[31000] via P2P/IPC/read
 20: hkn0409:2592866:2592990 [0] NCCL INFO Connected all trees
 20: hkn0409:2592866:2592990 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 20: hkn0409:2592866:2592990 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2592894:2592992 [1] NCCL INFO Connected all trees
 21: hkn0409:2592894:2592992 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 21: hkn0409:2592894:2592992 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2592894:2592992 [1] NCCL INFO comm 0x152220008fb0 rank 21 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  8: hkn0405:3214154:3214272 [0] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [send] via NET/IBext/0
 20: hkn0409:2592866:2592990 [0] NCCL INFO comm 0x146ac0008fb0 rank 20 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 22: hkn0409:2592882:2592991 [2] NCCL INFO comm 0x14cb04008fb0 rank 22 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 23: hkn0409:2592874:2592989 [3] NCCL INFO comm 0x14e8c8008fb0 rank 23 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  4: hkn0404:1346644:1346761 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [send] via NET/IBext/0
  9: hkn0405:3214182:3214280 [1] NCCL INFO Connected all trees
  9: hkn0405:3214182:3214280 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  9: hkn0405:3214182:3214280 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  5: hkn0404:1346653:1346760 [1] NCCL INFO Channel 00 : 5[4b000] -> 4[31000] via P2P/IPC/read
  8: hkn0405:3214154:3214272 [0] NCCL INFO Connected all trees
  8: hkn0405:3214154:3214272 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  8: hkn0405:3214154:3214272 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 11: hkn0405:3214162:3214281 [3] NCCL INFO comm 0x14b414008fb0 rank 11 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  8: hkn0405:3214154:3214272 [0] NCCL INFO comm 0x1516a8008fb0 rank 8 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  9: hkn0405:3214182:3214280 [1] NCCL INFO comm 0x149e34008fb0 rank 9 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 10: hkn0405:3214170:3214279 [2] NCCL INFO comm 0x153420008fb0 rank 10 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  5: hkn0404:1346653:1346760 [1] NCCL INFO Channel 01 : 5[4b000] -> 4[31000] via P2P/IPC/read
  5: hkn0404:1346653:1346760 [1] NCCL INFO Connected all trees
  5: hkn0404:1346653:1346760 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  5: hkn0404:1346653:1346760 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  4: hkn0404:1346644:1346761 [0] NCCL INFO Connected all trees
  4: hkn0404:1346644:1346761 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1346644:1346761 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  4: hkn0404:1346644:1346761 [0] NCCL INFO comm 0x15300c008fb0 rank 4 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  5: hkn0404:1346653:1346760 [1] NCCL INFO comm 0x14a50c008fb0 rank 5 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  6: hkn0404:1346665:1346763 [2] NCCL INFO comm 0x14aba8008fb0 rank 6 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  7: hkn0404:1346645:1346762 [3] NCCL INFO comm 0x14c0a4008fb0 rank 7 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  0: hkn0403:1776559:1776930 [0] NCCL INFO Connected all trees
  0: hkn0403:1776559:1776930 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1776559:1776930 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  1: hkn0403:1776565:1776936 [1] NCCL INFO Connected all trees
  1: hkn0403:1776565:1776936 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  1: hkn0403:1776565:1776936 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1776559:1776930 [0] NCCL INFO comm 0x150ba8008fb0 rank 0 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  1: hkn0403:1776565:1776936 [1] NCCL INFO comm 0x14fb54008fb0 rank 1 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  2: hkn0403:1776577:1776939 [2] NCCL INFO comm 0x14c978008fb0 rank 2 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  3: hkn0403:1776560:1776937 [3] NCCL INFO comm 0x148d70008fb0 rank 3 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  0: hkn0403:1776559:1776559 [0] NCCL INFO Launch mode Parallel
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618467, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "deepcam", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 55}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618537, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HelmholtzAI", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 58}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618537, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 61}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618537, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 64}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618537, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "HoreKa", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 67}}
  2: hdf5!!
259: hdf5!!
131: hdf5!!
387: hdf5!!
208: hdf5!!
315: hdf5!!
306: hdf5!!
322: hdf5!!
116: hdf5!!
 97: hdf5!!
  1: hdf5!!
444: hdf5!!
408: hdf5!!
254: hdf5!!
438: hdf5!!
509: hdf5!!
425: hdf5!!
413: hdf5!!
474: hdf5!!
441: hdf5!!
288: hdf5!!
217: hdf5!!
362: hdf5!!
240: hdf5!!
245: hdf5!!
 43: hdf5!!
 83: hdf5!!
102: hdf5!!
 65: hdf5!!
354: hdf5!!
173: hdf5!!
167: hdf5!!
153: hdf5!!
119: hdf5!!
368: hdf5!!
 96: hdf5!!
 51: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618537, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 98}}
422: hdf5!!
410: hdf5!!
494: hdf5!!
253: hdf5!!
 12: hdf5!!
210: hdf5!!
437: hdf5!!
511: hdf5!!
401: hdf5!!
448: hdf5!!
424: hdf5!!
256: hdf5!!
453: hdf5!!
488: hdf5!!
392: hdf5!!
224: hdf5!!
311: hdf5!!
363: hdf5!!
122: hdf5!!
312: hdf5!!
242: hdf5!!
304: hdf5!!
149: hdf5!!
246: hdf5!!
 16: hdf5!!
378: hdf5!!
364: hdf5!!
292: hdf5!!
 88: hdf5!!
357: hdf5!!
296: hdf5!!
332: hdf5!!
320: hdf5!!
 45: hdf5!!
 56: hdf5!!
100: hdf5!!
199: hdf5!!
 66: hdf5!!
355: hdf5!!
161: hdf5!!
 55: hdf5!!
127: hdf5!!
 28: hdf5!!
138: hdf5!!
184: hdf5!!
190: hdf5!!
 92: hdf5!!
154: hdf5!!
 34: hdf5!!
104: hdf5!!
176: hdf5!!
 10: hdf5!!
118: hdf5!!
 99: hdf5!!
 50: hdf5!!
 26: hdf5!!
132: hdf5!!
372: hdf5!!
468: hdf5!!
168: hdf5!!
  3: hdf5!!
420: hdf5!!
445: hdf5!!
397: hdf5!!
385: hdf5!!
409: hdf5!!
482: hdf5!!
495: hdf5!!
505: hdf5!!
255: hdf5!!
 13: hdf5!!
 38: hdf5!!
207: hdf5!!
228: hdf5!!
108: hdf5!!
211: hdf5!!
487: hdf5!!
508: hdf5!!
403: hdf5!!
498: hdf5!!
451: hdf5!!
  5: hdf5!!
389: hdf5!!
426: hdf5!!
414: hdf5!!
258: hdf5!!
473: hdf5!!
418: hdf5!!
452: hdf5!!
489: hdf5!!
467: hdf5!!
405: hdf5!!
429: hdf5!!
394: hdf5!!
501: hdf5!!
225: hdf5!!
442: hdf5!!
479: hdf5!!
249: hdf5!!
 22: hdf5!!
291: hdf5!!
216: hdf5!!
339: hdf5!!
325: hdf5!!
301: hdf5!!
159: hdf5!!
361: hdf5!!
120: hdf5!!
348: hdf5!!
193: hdf5!!
183: hdf5!!
221: hdf5!!
340: hdf5!!
318: hdf5!!
150: hdf5!!
247: hdf5!!
 17: hdf5!!
115: hdf5!!
328: hdf5!!
376: hdf5!!
 42: hdf5!!
365: hdf5!!
294: hdf5!!
 90: hdf5!!
358: hdf5!!
128: hdf5!!
298: hdf5!!
334: hdf5!!
382: hdf5!!
 80: hdf5!!
214: hdf5!!
236: hdf5!!
321: hdf5!!
 46: hdf5!!
 57: hdf5!!
141: hdf5!!
103: hdf5!!
197: hdf5!!
 64: hdf5!!
352: hdf5!!
160: hdf5!!
 54: hdf5!!
124: hdf5!!
 31: hdf5!!
175: hdf5!!
136: hdf5!!
185: hdf5!!
165: hdf5!!
191: hdf5!!
 94: hdf5!!
155: hdf5!!
 35: hdf5!!
107: hdf5!!
178: hdf5!!
  8: hdf5!!
202: hdf5!!
117: hdf5!!
370: hdf5!!
 98: hdf5!!
 48: hdf5!!
 25: hdf5!!
135: hdf5!!
373: hdf5!!
432: hdf5!!
 60: hdf5!!
 86: hdf5!!
469: hdf5!!
170: hdf5!!
146: hdf5!!
456: hdf5!!
461: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618537, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 99}}
421: hdf5!!
447: hdf5!!
396: hdf5!!
386: hdf5!!
411: hdf5!!
483: hdf5!!
492: hdf5!!
506: hdf5!!
252: hdf5!!
 15: hdf5!!
 39: hdf5!!
206: hdf5!!
231: hdf5!!
110: hdf5!!
209: hdf5!!
439: hdf5!!
484: hdf5!!
510: hdf5!!
400: hdf5!!
499: hdf5!!
450: hdf5!!
  7: hdf5!!
270: hdf5!!
391: hdf5!!
427: hdf5!!
412: hdf5!!
257: hdf5!!
475: hdf5!!
232: hdf5!!
419: hdf5!!
454: hdf5!!
491: hdf5!!
464: hdf5!!
406: hdf5!!
430: hdf5!!
395: hdf5!!
503: hdf5!!
226: hdf5!!
440: hdf5!!
 68: hdf5!!
476: hdf5!!
250: hdf5!!
 23: hdf5!!
310: hdf5!!
290: hdf5!!
219: hdf5!!
337: hdf5!!
324: hdf5!!
303: hdf5!!
277: hdf5!!
267: hdf5!!
157: hdf5!!
360: hdf5!!
121: hdf5!!
349: hdf5!!
314: hdf5!!
241: hdf5!!
194: hdf5!!
181: hdf5!!
222: hdf5!!
305: hdf5!!
343: hdf5!!
316: hdf5!!
148: hdf5!!
244: hdf5!!
 19: hdf5!!
114: hdf5!!
329: hdf5!!
377: hdf5!!
 40: hdf5!!
367: hdf5!!
295: hdf5!!
 89: hdf5!!
281: hdf5!!
344: hdf5!!
356: hdf5!!
130: hdf5!!
285: hdf5!!
299: hdf5!!
274: hdf5!!
333: hdf5!!
383: hdf5!!
 81: hdf5!!
215: hdf5!!
237: hdf5!!
 44: hdf5!!
 58: hdf5!!
142: hdf5!!
101: hdf5!!
196: hdf5!!
 67: hdf5!!
353: hdf5!!
163: hdf5!!
 52: hdf5!!
125: hdf5!!
 29: hdf5!!
 78: hdf5!!
174: hdf5!!
139: hdf5!!
187: hdf5!!
261: hdf5!!
166: hdf5!!
189: hdf5!!
 93: hdf5!!
152: hdf5!!
 32: hdf5!!
106: hdf5!!
177: hdf5!!
  9: hdf5!!
203: hdf5!!
371: hdf5!!
 49: hdf5!!
 24: hdf5!!
133: hdf5!!
374: hdf5!!
 72: hdf5!!
435: hdf5!!
 61: hdf5!!
 87: hdf5!!
471: hdf5!!
171: hdf5!!
144: hdf5!!
457: hdf5!!
463: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414618537, "event_type": "POINT_IN_TIME", "key": "seed", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 103}}
423: hdf5!!
446: hdf5!!
399: hdf5!!
384: hdf5!!
480: hdf5!!
493: hdf5!!
504: hdf5!!
 14: hdf5!!
 36: hdf5!!
205: hdf5!!
229: hdf5!!
111: hdf5!!
436: hdf5!!
485: hdf5!!
402: hdf5!!
497: hdf5!!
449: hdf5!!
  6: hdf5!!
269: hdf5!!
390: hdf5!!
415: hdf5!!
472: hdf5!!
234: hdf5!!
417: hdf5!!
455: hdf5!!
490: hdf5!!
465: hdf5!!
407: hdf5!!
431: hdf5!!
393: hdf5!!
502: hdf5!!
227: hdf5!!
443: hdf5!!
 71: hdf5!!
477: hdf5!!
248: hdf5!!
 20: hdf5!!
309: hdf5!!
289: hdf5!!
218: hdf5!!
338: hdf5!!
326: hdf5!!
300: hdf5!!
278: hdf5!!
266: hdf5!!
158: hdf5!!
123: hdf5!!
351: hdf5!!
313: hdf5!!
243: hdf5!!
192: hdf5!!
182: hdf5!!
223: hdf5!!
307: hdf5!!
342: hdf5!!
317: hdf5!!
151: hdf5!!
 18: hdf5!!
112: hdf5!!
330: hdf5!!
379: hdf5!!
 41: hdf5!!
366: hdf5!!
293: hdf5!!
 91: hdf5!!
283: hdf5!!
346: hdf5!!
359: hdf5!!
129: hdf5!!
287: hdf5!!
297: hdf5!!
275: hdf5!!
335: hdf5!!
380: hdf5!!
 82: hdf5!!
213: hdf5!!
239: hdf5!!
 47: hdf5!!
 59: hdf5!!
143: hdf5!!
198: hdf5!!
162: hdf5!!
 53: hdf5!!
126: hdf5!!
 30: hdf5!!
 77: hdf5!!
172: hdf5!!
137: hdf5!!
186: hdf5!!
262: hdf5!!
164: hdf5!!
188: hdf5!!
 95: hdf5!!
 33: hdf5!!
105: hdf5!!
179: hdf5!!
 11: hdf5!!
201: hdf5!!
369: hdf5!!
 27: hdf5!!
134: hdf5!!
375: hdf5!!
 73: hdf5!!
434: hdf5!!
 63: hdf5!!
 84: hdf5!!
470: hdf5!!
169: hdf5!!
145: hdf5!!
458: hdf5!!
460: hdf5!!
  0: hdf5!!
398: hdf5!!
481: hdf5!!
507: hdf5!!
 37: hdf5!!
204: hdf5!!
230: hdf5!!
109: hdf5!!
486: hdf5!!
496: hdf5!!
  4: hdf5!!
271: hdf5!!
388: hdf5!!
235: hdf5!!
416: hdf5!!
466: hdf5!!
404: hdf5!!
428: hdf5!!
500: hdf5!!
 69: hdf5!!
478: hdf5!!
251: hdf5!!
308: hdf5!!
336: hdf5!!
327: hdf5!!
302: hdf5!!
279: hdf5!!
265: hdf5!!
156: hdf5!!
350: hdf5!!
195: hdf5!!
180: hdf5!!
220: hdf5!!
341: hdf5!!
319: hdf5!!
113: hdf5!!
331: hdf5!!
280: hdf5!!
345: hdf5!!
286: hdf5!!
273: hdf5!!
381: hdf5!!
212: hdf5!!
238: hdf5!!
140: hdf5!!
 79: hdf5!!
260: hdf5!!
200: hdf5!!
 75: hdf5!!
433: hdf5!!
 62: hdf5!!
 85: hdf5!!
147: hdf5!!
459: hdf5!!
462: hdf5!!
268: hdf5!!
233: hdf5!!
 70: hdf5!!
276: hdf5!!
264: hdf5!!
282: hdf5!!
347: hdf5!!
284: hdf5!!
272: hdf5!!
 76: hdf5!!
263: hdf5!!
 74: hdf5!!
 21: hdf5!!
323: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
 50: root_dir: /tmp/deepcam/instance0
 33: root_dir: /tmp/deepcam/instance0
144: root_dir: /tmp/deepcam/instance0
 76: root_dir: /tmp/deepcam/instance0
324: root_dir: /tmp/deepcam/instance0
493: root_dir: /tmp/deepcam/instance0
451: root_dir: /tmp/deepcam/instance0
  6: root_dir: /tmp/deepcam/instance0
118: root_dir: /tmp/deepcam/instance0
295: root_dir: /tmp/deepcam/instance0
491: root_dir: /tmp/deepcam/instance0
125: root_dir: /tmp/deepcam/instance0
 31: root_dir: /tmp/deepcam/instance0
387: root_dir: /tmp/deepcam/instance0
346: root_dir: /tmp/deepcam/instance0
168: root_dir: /tmp/deepcam/instance0
433: root_dir: /tmp/deepcam/instance0
101: root_dir: /tmp/deepcam/instance0
 72: root_dir: /tmp/deepcam/instance0
 97: root_dir: /tmp/deepcam/instance0
352: root_dir: /tmp/deepcam/instance0
474: root_dir: /tmp/deepcam/instance0
452: root_dir: /tmp/deepcam/instance0
 70: root_dir: /tmp/deepcam/instance0
 96: root_dir: /tmp/deepcam/instance0
 84: root_dir: /tmp/deepcam/instance0
475: root_dir: /tmp/deepcam/instance0
148: root_dir: /tmp/deepcam/instance0
211: root_dir: /tmp/deepcam/instance0
 93: root_dir: /tmp/deepcam/instance0
139: root_dir: /tmp/deepcam/instance0
498: root_dir: /tmp/deepcam/instance0
384: root_dir: /tmp/deepcam/instance0
161: root_dir: /tmp/deepcam/instance0
422: root_dir: /tmp/deepcam/instance0
 23: root_dir: /tmp/deepcam/instance0
114: root_dir: /tmp/deepcam/instance0
334: root_dir: /tmp/deepcam/instance0
196: root_dir: /tmp/deepcam/instance0
425: root_dir: /tmp/deepcam/instance0
405: root_dir: /tmp/deepcam/instance0
500: root_dir: /tmp/deepcam/instance0
138: root_dir: /tmp/deepcam/instance0
416: root_dir: /tmp/deepcam/instance0
466: root_dir: /tmp/deepcam/instance0
 39: root_dir: /tmp/deepcam/instance0
122: root_dir: /tmp/deepcam/instance0
297: root_dir: /tmp/deepcam/instance0
430: root_dir: /tmp/deepcam/instance0
471: root_dir: /tmp/deepcam/instance0
412: root_dir: /tmp/deepcam/instance0
278: root_dir: /tmp/deepcam/instance0
 44: root_dir: /tmp/deepcam/instance0
321: root_dir: /tmp/deepcam/instance0
463: root_dir: /tmp/deepcam/instance0
506: root_dir: /tmp/deepcam/instance0
  8: root_dir: /tmp/deepcam/instance0
198: root_dir: /tmp/deepcam/instance0
  3: root_dir: /tmp/deepcam/instance0
 52: root_dir: /tmp/deepcam/instance0
171: root_dir: /tmp/deepcam/instance0
190: root_dir: /tmp/deepcam/instance0
320: root_dir: /tmp/deepcam/instance0
 47: root_dir: /tmp/deepcam/instance0
225: root_dir: /tmp/deepcam/instance0
 87: root_dir: /tmp/deepcam/instance0
440: root_dir: /tmp/deepcam/instance0
365: root_dir: /tmp/deepcam/instance0
 63: root_dir: /tmp/deepcam/instance0
467: root_dir: /tmp/deepcam/instance0
371: root_dir: /tmp/deepcam/instance0
240: root_dir: /tmp/deepcam/instance0
304: root_dir: /tmp/deepcam/instance0
336: root_dir: /tmp/deepcam/instance0
489: root_dir: /tmp/deepcam/instance0
248: root_dir: /tmp/deepcam/instance0
411: root_dir: /tmp/deepcam/instance0
 13: root_dir: /tmp/deepcam/instance0
167: root_dir: /tmp/deepcam/instance0
213: root_dir: /tmp/deepcam/instance0
191: root_dir: /tmp/deepcam/instance0
260: root_dir: /tmp/deepcam/instance0
152: root_dir: /tmp/deepcam/instance0
 24: root_dir: /tmp/deepcam/instance0
207: root_dir: /tmp/deepcam/instance0
159: root_dir: /tmp/deepcam/instance0
187: root_dir: /tmp/deepcam/instance0
390: root_dir: /tmp/deepcam/instance0
280: root_dir: /tmp/deepcam/instance0
173: root_dir: /tmp/deepcam/instance0
438: root_dir: /tmp/deepcam/instance0
344: root_dir: /tmp/deepcam/instance0
 94: root_dir: /tmp/deepcam/instance0
 58: root_dir: /tmp/deepcam/instance0
184: root_dir: /tmp/deepcam/instance0
209: root_dir: /tmp/deepcam/instance0
254: root_dir: /tmp/deepcam/instance0
 91: root_dir: /tmp/deepcam/instance0
 40: root_dir: /tmp/deepcam/instance0
376: root_dir: /tmp/deepcam/instance0
469: root_dir: /tmp/deepcam/instance0
379: root_dir: /tmp/deepcam/instance0
457: root_dir: /tmp/deepcam/instance0
 71: root_dir: /tmp/deepcam/instance0
210: root_dir: /tmp/deepcam/instance0
363: root_dir: /tmp/deepcam/instance0
381: root_dir: /tmp/deepcam/instance0
271: root_dir: /tmp/deepcam/instance0
153: root_dir: /tmp/deepcam/instance0
110: root_dir: /tmp/deepcam/instance0
212: root_dir: /tmp/deepcam/instance0
362: root_dir: /tmp/deepcam/instance0
 82: root_dir: /tmp/deepcam/instance0
  1: root_dir: /tmp/deepcam/instance0
166: root_dir: /tmp/deepcam/instance0
380: root_dir: /tmp/deepcam/instance0
 16: root_dir: /tmp/deepcam/instance0
283: root_dir: /tmp/deepcam/instance0
393: root_dir: /tmp/deepcam/instance0
249: root_dir: /tmp/deepcam/instance0
419: root_dir: /tmp/deepcam/instance0
477: root_dir: /tmp/deepcam/instance0
255: root_dir: /tmp/deepcam/instance0
206: root_dir: /tmp/deepcam/instance0
311: root_dir: /tmp/deepcam/instance0
316: root_dir: /tmp/deepcam/instance0
262: root_dir: /tmp/deepcam/instance0
 83: root_dir: /tmp/deepcam/instance0
388: root_dir: /tmp/deepcam/instance0
383: root_dir: /tmp/deepcam/instance0
308: root_dir: /tmp/deepcam/instance0
476: root_dir: /tmp/deepcam/instance0
485: root_dir: /tmp/deepcam/instance0
252: root_dir: /tmp/deepcam/instance0
176: root_dir: /tmp/deepcam/instance0
266: root_dir: /tmp/deepcam/instance0
439: root_dir: /tmp/deepcam/instance0
220: root_dir: /tmp/deepcam/instance0
272: root_dir: /tmp/deepcam/instance0
372: root_dir: /tmp/deepcam/instance0
307: root_dir: /tmp/deepcam/instance0
158: root_dir: /tmp/deepcam/instance0
303: root_dir: /tmp/deepcam/instance0
444: root_dir: /tmp/deepcam/instance0
111: root_dir: /tmp/deepcam/instance0
437: root_dir: /tmp/deepcam/instance0
274: root_dir: /tmp/deepcam/instance0
172: root_dir: /tmp/deepcam/instance0
 14: root_dir: /tmp/deepcam/instance0
351: root_dir: /tmp/deepcam/instance0
396: root_dir: /tmp/deepcam/instance0
360: root_dir: /tmp/deepcam/instance0
350: root_dir: /tmp/deepcam/instance0
447: root_dir: /tmp/deepcam/instance0
391: root_dir: /tmp/deepcam/instance0
237: root_dir: /tmp/deepcam/instance0
234: root_dir: /tmp/deepcam/instance0
282: root_dir: /tmp/deepcam/instance0
341: root_dir: /tmp/deepcam/instance0
 41: root_dir: /tmp/deepcam/instance0
300: root_dir: /tmp/deepcam/instance0
329: root_dir: /tmp/deepcam/instance0
267: root_dir: /tmp/deepcam/instance0
104: root_dir: /tmp/deepcam/instance0
347: root_dir: /tmp/deepcam/instance0
107: root_dir: /tmp/deepcam/instance0
446: root_dir: /tmp/deepcam/instance0
164: root_dir: /tmp/deepcam/instance0
 48: root_dir: /tmp/deepcam/instance0
510: root_dir: /tmp/deepcam/instance0
221: root_dir: /tmp/deepcam/instance0
 17: root_dir: /tmp/deepcam/instance0
397: root_dir: /tmp/deepcam/instance0
289: root_dir: /tmp/deepcam/instance0
312: root_dir: /tmp/deepcam/instance0
259: root_dir: /tmp/deepcam/instance0
242: root_dir: /tmp/deepcam/instance0
256: root_dir: /tmp/deepcam/instance0
 26: root_dir: /tmp/deepcam/instance0
217: root_dir: /tmp/deepcam/instance0
454: root_dir: /tmp/deepcam/instance0
484: root_dir: /tmp/deepcam/instance0
180: root_dir: /tmp/deepcam/instance0
511: root_dir: /tmp/deepcam/instance0
301: root_dir: /tmp/deepcam/instance0
204: root_dir: /tmp/deepcam/instance0
348: root_dir: /tmp/deepcam/instance0
131: root_dir: /tmp/deepcam/instance0
375: root_dir: /tmp/deepcam/instance0
258: root_dir: /tmp/deepcam/instance0
269: root_dir: /tmp/deepcam/instance0
487: root_dir: /tmp/deepcam/instance0
239: root_dir: /tmp/deepcam/instance0
181: root_dir: /tmp/deepcam/instance0
200: root_dir: /tmp/deepcam/instance0
 27: root_dir: /tmp/deepcam/instance0
106: root_dir: /tmp/deepcam/instance0
182: root_dir: /tmp/deepcam/instance0
401: root_dir: /tmp/deepcam/instance0
284: root_dir: /tmp/deepcam/instance0
270: root_dir: /tmp/deepcam/instance0
244: root_dir: /tmp/deepcam/instance0
 57: root_dir: /tmp/deepcam/instance0
154: root_dir: /tmp/deepcam/instance0
140: root_dir: /tmp/deepcam/instance0
233: root_dir: /tmp/deepcam/instance0
508: root_dir: /tmp/deepcam/instance0
399: root_dir: /tmp/deepcam/instance0
285: root_dir: /tmp/deepcam/instance0
219: root_dir: /tmp/deepcam/instance0
 67: root_dir: /tmp/deepcam/instance0
133: root_dir: /tmp/deepcam/instance0
227: root_dir: /tmp/deepcam/instance0
238: root_dir: /tmp/deepcam/instance0
 56: root_dir: /tmp/deepcam/instance0
 18: root_dir: /tmp/deepcam/instance0
478: root_dir: /tmp/deepcam/instance0
215: root_dir: /tmp/deepcam/instance0
273: root_dir: /tmp/deepcam/instance0
291: root_dir: /tmp/deepcam/instance0
218: root_dir: /tmp/deepcam/instance0
141: root_dir: /tmp/deepcam/instance0
177: root_dir: /tmp/deepcam/instance0
236: root_dir: /tmp/deepcam/instance0
245: root_dir: /tmp/deepcam/instance0
 19: root_dir: /tmp/deepcam/instance0
108: root_dir: /tmp/deepcam/instance0
216: root_dir: /tmp/deepcam/instance0
134: root_dir: /tmp/deepcam/instance0
 64: root_dir: /tmp/deepcam/instance0
202: root_dir: /tmp/deepcam/instance0
142: root_dir: /tmp/deepcam/instance0
482: root_dir: /tmp/deepcam/instance0
261: root_dir: /tmp/deepcam/instance0
290: root_dir: /tmp/deepcam/instance0
178: root_dir: /tmp/deepcam/instance0
235: root_dir: /tmp/deepcam/instance0
226: root_dir: /tmp/deepcam/instance0
130: root_dir: /tmp/deepcam/instance0
483: root_dir: /tmp/deepcam/instance0
 12: root_dir: /tmp/deepcam/instance0
 65: root_dir: /tmp/deepcam/instance0
229: root_dir: /tmp/deepcam/instance0
286: root_dir: /tmp/deepcam/instance0
143: root_dir: /tmp/deepcam/instance0
499: root_dir: /tmp/deepcam/instance0
193: root_dir: /tmp/deepcam/instance0
109: root_dir: /tmp/deepcam/instance0
135: root_dir: /tmp/deepcam/instance0
195: root_dir: /tmp/deepcam/instance0
264: root_dir: /tmp/deepcam/instance0
 66: root_dir: /tmp/deepcam/instance0
464: root_dir: /tmp/deepcam/instance0
306: root_dir: /tmp/deepcam/instance0
192: root_dir: /tmp/deepcam/instance0
313: root_dir: /tmp/deepcam/instance0
186: root_dir: /tmp/deepcam/instance0
119: root_dir: /tmp/deepcam/instance0
342: root_dir: /tmp/deepcam/instance0
194: root_dir: /tmp/deepcam/instance0
223: root_dir: /tmp/deepcam/instance0
132: root_dir: /tmp/deepcam/instance0
358: root_dir: /tmp/deepcam/instance0
423: root_dir: /tmp/deepcam/instance0
479: root_dir: /tmp/deepcam/instance0
156: root_dir: /tmp/deepcam/instance0
265: root_dir: /tmp/deepcam/instance0
100: root_dir: /tmp/deepcam/instance0
481: root_dir: /tmp/deepcam/instance0
147: root_dir: /tmp/deepcam/instance0
486: root_dir: /tmp/deepcam/instance0
480: root_dir: /tmp/deepcam/instance0
374: root_dir: /tmp/deepcam/instance0
414: root_dir: /tmp/deepcam/instance0
317: root_dir: /tmp/deepcam/instance0
230: root_dir: /tmp/deepcam/instance0
373: root_dir: /tmp/deepcam/instance0
247: root_dir: /tmp/deepcam/instance0
203: root_dir: /tmp/deepcam/instance0
231: root_dir: /tmp/deepcam/instance0
436: root_dir: /tmp/deepcam/instance0
183: root_dir: /tmp/deepcam/instance0
127: root_dir: /tmp/deepcam/instance0
314: root_dir: /tmp/deepcam/instance0
150: root_dir: /tmp/deepcam/instance0
392: root_dir: /tmp/deepcam/instance0
445: root_dir: /tmp/deepcam/instance0
315: root_dir: /tmp/deepcam/instance0
441: root_dir: /tmp/deepcam/instance0
 25: root_dir: /tmp/deepcam/instance0
188: root_dir: /tmp/deepcam/instance0
257: root_dir: /tmp/deepcam/instance0
 81: root_dir: /tmp/deepcam/instance0
175: root_dir: /tmp/deepcam/instance0
  5: root_dir: /tmp/deepcam/instance0
403: root_dir: /tmp/deepcam/instance0
288: root_dir: /tmp/deepcam/instance0
116: root_dir: /tmp/deepcam/instance0
331: root_dir: /tmp/deepcam/instance0
367: root_dir: /tmp/deepcam/instance0
251: root_dir: /tmp/deepcam/instance0
165: root_dir: /tmp/deepcam/instance0
355: root_dir: /tmp/deepcam/instance0
163: root_dir: /tmp/deepcam/instance0
287: root_dir: /tmp/deepcam/instance0
338: root_dir: /tmp/deepcam/instance0
 68: root_dir: /tmp/deepcam/instance0
459: root_dir: /tmp/deepcam/instance0
461: root_dir: /tmp/deepcam/instance0
333: root_dir: /tmp/deepcam/instance0
310: root_dir: /tmp/deepcam/instance0
293: root_dir: /tmp/deepcam/instance0
497: root_dir: /tmp/deepcam/instance0
246: root_dir: /tmp/deepcam/instance0
103: root_dir: /tmp/deepcam/instance0
305: root_dir: /tmp/deepcam/instance0
421: root_dir: /tmp/deepcam/instance0
448: root_dir: /tmp/deepcam/instance0
424: root_dir: /tmp/deepcam/instance0
 45: root_dir: /tmp/deepcam/instance0
 88: root_dir: /tmp/deepcam/instance0
 21: root_dir: /tmp/deepcam/instance0
 90: root_dir: /tmp/deepcam/instance0
145: root_dir: /tmp/deepcam/instance0
 42: root_dir: /tmp/deepcam/instance0
353: root_dir: /tmp/deepcam/instance0
456: root_dir: /tmp/deepcam/instance0
121: root_dir: /tmp/deepcam/instance0
169: root_dir: /tmp/deepcam/instance0
224: root_dir: /tmp/deepcam/instance0
296: root_dir: /tmp/deepcam/instance0
112: root_dir: /tmp/deepcam/instance0
253: root_dir: /tmp/deepcam/instance0
 53: root_dir: /tmp/deepcam/instance0
413: root_dir: /tmp/deepcam/instance0
432: root_dir: /tmp/deepcam/instance0
465: root_dir: /tmp/deepcam/instance0
105: root_dir: /tmp/deepcam/instance0
 62: root_dir: /tmp/deepcam/instance0
319: root_dir: /tmp/deepcam/instance0
120: root_dir: /tmp/deepcam/instance0
488: root_dir: /tmp/deepcam/instance0
417: root_dir: /tmp/deepcam/instance0
398: root_dir: /tmp/deepcam/instance0
243: root_dir: /tmp/deepcam/instance0
443: root_dir: /tmp/deepcam/instance0
250: root_dir: /tmp/deepcam/instance0
385: root_dir: /tmp/deepcam/instance0
356: root_dir: /tmp/deepcam/instance0
490: root_dir: /tmp/deepcam/instance0
370: root_dir: /tmp/deepcam/instance0
492: root_dir: /tmp/deepcam/instance0
426: root_dir: /tmp/deepcam/instance0
404: root_dir: /tmp/deepcam/instance0
357: root_dir: /tmp/deepcam/instance0
460: root_dir: /tmp/deepcam/instance0
328: root_dir: /tmp/deepcam/instance0
325: root_dir: /tmp/deepcam/instance0
185: root_dir: /tmp/deepcam/instance0
323: root_dir: /tmp/deepcam/instance0
146: root_dir: /tmp/deepcam/instance0
495: root_dir: /tmp/deepcam/instance0
366: root_dir: /tmp/deepcam/instance0
222: root_dir: /tmp/deepcam/instance0
407: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
322: root_dir: /tmp/deepcam/instance0
 49: root_dir: /tmp/deepcam/instance0
  4: root_dir: /tmp/deepcam/instance0
 28: root_dir: /tmp/deepcam/instance0
408: root_dir: /tmp/deepcam/instance0
345: root_dir: /tmp/deepcam/instance0
160: root_dir: /tmp/deepcam/instance0
276: root_dir: /tmp/deepcam/instance0
228: root_dir: /tmp/deepcam/instance0
 54: root_dir: /tmp/deepcam/instance0
214: root_dir: /tmp/deepcam/instance0
442: root_dir: /tmp/deepcam/instance0
 30: root_dir: /tmp/deepcam/instance0
 85: root_dir: /tmp/deepcam/instance0
494: root_dir: /tmp/deepcam/instance0
199: root_dir: /tmp/deepcam/instance0
 32: root_dir: /tmp/deepcam/instance0
509: root_dir: /tmp/deepcam/instance0
501: root_dir: /tmp/deepcam/instance0
292: root_dir: /tmp/deepcam/instance0
197: root_dir: /tmp/deepcam/instance0
332: root_dir: /tmp/deepcam/instance0
428: root_dir: /tmp/deepcam/instance0
 43: root_dir: /tmp/deepcam/instance0
277: root_dir: /tmp/deepcam/instance0
137: root_dir: /tmp/deepcam/instance0
 37: root_dir: /tmp/deepcam/instance0
162: root_dir: /tmp/deepcam/instance0
369: root_dir: /tmp/deepcam/instance0
434: root_dir: /tmp/deepcam/instance0
 80: root_dir: /tmp/deepcam/instance0
318: root_dir: /tmp/deepcam/instance0
189: root_dir: /tmp/deepcam/instance0
507: root_dir: /tmp/deepcam/instance0
335: root_dir: /tmp/deepcam/instance0
208: root_dir: /tmp/deepcam/instance0
458: root_dir: /tmp/deepcam/instance0
302: root_dir: /tmp/deepcam/instance0
279: root_dir: /tmp/deepcam/instance0
 69: root_dir: /tmp/deepcam/instance0
406: root_dir: /tmp/deepcam/instance0
 59: root_dir: /tmp/deepcam/instance0
129: root_dir: /tmp/deepcam/instance0
 22: root_dir: /tmp/deepcam/instance0
409: root_dir: /tmp/deepcam/instance0
201: root_dir: /tmp/deepcam/instance0
377: root_dir: /tmp/deepcam/instance0
 51: root_dir: /tmp/deepcam/instance0
275: root_dir: /tmp/deepcam/instance0
 29: root_dir: /tmp/deepcam/instance0
339: root_dir: /tmp/deepcam/instance0
330: root_dir: /tmp/deepcam/instance0
  7: root_dir: /tmp/deepcam/instance0
462: root_dir: /tmp/deepcam/instance0
  2: root_dir: /tmp/deepcam/instance0
394: root_dir: /tmp/deepcam/instance0
389: root_dir: /tmp/deepcam/instance0
136: root_dir: /tmp/deepcam/instance0
368: root_dir: /tmp/deepcam/instance0
343: root_dir: /tmp/deepcam/instance0
361: root_dir: /tmp/deepcam/instance0
 77: root_dir: /tmp/deepcam/instance0
232: root_dir: /tmp/deepcam/instance0
281: root_dir: /tmp/deepcam/instance0
298: root_dir: /tmp/deepcam/instance0
 75: root_dir: /tmp/deepcam/instance0
402: root_dir: /tmp/deepcam/instance0
 20: root_dir: /tmp/deepcam/instance0
309: root_dir: /tmp/deepcam/instance0
155: root_dir: /tmp/deepcam/instance0
115: root_dir: /tmp/deepcam/instance0
151: root_dir: /tmp/deepcam/instance0
294: root_dir: /tmp/deepcam/instance0
 46: root_dir: /tmp/deepcam/instance0
410: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
386: root_dir: /tmp/deepcam/instance0
340: root_dir: /tmp/deepcam/instance0
 11: root_dir: /tmp/deepcam/instance0
 78: root_dir: /tmp/deepcam/instance0
502: root_dir: /tmp/deepcam/instance0
 79: root_dir: /tmp/deepcam/instance0
435: root_dir: /tmp/deepcam/instance0
420: root_dir: /tmp/deepcam/instance0
 55: root_dir: /tmp/deepcam/instance0
429: root_dir: /tmp/deepcam/instance0
505: root_dir: /tmp/deepcam/instance0
179: root_dir: /tmp/deepcam/instance0
427: root_dir: /tmp/deepcam/instance0
128: root_dir: /tmp/deepcam/instance0
327: root_dir: /tmp/deepcam/instance0
113: root_dir: /tmp/deepcam/instance0
 60: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
473: root_dir: /tmp/deepcam/instance0
 61: root_dir: /tmp/deepcam/instance0
472: root_dir: /tmp/deepcam/instance0
 99: root_dir: /tmp/deepcam/instance0
 98: root_dir: /tmp/deepcam/instance0
299: root_dir: /tmp/deepcam/instance0
453: root_dir: /tmp/deepcam/instance0
449: root_dir: /tmp/deepcam/instance0
468: root_dir: /tmp/deepcam/instance0
418: root_dir: /tmp/deepcam/instance0
 73: root_dir: /tmp/deepcam/instance0
470: root_dir: /tmp/deepcam/instance0
  0: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725206, "event_type": "POINT_IN_TIME", "key": "number_of_ranks", "value": 512, "metadata": {"file": "./train_instance.py", "lineno": 211}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "number_of_nodes", "value": 128, "metadata": {"file": "./train_instance.py", "lineno": 212}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "accelerators_per_node", "value": 4, "metadata": {"file": "./train_instance.py", "lineno": 213}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "instance_id", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 215}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "checkpoint", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 217}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "./train_instance.py", "lineno": 218}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "batchnorm_group_size", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 219}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_frequency", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "data_format", "value": "dali-numpy/hdf5", "metadata": {"file": "./train_instance.py", "lineno": 222}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725209, "event_type": "POINT_IN_TIME", "key": "shuffle_mode", "value": "global", "metadata": {"file": "./train_instance.py", "lineno": 223}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725210, "event_type": "POINT_IN_TIME", "key": "data_oversampling_factor", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 224}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725216, "event_type": "POINT_IN_TIME", "key": "stage_dir_prefix", "value": "/tmp/deepcam", "metadata": {"file": "./train_instance.py", "lineno": 226}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725216, "event_type": "POINT_IN_TIME", "key": "stage_mode", "value": "node", "metadata": {"file": "./train_instance.py", "lineno": 227}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725216, "event_type": "POINT_IN_TIME", "key": "stage_batch_size", "value": -1, "metadata": {"file": "./train_instance.py", "lineno": 228}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725216, "event_type": "POINT_IN_TIME", "key": "stage_verify", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 229}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725216, "event_type": "POINT_IN_TIME", "key": "stage_full_data_per_node", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725216, "event_type": "POINT_IN_TIME", "key": "stage_use_direct_io", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 231}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725217, "event_type": "POINT_IN_TIME", "key": "precision_mode", "value": "amp", "metadata": {"file": "./train_instance.py", "lineno": 233}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725217, "event_type": "POINT_IN_TIME", "key": "enable_nhwc", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 234}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725217, "event_type": "POINT_IN_TIME", "key": "enable_graph", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 235}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725217, "event_type": "POINT_IN_TIME", "key": "enable_jit", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725217, "event_type": "POINT_IN_TIME", "key": "disable_comm_overlap", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 237}}
  0: Constructing DeepLabv3+ model...
  0: Number of output channels: 3
  0: Output stride: 16
  0: Number of Input Channels: 16
359: root_dir: /tmp/deepcam/instance0
 10: root_dir: /tmp/deepcam/instance0
117: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725938, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "LAMB", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 144}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725986, "event_type": "POINT_IN_TIME", "key": "opt_lr", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725986, "event_type": "POINT_IN_TIME", "key": "opt_bias_correction", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725986, "event_type": "POINT_IN_TIME", "key": "opt_betas", "value": [0.9, 0.999], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725986, "event_type": "POINT_IN_TIME", "key": "opt_eps", "value": 1e-06, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725986, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.01, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725986, "event_type": "POINT_IN_TIME", "key": "opt_grad_averaging", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725986, "event_type": "POINT_IN_TIME", "key": "opt_max_grad_norm", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725987, "event_type": "POINT_IN_TIME", "key": "scheduler_type", "value": "multistep", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725988, "event_type": "POINT_IN_TIME", "key": "scheduler_milestones", "value": [1100, 4096], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725988, "event_type": "POINT_IN_TIME", "key": "scheduler_decay_rate", "value": 0.1, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725988, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_steps", "value": 200, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414725988, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_factor", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: DeepLabv3_plus(
  0:   (xception_features): Xception(
  0:     (relu): ReLU()
  0:     (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  0:     (bn1): Sequential(
  0:       (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:     (bn2): Sequential(
  0:       (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (block1): Block(
  0:       (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
  0:           (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Seque
  0: ntial(
  0:           (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block2): Block(
  0:       (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1):
  0:  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block3): Block(
  0:       (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), 
  0: bias=False)
  0:       (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (2): ReLU()
  0:         (3): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (5): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d
  0: (728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block4): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=
  0: (3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block5): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2
  0: d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block6): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), p
  0: adding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block7): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momen
  0: tum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block8): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7
  0: 28, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block9
  0: ): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(
  0: 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block10): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU(
  0: )
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block11): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size
  0: =(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block12): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2
  0: ): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block13): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1)
  0: , bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block14): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_sa
  0: me(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNo
  0: rm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block15): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kerne
  0: l_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block16): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): Ba
  0: tchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block17): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride
  0: =(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block18): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e
  0: -05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block19): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1
  0: ), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block20): Block(
  0:       (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:         
  0:   (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
  0:           (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (conv3): SeparableConv2d_same(
  0:       (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1024, bias=False)
  0:       (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn3): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv4): SeparableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn4): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv5): Separa
  0: bleConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn5): Sequential(
  0:       (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (bottleneck): Bottleneck(
  0:     (aspp1): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp2): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp3): ASPP_module(
  0:       (atrous_con
  0: volution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp4): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (global_avg_pool): GlobalAveragePool(
  0:       (global_average_pool): Sequential(
  0:         (0): AdaptiveAvgPool2d(output_size=(1, 1))
  0:         (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         (2): TrainableAffine()
  0:         (3): ReLU(inplace=True)
  0:       )
  0:     )
  0:     (tiling): Tiling()
  0:     (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     (bn): Sequential(
  0:       (0): BatchNorm2d(256, eps=1e-05, m
  0: omentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (conv2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:   (bn2): Sequential(
  0:     (0): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:     (1): ReLU()
  0:   )
  0:   (upsample): DeconvUpsampler(
  0:     (deconv1): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (conv1): Sequential(
  0:       (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  0:     )
  0:     (deconv2): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (last_deconv): Sequential(
  0:       (0): ConvTranspose2d(256, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:     )
  0:   )
  0: )
  0: Number of trainable parameters: 56454720
  0: Creating Dataloaders
504: root_dir: /tmp/deepcam/instance0
  9: root_dir: /tmp/deepcam/instance0
 92: root_dir: /tmp/deepcam/instance0
123: root_dir: /tmp/deepcam/instance0
263: root_dir: /tmp/deepcam/instance0
124: root_dir: /tmp/deepcam/instance0
 86: root_dir: /tmp/deepcam/instance0
378: root_dir: /tmp/deepcam/instance0
 95: root_dir: /tmp/deepcam/instance0
364: root_dir: /tmp/deepcam/instance0
400: root_dir: /tmp/deepcam/instance0
174: root_dir: /tmp/deepcam/instance0
431: root_dir: /tmp/deepcam/instance0
382: root_dir: /tmp/deepcam/instance0
 74: root_dir: /tmp/deepcam/instance0
 35: root_dir: /tmp/deepcam/instance0
503: root_dir: /tmp/deepcam/instance0
 34: root_dir: /tmp/deepcam/instance0
268: root_dir: /tmp/deepcam/instance0
415: root_dir: /tmp/deepcam/instance0
455: root_dir: /tmp/deepcam/instance0
496: root_dir: /tmp/deepcam/instance0
170: root_dir: /tmp/deepcam/instance0
349: root_dir: /tmp/deepcam/instance0
354: root_dir: /tmp/deepcam/instance0
337: root_dir: /tmp/deepcam/instance0
102: root_dir: /tmp/deepcam/instance0
126: root_dir: /tmp/deepcam/instance0
205: root_dir: /tmp/deepcam/instance0
 38: root_dir: /tmp/deepcam/instance0
149: root_dir: /tmp/deepcam/instance0
241: root_dir: /tmp/deepcam/instance0
395: root_dir: /tmp/deepcam/instance0
 89: root_dir: /tmp/deepcam/instance0
157: root_dir: /tmp/deepcam/instance0
 15: root_dir: /tmp/deepcam/instance0
 36: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633414735614, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 121266, "metadata": {"file": "./train_instance.py", "lineno": 353}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414735614, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 15158, "metadata": {"file": "./train_instance.py", "lineno": 354}}
  0: Number of steps per epoch 118
  0: Creating Trainer
  0: Creating Validator
326: root_dir: /tmp/deepcam/instance0
450: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633414776336, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 398}}
  1: hdf5!!
420: hdf5!!
444: hdf5!!
396: hdf5!!
384: hdf5!!
408: hdf5!!
480: hdf5!!
492: hdf5!!
504: hdf5!!
252: hdf5!!
 12: hdf5!!
 36: hdf5!!
204: hdf5!!
228: hdf5!!
108: hdf5!!
208: hdf5!!
436: hdf5!!
484: hdf5!!
509: hdf5!!
400: hdf5!!
496: hdf5!!
448: hdf5!!
  4: hdf5!!
268: hdf5!!
388: hdf5!!
424: hdf5!!
412: hdf5!!
256: hdf5!!
472: hdf5!!
232: hdf5!!
417: hdf5!!
452: hdf5!!
488: hdf5!!
464: hdf5!!
404: hdf5!!
428: hdf5!!
392: hdf5!!
500: hdf5!!
224: hdf5!!
440: hdf5!!
 68: hdf5!!
476: hdf5!!
248: hdf5!!
 20: hdf5!!
308: hdf5!!
288: hdf5!!
216: hdf5!!
336: hdf5!!
324: hdf5!!
300: hdf5!!
276: hdf5!!
264: hdf5!!
156: hdf5!!
360: hdf5!!
120: hdf5!!
348: hdf5!!
312: hdf5!!
240: hdf5!!
192: hdf5!!
180: hdf5!!
220: hdf5!!
304: hdf5!!
340: hdf5!!
316: hdf5!!
148: hdf5!!
244: hdf5!!
 16: hdf5!!
112: hdf5!!
328: hdf5!!
376: hdf5!!
 40: hdf5!!
364: hdf5!!
292: hdf5!!
 88: hdf5!!
280: hdf5!!
344: hdf5!!
356: hdf5!!
128: hdf5!!
284: hdf5!!
296: hdf5!!
272: hdf5!!
332: hdf5!!
380: hdf5!!
 80: hdf5!!
212: hdf5!!
236: hdf5!!
320: hdf5!!
 45: hdf5!!
 57: hdf5!!
140: hdf5!!
100: hdf5!!
198: hdf5!!
 64: hdf5!!
352: hdf5!!
160: hdf5!!
 52: hdf5!!
124: hdf5!!
 28: hdf5!!
 76: hdf5!!
172: hdf5!!
136: hdf5!!
184: hdf5!!
260: hdf5!!
164: hdf5!!
188: hdf5!!
 92: hdf5!!
152: hdf5!!
 32: hdf5!!
104: hdf5!!
176: hdf5!!
  9: hdf5!!
200: hdf5!!
116: hdf5!!
368: hdf5!!
 96: hdf5!!
 48: hdf5!!
 24: hdf5!!
132: hdf5!!
372: hdf5!!
 72: hdf5!!
432: hdf5!!
 60: hdf5!!
 85: hdf5!!
468: hdf5!!
168: hdf5!!
144: hdf5!!
456: hdf5!!
460: hdf5!!
  2: hdf5!!
421: hdf5!!
445: hdf5!!
397: hdf5!!
385: hdf5!!
409: hdf5!!
481: hdf5!!
493: hdf5!!
505: hdf5!!
253: hdf5!!
 13: hdf5!!
 37: hdf5!!
205: hdf5!!
229: hdf5!!
109: hdf5!!
209: hdf5!!
437: hdf5!!
485: hdf5!!
510: hdf5!!
401: hdf5!!
497: hdf5!!
449: hdf5!!
  5: hdf5!!
269: hdf5!!
389: hdf5!!
425: hdf5!!
413: hdf5!!
257: hdf5!!
473: hdf5!!
233: hdf5!!
418: hdf5!!
453: hdf5!!
489: hdf5!!
465: hdf5!!
405: hdf5!!
429: hdf5!!
393: hdf5!!
501: hdf5!!
225: hdf5!!
441: hdf5!!
 69: hdf5!!
477: hdf5!!
249: hdf5!!
 21: hdf5!!
310: hdf5!!
290: hdf5!!
217: hdf5!!
337: hdf5!!
325: hdf5!!
301: hdf5!!
277: hdf5!!
265: hdf5!!
157: hdf5!!
361: hdf5!!
121: hdf5!!
349: hdf5!!
313: hdf5!!
241: hdf5!!
193: hdf5!!
181: hdf5!!
221: hdf5!!
305: hdf5!!
341: hdf5!!
317: hdf5!!
149: hdf5!!
245: hdf5!!
 17: hdf5!!
113: hdf5!!
329: hdf5!!
377: hdf5!!
 41: hdf5!!
365: hdf5!!
293: hdf5!!
 89: hdf5!!
281: hdf5!!
345: hdf5!!
357: hdf5!!
129: hdf5!!
285: hdf5!!
297: hdf5!!
273: hdf5!!
333: hdf5!!
381: hdf5!!
 81: hdf5!!
213: hdf5!!
237: hdf5!!
321: hdf5!!
 46: hdf5!!
 58: hdf5!!
141: hdf5!!
101: hdf5!!
199: hdf5!!
 65: hdf5!!
353: hdf5!!
161: hdf5!!
 53: hdf5!!
125: hdf5!!
 29: hdf5!!
 77: hdf5!!
173: hdf5!!
137: hdf5!!
185: hdf5!!
261: hdf5!!
165: hdf5!!
189: hdf5!!
 94: hdf5!!
153: hdf5!!
 33: hdf5!!
105: hdf5!!
177: hdf5!!
 10: hdf5!!
201: hdf5!!
117: hdf5!!
369: hdf5!!
 97: hdf5!!
 49: hdf5!!
 25: hdf5!!
133: hdf5!!
373: hdf5!!
 73: hdf5!!
433: hdf5!!
 61: hdf5!!
 86: hdf5!!
469: hdf5!!
169: hdf5!!
145: hdf5!!
457: hdf5!!
461: hdf5!!
  3: hdf5!!
422: hdf5!!
446: hdf5!!
398: hdf5!!
386: hdf5!!
410: hdf5!!
482: hdf5!!
494: hdf5!!
506: hdf5!!
255: hdf5!!
 14: hdf5!!
 38: hdf5!!
206: hdf5!!
230: hdf5!!
110: hdf5!!
210: hdf5!!
438: hdf5!!
486: hdf5!!
511: hdf5!!
402: hdf5!!
498: hdf5!!
450: hdf5!!
  6: hdf5!!
270: hdf5!!
390: hdf5!!
426: hdf5!!
414: hdf5!!
258: hdf5!!
474: hdf5!!
234: hdf5!!
419: hdf5!!
454: hdf5!!
490: hdf5!!
466: hdf5!!
406: hdf5!!
430: hdf5!!
394: hdf5!!
502: hdf5!!
226: hdf5!!
442: hdf5!!
 70: hdf5!!
478: hdf5!!
250: hdf5!!
 22: hdf5!!
311: hdf5!!
291: hdf5!!
218: hdf5!!
338: hdf5!!
326: hdf5!!
302: hdf5!!
278: hdf5!!
266: hdf5!!
158: hdf5!!
362: hdf5!!
122: hdf5!!
350: hdf5!!
314: hdf5!!
242: hdf5!!
194: hdf5!!
182: hdf5!!
222: hdf5!!
306: hdf5!!
342: hdf5!!
318: hdf5!!
150: hdf5!!
246: hdf5!!
 18: hdf5!!
114: hdf5!!
330: hdf5!!
378: hdf5!!
 42: hdf5!!
366: hdf5!!
294: hdf5!!
 90: hdf5!!
282: hdf5!!
346: hdf5!!
358: hdf5!!
130: hdf5!!
286: hdf5!!
298: hdf5!!
274: hdf5!!
334: hdf5!!
382: hdf5!!
 82: hdf5!!
214: hdf5!!
238: hdf5!!
322: hdf5!!
 47: hdf5!!
 59: hdf5!!
142: hdf5!!
102: hdf5!!
196: hdf5!!
 66: hdf5!!
354: hdf5!!
162: hdf5!!
 54: hdf5!!
126: hdf5!!
 30: hdf5!!
 78: hdf5!!
174: hdf5!!
138: hdf5!!
186: hdf5!!
262: hdf5!!
167: hdf5!!
190: hdf5!!
 95: hdf5!!
154: hdf5!!
 34: hdf5!!
106: hdf5!!
178: hdf5!!
 11: hdf5!!
202: hdf5!!
118: hdf5!!
370: hdf5!!
 98: hdf5!!
 50: hdf5!!
 26: hdf5!!
134: hdf5!!
374: hdf5!!
 74: hdf5!!
434: hdf5!!
 62: hdf5!!
 87: hdf5!!
470: hdf5!!
170: hdf5!!
146: hdf5!!
458: hdf5!!
462: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414776337, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 401}}
423: hdf5!!
447: hdf5!!
399: hdf5!!
387: hdf5!!
411: hdf5!!
483: hdf5!!
495: hdf5!!
507: hdf5!!
254: hdf5!!
 15: hdf5!!
 39: hdf5!!
207: hdf5!!
231: hdf5!!
111: hdf5!!
211: hdf5!!
439: hdf5!!
487: hdf5!!
508: hdf5!!
403: hdf5!!
499: hdf5!!
451: hdf5!!
  7: hdf5!!
271: hdf5!!
391: hdf5!!
427: hdf5!!
415: hdf5!!
259: hdf5!!
475: hdf5!!
235: hdf5!!
416: hdf5!!
455: hdf5!!
491: hdf5!!
467: hdf5!!
407: hdf5!!
431: hdf5!!
395: hdf5!!
503: hdf5!!
227: hdf5!!
443: hdf5!!
 71: hdf5!!
479: hdf5!!
251: hdf5!!
 23: hdf5!!
309: hdf5!!
289: hdf5!!
219: hdf5!!
339: hdf5!!
327: hdf5!!
303: hdf5!!
279: hdf5!!
267: hdf5!!
159: hdf5!!
363: hdf5!!
123: hdf5!!
351: hdf5!!
315: hdf5!!
243: hdf5!!
195: hdf5!!
183: hdf5!!
223: hdf5!!
307: hdf5!!
343: hdf5!!
319: hdf5!!
151: hdf5!!
247: hdf5!!
 19: hdf5!!
115: hdf5!!
331: hdf5!!
379: hdf5!!
 43: hdf5!!
367: hdf5!!
295: hdf5!!
 91: hdf5!!
283: hdf5!!
347: hdf5!!
359: hdf5!!
131: hdf5!!
287: hdf5!!
299: hdf5!!
275: hdf5!!
335: hdf5!!
383: hdf5!!
 83: hdf5!!
215: hdf5!!
239: hdf5!!
323: hdf5!!
 44: hdf5!!
 56: hdf5!!
143: hdf5!!
103: hdf5!!
197: hdf5!!
 67: hdf5!!
355: hdf5!!
163: hdf5!!
 55: hdf5!!
127: hdf5!!
 31: hdf5!!
 79: hdf5!!
175: hdf5!!
139: hdf5!!
187: hdf5!!
263: hdf5!!
166: hdf5!!
191: hdf5!!
 93: hdf5!!
155: hdf5!!
 35: hdf5!!
107: hdf5!!
179: hdf5!!
  8: hdf5!!
203: hdf5!!
119: hdf5!!
371: hdf5!!
 99: hdf5!!
 51: hdf5!!
 27: hdf5!!
135: hdf5!!
375: hdf5!!
 75: hdf5!!
435: hdf5!!
 63: hdf5!!
 84: hdf5!!
471: hdf5!!
171: hdf5!!
147: hdf5!!
459: hdf5!!
463: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414776337, "event_type": "INTERVAL_START", "key": "staging_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 405}}
  0: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
  0: :::MLLOG {"namespace": "", "time_ms": 1633414889592, "event_type": "INTERVAL_END", "key": "staging_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 425}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414889597, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 1, "step_num": 0}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414895313, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00017999999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414895314, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.16184575855731964, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414895314, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.4767353534698486, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414897274, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00038, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414897283, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.1954362839460373, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414897284, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.12977135181427, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414898205, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00058, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414898205, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.2667771875858307, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414898206, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.7706419229507446, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414899134, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0007800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414899134, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.31902754306793213, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414899134, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.4453621506690979, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414900076, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00098, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414900076, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.32840922474861145, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414900077, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.22622086107730865, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414901009, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00118, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414901010, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3318876028060913, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414901010, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.12455034255981445, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414901940, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00138, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414901940, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.35834819078445435, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414901940, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.07978850603103638, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414902862, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00158, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414902862, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.4467543363571167, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414902862, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.060998450964689255, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414903801, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0017800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414903801, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.49538925290107727, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414903801, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.049557339400053024, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414904734, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00198, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414904734, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5021179914474487, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414904734, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.040624406188726425, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414905664, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00218, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414905664, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5191216468811035, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414905664, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.04039989039301872, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414906411, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 1}}
  0: EVAL: first data load time: 0.32373825646936893
  0: EVAL: step 1 time -> 0.05779689736664295
  0: EVAL: step 2 time -> 0.12559449207037687
  0: EVAL: step 3 time -> 0.01211488712579012
  0: EVAL: step 4 time -> 0.011476771906018257
  0: EVAL: full eval time -> 1.0100475195795298
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907451, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.49904724274104434, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907451, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.05379984476019264, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907451, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907471, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907490, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 2, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907693, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0023799999999999997, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907693, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5392985343933105, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414907693, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.036287643015384674, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414908620, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0025800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414908621, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5443522930145264, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414908621, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.035608865320682526, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414909559, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00278, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414909560, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5510027408599854, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414909560, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.033673737198114395, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414910484, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00298, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414910485, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5542902946472168, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414910485, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0345810241997242, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414911420, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00318, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414911420, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5754226446151733, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414911420, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.030724868178367615, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414912362, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0033799999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414912362, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5772713422775269, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414912363, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.029871365055441856, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414913293, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0035800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414913293, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5877098441123962, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414913294, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02989012375473976, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414914217, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00378, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414914217, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5869035720825195, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414914217, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03015054389834404, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414915158, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00398, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414915158, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5928866267204285, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414915158, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.027629707008600235, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414916085, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414916085, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5969367623329163, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414916085, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.027455830946564674, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414917024, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414917024, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6059422492980957, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414917024, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02514479123055935, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414917958, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414917959, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6194984316825867, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414917959, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.024931378662586212, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414918520, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 2}}
  0: EVAL: first data load time: 0.0019838623702526093
  0: EVAL: step 1 time -> 0.012639106251299381
  0: EVAL: step 2 time -> 0.011617098934948444
  0: EVAL: step 3 time -> 0.011232314631342888
  0: EVAL: step 4 time -> 0.12430873140692711
  0: EVAL: full eval time -> 0.4019509945064783
  0: :::MLLOG {"namespace": "", "time_ms": 1633414918924, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6161849095774509, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414918924, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.02297475140112688, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414918924, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 2}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414918926, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414918945, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 3, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414919318, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414919319, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6184124946594238, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414919319, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.024998851120471954, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414920246, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414920246, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.625262439250946, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414920246, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.023745723068714142, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414921174, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414921175, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6324862241744995, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414921175, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.022372543811798096, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414922111, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414922111, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6280905604362488, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414922111, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.022338682785630226, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414923034, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414923035, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6359766125679016, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414923035, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.022372981533408165, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414923960, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414923961, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.642643392086029, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414923961, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021462691947817802, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414924888, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414924888, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.636293888092041, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414924888, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02204315736889839, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414925820, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414925820, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.648622989654541, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414925820, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020283890888094902, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414926747, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414926747, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.649505078792572, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414926747, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019778724759817123, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414927677, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414927678, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6480628252029419, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414927678, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020179832354187965, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414928600, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414928600, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6403030753135681, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414928600, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02042507939040661, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414929525, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414929526, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6512308120727539, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414929526, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019436189904808998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414929899, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 3}}
  0: EVAL: first data load time: 0.005404448136687279
  0: EVAL: step 1 time -> 0.012434371747076511
  0: EVAL: step 2 time -> 0.012100094929337502
  0: EVAL: step 3 time -> 0.011231525801122189
  0: EVAL: step 4 time -> 0.011120879091322422
  0: EVAL: full eval time -> 0.5421913648024201
  0: :::MLLOG {"namespace": "", "time_ms": 1633414930445, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.641671786350442, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414930445, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.019632150479145707, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414930445, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 3}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414930464, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414930488, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 4, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414932297, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414932298, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.654212474822998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414932298, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018359357491135597, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414933749, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414933749, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6610825657844543, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414933750, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018184425309300423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414934848, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414934848, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6687500476837158, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414934848, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017357664182782173, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414935784, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414935785, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6630957126617432, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414935785, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01798981986939907, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414936705, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414936706, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6592018604278564, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414936706, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01825096271932125, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414937635, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414937636, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6561960577964783, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414937636, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019236715510487556, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414938565, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414938565, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6664007902145386, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414938565, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017071465030312538, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414939499, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414939499, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6696071028709412, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414939499, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01685390993952751, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414940426, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414940427, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6772459745407104, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414940427, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016338352113962173, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414941361, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414941362, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6709117889404297, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414941362, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017039315775036812, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414942293, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414942293, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6662876605987549, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414942293, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017150692641735077, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414943228, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414943228, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6826564073562622, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414943228, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017500964924693108, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414943421, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 4}}
  0: EVAL: first data load time: 0.003974763676524162
  0: EVAL: step 1 time -> 0.012861998751759529
  0: EVAL: step 2 time -> 0.011524738743901253
  0: EVAL: step 3 time -> 0.011294141411781311
  0: EVAL: step 4 time -> 0.011024007573723793
  0: EVAL: full eval time -> 0.7491155741736293
  0: :::MLLOG {"namespace": "", "time_ms": 1633414944173, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6418593291290078, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414944173, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.02155436530782013, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414944173, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 4}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414944192, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414944216, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 5, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414946557, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414946557, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6747296452522278, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414946557, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01590484194457531, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414947708, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414947709, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6651633977890015, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414947709, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016944987699389458, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414948757, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414948757, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6825629472732544, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414948757, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015946991741657257, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414949705, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414949705, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6928014755249023, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414949705, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01646512746810913, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414950717, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414950717, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6810834407806396, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414950717, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015113674104213715, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414951639, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414951639, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7007074356079102, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414951640, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014996996149420738, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414952558, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414952559, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7022153735160828, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414952559, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015088499523699284, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414953495, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414953496, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6882606744766235, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414953496, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016429048031568527, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414954434, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414954434, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6993567943572998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414954434, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014135005883872509, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414955362, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414955363, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.694900631904602, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414955363, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015686653554439545, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414956300, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414956300, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7013133764266968, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414956300, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014917110092937946, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414957226, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414957226, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7205196619033813, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414957227, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013915032148361206, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414957229, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 5}}
  0: EVAL: first data load time: 0.0012879949063062668
  0: EVAL: step 1 time -> 0.017848990857601166
  0: EVAL: step 2 time -> 0.011504000052809715
  0: EVAL: step 3 time -> 0.011244597844779491
  0: EVAL: step 4 time -> 0.011099993251264095
  0: EVAL: full eval time -> 0.9848217852413654
  0: :::MLLOG {"namespace": "", "time_ms": 1633414958217, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.692118474464804, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414958217, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.015791047797509464, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414958217, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 5}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414958236, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414958259, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 6, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414960360, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414960360, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7187221050262451, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414960360, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013761719688773155, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414961460, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414961460, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7174155116081238, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414961460, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01370791345834732, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414962393, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414962393, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7175467610359192, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414962393, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013889109715819359, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414963325, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414963325, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7215456366539001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414963325, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013914568349719048, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414964251, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414964251, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7270504236221313, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414964251, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013711230829358101, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414965187, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414965187, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7052001953125, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414965187, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012936717830598354, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414967245, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414967245, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7153089046478271, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414967246, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013841040432453156, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414969180, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414969180, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.72374427318573, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414969180, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012794430367648602, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414970338, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414970338, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7319434285163879, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414970339, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012416939251124859, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414971276, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414971276, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6908806562423706, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414971276, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01354034710675478, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414972212, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414972213, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7131034135818481, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414972213, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014695935882627964, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414972954, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 6}}
  0: EVAL: first data load time: 0.002707121893763542
  0: EVAL: step 1 time -> 0.01272827573120594
  0: EVAL: step 2 time -> 0.011667666956782341
  0: EVAL: step 3 time -> 0.011269263923168182
  0: EVAL: step 4 time -> 0.011065634898841381
  0: EVAL: full eval time -> 0.7344477558508515
  0: :::MLLOG {"namespace": "", "time_ms": 1633414973691, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6968284976373862, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414973692, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.014680356333856297, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414973692, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 6}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414973711, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414973734, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 7, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414974364, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414974364, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7334505319595337, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414974365, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012433295138180256, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414976453, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414976453, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7430870532989502, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414976454, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012969095259904861, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414977468, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414977469, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7385902404785156, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414977469, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012458191253244877, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414978404, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414978404, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7564526796340942, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414978404, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012131714262068272, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414979334, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414979335, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7607709765434265, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414979335, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01165881846100092, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414980267, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414980268, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7461603283882141, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414980268, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012316382490098476, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414981203, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414981203, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7648249268531799, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414981204, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01142194215208292, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414982138, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414982138, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7253279089927673, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414982138, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012250371277332306, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414983079, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414983080, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7487050890922546, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414983080, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012008649297058582, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414984015, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414984016, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7566795945167542, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414984016, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013137049973011017, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414984944, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414984944, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7334291338920593, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414984945, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013074626214802265, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414985868, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414985868, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7597506642341614, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414985868, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013364489190280437, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414986424, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 7}}
  0: EVAL: first data load time: 0.007299976423382759
  0: EVAL: step 1 time -> 0.012749748304486275
  0: EVAL: step 2 time -> 0.01157706044614315
  0: EVAL: step 3 time -> 0.011287095956504345
  0: EVAL: step 4 time -> 0.011063635349273682
  0: EVAL: full eval time -> 0.3261607941240072
  0: :::MLLOG {"namespace": "", "time_ms": 1633414986753, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6965892211414765, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414986753, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.020774898687599987, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414986753, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 7}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414986773, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414986775, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 8, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414987154, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414987155, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7742738127708435, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414987155, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011188545264303684, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414988093, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414988094, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7502915859222412, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414988094, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011411122046411037, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414989032, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414989033, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7735697627067566, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414989033, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011032524518668652, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414989963, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414989963, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7637726664543152, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414989963, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012275011278688908, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414990896, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414990897, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7627047300338745, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414990897, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011696020141243935, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414991831, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414991832, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7389526963233948, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414991832, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01103542186319828, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414992763, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414992763, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7622613906860352, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414992763, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01115422509610653, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414993697, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414993698, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7653191685676575, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414993698, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010747766122221947, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414994629, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414994629, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7779650092124939, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414994630, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010289204306900501, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414995563, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414995563, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7662915587425232, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414995563, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011312693357467651, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414996496, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414996496, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7717628479003906, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414996496, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010600030422210693, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414997423, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414997423, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7589369416236877, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414997423, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010938102379441261, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414997800, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 8}}
  0: EVAL: first data load time: 0.005225383676588535
  0: EVAL: step 1 time -> 0.012556711211800575
  0: EVAL: step 2 time -> 0.011578095145523548
  0: EVAL: step 3 time -> 0.011361815966665745
  0: EVAL: step 4 time -> 0.01106349565088749
  0: EVAL: full eval time -> 0.6122989384457469
  0: :::MLLOG {"namespace": "", "time_ms": 1633414998415, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.712502912034899, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414998415, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.015791433344165415, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414998415, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 8}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414998435, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414998458, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 9, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415000314, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415000314, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7773756384849548, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415000315, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00959763489663601, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415001972, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415001973, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7752643823623657, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415001973, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01033838465809822, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415003083, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415003083, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7972022891044617, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415003083, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009808659553527832, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415004013, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415004013, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7727001905441284, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415004013, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010300004854798317, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415004946, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415004946, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7823188304901123, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415004947, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010027776472270489, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415005896, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415005897, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.798644483089447, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415005897, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01013894286006689, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415006848, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415006849, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7986454367637634, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415006849, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009547415189445019, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415007790, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415007790, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.787093997001648, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415007790, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01027347706258297, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415008716, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415008717, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7943634986877441, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415008717, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010000892914831638, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415009644, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415009645, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7813795208930969, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415009645, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009951055981218815, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415010574, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415010575, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7896600365638733, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415010575, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009831252507865429, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415011510, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415011511, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.771714985370636, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415011511, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010651466436684132, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415011698, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 9}}
  0: EVAL: first data load time: 0.001324857585132122
  0: EVAL: step 1 time -> 0.012682069092988968
  0: EVAL: step 2 time -> 0.011593949981033802
  0: EVAL: step 3 time -> 0.011376847513020039
  0: EVAL: step 4 time -> 0.011160533875226974
  0: EVAL: full eval time -> 0.5244323769584298
  0: :::MLLOG {"namespace": "", "time_ms": 1633415012226, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7506775635184391, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415012226, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.018114379125812277, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415012226, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 9}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415012245, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415012268, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 10, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415014715, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415014715, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8036704063415527, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415014715, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009240606799721718, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415015839, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415015840, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8004361391067505, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415015840, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009486337192356586, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415016889, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415016889, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7915300726890564, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415016889, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009225815534591675, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415017812, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415017813, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7777613401412964, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415017813, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009356407448649406, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415018747, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415018748, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7994943261146545, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415018748, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009095358662307262, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415019675, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415019675, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8045305013656616, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415019675, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009345673955976963, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415020604, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415020604, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8084590435028076, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415020605, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009623879566788673, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415021543, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415021543, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7906484007835388, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415021543, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010368787683546543, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415022478, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415022478, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7925790548324585, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415022478, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009663703851401806, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415023408, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415023408, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7819502949714661, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415023408, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009985423646867275, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415024337, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415024338, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8009955883026123, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415024338, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009933819994330406, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025272, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025273, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7967497110366821, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025273, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009646727703511715, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025276, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 10}}
  0: EVAL: first data load time: 0.0020361393690109253
  0: EVAL: step 1 time -> 0.012966997921466827
  0: EVAL: step 2 time -> 0.011566372588276863
  0: EVAL: step 3 time -> 0.011250218376517296
  0: EVAL: step 4 time -> 0.011377629823982716
  0: EVAL: full eval time -> 0.5372748924419284
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025816, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.77395709206772, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025816, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01146511264614292, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025817, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025836, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415025859, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 11, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415028623, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415028624, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8155689239501953, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415028624, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008956646546721458, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415029565, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415029565, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7914285659790039, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415029565, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008664560504257679, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415030494, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415030494, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8089375495910645, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415030494, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009320962242782116, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415031429, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415031429, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7961685061454773, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415031429, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00793365202844143, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415032367, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415032368, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.787270188331604, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415032368, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009104271419346333, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415033294, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415033294, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7980685830116272, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415033294, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008817121386528015, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415034218, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415034218, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8236680030822754, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415034219, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009100150316953659, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415035155, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415035155, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8139597177505493, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415035156, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009368215687572956, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415036084, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415036084, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8101513981819153, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415036084, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009640395641326904, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415037018, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415037019, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8116055727005005, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415037019, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008686840534210205, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415037940, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415037941, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8032048344612122, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415037941, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009187852032482624, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415038685, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 11}}
  0: EVAL: first data load time: 0.00275272224098444
  0: EVAL: step 1 time -> 0.012560030445456505
  0: EVAL: step 2 time -> 0.011652959510684013
  0: EVAL: step 3 time -> 0.011371699161827564
  0: EVAL: step 4 time -> 0.011050406843423843
  0: EVAL: full eval time -> 0.747779238037765
  0: :::MLLOG {"namespace": "", "time_ms": 1633415039437, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7081564422458437, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415039437, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.0214976144507026, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415039437, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 11}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415039456, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415039481, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 12, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415040093, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415040093, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8114917278289795, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415040093, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00807007122784853, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415042020, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415042020, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8349514007568359, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415042020, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006932142656296492, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415042947, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415042947, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8472318649291992, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415042947, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0068093459121882915, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415043877, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415043877, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8470482230186462, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415043877, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006533403880894184, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415044803, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415044803, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8513591885566711, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415044803, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0061155054718256, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415045732, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415045732, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8458536863327026, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415045732, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0059845768846571445, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415046670, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415046670, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8495997786521912, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415046670, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006208900362253189, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415047595, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415047595, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8525919318199158, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415047595, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006127350963652134, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415048520, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415048520, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8485475182533264, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415048520, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006366633344441652, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415049454, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415049454, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8541939854621887, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415049454, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005661388859152794, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415050380, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415050381, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8572481870651245, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415050381, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005721243564039469, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415051306, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415051306, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.849270224571228, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415051307, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0061086989007890224, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415051874, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 12}}
  0: EVAL: first data load time: 0.0030013564974069595
  0: EVAL: step 1 time -> 0.012994864955544472
  0: EVAL: step 2 time -> 0.011673366650938988
  0: EVAL: step 3 time -> 0.011294887401163578
  0: EVAL: step 4 time -> 0.0110875703394413
  0: EVAL: full eval time -> 0.7393725328147411
  0: :::MLLOG {"namespace": "", "time_ms": 1633415052616, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8219585083990302, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415052616, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.009790248646870156, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415052616, "event_type": "POINT_IN_TIME", "key": "target_accuracy_reached", "value": 0.82, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 374, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415052616, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 12}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415052636, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415052660, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 507, "status": "success"}}
288: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
288: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
372: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
372: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
251: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
207: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
392: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
251: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 67: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
207: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
392: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 67: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
343: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
343: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
168: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
168: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
208: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
208: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
311: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
311: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
229: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
229: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
348: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
348: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
438: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
381: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
438: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
381: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
264: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
147: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
264: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
147: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
421: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
420: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
421: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
420: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
119: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
119: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
116: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
116: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
414: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
414: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
363: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
363: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
280: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
280: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
448: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
448: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
344: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
344: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
128: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
128: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
258: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
258: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
226: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
226: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
335: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
335: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
350: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
350: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 25: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 25: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 27: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 27: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
152: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
152: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
442: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
441: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
442: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
441: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  7: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  7: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 40: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 40: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
405: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
405: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
387: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
387: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
377: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
271: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
377: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
271: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
161: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
161: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
272: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
272: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
221: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
221: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
213: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
213: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
331: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
331: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
338: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
338: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
365: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
365: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 58: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 58: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
115: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
115: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
121: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
121: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
230: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
230: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  0: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  0: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
308: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
308: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 72: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 72: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
436: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
436: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
319: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
319: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
397: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
397: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
360: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
360: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
493: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
493: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
494: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
494: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
176: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
176: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 90: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 90: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
340: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
340: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
246: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
246: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
244: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
244: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
301: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
301: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
102: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
102: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 54: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 54: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
412: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
412: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
374: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
374: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 68: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 68: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
148: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
148: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  4: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  4: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
267: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
267: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
404: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
404: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
248: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
248: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
164: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
167: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
164: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
167: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 83: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 83: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
384: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
384: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
408: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
408: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
160: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
160: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
411: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
411: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
376: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
376: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
252: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
252: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
109: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
109: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
210: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
210: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 56: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 56: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
497: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
497: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
499: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
499: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 16: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 16: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
346: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
346: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
380: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
380: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
135: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
135: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
466: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
466: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
268: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
268: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
120: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
120: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
273: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
273: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
396: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
396: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 10: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
153: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 10: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
153: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
470: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
470: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
100: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
100: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
393: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
393: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
364: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
364: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
292: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
292: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
293: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
293: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
509: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
509: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
316: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
316: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
256: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
256: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 44: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 44: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
112: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
112: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
170: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
170: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
212: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
212: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
337: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
337: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
220: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
220: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
511: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
511: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
475: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
472: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
475: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
472: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
312: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
312: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
476: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
476: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
332: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
332: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
289: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
289: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
130: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
130: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
507: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
507: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
300: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
300: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
283: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
283: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 32: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 32: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
146: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
146: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 88: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 88: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
202: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
202: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
307: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
307: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  2: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  2: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
484: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
484: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
305: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
305: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 81: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 81: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
110: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
110: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 14: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 14: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
447: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
447: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
446: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
446: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
278: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
278: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
330: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
330: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 20: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 20: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
464: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
464: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
243: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
243: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 94: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 94: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
468: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
468: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
191: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
191: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
356: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
356: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
132: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
132: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
149: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
149: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
138: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
138: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 69: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 69: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
349: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
349: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
320: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
320: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
490: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
490: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 64: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 64: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
355: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
355: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 41: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 41: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
219: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
219: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
125: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
125: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  9: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  9: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
422: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
422: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
362: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
362: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
443: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
443: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
431: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
431: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
255: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
428: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
255: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
428: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
483: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
483: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
480: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
480: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
439: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
439: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 52: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 52: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
309: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
205: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
205: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
309: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
158: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
158: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
236: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
236: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
237: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
237: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
488: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
488: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
451: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
451: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
373: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
373: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 50: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 48: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 24: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 50: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 24: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 48: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
336: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
336: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
250: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
250: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
503: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
503: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 61: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 61: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
181: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
181: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  6: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  6: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
180: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
180: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
342: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
342: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
260: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
260: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
263: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
263: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
200: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
200: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
266: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
266: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
477: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
477: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
286: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
286: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
228: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
228: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
162: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
162: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
433: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
433: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
124: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
124: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
276: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
276: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
294: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
294: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 59: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 59: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 31: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 31: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 30: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 30: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 12: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 12: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
198: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
379: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
198: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
379: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
199: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
406: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
199: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
406: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
424: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
424: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
427: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
427: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
209: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
209: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 17: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 17: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 74: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 74: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
245: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
418: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
245: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
410: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
418: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
410: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
417: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
417: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
166: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
166: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
314: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
314: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 45: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 45: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
187: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
187: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
474: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
474: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
328: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
328: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 80: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 80: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
239: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
239: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
352: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
352: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 77: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 77: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
386: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
386: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
334: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
334: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
415: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
415: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
188: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
188: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
117: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
117: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
216: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 92: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 92: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
216: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
257: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
257: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
136: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
136: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
382: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
347: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
391: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
391: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
382: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
347: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 96: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 96: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
269: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
269: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
366: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
366: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
394: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
394: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
306: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
306: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 21: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 21: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 86: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 86: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
235: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
235: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
326: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
326: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
222: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
108: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
155: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
222: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
155: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
108: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
122: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
122: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
281: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
281: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
129: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
129: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
453: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
453: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
274: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
274: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
156: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
456: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
156: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
456: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
169: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
169: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
284: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
317: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
284: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
317: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
105: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
105: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 51: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 51: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
444: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
444: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
500: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
500: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
174: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
174: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
144: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
144: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
299: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
299: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
114: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
114: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
454: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
454: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
486: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
486: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  3: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  3: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
399: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
399: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
460: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
460: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
400: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
400: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
303: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
303: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
179: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
179: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
241: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
241: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
291: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
291: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
327: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
327: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  8: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  8: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
262: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
262: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
432: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
432: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
103: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
103: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
215: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
215: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 91: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 91: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
322: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
322: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 71: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 71: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 97: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 97: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
358: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
358: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
465: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
465: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
471: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
471: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
371: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
371: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 60: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 60: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
510: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
510: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 66: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 66: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
134: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
134: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
388: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
388: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
206: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
206: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
254: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
254: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 42: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 42: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
194: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
194: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
296: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
296: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
425: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
425: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
402: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
402: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
489: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
479: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
489: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
479: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
416: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
416: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
449: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
449: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
495: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
495: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
315: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
315: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 36: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 36: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
186: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
186: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
106: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
106: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 34: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 34: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
452: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
452: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
150: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
150: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
227: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
227: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
127: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
127: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
463: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
463: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 47: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 47: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 28: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 28: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
279: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
279: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
203: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
203: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 79: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 79: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 84: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 84: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
143: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
143: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
430: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
430: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 18: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 18: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 95: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 95: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 15: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 15: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 75: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
504: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 75: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
504: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
457: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
457: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 55: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 55: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
324: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
324: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
354: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
354: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
232: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
232: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
190: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
190: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
368: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
368: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
139: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
139: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
178: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
178: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
217: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
217: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
172: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
172: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
487: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
487: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
502: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
502: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 23: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 23: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
240: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
240: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 98: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 98: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
157: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
157: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
359: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
359: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
434: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
434: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
192: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
192: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
390: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
390: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 63: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
287: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
287: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 63: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
184: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
184: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
323: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
323: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
298: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
298: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
401: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
401: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
461: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
461: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
142: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
142: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 35: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 35: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
104: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
104: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
498: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
498: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
505: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
505: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 76: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 76: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 39: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 39: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
482: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
482: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 87: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 87: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
458: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
458: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
224: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
224: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
173: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
173: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
369: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
369: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
234: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
234: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
195: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
195: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
140: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
140: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 38: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 38: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 49: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 49: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
197: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
197: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
395: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
395: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
249: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
249: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
290: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
290: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
204: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
204: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 43: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 43: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
211: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
211: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
171: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
171: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
238: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
238: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
345: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
345: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
333: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
333: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
282: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
282: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
339: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
339: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
329: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
329: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
383: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
383: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
413: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
413: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
265: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
265: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
154: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
154: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
131: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
131: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  5: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  5: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
440: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 73: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
437: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
437: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
440: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 73: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
123: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
123: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 65: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 65: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
275: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
275: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
407: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
407: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
231: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
231: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
361: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
361: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
247: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
247: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
261: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
261: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 53: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 53: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
367: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
367: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
508: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
508: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
214: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
214: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
378: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
378: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
177: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
177: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
259: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
259: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 26: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 26: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
  1: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
  1: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
351: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
351: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
165: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
165: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
423: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
423: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
419: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
419: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
473: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
253: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
473: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
253: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
445: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
445: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
450: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
450: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
485: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
485: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
398: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
398: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
506: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
506: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
145: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
145: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
310: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
302: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
310: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
302: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
313: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
313: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
189: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
189: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
304: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
304: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
467: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
467: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
295: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
295: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
492: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
492: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
478: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
478: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
469: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
469: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
118: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
118: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
357: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
357: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 89: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 89: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 93: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 93: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
385: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
385: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
111: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
111: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
429: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
429: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 46: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 46: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
270: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
270: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
163: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
163: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
242: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
242: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
277: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
277: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
185: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
185: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
113: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
113: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
341: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
341: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 82: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 82: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 29: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 29: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
 57: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
 57: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
409: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
409: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
318: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
318: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
321: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
321: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
101: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
101: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
426: ENDING TIMING RUN AT 2021-10-05 08:24:18 AM
426: RESULT,DEEPCAM_HPC,,470,qv2382,2021-10-05 08:16:28 AM
151: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
151: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
223: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
223: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
285: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
285: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
175: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
175: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
496: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
496: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
159: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
159: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
133: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
133: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 11: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 11: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 62: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 62: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 70: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 70: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
459: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
459: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 19: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 19: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
375: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
375: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
462: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
462: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
491: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
491: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
481: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
481: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 13: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 13: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 78: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 78: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
370: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
370: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
325: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
325: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 22: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 22: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
126: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
126: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 37: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 37: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 33: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 33: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
201: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
201: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
218: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
218: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
353: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
353: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 99: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 99: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
501: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
501: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
 85: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
 85: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
403: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
403: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
137: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
137: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
455: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
455: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
435: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
435: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
297: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
297: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
225: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
225: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
389: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
389: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
193: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
193: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
233: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
233: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
141: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
141: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
196: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
196: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
107: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
107: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
182: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
182: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
183: ENDING TIMING RUN AT 2021-10-05 08:24:19 AM
183: RESULT,DEEPCAM_HPC,,471,qv2382,2021-10-05 08:16:28 AM
